{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"HOME Welcome to the docki Github page Go back to docki.io page What do U mean about knowledge transfert ? Let's having fun, and #RTFM ! U should select find U'r plaisir into the nav bar on the left Don't forget, U should add the search section as your search engine","title":"HOME"},{"location":"#home","text":"Welcome to the docki Github page Go back to docki.io page What do U mean about knowledge transfert ? Let's having fun, and #RTFM ! U should select find U'r plaisir into the nav bar on the left Don't forget, U should add the search section as your search engine","title":"HOME"},{"location":"cloud/aws/","text":"Amazon Web Services Here are somes aws tips & tricks L\u00e9xique AMI : Amazon Machine Images (template) in progress.. DevOps Implementing Development Processes What is devOPS ? \"DevOps is the unions of people, process and products to enable continuous of value to end users.\" - Donovan Brown Products suite Azure DevOps is a suite of products that allows any organization to do better DevOps : Azure Board Deliver Value to your users daster using proven agile tools to plan, and discuss work across your teams. Azure Pipelines Build, test, and deploy with CI/CD that works with any language, platform, and cloud. Connect to GitHub or any other Git provider and deploy continously Azure Repos Get unlimited, cloud-hosted private Git repos and collaborate to build better code with pull requests and advanced file management. Azure Test Plans Test and ship with confidence using manual and exploratory testing tools. Azure Artifacts Create, host and share packages with your team, and add artifacts to your CI/CD pipelines with a single click. Extensions Marketplace Access extensions from Slack to SonarCloud to 1,000 other apps and services \u2013 built by the community.","title":"Amazon Web Services"},{"location":"cloud/aws/#amazon-web-services","text":"Here are somes aws tips & tricks","title":"Amazon Web Services"},{"location":"cloud/aws/#lexique","text":"AMI : Amazon Machine Images (template) in progress..","title":"L\u00e9xique"},{"location":"cloud/aws/#devops-implementing-development-processes","text":"","title":"DevOps Implementing Development Processes"},{"location":"cloud/aws/#what-is-devops","text":"\"DevOps is the unions of people, process and products to enable continuous of value to end users.\" - Donovan Brown","title":"What is devOPS ?"},{"location":"cloud/aws/#products-suite","text":"Azure DevOps is a suite of products that allows any organization to do better DevOps : Azure Board Deliver Value to your users daster using proven agile tools to plan, and discuss work across your teams. Azure Pipelines Build, test, and deploy with CI/CD that works with any language, platform, and cloud. Connect to GitHub or any other Git provider and deploy continously Azure Repos Get unlimited, cloud-hosted private Git repos and collaborate to build better code with pull requests and advanced file management. Azure Test Plans Test and ship with confidence using manual and exploratory testing tools. Azure Artifacts Create, host and share packages with your team, and add artifacts to your CI/CD pipelines with a single click. Extensions Marketplace Access extensions from Slack to SonarCloud to 1,000 other apps and services \u2013 built by the community.","title":"Products suite"},{"location":"cloud/awx/","text":"Installing AWX This document provides a guide for installing AWX. Main page : https://github.com/ansible/awx/blob/17.0.1/INSTALL.md Getting started Clone the repo If you have not already done so, you will need to clone, or create a local copy, of the AWX repo . We generally recommend that you view the releases page: https://github.com/ansible/awx/releases ...and clone the latest stable release, e.g., git clone -b x.y.z https://github.com/ansible/awx.git Please note that deploying from HEAD (or the latest commit) is not stable, and that if you want to do this, you should proceed at your own risk (also, see the section #official-vs-building-images for building your own image). For more on how to clone the repo, view git clone help . Once you have a local copy, run the commands in the following sections from the root of the project tree. AWX branding You can optionally install the AWX branding assets from the awx-logos repo . Prior to installing, please review and agree to the trademark guidelines . To install the assets, clone the awx-logos repo so that it is next to your awx clone. As you progress through the installation steps, you'll be setting variables in the inventory file. To include the assets in the build, set awx_official=true . Prerequisites Before you can run a deployment, you'll need the following installed in your local environment: Ansible Requires Version 2.8+ Docker A recent version docker Python module This is incompatible with docker-py . If you have previously installed docker-py , please uninstall it. We use this module instead of docker-py because it is what the docker-compose Python module requires. community.general.docker_image collection This is only required if you are using Ansible >= 2.10 GNU Make Git Requires Version 1.8.4+ Python 3.6+ Node 14.x LTS version This is only required if you're building your own container images with use_container_for_build=false NPM 6.x LTS This is only required if you're building your own container images with use_container_for_build=false System Requirements The system that runs the AWX service will need to satisfy the following requirements At least 4GB of memory At least 2 cpu cores At least 20GB of space Running Docker, Openshift, or Kubernetes If you choose to use an external PostgreSQL database, please note that the minimum version is 10+. Choose a deployment platform We currently support running AWX as a containerized application using Docker images deployed to either an OpenShift cluster, a Kubernetes cluster, or docker-compose. The remainder of this document will walk you through the process of building the images, and deploying them to either platform. \u00d2You'll begin by setting variables in the inventory file according to the platform you wish to use, and then you'll start the image build and deployment process by running the playbook. In the sections below, you'll find deployment details and instructions for each platform: - OpenShift - Kubernetes - Docker Compose . Official vs Building Images When installing AWX you have the option of building your own image or using the image provided on DockerHub (see awx ) This is controlled by the following variables in the inventory file dockerhub_base=ansible dockerhub_version=latest If these variables are present then all deployments will use these hosted images. If the variables are not present then the images will be built during the install. dockerhub_base The base location on DockerHub where the images are hosted (by default this pulls a container image named ansible/awx:tag ) dockerhub_version Multiple versions are provided. latest always pulls the most recent. You may also select version numbers at different granularities: 1, 1.0, 1.0.1, 1.0.0.123 use_container_for_build Use a local distribution build container image for building the AWX package. This is helpful if you don't want to bother installing the build-time dependencies as it is taken care of already. Upgrading from previous versions Upgrading AWX involves rerunning the install playbook. Download a newer release from https://github.com/ansible/awx/releases and re-populate the inventory file with your customized variables. For convenience, you can create a file called vars.yml : admin_password: 'adminpass' pg_password: 'pgpass' secret_key: 'mysupersecret' And pass it to the installer: $ ansible-playbook -i inventory install.yml -e @vars.yml OpenShift Prerequisites To complete a deployment to OpenShift, you will need access to an OpenShift cluster. For demo and testing purposes, you can use Minishift to create a single node cluster running inside a virtual machine. When using OpenShift for deploying AWX make sure you have correct privileges to add the security context 'privileged', otherwise the installation will fail. The privileged context is needed because of the use of the bubblewrap tool to add an additional layer of security when using containers. You will also need to have the oc command in your PATH. The install.yml playbook will call out to oc when logging into, and creating objects on the cluster. The default resource requests per-deployment requires: Memory: 6GB CPU: 3 cores This can be tuned by overriding the variables found in /installer/roles/kubernetes/defaults/main.yml . Special care should be taken when doing this as undersized instances will experience crashes and resource exhaustion. For more detail on how resource requests are formed see: https://docs.openshift.com/container-platform/latest/dev_guide/compute_resources.html#dev-compute-resources Pre-install steps Before starting the install, review the inventory file, and uncomment and provide values for the following variables found in the [all:vars] section: openshift_host IP address or hostname of the OpenShift cluster. If you're using Minishift, this will be the value returned by minishift ip . openshift_skip_tls_verify Boolean. Set to True if using self-signed certs. openshift_project Name of the OpenShift project that will be created, and used as the namespace for the AWX app. Defaults to awx . openshift_user Username of the OpenShift user that will create the project, and deploy the application. Defaults to developer . openshift_pg_emptydir Boolean. Set to True to use an emptyDir volume when deploying the PostgreSQL pod. Note: This should only be used for demo and testing purposes. docker_registry IP address and port, or URL, for accessing a registry that the OpenShift cluster can access. Defaults to 172.30.1.1:5000 , the internal registry delivered with Minishift. This is not needed if you are using official hosted images. docker_registry_repository Namespace to use when pushing and pulling images to and from the registry. Generally this will match the project name. It defaults to awx . This is not needed if you are using official hosted images. docker_registry_username Username of the user that will push images to the registry. Will generally match the openshift_user value. Defaults to developer . This is not needed if you are using official hosted images. Deploying to Minishift Install Minishift by following the installation guide . The recommended minimum resources for your Minishift VM: $ minishift start --cpus = 4 --memory = 8GB The Minishift VM contains a Docker daemon, which you can use to build the AWX images. This is generally the approach you should take, and we recommend doing so. To use this instance, run the following command to setup your environment: # Set DOCKER environment variable to point to the Minishift VM $ eval $( minishift docker-env ) Note If you choose to not use the Docker instance running inside the VM, and build the images externally, you will have to enable the OpenShift cluster to access the images. This involves pushing the images to an external Docker registry, and granting the cluster access to it, or exposing the internal registry, and pushing the images into it. PostgreSQL By default, AWX will deploy a PostgreSQL pod inside of your cluster. You will need to create a Persistent Volume Claim which is named postgresql by default, and can be overridden by setting the openshift_pg_pvc_name variable. For testing and demo purposes, you may set openshift_pg_emptydir=yes . If you wish to use an external database, in the inventory file, set the value of pg_hostname , and update pg_username , pg_password , pg_admin_password , pg_database , and pg_port with the connection information. When setting pg_hostname the installer will assume you have configured the database in that location and will not launch the postgresql pod. Run the installer To start the install, you will pass two extra variables on the command line. The first is openshift_password , which is the password for the openshift_user , and the second is docker_registry_password , which is the password associated with docker_registry_username . If you're using the OpenShift internal registry, then you'll pass an access token for the docker_registry_password value, rather than a password. The oc whoami -t command will generate the required token, as long as you're logged into the cluster via oc cluster login . Run the following command (docker_registry_password is optional if using official images): # Start the install $ ansible-playbook -i inventory install.yml -e openshift_password = developer -e docker_registry_password = $( oc whoami -t ) Post-install After the playbook run completes, check the status of the deployment by running oc get pods : # View the running pods $ oc get pods NAME READY STATUS RESTARTS AGE awx-3886581826-5mv0l 4 /4 Running 0 8s postgresql-1-l85fh 1 /1 Running 0 20m In the above example, the name of the AWX pod is awx-3886581826-5mv0l . Before accessing the AWX web interface, setup tasks and database migrations need to complete. These tasks are running in the awx_task container inside the AWX pod. To monitor their status, tail the container's STDOUT by running the following command, replacing the AWX pod name with the pod name from your environment: # Follow the awx_task log output $ oc logs -f awx-3886581826-5mv0l -c awx-celery You will see the following indicating that database migrations are running: Using /etc/ansible/ansible.cfg as config file 127 .0.0.1 | SUCCESS = > { \"changed\" : false, \"db\" : \"awx\" } Operations to perform: Synchronize unmigrated apps: solo, api, staticfiles, messages, channels, django_extensions, ui, rest_framework, polymorphic Apply all migrations: sso, taggit, sessions, sites, kombu_transport_django, social_auth, contenttypes, auth, conf, main Synchronizing apps without migrations: Creating tables... Running deferred SQL... Installing custom SQL... Running migrations: Rendering model states... DONE Applying contenttypes.0001_initial... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0001_initial... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying taggit.0001_initial... OK Applying taggit.0002_auto_20150616_2121... OK ... When you see output similar to the following, you'll know that database migrations have completed, and you can access the web interface: Python 2 .7.5 ( default, Nov 6 2016 , 00 :28:07 ) [ GCC 4 .8.5 20150623 ( Red Hat 4 .8.5-11 )] on linux2 Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information. ( InteractiveConsole ) >>> <User: admin> >>> Default organization added. Demo Credential, Inventory, and Job Template added. Successfully registered instance awx-3886581826-5mv0l ( changed: True ) Creating instance group tower Added instance awx-3886581826-5mv0l to tower Once database migrations complete, the web interface will be accessible. Accessing AWX The AWX web interface is running in the AWX pod, behind the awx-web-svc service. To view the service, and its port value, run the following command: # View available services $ oc get services NAME CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE awx-web-svc 172 .30.111.74 <nodes> 8052 :30083/TCP 37m postgresql 172 .30.102.9 <none> 5432 /TCP 38m The deployment process creates a route, awx-web-svc , to expose the service. How the ingres is actually created will vary depending on your environment, and how the cluster is configured. You can view the route, and the external IP address and hostname assigned to it, by running the following command: # View available routes $ oc get routes NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD awx-web-svc awx-web-svc-awx.192.168.64.2.nip.io awx-web-svc http edge/Allow None The above example is taken from a Minishift instance. From a web browser, use https to access the HOST/PORT value from your environment. Using the above example, the URL to access the server would be https://awx-web-svc-awx.192.168.64.2.nip.io . Once you access the AWX server, you will be prompted with a login dialog. The default administrator username is admin , and the password is password . Kubernetes Prerequisites A Kubernetes deployment will require you to have access to a Kubernetes cluster as well as the following tools: kubectl helm The installation program will reference kubectl directly. helm is only necessary if you are letting the installer configure PostgreSQL for you. The default resource requests per-pod requires: Memory: 6GB CPU: 3 cores This can be tuned by overriding the variables found in /installer/roles/kubernetes/defaults/main.yml . Special care should be taken when doing this as undersized instances will experience crashes and resource exhaustion. For more detail on how resource requests are formed see: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/ Pre-install steps Before starting the install process, review the inventory file, and uncomment and provide values for the following variables found in the [all:vars] section uncommenting when necessary. Make sure the openshift and standalone docker sections are commented out: kubernetes_context Prior to running the installer, make sure you've configured the context for the cluster you'll be installing to. This is how the installer knows which cluster to connect to and what authentication to use kubernetes_namespace Name of the Kubernetes namespace where the AWX resources will be installed. This will be created if it doesn't exist docker_registry_ These settings should be used if building your own base images. You'll need access to an external registry and are responsible for making sure your kube cluster can talk to it and use it. If these are undefined and the dockerhub_ configuration settings are uncommented then the images will be pulled from dockerhub instead Configuring Helm If you want the AWX installer to manage creating the database pod (rather than installing and configuring postgres on your own). Then you will need to have a working helm installation, you can find details here: https://helm.sh/docs/intro/quickstart/ . You do not need to create a Persistent Volume Claim as Helm does it for you. However, an existing one may be used by setting the pg_persistence_existingclaim variable. Newer Kubernetes clusters with RBAC enabled will need to make sure a service account is created, make sure to follow the instructions here https://helm.sh/docs/topics/rbac/ Run the installer After making changes to the inventory file use ansible-playbook to begin the install $ ansible-playbook -i inventory install.yml Post-install After the playbook run completes, check the status of the deployment by running kubectl get pods --namespace awx (replace awx with the namespace you used): # View the running pods, it may take a few minutes for everything to be marked in the Running state $ kubectl get pods --namespace awx NAME READY STATUS RESTARTS AGE awx-2558692395-2r8ss 4 /4 Running 0 29s awx-postgresql-355348841-kltkn 1 /1 Running 0 1m Accessing AWX The AWX web interface is running in the AWX pod behind the awx-web-svc service: # View available services $ kubectl get svc --namespace awx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE awx-postgresql ClusterIP 10 .7.250.208 <none> 5432 /TCP 2m awx-web-svc NodePort 10 .7.241.35 <none> 80 :30177/TCP 1m The deployment process creates an Ingress named awx-web-svc also. Some kubernetes cloud providers will automatically handle routing configuration when an Ingress is created others may require that you more explicitly configure it. You can see what kubernetes knows about things with: kubectl get ing --namespace awx NAME HOSTS ADDRESS PORTS AGE awx-web-svc * 35 .227.x.y 80 3m If your provider is able to allocate an IP Address from the Ingress controller then you can navigate to the address and access the AWX interface. For some providers it can take a few minutes to allocate and make this accessible. For other providers it may require you to manually intervene. SSL Termination Unlike Openshift's Route the Kubernetes Ingress doesn't yet handle SSL termination. As such the default configuration will only expose AWX through HTTP on port 80. You are responsible for configuring SSL support until support is added (either to Kubernetes or AWX itself). Docker-Compose Prerequisites Docker on the host where AWX will be deployed. After installing Docker, the Docker service must be started (depending on your OS, you may have to add the local user that uses Docker to the docker group, refer to the documentation for details) docker-compose Python module. This also installs the docker Python module, which is incompatible with docker-py . If you have previously installed docker-py , please uninstall it. Docker Compose . Pre-install steps Deploying to a remote host By default, the delivered installer/inventory file will deploy AWX to the local host. It is possible, however, to deploy to a remote host. The installer/install.yml playbook can be used to build images on the local host, and ship the built images to, and run deployment tasks on, a remote host. To do this, modify the installer/inventory file, by commenting out localhost , and adding the remote host. For example, suppose you wish to build images locally on your CI/CD host, and deploy them to a remote host named awx-server . To do this, add awx-server to the installer/inventory file, and comment out or remove localhost , as demonstrated by the following: # localhost ansible_connection=local awx-server [all:vars] ... In the above example, image build tasks will be delegated to localhost , which is typically where the clone of the AWX project exists. Built images will be archived, copied to remote host, and imported into the remote Docker image cache. Tasks to start the AWX containers will then execute on the remote host. If you choose to use the official images then the remote host will be the one to pull those images. Note You may also want to set additional variables to control how Ansible connects to the host. For more information about this, view Behavioral Inventory Parameters . As mentioned above, in Prerequisites , the prerequisites are required on the remote host. When deploying to a remote host, the playbook does not execute tasks with the become option. For this reason, make sure the user that connects to the remote host has privileges to run the docker command. This typically means that non-privileged users need to be part of the docker group. Inventory variables Before starting the install process, review the inventory file, and uncomment and provide values for the following variables found in the [all:vars] section: postgres_data_dir If you're using the default PostgreSQL container (see PostgreSQL below), provide a path that can be mounted to the container, and where the database can be persisted. host_port Provide a port number that can be mapped from the Docker daemon host to the web server running inside the AWX container. If undefined no port will be exposed. Defaults to 80 . host_port_ssl Provide a port number that can be mapped from the Docker daemon host to the web server running inside the AWX container for SSL support. If undefined no port will be exposed. Defaults to 443 , only works if you also set ssl_certificate (see below). ssl_certificate Optionally, provide the path to a file that contains a certificate and its private key. This needs to be a .pem-file docker_compose_dir When using docker-compose, the docker-compose.yml file will be created there (default ~/.awx/awxcompose ). custom_venv_dir Adds the custom venv environments from the local host to be passed into the containers at install. ca_trust_dir If you're using a non trusted CA, provide a path where the untrusted Certs are stored on your Host. Docker registry If you wish to tag and push built images to a Docker registry, set the following variables in the inventory file: docker_registry IP address and port, or URL, for accessing a registry. docker_registry_repository Namespace to use when pushing and pulling images to and from the registry. Defaults to awx . docker_registry_username Username of the user that will push images to the registry. Defaults to developer . Note These settings are ignored if using official images Proxy settings http_proxy IP address and port, or URL, for using an http_proxy. https_proxy IP address and port, or URL, for using an https_proxy. no_proxy Exclude IP address or URL from the proxy. PostgreSQL AWX requires access to a PostgreSQL database, and by default, one will be created and deployed in a container, and data will be persisted to a host volume. In this scenario, you must set the value of postgres_data_dir to a path that can be mounted to the container. When the container is stopped, the database files will still exist in the specified path. If you wish to use an external database, in the inventory file, set the value of pg_hostname , and update pg_username , pg_password , pg_admin_password , pg_database , and pg_port with the connection information. Run the installer If you are not pushing images to a Docker registry, start the install by running the following: # Set the working directory to installer $ cd installer # Run the Ansible playbook $ ansible-playbook -i inventory install.yml If you're pushing built images to a repository, then use the -e option to pass the registry password as follows, replacing password with the password of the username assigned to docker_registry_username (note that you will also need to remove dockerhub_base and dockerhub_version from the inventory file): # Set the working directory to installer $ cd installer # Run the Ansible playbook $ ansible-playbook -i inventory -e docker_registry_password = password install.yml Post-install After the playbook run completes, Docker starts a series of containers that provide the services that make up AWX. You can view the running containers using the docker ps command. If you're deploying using Docker Compose, container names will be prefixed by the name of the folder where the docker-compose.yml file is created (by default, awx ). Immediately after the containers start, the awx_task container will perform required setup tasks, including database migrations. These tasks need to complete before the web interface can be accessed. To monitor the progress, you can follow the container's STDOUT by running the following: # Tail the awx_task log $ docker logs -f awx_task You will see output similar to the following: Using /etc/ansible/ansible.cfg as config file 127 .0.0.1 | SUCCESS = > { \"changed\" : false, \"db\" : \"awx\" } Operations to perform: Synchronize unmigrated apps: solo, api, staticfiles, messages, channels, django_extensions, ui, rest_framework, polymorphic Apply all migrations: sso, taggit, sessions, sites, kombu_transport_django, social_auth, contenttypes, auth, conf, main Synchronizing apps without migrations: Creating tables... Running deferred SQL... Installing custom SQL... Running migrations: Rendering model states... DONE Applying contenttypes.0001_initial... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0001_initial... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying taggit.0001_initial... OK Applying taggit.0002_auto_20150616_2121... OK Applying main.0001_initial... OK ... Once migrations complete, you will see the following log output, indicating that migrations have completed: Python 2 .7.5 ( default, Nov 6 2016 , 00 :28:07 ) [ GCC 4 .8.5 20150623 ( Red Hat 4 .8.5-11 )] on linux2 Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information. ( InteractiveConsole ) >>> <User: admin> >>> Default organization added. Demo Credential, Inventory, and Job Template added. Successfully registered instance awx ( changed: True ) Creating instance group tower Added instance awx to tower ( changed: True ) ... Accessing AWX The AWX web server is accessible on the deployment host, using the host_port value set in the inventory file. The default URL is http://localhost . You will prompted with a login dialog. The default administrator username is admin , and the password is password . Installing the AWX CLI awx is the official command-line client for AWX. It: Uses naming and structure consistent with the AWX HTTP API Provides consistent output formats with optional machine-parsable formats To the extent possible, auto-detects API versions, available endpoints, and feature support across multiple versions of AWX. Potential uses include: Configuring and launching jobs/playbooks Checking on the status and output of job runs Managing objects like organizations, users, teams, etc... The preferred way to install the AWX CLI is through pip directly from PyPI: pip3 install awxkit awx --help Building the CLI Documentation To build the docs, spin up a real AWX server, pip3 install sphinx sphinxcontrib-autoprogram , and run: ~ cd awxkit/awxkit/cli/docs ~ TOWER_HOST=https://awx.example.org TOWER_USERNAME=example TOWER_PASSWORD=secret make clean html ~ cd build/html/ && python -m http.server Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ..","title":"Installing AWX"},{"location":"cloud/awx/#installing-awx","text":"This document provides a guide for installing AWX. Main page : https://github.com/ansible/awx/blob/17.0.1/INSTALL.md","title":"Installing AWX"},{"location":"cloud/awx/#getting-started","text":"","title":"Getting started"},{"location":"cloud/awx/#clone-the-repo","text":"If you have not already done so, you will need to clone, or create a local copy, of the AWX repo . We generally recommend that you view the releases page: https://github.com/ansible/awx/releases ...and clone the latest stable release, e.g., git clone -b x.y.z https://github.com/ansible/awx.git Please note that deploying from HEAD (or the latest commit) is not stable, and that if you want to do this, you should proceed at your own risk (also, see the section #official-vs-building-images for building your own image). For more on how to clone the repo, view git clone help . Once you have a local copy, run the commands in the following sections from the root of the project tree.","title":"Clone the repo"},{"location":"cloud/awx/#awx-branding","text":"You can optionally install the AWX branding assets from the awx-logos repo . Prior to installing, please review and agree to the trademark guidelines . To install the assets, clone the awx-logos repo so that it is next to your awx clone. As you progress through the installation steps, you'll be setting variables in the inventory file. To include the assets in the build, set awx_official=true .","title":"AWX branding"},{"location":"cloud/awx/#prerequisites","text":"Before you can run a deployment, you'll need the following installed in your local environment: Ansible Requires Version 2.8+ Docker A recent version docker Python module This is incompatible with docker-py . If you have previously installed docker-py , please uninstall it. We use this module instead of docker-py because it is what the docker-compose Python module requires. community.general.docker_image collection This is only required if you are using Ansible >= 2.10 GNU Make Git Requires Version 1.8.4+ Python 3.6+ Node 14.x LTS version This is only required if you're building your own container images with use_container_for_build=false NPM 6.x LTS This is only required if you're building your own container images with use_container_for_build=false","title":"Prerequisites"},{"location":"cloud/awx/#system-requirements","text":"The system that runs the AWX service will need to satisfy the following requirements At least 4GB of memory At least 2 cpu cores At least 20GB of space Running Docker, Openshift, or Kubernetes If you choose to use an external PostgreSQL database, please note that the minimum version is 10+.","title":"System Requirements"},{"location":"cloud/awx/#choose-a-deployment-platform","text":"We currently support running AWX as a containerized application using Docker images deployed to either an OpenShift cluster, a Kubernetes cluster, or docker-compose. The remainder of this document will walk you through the process of building the images, and deploying them to either platform. \u00d2You'll begin by setting variables in the inventory file according to the platform you wish to use, and then you'll start the image build and deployment process by running the playbook. In the sections below, you'll find deployment details and instructions for each platform: - OpenShift - Kubernetes - Docker Compose .","title":"Choose a deployment platform"},{"location":"cloud/awx/#official-vs-building-images","text":"When installing AWX you have the option of building your own image or using the image provided on DockerHub (see awx ) This is controlled by the following variables in the inventory file dockerhub_base=ansible dockerhub_version=latest If these variables are present then all deployments will use these hosted images. If the variables are not present then the images will be built during the install. dockerhub_base The base location on DockerHub where the images are hosted (by default this pulls a container image named ansible/awx:tag ) dockerhub_version Multiple versions are provided. latest always pulls the most recent. You may also select version numbers at different granularities: 1, 1.0, 1.0.1, 1.0.0.123 use_container_for_build Use a local distribution build container image for building the AWX package. This is helpful if you don't want to bother installing the build-time dependencies as it is taken care of already.","title":"Official vs Building Images"},{"location":"cloud/awx/#upgrading-from-previous-versions","text":"Upgrading AWX involves rerunning the install playbook. Download a newer release from https://github.com/ansible/awx/releases and re-populate the inventory file with your customized variables. For convenience, you can create a file called vars.yml : admin_password: 'adminpass' pg_password: 'pgpass' secret_key: 'mysupersecret' And pass it to the installer: $ ansible-playbook -i inventory install.yml -e @vars.yml","title":"Upgrading from previous versions"},{"location":"cloud/awx/#openshift","text":"","title":"OpenShift"},{"location":"cloud/awx/#prerequisites_1","text":"To complete a deployment to OpenShift, you will need access to an OpenShift cluster. For demo and testing purposes, you can use Minishift to create a single node cluster running inside a virtual machine. When using OpenShift for deploying AWX make sure you have correct privileges to add the security context 'privileged', otherwise the installation will fail. The privileged context is needed because of the use of the bubblewrap tool to add an additional layer of security when using containers. You will also need to have the oc command in your PATH. The install.yml playbook will call out to oc when logging into, and creating objects on the cluster. The default resource requests per-deployment requires: Memory: 6GB CPU: 3 cores This can be tuned by overriding the variables found in /installer/roles/kubernetes/defaults/main.yml . Special care should be taken when doing this as undersized instances will experience crashes and resource exhaustion. For more detail on how resource requests are formed see: https://docs.openshift.com/container-platform/latest/dev_guide/compute_resources.html#dev-compute-resources","title":"Prerequisites"},{"location":"cloud/awx/#pre-install-steps","text":"Before starting the install, review the inventory file, and uncomment and provide values for the following variables found in the [all:vars] section: openshift_host IP address or hostname of the OpenShift cluster. If you're using Minishift, this will be the value returned by minishift ip . openshift_skip_tls_verify Boolean. Set to True if using self-signed certs. openshift_project Name of the OpenShift project that will be created, and used as the namespace for the AWX app. Defaults to awx . openshift_user Username of the OpenShift user that will create the project, and deploy the application. Defaults to developer . openshift_pg_emptydir Boolean. Set to True to use an emptyDir volume when deploying the PostgreSQL pod. Note: This should only be used for demo and testing purposes. docker_registry IP address and port, or URL, for accessing a registry that the OpenShift cluster can access. Defaults to 172.30.1.1:5000 , the internal registry delivered with Minishift. This is not needed if you are using official hosted images. docker_registry_repository Namespace to use when pushing and pulling images to and from the registry. Generally this will match the project name. It defaults to awx . This is not needed if you are using official hosted images. docker_registry_username Username of the user that will push images to the registry. Will generally match the openshift_user value. Defaults to developer . This is not needed if you are using official hosted images.","title":"Pre-install steps"},{"location":"cloud/awx/#deploying-to-minishift","text":"Install Minishift by following the installation guide . The recommended minimum resources for your Minishift VM: $ minishift start --cpus = 4 --memory = 8GB The Minishift VM contains a Docker daemon, which you can use to build the AWX images. This is generally the approach you should take, and we recommend doing so. To use this instance, run the following command to setup your environment: # Set DOCKER environment variable to point to the Minishift VM $ eval $( minishift docker-env ) Note If you choose to not use the Docker instance running inside the VM, and build the images externally, you will have to enable the OpenShift cluster to access the images. This involves pushing the images to an external Docker registry, and granting the cluster access to it, or exposing the internal registry, and pushing the images into it.","title":"Deploying to Minishift"},{"location":"cloud/awx/#postgresql","text":"By default, AWX will deploy a PostgreSQL pod inside of your cluster. You will need to create a Persistent Volume Claim which is named postgresql by default, and can be overridden by setting the openshift_pg_pvc_name variable. For testing and demo purposes, you may set openshift_pg_emptydir=yes . If you wish to use an external database, in the inventory file, set the value of pg_hostname , and update pg_username , pg_password , pg_admin_password , pg_database , and pg_port with the connection information. When setting pg_hostname the installer will assume you have configured the database in that location and will not launch the postgresql pod.","title":"PostgreSQL"},{"location":"cloud/awx/#run-the-installer","text":"To start the install, you will pass two extra variables on the command line. The first is openshift_password , which is the password for the openshift_user , and the second is docker_registry_password , which is the password associated with docker_registry_username . If you're using the OpenShift internal registry, then you'll pass an access token for the docker_registry_password value, rather than a password. The oc whoami -t command will generate the required token, as long as you're logged into the cluster via oc cluster login . Run the following command (docker_registry_password is optional if using official images): # Start the install $ ansible-playbook -i inventory install.yml -e openshift_password = developer -e docker_registry_password = $( oc whoami -t )","title":"Run the installer"},{"location":"cloud/awx/#post-install","text":"After the playbook run completes, check the status of the deployment by running oc get pods : # View the running pods $ oc get pods NAME READY STATUS RESTARTS AGE awx-3886581826-5mv0l 4 /4 Running 0 8s postgresql-1-l85fh 1 /1 Running 0 20m In the above example, the name of the AWX pod is awx-3886581826-5mv0l . Before accessing the AWX web interface, setup tasks and database migrations need to complete. These tasks are running in the awx_task container inside the AWX pod. To monitor their status, tail the container's STDOUT by running the following command, replacing the AWX pod name with the pod name from your environment: # Follow the awx_task log output $ oc logs -f awx-3886581826-5mv0l -c awx-celery You will see the following indicating that database migrations are running: Using /etc/ansible/ansible.cfg as config file 127 .0.0.1 | SUCCESS = > { \"changed\" : false, \"db\" : \"awx\" } Operations to perform: Synchronize unmigrated apps: solo, api, staticfiles, messages, channels, django_extensions, ui, rest_framework, polymorphic Apply all migrations: sso, taggit, sessions, sites, kombu_transport_django, social_auth, contenttypes, auth, conf, main Synchronizing apps without migrations: Creating tables... Running deferred SQL... Installing custom SQL... Running migrations: Rendering model states... DONE Applying contenttypes.0001_initial... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0001_initial... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying taggit.0001_initial... OK Applying taggit.0002_auto_20150616_2121... OK ... When you see output similar to the following, you'll know that database migrations have completed, and you can access the web interface: Python 2 .7.5 ( default, Nov 6 2016 , 00 :28:07 ) [ GCC 4 .8.5 20150623 ( Red Hat 4 .8.5-11 )] on linux2 Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information. ( InteractiveConsole ) >>> <User: admin> >>> Default organization added. Demo Credential, Inventory, and Job Template added. Successfully registered instance awx-3886581826-5mv0l ( changed: True ) Creating instance group tower Added instance awx-3886581826-5mv0l to tower Once database migrations complete, the web interface will be accessible.","title":"Post-install"},{"location":"cloud/awx/#accessing-awx","text":"The AWX web interface is running in the AWX pod, behind the awx-web-svc service. To view the service, and its port value, run the following command: # View available services $ oc get services NAME CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE awx-web-svc 172 .30.111.74 <nodes> 8052 :30083/TCP 37m postgresql 172 .30.102.9 <none> 5432 /TCP 38m The deployment process creates a route, awx-web-svc , to expose the service. How the ingres is actually created will vary depending on your environment, and how the cluster is configured. You can view the route, and the external IP address and hostname assigned to it, by running the following command: # View available routes $ oc get routes NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD awx-web-svc awx-web-svc-awx.192.168.64.2.nip.io awx-web-svc http edge/Allow None The above example is taken from a Minishift instance. From a web browser, use https to access the HOST/PORT value from your environment. Using the above example, the URL to access the server would be https://awx-web-svc-awx.192.168.64.2.nip.io . Once you access the AWX server, you will be prompted with a login dialog. The default administrator username is admin , and the password is password .","title":"Accessing AWX"},{"location":"cloud/awx/#kubernetes","text":"","title":"Kubernetes"},{"location":"cloud/awx/#prerequisites_2","text":"A Kubernetes deployment will require you to have access to a Kubernetes cluster as well as the following tools: kubectl helm The installation program will reference kubectl directly. helm is only necessary if you are letting the installer configure PostgreSQL for you. The default resource requests per-pod requires: Memory: 6GB CPU: 3 cores This can be tuned by overriding the variables found in /installer/roles/kubernetes/defaults/main.yml . Special care should be taken when doing this as undersized instances will experience crashes and resource exhaustion. For more detail on how resource requests are formed see: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/","title":"Prerequisites"},{"location":"cloud/awx/#pre-install-steps_1","text":"Before starting the install process, review the inventory file, and uncomment and provide values for the following variables found in the [all:vars] section uncommenting when necessary. Make sure the openshift and standalone docker sections are commented out: kubernetes_context Prior to running the installer, make sure you've configured the context for the cluster you'll be installing to. This is how the installer knows which cluster to connect to and what authentication to use kubernetes_namespace Name of the Kubernetes namespace where the AWX resources will be installed. This will be created if it doesn't exist docker_registry_ These settings should be used if building your own base images. You'll need access to an external registry and are responsible for making sure your kube cluster can talk to it and use it. If these are undefined and the dockerhub_ configuration settings are uncommented then the images will be pulled from dockerhub instead","title":"Pre-install steps"},{"location":"cloud/awx/#configuring-helm","text":"If you want the AWX installer to manage creating the database pod (rather than installing and configuring postgres on your own). Then you will need to have a working helm installation, you can find details here: https://helm.sh/docs/intro/quickstart/ . You do not need to create a Persistent Volume Claim as Helm does it for you. However, an existing one may be used by setting the pg_persistence_existingclaim variable. Newer Kubernetes clusters with RBAC enabled will need to make sure a service account is created, make sure to follow the instructions here https://helm.sh/docs/topics/rbac/","title":"Configuring Helm"},{"location":"cloud/awx/#run-the-installer_1","text":"After making changes to the inventory file use ansible-playbook to begin the install $ ansible-playbook -i inventory install.yml","title":"Run the installer"},{"location":"cloud/awx/#post-install_1","text":"After the playbook run completes, check the status of the deployment by running kubectl get pods --namespace awx (replace awx with the namespace you used): # View the running pods, it may take a few minutes for everything to be marked in the Running state $ kubectl get pods --namespace awx NAME READY STATUS RESTARTS AGE awx-2558692395-2r8ss 4 /4 Running 0 29s awx-postgresql-355348841-kltkn 1 /1 Running 0 1m","title":"Post-install"},{"location":"cloud/awx/#accessing-awx_1","text":"The AWX web interface is running in the AWX pod behind the awx-web-svc service: # View available services $ kubectl get svc --namespace awx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE awx-postgresql ClusterIP 10 .7.250.208 <none> 5432 /TCP 2m awx-web-svc NodePort 10 .7.241.35 <none> 80 :30177/TCP 1m The deployment process creates an Ingress named awx-web-svc also. Some kubernetes cloud providers will automatically handle routing configuration when an Ingress is created others may require that you more explicitly configure it. You can see what kubernetes knows about things with: kubectl get ing --namespace awx NAME HOSTS ADDRESS PORTS AGE awx-web-svc * 35 .227.x.y 80 3m If your provider is able to allocate an IP Address from the Ingress controller then you can navigate to the address and access the AWX interface. For some providers it can take a few minutes to allocate and make this accessible. For other providers it may require you to manually intervene.","title":"Accessing AWX"},{"location":"cloud/awx/#ssl-termination","text":"Unlike Openshift's Route the Kubernetes Ingress doesn't yet handle SSL termination. As such the default configuration will only expose AWX through HTTP on port 80. You are responsible for configuring SSL support until support is added (either to Kubernetes or AWX itself).","title":"SSL Termination"},{"location":"cloud/awx/#docker-compose","text":"","title":"Docker-Compose"},{"location":"cloud/awx/#prerequisites_3","text":"Docker on the host where AWX will be deployed. After installing Docker, the Docker service must be started (depending on your OS, you may have to add the local user that uses Docker to the docker group, refer to the documentation for details) docker-compose Python module. This also installs the docker Python module, which is incompatible with docker-py . If you have previously installed docker-py , please uninstall it. Docker Compose .","title":"Prerequisites"},{"location":"cloud/awx/#pre-install-steps_2","text":"","title":"Pre-install steps"},{"location":"cloud/awx/#deploying-to-a-remote-host","text":"By default, the delivered installer/inventory file will deploy AWX to the local host. It is possible, however, to deploy to a remote host. The installer/install.yml playbook can be used to build images on the local host, and ship the built images to, and run deployment tasks on, a remote host. To do this, modify the installer/inventory file, by commenting out localhost , and adding the remote host. For example, suppose you wish to build images locally on your CI/CD host, and deploy them to a remote host named awx-server . To do this, add awx-server to the installer/inventory file, and comment out or remove localhost , as demonstrated by the following: # localhost ansible_connection=local awx-server [all:vars] ... In the above example, image build tasks will be delegated to localhost , which is typically where the clone of the AWX project exists. Built images will be archived, copied to remote host, and imported into the remote Docker image cache. Tasks to start the AWX containers will then execute on the remote host. If you choose to use the official images then the remote host will be the one to pull those images. Note You may also want to set additional variables to control how Ansible connects to the host. For more information about this, view Behavioral Inventory Parameters . As mentioned above, in Prerequisites , the prerequisites are required on the remote host. When deploying to a remote host, the playbook does not execute tasks with the become option. For this reason, make sure the user that connects to the remote host has privileges to run the docker command. This typically means that non-privileged users need to be part of the docker group.","title":"Deploying to a remote host"},{"location":"cloud/awx/#inventory-variables","text":"Before starting the install process, review the inventory file, and uncomment and provide values for the following variables found in the [all:vars] section: postgres_data_dir If you're using the default PostgreSQL container (see PostgreSQL below), provide a path that can be mounted to the container, and where the database can be persisted. host_port Provide a port number that can be mapped from the Docker daemon host to the web server running inside the AWX container. If undefined no port will be exposed. Defaults to 80 . host_port_ssl Provide a port number that can be mapped from the Docker daemon host to the web server running inside the AWX container for SSL support. If undefined no port will be exposed. Defaults to 443 , only works if you also set ssl_certificate (see below). ssl_certificate Optionally, provide the path to a file that contains a certificate and its private key. This needs to be a .pem-file docker_compose_dir When using docker-compose, the docker-compose.yml file will be created there (default ~/.awx/awxcompose ). custom_venv_dir Adds the custom venv environments from the local host to be passed into the containers at install. ca_trust_dir If you're using a non trusted CA, provide a path where the untrusted Certs are stored on your Host.","title":"Inventory variables"},{"location":"cloud/awx/#docker-registry","text":"If you wish to tag and push built images to a Docker registry, set the following variables in the inventory file: docker_registry IP address and port, or URL, for accessing a registry. docker_registry_repository Namespace to use when pushing and pulling images to and from the registry. Defaults to awx . docker_registry_username Username of the user that will push images to the registry. Defaults to developer . Note These settings are ignored if using official images","title":"Docker registry"},{"location":"cloud/awx/#proxy-settings","text":"http_proxy IP address and port, or URL, for using an http_proxy. https_proxy IP address and port, or URL, for using an https_proxy. no_proxy Exclude IP address or URL from the proxy.","title":"Proxy settings"},{"location":"cloud/awx/#postgresql_1","text":"AWX requires access to a PostgreSQL database, and by default, one will be created and deployed in a container, and data will be persisted to a host volume. In this scenario, you must set the value of postgres_data_dir to a path that can be mounted to the container. When the container is stopped, the database files will still exist in the specified path. If you wish to use an external database, in the inventory file, set the value of pg_hostname , and update pg_username , pg_password , pg_admin_password , pg_database , and pg_port with the connection information.","title":"PostgreSQL"},{"location":"cloud/awx/#run-the-installer_2","text":"If you are not pushing images to a Docker registry, start the install by running the following: # Set the working directory to installer $ cd installer # Run the Ansible playbook $ ansible-playbook -i inventory install.yml If you're pushing built images to a repository, then use the -e option to pass the registry password as follows, replacing password with the password of the username assigned to docker_registry_username (note that you will also need to remove dockerhub_base and dockerhub_version from the inventory file): # Set the working directory to installer $ cd installer # Run the Ansible playbook $ ansible-playbook -i inventory -e docker_registry_password = password install.yml","title":"Run the installer"},{"location":"cloud/awx/#post-install_2","text":"After the playbook run completes, Docker starts a series of containers that provide the services that make up AWX. You can view the running containers using the docker ps command. If you're deploying using Docker Compose, container names will be prefixed by the name of the folder where the docker-compose.yml file is created (by default, awx ). Immediately after the containers start, the awx_task container will perform required setup tasks, including database migrations. These tasks need to complete before the web interface can be accessed. To monitor the progress, you can follow the container's STDOUT by running the following: # Tail the awx_task log $ docker logs -f awx_task You will see output similar to the following: Using /etc/ansible/ansible.cfg as config file 127 .0.0.1 | SUCCESS = > { \"changed\" : false, \"db\" : \"awx\" } Operations to perform: Synchronize unmigrated apps: solo, api, staticfiles, messages, channels, django_extensions, ui, rest_framework, polymorphic Apply all migrations: sso, taggit, sessions, sites, kombu_transport_django, social_auth, contenttypes, auth, conf, main Synchronizing apps without migrations: Creating tables... Running deferred SQL... Installing custom SQL... Running migrations: Rendering model states... DONE Applying contenttypes.0001_initial... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0001_initial... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying taggit.0001_initial... OK Applying taggit.0002_auto_20150616_2121... OK Applying main.0001_initial... OK ... Once migrations complete, you will see the following log output, indicating that migrations have completed: Python 2 .7.5 ( default, Nov 6 2016 , 00 :28:07 ) [ GCC 4 .8.5 20150623 ( Red Hat 4 .8.5-11 )] on linux2 Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information. ( InteractiveConsole ) >>> <User: admin> >>> Default organization added. Demo Credential, Inventory, and Job Template added. Successfully registered instance awx ( changed: True ) Creating instance group tower Added instance awx to tower ( changed: True ) ...","title":"Post-install"},{"location":"cloud/awx/#accessing-awx_2","text":"The AWX web server is accessible on the deployment host, using the host_port value set in the inventory file. The default URL is http://localhost . You will prompted with a login dialog. The default administrator username is admin , and the password is password .","title":"Accessing AWX"},{"location":"cloud/awx/#installing-the-awx-cli","text":"awx is the official command-line client for AWX. It: Uses naming and structure consistent with the AWX HTTP API Provides consistent output formats with optional machine-parsable formats To the extent possible, auto-detects API versions, available endpoints, and feature support across multiple versions of AWX. Potential uses include: Configuring and launching jobs/playbooks Checking on the status and output of job runs Managing objects like organizations, users, teams, etc... The preferred way to install the AWX CLI is through pip directly from PyPI: pip3 install awxkit awx --help","title":"Installing the AWX CLI"},{"location":"cloud/awx/#building-the-cli-documentation","text":"To build the docs, spin up a real AWX server, pip3 install sphinx sphinxcontrib-autoprogram , and run: ~ cd awxkit/awxkit/cli/docs ~ TOWER_HOST=https://awx.example.org TOWER_USERNAME=example TOWER_PASSWORD=secret make clean html ~ cd build/html/ && python -m http.server Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ..","title":"Building the CLI Documentation"},{"location":"cloud/az-104/","text":"Microsoft Azure Administrator Pr\u00e9requis pour les administrateurs Azure Blob Storage Azure Blob Storage is Microsoft's object storage solution for the cloud . Blob Storage is optimized for storing massive amounts of unstructured data. Unstructured data is data that doesn't adhere to a particular data model or definition, such as text or binary data. Blob Storage is designed for: Serving images or documents directly to a browser. Storing files for distributed access. Streaming video and audio. Writing to log files. Storing data for backup and restore, disaster recovery, and archiving. Storing data for analysis by an on-premises or Azure-hosted service. Azure Command-Line Interface (CLI) https://learn.microsoft.com/en-us/cli/azure/ Azure PowerShell https://learn.microsoft.com/en-us/powershell/module/az.compute/new-azvm?view=azps-9.4.0 The New-AzVM cmdlet creates a virtual machine in Azure.This cmdlet takes a virtual machine object as input.The New-AzVM cmdlet will create a new storage account for boot diagnostics if one does not already exist. Use the New-AzVMConfig cmdlet to create a virtual machine object. Then use the following cmdlets to set different properties of the virtual machine object: Add-AzVMNetworkInterface to set the network profile. Set-AzVMOperatingSystem to set the OS profile. Set-AzVMSourceImage to set the source image. Set-AzVMOSDisk to set the OS disk(storage profile). Get-AzComputeResourceSku can also be used to find out available virtual machine sizes for your subscription and region. The SimpleParameterSet provides a convenient method to create a VM by making common VM creation arguments optional. See Quickstart: Create a Windows virtual machine in Azure with PowerShell for tutorial. Syntax : New-AzVM [[ -ResourceGroupName ] < String >] [[ -Location ] < String >] [ -EdgeZone < String >] [[ -Zone ] < String []>] [ -PublicIpSku < String >] -Name < String > -Credential < PSCredential > [ -NetworkInterfaceDeleteOption < String >] [ -VirtualNetworkName < String >] [ -AddressPrefix < String >] [ -SubnetName < String >] [ -SubnetAddressPrefix < String >] [ -PublicIpAddressName < String >] [ -DomainNameLabel < String >] [ -AllocationMethod < String >] [ -SecurityGroupName < String >] [ -OpenPorts < Int32 []>] [ -Image < String >] [ -Size < String >] [ -AvailabilitySetName < String >] [ -SystemAssignedIdentity ] [ -UserAssignedIdentity < String >] [ -AsJob ] [ -OSDiskDeleteOption < String >] [ -DataDiskSizeInGb < Int32 []>] [ -DataDiskDeleteOption < String >] [ -EnableUltraSSD ] [ -ProximityPlacementGroupId < String >] [ -HostId < String >] [ -VmssId < String >] [ -Priority < String >] [ -EvictionPolicy < String >] [ -MaxPrice < Double >] [ -EncryptionAtHost ] [ -HostGroupId < String >] [ -SshKeyName < String >] [ -GenerateSshKey ] [ -CapacityReservationGroupId < String >] [ -UserData < String >] [ -ImageReferenceId < String >] [ -PlatformFaultDomain < Int32 >] [ -HibernationEnabled ] [ -vCPUCountAvailable < Int32 >] [ -vCPUCountPerCore < Int32 >] [ -DiskControllerType < String >] [ -DefaultProfile < IAzureContextContainer >] [ -WhatIf ] [ -Confirm ] [< CommonParameters >] Example Create a virtual machine New-AzVM -Name MyVm -Credential ( Get-Credential ) VERBOSE : Use 'mstsc /v:myvm-222222.eastus.cloudapp.azure.com' to connect to the VM . ResourceGroupName : MyVm Id : / subscriptions / 00000000 - 0000 - 0000 - 0000 - 000000000000 / resourceGroups / MyVm / provi ders / Microsoft . Compute / virtualMachines / MyVm VmId : 11111111 - 1111 - 1111 - 1111 - 111111111111 Name : MyVm Type : Microsoft . Compute / virtualMachines Location : eastus Tags : {} HardwareProfile : { VmSize } NetworkProfile : { NetworkInterfaces } OSProfile : { ComputerName , AdminUsername , WindowsConfiguration , Secrets } ProvisioningState : Succeeded StorageProfile : { ImageReference , OsDisk , DataDisks } FullyQualifiedDomainName : myvm - 222222 . eastus . cloudapp . azure . com Utiliser Azure Resource Manager Terminology If you're new to Azure Resource Manager, there are some terms you might not be familiar with. resource - A manageable item that is available through Azure.Virtual machines, storage accounts, web apps, databases, and virtual networks are examples of resources.Resource groups, subscriptions, management groups, and tags are also examples of resources. resource group - A container that holds related resources for an Azure solution.The resource group includes those resources that you want to manage as a group.You decide which resources belong in a resource group based on what makes the most sense for your organization.See Resource groups . resource provider - A service that supplies Azure resources.For example, a common resource provider is Microsoft.Compute , which supplies the virtual machine resource. Microsoft.Storage is another common resource provider.See Resource providers and types . declarative syntax - Syntax that lets you state \"Here's what I intend to create\" without having to write the sequence of programming commands to create it.ARM templates and Bicep files are examples of declarative syntax.In those files, you define the properties for the infrastructure to deploy to Azure. ARM template - A JavaScript Object Notation (JSON) file that defines one or more resources to deploy to a resource group, subscription, management group, or tenant.The template can be used to deploy the resources consistently and repeatedly.See Template deployment overview . Bicep file - A file for declaratively deploying Azure resources.Bicep is a language that's been designed to provide the best authoring experience for infrastructure as code solutions in Azure.See Bicep overview . For more definitions of Azure terminology, see Azure fundamental concepts . Couche de gestion coh\u00e9rente Azure Resource Manager offre plusieurs avantages : Vous pouvez d\u00e9ployer, g\u00e9rer et surveiller toutes les ressources de votre solution comme un groupe, plut\u00f4t que de les g\u00e9rer individuellement. Vous pouvez d\u00e9ployer votre solution \u00e0 plusieurs reprises tout au long du cycle de vie de d\u00e9veloppement et avoir ainsi l\u2019assurance que vos ressources pr\u00e9sentent un \u00e9tat coh\u00e9rent lors de leur d\u00e9ploiement. Vous pouvez g\u00e9rer votre infrastructure \u00e0 l\u2019aide de mod\u00e8les d\u00e9claratifs plut\u00f4t que de scripts. Vous pouvez d\u00e9finir les d\u00e9pendances entre les ressources afin de les d\u00e9ployer dans le bon ordre. Vous pouvez appliquer le contr\u00f4le d\u2019acc\u00e8s \u00e0 tous les services dans votre groupe de ressources, car le contr\u00f4le d\u2019acc\u00e8s en fonction du r\u00f4le (RBAC) est int\u00e9gr\u00e9 en mode natif \u00e0 la plateforme de gestion. Vous pouvez appliquer des balises aux ressources pour organiser logiquement toutes les ressources de votre abonnement. Vous pouvez clarifier la facturation de votre organisation en affichant les co\u00fbts d\u2019un groupe de ressources partageant la m\u00eame balise. Fournisseurs de ressources Chaque fournisseur de ressources propose un ensemble de ressources et d\u2019op\u00e9rations permettant de g\u00e9rer un service Azure.Par exemple, si vous voulez stocker des cl\u00e9s et des secrets, vous utilisez le fournisseur de ressources Microsoft.KeyVault .Ce fournisseur de ressources offre un type de ressource appel\u00e9 vaults pour cr\u00e9er le coffre de cl\u00e9s. Le nom d\u2019un type de ressource est au format : {fournisseur de ressources}/{type de ressource} .Par exemple, le type de coffre de cl\u00e9s est Microsoft.KeyVault\\vaults . Groupes de ressources Dans leur forme la plus simple, les groupes de ressources sont un regroupement logique de ressources.Il existe quelques r\u00e8gles pour les groupes de ressources. Les ressources peuvent appartenir \u00e0 un seul groupe de ressources \u00e0 la fois. Les groupes de ressources ne peuvent pas \u00eatre renomm\u00e9s. Les groupes de ressources peuvent avoir des ressources de types diff\u00e9rents (services). Les groupes de ressources peuvent avoir des ressources provenant de diff\u00e9rentes r\u00e9gions. En attribuant des autorisations d\u2019\u00e9tendue \u00e0 un groupe de ressources, vous pouvez ajouter/supprimer et modifier des ressources facilement sans avoir \u00e0 recr\u00e9er les attributions et les \u00e9tendues. Verrous Les verrous Resource Manager permettent aux organisations de mettre en place une structure qui emp\u00eache la suppression accidentelle des ressources dans Azure. Vous pouvez associer le verrou \u00e0 un abonnement, \u00e0 un groupe de ressources ou \u00e0 une ressource. Les ressources enfants h\u00e9ritent des verrous. Il existe deux types de verrous de ressource. Verrous en lecture seule , qui emp\u00eachent toute modification apport\u00e9e \u00e0 la ressource. Verrous de suppression , qui emp\u00eachent la suppression. Manage groups Utilisation de [[#Azure PowerShell|PowerShell]] pour supprimer des groups de ressources Remove-AzResourceGroup -Name \"ContosoRG01\" Conclusion Documentation Azure Resource Manager Azure Resource Manager est le service de d\u00e9ploiement et de gestion d\u2019Azure.Il fournit une couche de gestion qui vous permet de cr\u00e9er, de mettre \u00e0 jour et de supprimer des ressources dans votre compte Azure.Vous utilisez des fonctionnalit\u00e9s de gestion, telles que le contr\u00f4le d\u2019acc\u00e8s, les verrous et les \u00e9tiquettes, pour s\u00e9curiser et organiser vos ressources apr\u00e8s le d\u00e9ploiement. Identifier les fonctionnalit\u00e9s et les cas d\u2019usage Azure Resource Manager. D\u00e9crire chaque composant Azure Resource Manager et son utilisation. Organiser vos ressources Azure avec des groupes de ressources. Appliquer des verrous Azure Resource Manager. D\u00e9placer des ressources Azure entre des groupes, des abonnements et des r\u00e9gions. Supprimer des ressources et des groupes de ressources. Appliquer et suivre les limites des ressources. Templates Some templates provide everything you need to deploy your solution, while others might serve as a starting point for your template. Either way, you can study these templates to learn how to best author and structure your own templates. The README.md file provides an overview of what the template does. The azuredeploy.json file defines the resources that will be deployed. The azuredeploy.parameters.json file provides the values the template needs. Template based on a JavaScript Object Notation (JSON) file that defines the infrastructure and configuration for the deployment. Azure Resource Manager won't make any changes to the deployed resources in case of the same template is run a second time. Bicep Azure Bicep is a domain-specific language (DSL) that uses declarative syntax to deploy Azure resources.It provides concise syntax, reliable type safety, and support for code reuse. You can use Bicep instead of JSON to develop your Azure Resource Manager templates (ARM templates).The JSON syntax to create an ARM template can be verbose and require complicated expressions.Bicep syntax reduces that complexity and improves the development experience.Bicep is a transparent abstraction over ARM template JSON and doesn't lose any of the JSON template capabilities. Bicep provides many improvements over JSON for template authoring, including: Simpler syntax : Bicep provides a simpler syntax for writing templates.You can reference parameters and variables directly, without using complicated functions.String interpolation is used in place of concatenation to combine values for names and other items.You can reference the properties of a resource directly by using its symbolic name instead of complex reference statements.These syntax improvements help both with authoring and reading Bicep templates. Modules : You can break down complex template deployments into smaller module files and reference them in a main template.These modules provide easier management and greater reusability. Automatic dependency management : In most situations, Bicep automatically detects dependencies between your resources.This process removes some of the work involved in template authoring. Type validation and IntelliSense : The Bicep extension for Visual Studio Code features rich validation and IntelliSense for all Azure resource type API definitions.This feature helps provide an easier authoring experience. Conclusion To implement infrastructure as code for your Azure solutions, use Azure Resource Manager templates. The template is a JavaScript Object Notation (JSON) file that defines the infrastructure and configuration for your project. The template uses declarative syntax, which lets you state what you intend to deploy without having to write the sequence of programming commands to create it. In the template, you specify the resources to deploy and the properties for those resources. You should now be able to: List the advantages of Azure templates. Identify the Azure template schema components. Specify Azure template parameters. Locate and use Azure Quickstart Templates. Automate Azure tasks using scripts with PowerShell How to manage powershell azure ressource thanks to scripts ? Cmdlets (\"command-let\") A PowerShell command is called a cmdlet (pronounced \"command-let\"). A cmdlet is a command that manipulates a single feature. The term cmdlet refers to a \u201csmall command\u201d. By convention, cmdlet authors are encouraged to create simple, single-function cmdlets. Get-Help -Name Get-ChildItem -Detailed Modules Cmdlets are delivered in modules. A PowerShell module is a DLL that includes code to process each available cmdlet. You load cmdlets into PowerShell by loading the module that contains them. You can get the list of loaded modules using the Get-Module command: Get-Module Az PowerShell This module is available from dthe main global repository named PowerShell Gallery . Install-Module cmdlets will be use. Install Az from the PSGallery (PowerShell Gallery) : Install-Module -Name Az -Scope CurrentUser -Repository PSGallery -Force Update the module : Update-Module -Name Az Connect to Az This command will prompt on your browser login page Connect-AzAccount Subscriptions Modify the subscription : Set-AzContext -Subscription '00000000-0000-0000-0000-000000000000' Manage ressource group List current ressource group Get-AzResourceGroup Formalize it by the Format-Table cmdlet Get-AzResourceGroup | Format-Table Example : ResourceGroupName Location ProvisioningState Tags TagsTable ResourceId ----------------- -------- ----------------- ---- --------- ---------- cloud-shell-storage-southcentralus southcentralus Succeeded / subscriptions / 00000000 - 0000 - 0000 ... ExerciseResources eastus Succeeded / subscriptions / 00000000 - 0000 - 0000 ... Create ressource : New-AzResourceGroup -Name < name > -Location < location > Control Azure services with the CLI Azure CLI vous permet de contr\u00f4ler presque tous les aspects de chaque ressource Azure.Vous pouvez travailler avec des groupes de ressources, du stockage, des machines virtuelles, Azure Active Directory (Azure AD), des conteneurs, l\u2019apprentissage automatique, etc. Les commandes de l\u2019interface CLI sont structur\u00e9es en groupes et sous-groupes .Chaque groupe repr\u00e9sente un service fourni par Azure, et les sous-groupes s\u00e9parent les commandes pour ces services en regroupements logiques.Par exemple, le groupe storage contient des sous-groupes, dont account , blob et queue . Installation Install azure-cli (for mac) brew install azure-cli az --version Create ressource 1.Connection az login ``` 2.Create Create ressource group first : ```cli az group create --name <name> --location <location> You don't need to create a resource group when using the free Azure Sandbox.Instead, you'll use a previously created resource group. 3.Check List group.s az group list You can use the Copy button to copy commands to the clipboard. To paste, right-click on a new line in the Cloud Shell terminal and select Paste or use the keyboard shortcut Shift+Insert (\u2318+V on macOS). Summary Azure CLI is a good choice for anyone new to using the Azure command line and scripting.The simplicity of its syntax and its cross-platform compatibility help reduce the risk of errors related to the execution of regular and repetitive tasks.In this module, you used Azure CLI commands to create a resource group and deploy a web application using a small set of commands.These commands could be combined into a shell script as part of an automation solution. Deploy Azure Infrastructure using JSON ARM Templates In this unit, you learn about using Azure Resource Manager templates (ARM templates) to implement infrastructure as code.You survey the sections of an ARM template, learn how to deploy your ARM template to Azure, and delve into detail on the resources section of the ARM template. implement an JSON ARM template by using Visual Studio Code. Declare resources and add flexibility to your template by adding parameters and outputs. What is infrastructure as code? Infrastructure as code enables you to describe, through code, the infrastructure that you need for your application. With infrastructure as code, you can maintain both your application code and everything you need to deploy your application in a central code repository.The advantages to infrastructure as code are: Consistent configurations Improved scalability Faster deployments Better traceability What is an ARM template? ARM templates are JavaScript Object Notation (JSON) files that define the infrastructure and configuration for your deployment.The template uses a declarative syntax .The declarative syntax is a way of building the structure and elements that outline what resources will look like without describing its control flow.Declarative syntax is different than imperative syntax , which uses commands for the computer to perform.Imperative scripting focuses on specifying each step in deploying the resources. ARM templates allow you to declare what you intend to deploy without having to write the sequence of programming commands to create it.In an ARM template, you specify the resources and the properties for those resources.Then Azure Resource Manager uses that information to deploy the resources in an organized and consistent manner. ![[Pasted image 20230223152543.png]] Resource Manager also has built-in validation.It checks the template before starting the deployment to make sure the deployment will succeed. ARM template file structure When writing an ARM template, you need to understand all the parts that make up the template and what they do.ARM template files are made up of the following elements: Element Description schema A required section that defines the location of the JSON schema file that describes the structure of JSON data.The version number you use depends on the scope of the deployment and your JSON editor. contentVersion A required section that defines the version of your template (such as 1.0.0.0).You can use this value to document significant changes in your template to ensure you're deploying the right template. apiProfile An optional section that defines a collection of API versions for resource types.You can use this value to avoid having to specify API versions for each resource in the template. parameters An optional section where you define values that are provided during deployment.These values can be provided by a parameter file, by command-line parameters, or in the Azure portal. variables An optional section where you define values that are used to simplify template language expressions. functions An optional section where you can define user-defined functions that are available within the template.User-defined functions can simplify your template when complicated expressions are used repeatedly in your template. resources A required section that defines the actual items you want to deploy or update in a resource group or a subscription. output An optional section where you specify the values that will be returned at the end of the deployment. Reference https://learn.microsoft.com/fr-fr/training/paths/az-104-administrator-prerequisites/","title":"Microsoft Azure Administrator"},{"location":"cloud/az-104/#microsoft-azure-administrator","text":"Pr\u00e9requis pour les administrateurs Azure","title":"Microsoft Azure Administrator"},{"location":"cloud/az-104/#blob-storage","text":"Azure Blob Storage is Microsoft's object storage solution for the cloud . Blob Storage is optimized for storing massive amounts of unstructured data. Unstructured data is data that doesn't adhere to a particular data model or definition, such as text or binary data. Blob Storage is designed for: Serving images or documents directly to a browser. Storing files for distributed access. Streaming video and audio. Writing to log files. Storing data for backup and restore, disaster recovery, and archiving. Storing data for analysis by an on-premises or Azure-hosted service.","title":"Blob Storage"},{"location":"cloud/az-104/#azure-command-line-interface-cli","text":"https://learn.microsoft.com/en-us/cli/azure/","title":"Azure Command-Line Interface (CLI)"},{"location":"cloud/az-104/#azure-powershell","text":"https://learn.microsoft.com/en-us/powershell/module/az.compute/new-azvm?view=azps-9.4.0 The New-AzVM cmdlet creates a virtual machine in Azure.This cmdlet takes a virtual machine object as input.The New-AzVM cmdlet will create a new storage account for boot diagnostics if one does not already exist. Use the New-AzVMConfig cmdlet to create a virtual machine object. Then use the following cmdlets to set different properties of the virtual machine object: Add-AzVMNetworkInterface to set the network profile. Set-AzVMOperatingSystem to set the OS profile. Set-AzVMSourceImage to set the source image. Set-AzVMOSDisk to set the OS disk(storage profile). Get-AzComputeResourceSku can also be used to find out available virtual machine sizes for your subscription and region. The SimpleParameterSet provides a convenient method to create a VM by making common VM creation arguments optional. See Quickstart: Create a Windows virtual machine in Azure with PowerShell for tutorial. Syntax : New-AzVM [[ -ResourceGroupName ] < String >] [[ -Location ] < String >] [ -EdgeZone < String >] [[ -Zone ] < String []>] [ -PublicIpSku < String >] -Name < String > -Credential < PSCredential > [ -NetworkInterfaceDeleteOption < String >] [ -VirtualNetworkName < String >] [ -AddressPrefix < String >] [ -SubnetName < String >] [ -SubnetAddressPrefix < String >] [ -PublicIpAddressName < String >] [ -DomainNameLabel < String >] [ -AllocationMethod < String >] [ -SecurityGroupName < String >] [ -OpenPorts < Int32 []>] [ -Image < String >] [ -Size < String >] [ -AvailabilitySetName < String >] [ -SystemAssignedIdentity ] [ -UserAssignedIdentity < String >] [ -AsJob ] [ -OSDiskDeleteOption < String >] [ -DataDiskSizeInGb < Int32 []>] [ -DataDiskDeleteOption < String >] [ -EnableUltraSSD ] [ -ProximityPlacementGroupId < String >] [ -HostId < String >] [ -VmssId < String >] [ -Priority < String >] [ -EvictionPolicy < String >] [ -MaxPrice < Double >] [ -EncryptionAtHost ] [ -HostGroupId < String >] [ -SshKeyName < String >] [ -GenerateSshKey ] [ -CapacityReservationGroupId < String >] [ -UserData < String >] [ -ImageReferenceId < String >] [ -PlatformFaultDomain < Int32 >] [ -HibernationEnabled ] [ -vCPUCountAvailable < Int32 >] [ -vCPUCountPerCore < Int32 >] [ -DiskControllerType < String >] [ -DefaultProfile < IAzureContextContainer >] [ -WhatIf ] [ -Confirm ] [< CommonParameters >]","title":"Azure PowerShell"},{"location":"cloud/az-104/#example","text":"","title":"Example"},{"location":"cloud/az-104/#create-a-virtual-machine","text":"New-AzVM -Name MyVm -Credential ( Get-Credential ) VERBOSE : Use 'mstsc /v:myvm-222222.eastus.cloudapp.azure.com' to connect to the VM . ResourceGroupName : MyVm Id : / subscriptions / 00000000 - 0000 - 0000 - 0000 - 000000000000 / resourceGroups / MyVm / provi ders / Microsoft . Compute / virtualMachines / MyVm VmId : 11111111 - 1111 - 1111 - 1111 - 111111111111 Name : MyVm Type : Microsoft . Compute / virtualMachines Location : eastus Tags : {} HardwareProfile : { VmSize } NetworkProfile : { NetworkInterfaces } OSProfile : { ComputerName , AdminUsername , WindowsConfiguration , Secrets } ProvisioningState : Succeeded StorageProfile : { ImageReference , OsDisk , DataDisks } FullyQualifiedDomainName : myvm - 222222 . eastus . cloudapp . azure . com","title":"Create a virtual machine"},{"location":"cloud/az-104/#utiliser-azure-resource-manager","text":"","title":"Utiliser Azure Resource Manager"},{"location":"cloud/az-104/#terminology","text":"If you're new to Azure Resource Manager, there are some terms you might not be familiar with. resource - A manageable item that is available through Azure.Virtual machines, storage accounts, web apps, databases, and virtual networks are examples of resources.Resource groups, subscriptions, management groups, and tags are also examples of resources. resource group - A container that holds related resources for an Azure solution.The resource group includes those resources that you want to manage as a group.You decide which resources belong in a resource group based on what makes the most sense for your organization.See Resource groups . resource provider - A service that supplies Azure resources.For example, a common resource provider is Microsoft.Compute , which supplies the virtual machine resource. Microsoft.Storage is another common resource provider.See Resource providers and types . declarative syntax - Syntax that lets you state \"Here's what I intend to create\" without having to write the sequence of programming commands to create it.ARM templates and Bicep files are examples of declarative syntax.In those files, you define the properties for the infrastructure to deploy to Azure. ARM template - A JavaScript Object Notation (JSON) file that defines one or more resources to deploy to a resource group, subscription, management group, or tenant.The template can be used to deploy the resources consistently and repeatedly.See Template deployment overview . Bicep file - A file for declaratively deploying Azure resources.Bicep is a language that's been designed to provide the best authoring experience for infrastructure as code solutions in Azure.See Bicep overview . For more definitions of Azure terminology, see Azure fundamental concepts .","title":"Terminology"},{"location":"cloud/az-104/#couche-de-gestion-coherente","text":"Azure Resource Manager offre plusieurs avantages : Vous pouvez d\u00e9ployer, g\u00e9rer et surveiller toutes les ressources de votre solution comme un groupe, plut\u00f4t que de les g\u00e9rer individuellement. Vous pouvez d\u00e9ployer votre solution \u00e0 plusieurs reprises tout au long du cycle de vie de d\u00e9veloppement et avoir ainsi l\u2019assurance que vos ressources pr\u00e9sentent un \u00e9tat coh\u00e9rent lors de leur d\u00e9ploiement. Vous pouvez g\u00e9rer votre infrastructure \u00e0 l\u2019aide de mod\u00e8les d\u00e9claratifs plut\u00f4t que de scripts. Vous pouvez d\u00e9finir les d\u00e9pendances entre les ressources afin de les d\u00e9ployer dans le bon ordre. Vous pouvez appliquer le contr\u00f4le d\u2019acc\u00e8s \u00e0 tous les services dans votre groupe de ressources, car le contr\u00f4le d\u2019acc\u00e8s en fonction du r\u00f4le (RBAC) est int\u00e9gr\u00e9 en mode natif \u00e0 la plateforme de gestion. Vous pouvez appliquer des balises aux ressources pour organiser logiquement toutes les ressources de votre abonnement. Vous pouvez clarifier la facturation de votre organisation en affichant les co\u00fbts d\u2019un groupe de ressources partageant la m\u00eame balise.","title":"Couche de gestion coh\u00e9rente"},{"location":"cloud/az-104/#fournisseurs-de-ressources","text":"Chaque fournisseur de ressources propose un ensemble de ressources et d\u2019op\u00e9rations permettant de g\u00e9rer un service Azure.Par exemple, si vous voulez stocker des cl\u00e9s et des secrets, vous utilisez le fournisseur de ressources Microsoft.KeyVault .Ce fournisseur de ressources offre un type de ressource appel\u00e9 vaults pour cr\u00e9er le coffre de cl\u00e9s. Le nom d\u2019un type de ressource est au format : {fournisseur de ressources}/{type de ressource} .Par exemple, le type de coffre de cl\u00e9s est Microsoft.KeyVault\\vaults .","title":"Fournisseurs de ressources"},{"location":"cloud/az-104/#groupes-de-ressources","text":"Dans leur forme la plus simple, les groupes de ressources sont un regroupement logique de ressources.Il existe quelques r\u00e8gles pour les groupes de ressources. Les ressources peuvent appartenir \u00e0 un seul groupe de ressources \u00e0 la fois. Les groupes de ressources ne peuvent pas \u00eatre renomm\u00e9s. Les groupes de ressources peuvent avoir des ressources de types diff\u00e9rents (services). Les groupes de ressources peuvent avoir des ressources provenant de diff\u00e9rentes r\u00e9gions. En attribuant des autorisations d\u2019\u00e9tendue \u00e0 un groupe de ressources, vous pouvez ajouter/supprimer et modifier des ressources facilement sans avoir \u00e0 recr\u00e9er les attributions et les \u00e9tendues.","title":"Groupes de ressources"},{"location":"cloud/az-104/#verrous","text":"Les verrous Resource Manager permettent aux organisations de mettre en place une structure qui emp\u00eache la suppression accidentelle des ressources dans Azure. Vous pouvez associer le verrou \u00e0 un abonnement, \u00e0 un groupe de ressources ou \u00e0 une ressource. Les ressources enfants h\u00e9ritent des verrous. Il existe deux types de verrous de ressource. Verrous en lecture seule , qui emp\u00eachent toute modification apport\u00e9e \u00e0 la ressource. Verrous de suppression , qui emp\u00eachent la suppression.","title":"Verrous"},{"location":"cloud/az-104/#manage-groups","text":"Utilisation de [[#Azure PowerShell|PowerShell]] pour supprimer des groups de ressources Remove-AzResourceGroup -Name \"ContosoRG01\"","title":"Manage groups"},{"location":"cloud/az-104/#conclusion","text":"Documentation Azure Resource Manager Azure Resource Manager est le service de d\u00e9ploiement et de gestion d\u2019Azure.Il fournit une couche de gestion qui vous permet de cr\u00e9er, de mettre \u00e0 jour et de supprimer des ressources dans votre compte Azure.Vous utilisez des fonctionnalit\u00e9s de gestion, telles que le contr\u00f4le d\u2019acc\u00e8s, les verrous et les \u00e9tiquettes, pour s\u00e9curiser et organiser vos ressources apr\u00e8s le d\u00e9ploiement. Identifier les fonctionnalit\u00e9s et les cas d\u2019usage Azure Resource Manager. D\u00e9crire chaque composant Azure Resource Manager et son utilisation. Organiser vos ressources Azure avec des groupes de ressources. Appliquer des verrous Azure Resource Manager. D\u00e9placer des ressources Azure entre des groupes, des abonnements et des r\u00e9gions. Supprimer des ressources et des groupes de ressources. Appliquer et suivre les limites des ressources.","title":"Conclusion"},{"location":"cloud/az-104/#templates","text":"Some templates provide everything you need to deploy your solution, while others might serve as a starting point for your template. Either way, you can study these templates to learn how to best author and structure your own templates. The README.md file provides an overview of what the template does. The azuredeploy.json file defines the resources that will be deployed. The azuredeploy.parameters.json file provides the values the template needs. Template based on a JavaScript Object Notation (JSON) file that defines the infrastructure and configuration for the deployment. Azure Resource Manager won't make any changes to the deployed resources in case of the same template is run a second time.","title":"Templates"},{"location":"cloud/az-104/#bicep","text":"Azure Bicep is a domain-specific language (DSL) that uses declarative syntax to deploy Azure resources.It provides concise syntax, reliable type safety, and support for code reuse. You can use Bicep instead of JSON to develop your Azure Resource Manager templates (ARM templates).The JSON syntax to create an ARM template can be verbose and require complicated expressions.Bicep syntax reduces that complexity and improves the development experience.Bicep is a transparent abstraction over ARM template JSON and doesn't lose any of the JSON template capabilities. Bicep provides many improvements over JSON for template authoring, including: Simpler syntax : Bicep provides a simpler syntax for writing templates.You can reference parameters and variables directly, without using complicated functions.String interpolation is used in place of concatenation to combine values for names and other items.You can reference the properties of a resource directly by using its symbolic name instead of complex reference statements.These syntax improvements help both with authoring and reading Bicep templates. Modules : You can break down complex template deployments into smaller module files and reference them in a main template.These modules provide easier management and greater reusability. Automatic dependency management : In most situations, Bicep automatically detects dependencies between your resources.This process removes some of the work involved in template authoring. Type validation and IntelliSense : The Bicep extension for Visual Studio Code features rich validation and IntelliSense for all Azure resource type API definitions.This feature helps provide an easier authoring experience.","title":"Bicep"},{"location":"cloud/az-104/#conclusion_1","text":"To implement infrastructure as code for your Azure solutions, use Azure Resource Manager templates. The template is a JavaScript Object Notation (JSON) file that defines the infrastructure and configuration for your project. The template uses declarative syntax, which lets you state what you intend to deploy without having to write the sequence of programming commands to create it. In the template, you specify the resources to deploy and the properties for those resources. You should now be able to: List the advantages of Azure templates. Identify the Azure template schema components. Specify Azure template parameters. Locate and use Azure Quickstart Templates.","title":"Conclusion"},{"location":"cloud/az-104/#automate-azure-tasks-using-scripts-with-powershell","text":"How to manage powershell azure ressource thanks to scripts ?","title":"Automate Azure tasks using scripts with PowerShell"},{"location":"cloud/az-104/#cmdlets-command-let","text":"A PowerShell command is called a cmdlet (pronounced \"command-let\"). A cmdlet is a command that manipulates a single feature. The term cmdlet refers to a \u201csmall command\u201d. By convention, cmdlet authors are encouraged to create simple, single-function cmdlets. Get-Help -Name Get-ChildItem -Detailed","title":"Cmdlets (\"command-let\")"},{"location":"cloud/az-104/#modules","text":"Cmdlets are delivered in modules. A PowerShell module is a DLL that includes code to process each available cmdlet. You load cmdlets into PowerShell by loading the module that contains them. You can get the list of loaded modules using the Get-Module command: Get-Module","title":"Modules"},{"location":"cloud/az-104/#az-powershell","text":"This module is available from dthe main global repository named PowerShell Gallery . Install-Module cmdlets will be use. Install Az from the PSGallery (PowerShell Gallery) : Install-Module -Name Az -Scope CurrentUser -Repository PSGallery -Force Update the module : Update-Module -Name Az","title":"Az PowerShell"},{"location":"cloud/az-104/#connect-to-az","text":"This command will prompt on your browser login page Connect-AzAccount","title":"Connect to Az"},{"location":"cloud/az-104/#subscriptions","text":"Modify the subscription : Set-AzContext -Subscription '00000000-0000-0000-0000-000000000000'","title":"Subscriptions"},{"location":"cloud/az-104/#manage-ressource-group","text":"List current ressource group Get-AzResourceGroup Formalize it by the Format-Table cmdlet Get-AzResourceGroup | Format-Table Example : ResourceGroupName Location ProvisioningState Tags TagsTable ResourceId ----------------- -------- ----------------- ---- --------- ---------- cloud-shell-storage-southcentralus southcentralus Succeeded / subscriptions / 00000000 - 0000 - 0000 ... ExerciseResources eastus Succeeded / subscriptions / 00000000 - 0000 - 0000 ... Create ressource : New-AzResourceGroup -Name < name > -Location < location >","title":"Manage ressource group"},{"location":"cloud/az-104/#control-azure-services-with-the-cli","text":"Azure CLI vous permet de contr\u00f4ler presque tous les aspects de chaque ressource Azure.Vous pouvez travailler avec des groupes de ressources, du stockage, des machines virtuelles, Azure Active Directory (Azure AD), des conteneurs, l\u2019apprentissage automatique, etc. Les commandes de l\u2019interface CLI sont structur\u00e9es en groupes et sous-groupes .Chaque groupe repr\u00e9sente un service fourni par Azure, et les sous-groupes s\u00e9parent les commandes pour ces services en regroupements logiques.Par exemple, le groupe storage contient des sous-groupes, dont account , blob et queue .","title":"Control Azure services with the CLI"},{"location":"cloud/az-104/#installation","text":"Install azure-cli (for mac) brew install azure-cli az --version","title":"Installation"},{"location":"cloud/az-104/#create-ressource","text":"1.Connection az login ``` 2.Create Create ressource group first : ```cli az group create --name <name> --location <location> You don't need to create a resource group when using the free Azure Sandbox.Instead, you'll use a previously created resource group. 3.Check List group.s az group list You can use the Copy button to copy commands to the clipboard. To paste, right-click on a new line in the Cloud Shell terminal and select Paste or use the keyboard shortcut Shift+Insert (\u2318+V on macOS).","title":"Create ressource"},{"location":"cloud/az-104/#summary","text":"Azure CLI is a good choice for anyone new to using the Azure command line and scripting.The simplicity of its syntax and its cross-platform compatibility help reduce the risk of errors related to the execution of regular and repetitive tasks.In this module, you used Azure CLI commands to create a resource group and deploy a web application using a small set of commands.These commands could be combined into a shell script as part of an automation solution.","title":"Summary"},{"location":"cloud/az-104/#deploy-azure-infrastructure-using-json-arm-templates","text":"In this unit, you learn about using Azure Resource Manager templates (ARM templates) to implement infrastructure as code.You survey the sections of an ARM template, learn how to deploy your ARM template to Azure, and delve into detail on the resources section of the ARM template. implement an JSON ARM template by using Visual Studio Code. Declare resources and add flexibility to your template by adding parameters and outputs.","title":"Deploy Azure Infrastructure using JSON ARM Templates"},{"location":"cloud/az-104/#what-is-infrastructure-as-code","text":"Infrastructure as code enables you to describe, through code, the infrastructure that you need for your application. With infrastructure as code, you can maintain both your application code and everything you need to deploy your application in a central code repository.The advantages to infrastructure as code are: Consistent configurations Improved scalability Faster deployments Better traceability","title":"What is infrastructure as code?"},{"location":"cloud/az-104/#what-is-an-arm-template","text":"ARM templates are JavaScript Object Notation (JSON) files that define the infrastructure and configuration for your deployment.The template uses a declarative syntax .The declarative syntax is a way of building the structure and elements that outline what resources will look like without describing its control flow.Declarative syntax is different than imperative syntax , which uses commands for the computer to perform.Imperative scripting focuses on specifying each step in deploying the resources. ARM templates allow you to declare what you intend to deploy without having to write the sequence of programming commands to create it.In an ARM template, you specify the resources and the properties for those resources.Then Azure Resource Manager uses that information to deploy the resources in an organized and consistent manner. ![[Pasted image 20230223152543.png]] Resource Manager also has built-in validation.It checks the template before starting the deployment to make sure the deployment will succeed.","title":"What is an ARM template?"},{"location":"cloud/az-104/#arm-template-file-structure","text":"When writing an ARM template, you need to understand all the parts that make up the template and what they do.ARM template files are made up of the following elements: Element Description schema A required section that defines the location of the JSON schema file that describes the structure of JSON data.The version number you use depends on the scope of the deployment and your JSON editor. contentVersion A required section that defines the version of your template (such as 1.0.0.0).You can use this value to document significant changes in your template to ensure you're deploying the right template. apiProfile An optional section that defines a collection of API versions for resource types.You can use this value to avoid having to specify API versions for each resource in the template. parameters An optional section where you define values that are provided during deployment.These values can be provided by a parameter file, by command-line parameters, or in the Azure portal. variables An optional section where you define values that are used to simplify template language expressions. functions An optional section where you can define user-defined functions that are available within the template.User-defined functions can simplify your template when complicated expressions are used repeatedly in your template. resources A required section that defines the actual items you want to deploy or update in a resource group or a subscription. output An optional section where you specify the values that will be returned at the end of the deployment.","title":"ARM template file structure"},{"location":"cloud/az-104/#reference","text":"https://learn.microsoft.com/fr-fr/training/paths/az-104-administrator-prerequisites/","title":"Reference"},{"location":"cloud/azure/","text":"Microsoft Azure Journalisation \u00e0 l\u2019aide d\u2019Azure CLI La version actuelle d\u2019Azure CLI ne vous permet pas de g\u00e9rer la journalisation des applications dans Stockage Blob. Activer Pour activer la journalisation des applications dans le syst\u00e8me de fichiers, ex\u00e9cutez cette commande : az webapp log config - -application-logging true - -level verbose - -name < app-name > - -resource-group < resource-group-name > Par exemple, pour activer la journalisation dans le syst\u00e8me de fichiers pour une application appel\u00e9e contosofashions123 en capturant tous les messages, ex\u00e9cutez cette commande. az webapp log config - -application-logging true - -level verbose - -name contosofashions123 - -resource-group contosofashionsRG Il n\u2019existe actuellement aucun moyen de d\u00e9sactiver la journalisation des applications \u00e0 l\u2019aide de commandes Azure CLI. Reset Toutefois, la commande suivante permet de r\u00e9initialiser la journalisation dans le syst\u00e8me de fichiers au niveau erreur simplement. az webapp log config - -application-logging false - -name < app-name > - -resource-group < resource-group-name > Status Pour conna\u00eetre l\u2019\u00e9tat actuel de la journalisation d\u2019une application, utilisez cette commande. az webapp log show - -name < app-name > - -resource-group < resource-group-name >","title":"Microsoft Azure"},{"location":"cloud/azure/#microsoft-azure","text":"","title":"Microsoft Azure"},{"location":"cloud/azure/#journalisation-a-laide-dazure-cli","text":"La version actuelle d\u2019Azure CLI ne vous permet pas de g\u00e9rer la journalisation des applications dans Stockage Blob.","title":"Journalisation \u00e0 l\u2019aide d\u2019Azure CLI"},{"location":"cloud/azure/#activer","text":"Pour activer la journalisation des applications dans le syst\u00e8me de fichiers, ex\u00e9cutez cette commande : az webapp log config - -application-logging true - -level verbose - -name < app-name > - -resource-group < resource-group-name > Par exemple, pour activer la journalisation dans le syst\u00e8me de fichiers pour une application appel\u00e9e contosofashions123 en capturant tous les messages, ex\u00e9cutez cette commande. az webapp log config - -application-logging true - -level verbose - -name contosofashions123 - -resource-group contosofashionsRG Il n\u2019existe actuellement aucun moyen de d\u00e9sactiver la journalisation des applications \u00e0 l\u2019aide de commandes Azure CLI.","title":"Activer"},{"location":"cloud/azure/#reset","text":"Toutefois, la commande suivante permet de r\u00e9initialiser la journalisation dans le syst\u00e8me de fichiers au niveau erreur simplement. az webapp log config - -application-logging false - -name < app-name > - -resource-group < resource-group-name >","title":"Reset"},{"location":"cloud/azure/#status","text":"Pour conna\u00eetre l\u2019\u00e9tat actuel de la journalisation d\u2019une application, utilisez cette commande. az webapp log show - -name < app-name > - -resource-group < resource-group-name >","title":"Status"},{"location":"cloud/cgp/","text":"Google Cloud Platforme Here are somes aws tips & tricks in progress..","title":"Google Cloud Platforme"},{"location":"cloud/cgp/#google-cloud-platforme","text":"Here are somes aws tips & tricks in progress..","title":"Google Cloud Platforme"},{"location":"cloud/kvm/","text":"QEMU-KVM How to convert ? How to convert qcow2 virtual disk file ? : qemu-img convert -f qcow2 qcow2_file_name -O vdi vdi_file_name Example : Format centos7_64.qcow2 image to vdi file : qemu-img convert -f qcow2 centos7_64.qcow2 -O vdi centos7_64.vdi","title":"QEMU-KVM"},{"location":"cloud/kvm/#qemu-kvm","text":"","title":"QEMU-KVM"},{"location":"cloud/kvm/#how-to-convert","text":"How to convert qcow2 virtual disk file ? : qemu-img convert -f qcow2 qcow2_file_name -O vdi vdi_file_name","title":"How to convert ?"},{"location":"cloud/kvm/#example","text":"Format centos7_64.qcow2 image to vdi file : qemu-img convert -f qcow2 centos7_64.qcow2 -O vdi centos7_64.vdi","title":"Example :"},{"location":"cloud/oci/","text":"Oracle Cloud Infrastructure Here are somes oci tips & tricks in progress..","title":"Oracle Cloud Infrastructure"},{"location":"cloud/oci/#oracle-cloud-infrastructure","text":"Here are somes oci tips & tricks in progress..","title":"Oracle Cloud Infrastructure"},{"location":"cloud/pve/","text":"Proxmox Virtual Environment Subscription How to remove Proxmox proxy subscription pop up ? Change to Active Situated at the line ~120 Change the status to Active : sed -i.bak 's/notfound/active/g' /usr/share/perl5/PVE/API2/Subscription.pm sed -i.bak 's/There is no subscription key/It seams to be active right ?/' /usr/share/perl5/PVE/API2/Subscription.pm Restart service Restart pveproxy service & refresh next your web page : systemctl restart pveproxy.service Grub /etc/default/grub GRUB_DISTRIBUTOR = \"Proxmox Virtual Environnement\" GRUB_CMDLINE_LINUX_DEFAULT = \"quiet intel_iommu=on\" GRUB_CMDLINE_LINUX = \"consoleblank=300\" Apply grub modifications update-grub or grub-mkconfig -o /boot/grub/grub.cfg or grub2-mkconfig -o /boot/grub2/grub.cfg Modules /etc/modules # Virtual Function I/O vfio vfio_iommu_type1 vfio_pci vfio_virqfd # Chip drivers coretemp Update initramfs update-initramfs -u -k all Repositories /etc/apt/sources.list # not for production use deb http://download.proxmox.com/debian buster pve-no-subscription /etc/apt/sources.list.d/pve-enterprise.list # deb https://enterprise.proxmox.com/debian/pve bullseye pve-enterprise","title":"Proxmox Virtual Environment"},{"location":"cloud/pve/#proxmox-virtual-environment","text":"","title":"Proxmox Virtual Environment"},{"location":"cloud/pve/#subscription","text":"How to remove Proxmox proxy subscription pop up ?","title":"Subscription"},{"location":"cloud/pve/#change-to-active","text":"Situated at the line ~120 Change the status to Active : sed -i.bak 's/notfound/active/g' /usr/share/perl5/PVE/API2/Subscription.pm sed -i.bak 's/There is no subscription key/It seams to be active right ?/' /usr/share/perl5/PVE/API2/Subscription.pm","title":"Change to Active"},{"location":"cloud/pve/#restart-service","text":"Restart pveproxy service & refresh next your web page : systemctl restart pveproxy.service","title":"Restart service"},{"location":"cloud/pve/#grub","text":"/etc/default/grub GRUB_DISTRIBUTOR = \"Proxmox Virtual Environnement\" GRUB_CMDLINE_LINUX_DEFAULT = \"quiet intel_iommu=on\" GRUB_CMDLINE_LINUX = \"consoleblank=300\"","title":"Grub"},{"location":"cloud/pve/#apply-grub-modifications","text":"update-grub or grub-mkconfig -o /boot/grub/grub.cfg or grub2-mkconfig -o /boot/grub2/grub.cfg","title":"Apply grub modifications"},{"location":"cloud/pve/#modules","text":"/etc/modules # Virtual Function I/O vfio vfio_iommu_type1 vfio_pci vfio_virqfd # Chip drivers coretemp","title":"Modules"},{"location":"cloud/pve/#update-initramfs","text":"update-initramfs -u -k all","title":"Update initramfs"},{"location":"cloud/pve/#repositories","text":"/etc/apt/sources.list # not for production use deb http://download.proxmox.com/debian buster pve-no-subscription /etc/apt/sources.list.d/pve-enterprise.list # deb https://enterprise.proxmox.com/debian/pve bullseye pve-enterprise","title":"Repositories"},{"location":"cloud/readme/","text":"Cloud Infrastructure Cas d'usage Il \u00e9xiste en r\u00e9alist\u00e9 divers type de platformes dans le cloud. Chacune d'entre elle on leur sp\u00e9cificit\u00e9es. IAAS (Infrastructure en tant que service) Il contient les blocs de construction fondamentaux de l'informatique dans le cloud et donne habituellement acc\u00e8s \u00e0 des fonctionnalit\u00e9s de mise en r\u00e9seau, \u00e0 des ordinateurs (virtuels ou sur du mat\u00e9riel d\u00e9di\u00e9) et \u00e0 de l'espace de stockage de donn\u00e9es. Le service IaaS offre le niveau le plus \u00e9lev\u00e9 de flexibilit\u00e9 et de contr\u00f4le de gestion en ce qui concerne les ressources informatiques. Ce services est tr\u00e8s similaire aux ressources informatiques existantes avec lesquelles les services informatiques et les d\u00e9veloppeurs sont aujourd'hui familiaris\u00e9s. PAAS (Plate-forme en tant que service) Gr\u00e2ce au service PaaS, les entreprises n'ont plus besoin de g\u00e9rer l'infrastructure sous-jacente (en r\u00e8gle g\u00e9n\u00e9rale, le mat\u00e9riel et les syst\u00e8mes d'exploitation) et vous pouvez vous concentrer sur le d\u00e9ploiement et la gestion de vos applications. Vous \u00eates ainsi plus efficace, car vous n'avez pas \u00e0 vous soucier de l'approvisionnement des ressources, de la planification des capacit\u00e9s, de la maintenance logicielle, de l'application de correctifs ou de toute autre charge indiff\u00e9renci\u00e9e li\u00e9e \u00e0 l'ex\u00e9cution de votre application. SAAS (Logiciel en tant que service) Le logiciel en tant que service offre un produit final qui est ex\u00e9cut\u00e9 et g\u00e9r\u00e9 par le prestataire de services. Dans la plupart des cas, les personnes qui font r\u00e9f\u00e9rence au service Saas pensent aux applications des utilisateurs finaux. Avec une offre SaaS, vous n'avez pas \u00e0 vous soucier de la gestion du service ou de celle de l'infrastructure sous-jacente. Vous devez juste r\u00e9fl\u00e9chir \u00e0 l'utilisation de ce logiciel sp\u00e9cifique. Une messagerie Web dans laquelle vous pouvez envoyer et recevoir des e-mails sans avoir \u00e0 g\u00e9rer des ajouts de fonctionnalit\u00e9s ni \u00e0 effectuer la maintenance des serveurs et des syst\u00e8mes d'exploitation sur lesquels elle s'ex\u00e9cute est un exemple courant d'application SaaS. Memory sync && echo 3 > /proc/sys/vm/drop_caches","title":"Cloud Infrastructure"},{"location":"cloud/readme/#cloud-infrastructure","text":"","title":"Cloud Infrastructure"},{"location":"cloud/readme/#cas-dusage","text":"Il \u00e9xiste en r\u00e9alist\u00e9 divers type de platformes dans le cloud. Chacune d'entre elle on leur sp\u00e9cificit\u00e9es.","title":"Cas d'usage"},{"location":"cloud/readme/#iaas-infrastructure-en-tant-que-service","text":"Il contient les blocs de construction fondamentaux de l'informatique dans le cloud et donne habituellement acc\u00e8s \u00e0 des fonctionnalit\u00e9s de mise en r\u00e9seau, \u00e0 des ordinateurs (virtuels ou sur du mat\u00e9riel d\u00e9di\u00e9) et \u00e0 de l'espace de stockage de donn\u00e9es. Le service IaaS offre le niveau le plus \u00e9lev\u00e9 de flexibilit\u00e9 et de contr\u00f4le de gestion en ce qui concerne les ressources informatiques. Ce services est tr\u00e8s similaire aux ressources informatiques existantes avec lesquelles les services informatiques et les d\u00e9veloppeurs sont aujourd'hui familiaris\u00e9s.","title":"IAAS (Infrastructure en tant que service)"},{"location":"cloud/readme/#paas-plate-forme-en-tant-que-service","text":"Gr\u00e2ce au service PaaS, les entreprises n'ont plus besoin de g\u00e9rer l'infrastructure sous-jacente (en r\u00e8gle g\u00e9n\u00e9rale, le mat\u00e9riel et les syst\u00e8mes d'exploitation) et vous pouvez vous concentrer sur le d\u00e9ploiement et la gestion de vos applications. Vous \u00eates ainsi plus efficace, car vous n'avez pas \u00e0 vous soucier de l'approvisionnement des ressources, de la planification des capacit\u00e9s, de la maintenance logicielle, de l'application de correctifs ou de toute autre charge indiff\u00e9renci\u00e9e li\u00e9e \u00e0 l'ex\u00e9cution de votre application.","title":"PAAS (Plate-forme en tant que service)"},{"location":"cloud/readme/#saas-logiciel-en-tant-que-service","text":"Le logiciel en tant que service offre un produit final qui est ex\u00e9cut\u00e9 et g\u00e9r\u00e9 par le prestataire de services. Dans la plupart des cas, les personnes qui font r\u00e9f\u00e9rence au service Saas pensent aux applications des utilisateurs finaux. Avec une offre SaaS, vous n'avez pas \u00e0 vous soucier de la gestion du service ou de celle de l'infrastructure sous-jacente. Vous devez juste r\u00e9fl\u00e9chir \u00e0 l'utilisation de ce logiciel sp\u00e9cifique. Une messagerie Web dans laquelle vous pouvez envoyer et recevoir des e-mails sans avoir \u00e0 g\u00e9rer des ajouts de fonctionnalit\u00e9s ni \u00e0 effectuer la maintenance des serveurs et des syst\u00e8mes d'exploitation sur lesquels elle s'ex\u00e9cute est un exemple courant d'application SaaS.","title":"SAAS (Logiciel en tant que service)"},{"location":"cloud/readme/#memory","text":"sync && echo 3 > /proc/sys/vm/drop_caches","title":"Memory"},{"location":"cloud/vmware/","text":"VMware Rescan Storage How to rescan storage ? USB Datastore How to add an USB hard drive as Datastore ? Disabling usb arbitrator service Stopping /etc/init.d/usbarbitrator stop Disabling chkconfig usbarbitrator off Labeling partedUtil mklabel /dev/disks/mpx.vmhba32:C0:T0:L0 gpt Get the partition table \u26a0\ufe0f This command will bring you a number : eval expr $( partedUtil getptbl /dev/disks/mpx.vmhba32:C0:T0:L0 | tail -1 | awk '{print $1 \" \\\\* \" $2 \" \\\\* \" $3}' ) - 1 Dont forget to fill the number found : partedUtil setptbl /dev/disks/mpx.vmhba32:C0:T0:L0 gpt \"1 2048 ${ NUMBER } AA31E02A400F11DB9590000C2911D1B8 0\" Last step vmkfstools -C vmfs6 -S USB-Datastore /dev/disks/mpx.vmhba32:C0:T0:L0:1 License Removing License rm -r /etc/vmware/license.cfg Get a new trial license cp /etc/vmware/.#license.cfg /etc/vmware/license.cfg Restarting VPXA /etc/init.d/vpxa restart","title":"VMware"},{"location":"cloud/vmware/#vmware","text":"","title":"VMware"},{"location":"cloud/vmware/#rescan-storage","text":"How to rescan storage ?","title":"Rescan Storage"},{"location":"cloud/vmware/#usb-datastore","text":"How to add an USB hard drive as Datastore ?","title":"USB Datastore"},{"location":"cloud/vmware/#disabling-usb-arbitrator-service","text":"","title":"Disabling usb arbitrator service"},{"location":"cloud/vmware/#stopping","text":"/etc/init.d/usbarbitrator stop","title":"Stopping"},{"location":"cloud/vmware/#disabling","text":"chkconfig usbarbitrator off","title":"Disabling"},{"location":"cloud/vmware/#labeling","text":"partedUtil mklabel /dev/disks/mpx.vmhba32:C0:T0:L0 gpt","title":"Labeling"},{"location":"cloud/vmware/#get-the-partition-table","text":"\u26a0\ufe0f This command will bring you a number : eval expr $( partedUtil getptbl /dev/disks/mpx.vmhba32:C0:T0:L0 | tail -1 | awk '{print $1 \" \\\\* \" $2 \" \\\\* \" $3}' ) - 1 Dont forget to fill the number found : partedUtil setptbl /dev/disks/mpx.vmhba32:C0:T0:L0 gpt \"1 2048 ${ NUMBER } AA31E02A400F11DB9590000C2911D1B8 0\"","title":"Get the partition table"},{"location":"cloud/vmware/#last-step","text":"vmkfstools -C vmfs6 -S USB-Datastore /dev/disks/mpx.vmhba32:C0:T0:L0:1","title":"Last step"},{"location":"cloud/vmware/#license","text":"","title":"License"},{"location":"cloud/vmware/#removing-license","text":"rm -r /etc/vmware/license.cfg","title":"Removing License"},{"location":"cloud/vmware/#get-a-new-trial-license","text":"cp /etc/vmware/.#license.cfg /etc/vmware/license.cfg","title":"Get a new trial license"},{"location":"cloud/vmware/#restarting-vpxa","text":"/etc/init.d/vpxa restart","title":"Restarting VPXA"},{"location":"dev/docker/","text":"Docker Lister les processus en cours : docker ps -a Images Chaque processus d\u00e9pendera d'une image pareil \u00e0 une iso + son appli pour une vm. Chercher une image : docker search nginx T\u00e9l\u00e9charger une image : docker pull nginx Lister les images t\u00e9l\u00e9charg\u00e9es : docker images ou docker image ls Supprimer une image : docker rmi nginx \u26a0 Si une image est sur le disque mais nous est impossible de supprimer (on parlera d'une image souvent test\u00e9 \u00e0 l'installation de docker) Nous allons devoir forcer sa suppression : docker rmi -f hello-world Voir l'historique de son image : docker history sboistel/image:verison ( 1 .1 ) Commit Apr\u00e8s avoir fait des changements sur une image, comment enregister tout \u00e7a ? docker commit mycentos01 sboistel/mycentos:1.0 DockerFile Cr\u00e9er un docker file : vim dockerfile FROM centos RPM yum install -y wget RPM yum install yum-utils Warning Plus il y aura de nombre de ligne dans le dockerfile, plus le nombre de couche sera important et engedra les performences. Construire l'image : docker build -t sboistel/mycentos:1.0 docker build -t mon_image:v1.0 Champs Liste des diff\u00e9rents champs compl\u00e9table : FROM : Pour les images vierge seuelement ! LABEL version : Donner une version LABEL description : D\u00e9crire la version ENV : Variable d'environnement : Example JAVA_HOME /usr/bin/java ORACLE_HOME /u01/app/oracle/$ORACLE_SID/ RUN : Commande \u00e0 effectuer \"yum install ..\" WORKDIR : Emplacement de travail ... Run / Exec Plusieurs arguments serrons ici utilis\u00e9s : t : Avoir un terminal en sortie i : Interactif Exemple : docker run -ti ubuntu Ex\u00e9cuter une commande dans l'environnement Bash : docker run -ti ubuntu ps Ex\u00e9cuter une commande dans un conteneur d\u00e9tach\u00e9 en cours d'\u00e9x\u00e9cution : docker exec -name = container01 -hostname = host01 centos ping 127 .0.0.1 Attach\u00e9 / Non Attach\u00e9 Ex\u00e9cuter l'image ubuntu avec des param\u00e8tres d'attachements : docker run --name = container01 --hostname = host01 -it ubuntu Ex\u00e9cuter l'image ubuntu avec des param\u00e8tres de d\u00e9tachement : docker run -d -it centos ping 127 .0.0.1 Du coup, o\u00f9 se passes les informations du conteneur d\u00e9tach\u00e9 ? : docker logs ID_DU_CONTAINER Rappel pour avoir l'id du conteneur : docker ps Afin de r\u00e9ccup\u00e9rer la main sur la session du conteneur d\u00e9tach\u00e9 : docker attache ID_DU_CONTAINER Revenir au mode d\u00e9tach\u00e9, faire la combinaison suivante : CTRL + Q Inspecter un conteneur Avoir les informations du conteneur en format json : docker inspect container01 Agr\u00e9gation de recherche R\u00e9colter seulement ce qui nous int\u00e9r\u00e8sse ? Avoir un status docker inspect --format = '![](./Docker/.State.Status)' container01 Avoir l'iP du container01 docker inspect --format = '![](./Docker/.NetworkSettings.IPAddress)' container01 R\u00e9ccolter le tableau State : docker inspect --format = '![](./Docker/json .State)' container01 Filtres Filtrer tout les conteneur ayant comme nom web : docker ps -a --filter name = web Filtrer tout les conteneurs ayant un status ferm\u00e9 : docker ps -a --filter status = exited Formater l'affichage Formater la sortie : docker ps -a --format \"![](./Docker/.Names) : ![](./Docker/.Status)\" Import / Export Export Comment exporter son image ? docker export -o mycentos01.tar mycentos V\u00e9rifier son export : tar tvf mycentos01.tar Tout est ok, je compresse : gzip mycentos01.tar Import Comment import une image export\u00e9e ? : docker import mycentos.tar.gz mycentos:1.0 Containers L'objectif de la conteneurisation est de faire en sorte qu'un ensemble logiciel coh\u00e9rent puisse fonctionner au sein d'un conteneur. Pour qu'une application puisse tourner au sein d'un conteneur, elle doit \u00eatre empaquet\u00e9e, c'est \u00e0 dire qu'on la met \u00e0 l'int\u00e9rieur d'un paquet (une image dans la terminologie des conteneurs) avec ses d\u00e9pendances. Il existe d'ailleurs des images officielles, sur le Hub Docker par exemple, permettant de faire tourner tout type de logiciel (MySQL, Java 8, wordpresse, etc). Type de syst\u00e8me Il y a plusieurs type de syst\u00e8me de conteneurisation. Dotcloud plus connu sous le nom de Docker sera de moins en moins utilis\u00e9 car tant \u00e0 le d\u00e9pr\u00e9cier. On trouvera aussi : CoreOS Mesos LXC OpenVZ Containerd etc ... Dockerless ================================================================================ To run Docker as a non-privileged user, consider setting up the Docker daemon in rootless mode for your user: dockerd-rootless-setuptool.sh install Visit https://docs.docker.com/go/rootless/ to learn about rootless mode. To run the Docker daemon as a fully privileged service, but granting non-root users access, refer to https://docs.docker.com/go/daemon-access/ WARNING: Access to the remote API on a privileged Docker daemon is equivalent to root access on the host. Refer to the 'Docker daemon attack surface' documentation for details: https://docs.docker.com/go/attack-surface/ ================================================================================","title":"Docker"},{"location":"dev/docker/#docker","text":"Lister les processus en cours : docker ps -a","title":"Docker"},{"location":"dev/docker/#images","text":"Chaque processus d\u00e9pendera d'une image pareil \u00e0 une iso + son appli pour une vm. Chercher une image : docker search nginx T\u00e9l\u00e9charger une image : docker pull nginx Lister les images t\u00e9l\u00e9charg\u00e9es : docker images ou docker image ls Supprimer une image : docker rmi nginx \u26a0 Si une image est sur le disque mais nous est impossible de supprimer (on parlera d'une image souvent test\u00e9 \u00e0 l'installation de docker) Nous allons devoir forcer sa suppression : docker rmi -f hello-world Voir l'historique de son image : docker history sboistel/image:verison ( 1 .1 )","title":"Images"},{"location":"dev/docker/#commit","text":"Apr\u00e8s avoir fait des changements sur une image, comment enregister tout \u00e7a ? docker commit mycentos01 sboistel/mycentos:1.0","title":"Commit"},{"location":"dev/docker/#dockerfile","text":"Cr\u00e9er un docker file : vim dockerfile FROM centos RPM yum install -y wget RPM yum install yum-utils Warning Plus il y aura de nombre de ligne dans le dockerfile, plus le nombre de couche sera important et engedra les performences. Construire l'image : docker build -t sboistel/mycentos:1.0 docker build -t mon_image:v1.0","title":"DockerFile"},{"location":"dev/docker/#champs","text":"Liste des diff\u00e9rents champs compl\u00e9table : FROM : Pour les images vierge seuelement ! LABEL version : Donner une version LABEL description : D\u00e9crire la version ENV : Variable d'environnement : Example JAVA_HOME /usr/bin/java ORACLE_HOME /u01/app/oracle/$ORACLE_SID/ RUN : Commande \u00e0 effectuer \"yum install ..\" WORKDIR : Emplacement de travail ...","title":"Champs"},{"location":"dev/docker/#run-exec","text":"Plusieurs arguments serrons ici utilis\u00e9s : t : Avoir un terminal en sortie i : Interactif","title":"Run / Exec"},{"location":"dev/docker/#exemple","text":"docker run -ti ubuntu Ex\u00e9cuter une commande dans l'environnement Bash : docker run -ti ubuntu ps Ex\u00e9cuter une commande dans un conteneur d\u00e9tach\u00e9 en cours d'\u00e9x\u00e9cution : docker exec -name = container01 -hostname = host01 centos ping 127 .0.0.1","title":"Exemple :"},{"location":"dev/docker/#attache-non-attache","text":"Ex\u00e9cuter l'image ubuntu avec des param\u00e8tres d'attachements : docker run --name = container01 --hostname = host01 -it ubuntu Ex\u00e9cuter l'image ubuntu avec des param\u00e8tres de d\u00e9tachement : docker run -d -it centos ping 127 .0.0.1 Du coup, o\u00f9 se passes les informations du conteneur d\u00e9tach\u00e9 ? : docker logs ID_DU_CONTAINER Rappel pour avoir l'id du conteneur : docker ps Afin de r\u00e9ccup\u00e9rer la main sur la session du conteneur d\u00e9tach\u00e9 : docker attache ID_DU_CONTAINER Revenir au mode d\u00e9tach\u00e9, faire la combinaison suivante : CTRL + Q","title":"Attach\u00e9 / Non Attach\u00e9"},{"location":"dev/docker/#inspecter-un-conteneur","text":"Avoir les informations du conteneur en format json : docker inspect container01","title":"Inspecter un conteneur"},{"location":"dev/docker/#agregation-de-recherche","text":"R\u00e9colter seulement ce qui nous int\u00e9r\u00e8sse ? Avoir un status docker inspect --format = '![](./Docker/.State.Status)' container01 Avoir l'iP du container01 docker inspect --format = '![](./Docker/.NetworkSettings.IPAddress)' container01 R\u00e9ccolter le tableau State : docker inspect --format = '![](./Docker/json .State)' container01","title":"Agr\u00e9gation de recherche"},{"location":"dev/docker/#filtres","text":"Filtrer tout les conteneur ayant comme nom web : docker ps -a --filter name = web Filtrer tout les conteneurs ayant un status ferm\u00e9 : docker ps -a --filter status = exited","title":"Filtres"},{"location":"dev/docker/#formater-laffichage","text":"Formater la sortie : docker ps -a --format \"![](./Docker/.Names) : ![](./Docker/.Status)\"","title":"Formater l'affichage"},{"location":"dev/docker/#import-export","text":"","title":"Import / Export"},{"location":"dev/docker/#export","text":"Comment exporter son image ? docker export -o mycentos01.tar mycentos V\u00e9rifier son export : tar tvf mycentos01.tar Tout est ok, je compresse : gzip mycentos01.tar","title":"Export"},{"location":"dev/docker/#import","text":"Comment import une image export\u00e9e ? : docker import mycentos.tar.gz mycentos:1.0","title":"Import"},{"location":"dev/docker/#containers","text":"L'objectif de la conteneurisation est de faire en sorte qu'un ensemble logiciel coh\u00e9rent puisse fonctionner au sein d'un conteneur. Pour qu'une application puisse tourner au sein d'un conteneur, elle doit \u00eatre empaquet\u00e9e, c'est \u00e0 dire qu'on la met \u00e0 l'int\u00e9rieur d'un paquet (une image dans la terminologie des conteneurs) avec ses d\u00e9pendances. Il existe d'ailleurs des images officielles, sur le Hub Docker par exemple, permettant de faire tourner tout type de logiciel (MySQL, Java 8, wordpresse, etc).","title":"Containers"},{"location":"dev/docker/#type-de-systeme","text":"Il y a plusieurs type de syst\u00e8me de conteneurisation. Dotcloud plus connu sous le nom de Docker sera de moins en moins utilis\u00e9 car tant \u00e0 le d\u00e9pr\u00e9cier. On trouvera aussi : CoreOS Mesos LXC OpenVZ Containerd etc ...","title":"Type de syst\u00e8me"},{"location":"dev/docker/#dockerless","text":"================================================================================ To run Docker as a non-privileged user, consider setting up the Docker daemon in rootless mode for your user: dockerd-rootless-setuptool.sh install Visit https://docs.docker.com/go/rootless/ to learn about rootless mode. To run the Docker daemon as a fully privileged service, but granting non-root users access, refer to https://docs.docker.com/go/daemon-access/ WARNING: Access to the remote API on a privileged Docker daemon is equivalent to root access on the host. Refer to the 'Docker daemon attack surface' documentation for details: https://docs.docker.com/go/attack-surface/ ================================================================================","title":"Dockerless"},{"location":"dev/elastik/","text":"Elasticsearch / Logstash / Kibana Pr\u00e9sentation Description de stack ELK D\u00e9ploiement et savoir faire Mise en place de r\u00e9ccup\u00e9ration des m\u00e9trics ? -> Audite Prerequis : Centos 7 4G RAM 2 CPU https://www.elastic.co/guide/en/cloud-enterprise/2.1/ece-prereqs.html https://grokdebug.herokuapp.com/ /usr/share/elasticsearch/bin/elasticsearch-setup-passwords interactive curl -X PUT \"localhost:9200/elk-001?pretty\" SSH Port Forward list : ssh -L 127.0.0.1:8080:local_ip:80 user@ip # centreon ssh -L 127.0.0.1:5601:local_ip:5601 user@ip # kibana ssh -L 127.0.0.1:9200:local_ip:9200 user@ip # elasticsearch FileBeat : curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.11.1-x86_64.rpm rpm -vi filebeat-7.11.1-x86_64.rpm MetricBeat : curl -L -O https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-7.11.1-x86_64.rpm rpm -vi metricbeat-7.11.1-x86_64.rpm Elasticsearch Elasticsearch is composed by : LOGSTASH KIBANA X-PACK BEATS LOGSTASH Logstash is an event processing pipeline KIBANA Kibana is a monitoring analyse platforme which allow human to easly read elasticsearch datas We can call Kibana as the elasticsearch's dashboard X-PACK Is a packe of features for Kibana Security Monitoring Alerting Reporting Machine Learning Abnormality Detection Forcasting Graph Elasticsearch SQL BEATS Beats farm data for logstash","title":"Elasticsearch / Logstash / Kibana"},{"location":"dev/elastik/#elasticsearch-logstash-kibana","text":"","title":"Elasticsearch / Logstash / Kibana"},{"location":"dev/elastik/#presentation","text":"Description de stack ELK D\u00e9ploiement et savoir faire Mise en place de r\u00e9ccup\u00e9ration des m\u00e9trics ? -> Audite","title":"Pr\u00e9sentation"},{"location":"dev/elastik/#prerequis","text":"Centos 7 4G RAM 2 CPU https://www.elastic.co/guide/en/cloud-enterprise/2.1/ece-prereqs.html https://grokdebug.herokuapp.com/ /usr/share/elasticsearch/bin/elasticsearch-setup-passwords interactive curl -X PUT \"localhost:9200/elk-001?pretty\"","title":"Prerequis :"},{"location":"dev/elastik/#ssh-port-forward-list","text":"ssh -L 127.0.0.1:8080:local_ip:80 user@ip # centreon ssh -L 127.0.0.1:5601:local_ip:5601 user@ip # kibana ssh -L 127.0.0.1:9200:local_ip:9200 user@ip # elasticsearch","title":"SSH Port Forward list :"},{"location":"dev/elastik/#filebeat","text":"curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.11.1-x86_64.rpm rpm -vi filebeat-7.11.1-x86_64.rpm","title":"FileBeat :"},{"location":"dev/elastik/#metricbeat","text":"curl -L -O https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-7.11.1-x86_64.rpm rpm -vi metricbeat-7.11.1-x86_64.rpm","title":"MetricBeat :"},{"location":"dev/elastik/#elasticsearch","text":"Elasticsearch is composed by : LOGSTASH KIBANA X-PACK BEATS","title":"Elasticsearch"},{"location":"dev/elastik/#logstash","text":"Logstash is an event processing pipeline","title":"LOGSTASH"},{"location":"dev/elastik/#kibana","text":"Kibana is a monitoring analyse platforme which allow human to easly read elasticsearch datas We can call Kibana as the elasticsearch's dashboard","title":"KIBANA"},{"location":"dev/elastik/#x-pack","text":"Is a packe of features for Kibana Security Monitoring Alerting Reporting Machine Learning Abnormality Detection Forcasting Graph Elasticsearch SQL","title":"X-PACK"},{"location":"dev/elastik/#beats","text":"Beats farm data for logstash","title":"BEATS"},{"location":"dev/git/","text":"Git Here are somes git tips & tricks Using Git The following commands can be helpful for working with git . git command Comment git init Initialize a directory as git managed repository git clone <repo_url> Clone a remote repository to your local client git status Shows uncommited changes, new files etc. git add <wildcard_or_filename> Stage an updated / new file to the next commit git rm <wildcard_or_filename> Remove a file and stage the removal for the next commit git commit -m \"<commit message\"> Commit staged changes under a new commit git commit Will open an editor to write more descriptive commit messages. See here for a guide on good commit messages git checkout <branch_name> Switch to another branch git branch Shows a list of existing branches git branch <branch_name> Creates a new branch (from the currently checked out branch) git merge <branch_name> Merge changes from branch_name to the currently checked out branch git push Push commited changes to the remote repository git pull Pull current state from the remote repository to your local repo Working with git-flow Git-flow assists you by combining multiple steps of git commands to one git-flow command which will do a workflow of steps. Although git-flow makes live easier in some cases, it makes it also more complex sometimes and you need to execute some steps before or after using a git-flow command as regular git command. (See below) As an example, here is the comparison between the regular git commands and the appropriate git-flow command for creating a release. git-flow command git command git-flow feature start <feature_name> git checkout -b feature/<feature_name> develop git-flow feature finish <feature_name> [--squash] git checkout develop git merge [--squash] --no-ff feature/<feature_name> git branch -d feature/<feature_name> Another git-flow cheat sheet can be found here . Config Username Ajout le nom d'utilisateur au profil git config --global user.name \"sboistel\" Mail Ajout le mail du profil git config --global user.email \" sboistel@mail.com \" Credentials Garder en m\u00e9moire les donn\u00e9es de connexion au repo : git config credential.helper store Branches Lister les Branches git branche Checkout V\u00e9rifier quel est la branche sur laquelle nous sommes: git checkout Changer de branche : git checkout nom_branche Manage Push Push vers vers une autre branche que Master : git push -u origin nom_branche Merge Se positionner sur la branche master (principale..), et ensuite git merge nom_branche Ne pas omettre de push ensuite ;) git push Stash Le stash permet de garder les modifications faites en local sans les propager. On pourra v\u00e9rifier ce qu'il est possible de save : git stash list Clear la liste stash git stash clear Commiter un stash git stash pop","title":"Git"},{"location":"dev/git/#git","text":"Here are somes git tips & tricks","title":"Git"},{"location":"dev/git/#using-git","text":"The following commands can be helpful for working with git . git command Comment git init Initialize a directory as git managed repository git clone <repo_url> Clone a remote repository to your local client git status Shows uncommited changes, new files etc. git add <wildcard_or_filename> Stage an updated / new file to the next commit git rm <wildcard_or_filename> Remove a file and stage the removal for the next commit git commit -m \"<commit message\"> Commit staged changes under a new commit git commit Will open an editor to write more descriptive commit messages. See here for a guide on good commit messages git checkout <branch_name> Switch to another branch git branch Shows a list of existing branches git branch <branch_name> Creates a new branch (from the currently checked out branch) git merge <branch_name> Merge changes from branch_name to the currently checked out branch git push Push commited changes to the remote repository git pull Pull current state from the remote repository to your local repo","title":"Using Git"},{"location":"dev/git/#working-with-git-flow","text":"Git-flow assists you by combining multiple steps of git commands to one git-flow command which will do a workflow of steps. Although git-flow makes live easier in some cases, it makes it also more complex sometimes and you need to execute some steps before or after using a git-flow command as regular git command. (See below) As an example, here is the comparison between the regular git commands and the appropriate git-flow command for creating a release. git-flow command git command git-flow feature start <feature_name> git checkout -b feature/<feature_name> develop git-flow feature finish <feature_name> [--squash] git checkout develop git merge [--squash] --no-ff feature/<feature_name> git branch -d feature/<feature_name> Another git-flow cheat sheet can be found here .","title":"Working with git-flow"},{"location":"dev/git/#config","text":"","title":"Config"},{"location":"dev/git/#username","text":"Ajout le nom d'utilisateur au profil git config --global user.name \"sboistel\"","title":"Username"},{"location":"dev/git/#mail","text":"Ajout le mail du profil git config --global user.email \" sboistel@mail.com \"","title":"Mail"},{"location":"dev/git/#credentials","text":"Garder en m\u00e9moire les donn\u00e9es de connexion au repo : git config credential.helper store","title":"Credentials"},{"location":"dev/git/#branches","text":"Lister les Branches git branche","title":"Branches"},{"location":"dev/git/#checkout","text":"V\u00e9rifier quel est la branche sur laquelle nous sommes: git checkout Changer de branche : git checkout nom_branche","title":"Checkout"},{"location":"dev/git/#manage","text":"","title":"Manage"},{"location":"dev/git/#push","text":"Push vers vers une autre branche que Master : git push -u origin nom_branche","title":"Push"},{"location":"dev/git/#merge","text":"Se positionner sur la branche master (principale..), et ensuite git merge nom_branche Ne pas omettre de push ensuite ;) git push","title":"Merge"},{"location":"dev/git/#stash","text":"Le stash permet de garder les modifications faites en local sans les propager. On pourra v\u00e9rifier ce qu'il est possible de save : git stash list Clear la liste stash git stash clear Commiter un stash git stash pop","title":"Stash"},{"location":"dev/kubernetes/","text":"Kubernetes Created Tuesday 25 January 2022 Kubernetes ou K8s (8 \u00e9tant le nombre de lettre dans Kubernetes) Kubernetes est un Orchestrateur (g\u00e8re des clusters) Il aura plusieurs notions : - Gestion des configurations - Gestion des mots de passe (secrets) - RBAC (Role base acces controler) \"IAM\" Lexique Kubelet : Deamond s'\u00e9x\u00e9cutant dans les workers Cluster Un cluster c'est quoi ? Un ensemble de noeud de type linux ou windows Pods Un cluster \u00e9xecute des pods, mais de quoi s'agit-il ? Il s'agit d'un ensemble de conteneurs se partageant les ressources. Lister les pods : kubectl get pods Tester les ports : kubectl port-forward POD_NAME 8000 :80 R\u00e9ccup\u00e9rer les \u00e9l\u00e8ments d'un pod : kubectl describe po/POD_NAME Service Les service exposent les ports d'un pod Nodes Deux types de noeud : Que font les Master ? Gestion du cluster Orchestre l'\u00e9x\u00e9cution des pods sur les noeuds Expose l'API server Que font les Marker ? Ex\u00e9cute les pods Fournit les ressources aux pods Communique avec le master (actions \u00e0 ex\u00e9cuter ...) Lister les noeuds : kubectl get nodes","title":"Kubernetes"},{"location":"dev/kubernetes/#kubernetes","text":"Created Tuesday 25 January 2022 Kubernetes ou K8s (8 \u00e9tant le nombre de lettre dans Kubernetes) Kubernetes est un Orchestrateur (g\u00e8re des clusters) Il aura plusieurs notions : - Gestion des configurations - Gestion des mots de passe (secrets) - RBAC (Role base acces controler) \"IAM\"","title":"Kubernetes"},{"location":"dev/kubernetes/#lexique","text":"Kubelet : Deamond s'\u00e9x\u00e9cutant dans les workers","title":"Lexique"},{"location":"dev/kubernetes/#cluster","text":"Un cluster c'est quoi ? Un ensemble de noeud de type linux ou windows","title":"Cluster"},{"location":"dev/kubernetes/#pods","text":"Un cluster \u00e9xecute des pods, mais de quoi s'agit-il ? Il s'agit d'un ensemble de conteneurs se partageant les ressources. Lister les pods : kubectl get pods Tester les ports : kubectl port-forward POD_NAME 8000 :80 R\u00e9ccup\u00e9rer les \u00e9l\u00e8ments d'un pod : kubectl describe po/POD_NAME","title":"Pods"},{"location":"dev/kubernetes/#service","text":"Les service exposent les ports d'un pod","title":"Service"},{"location":"dev/kubernetes/#nodes","text":"Deux types de noeud : Que font les Master ? Gestion du cluster Orchestre l'\u00e9x\u00e9cution des pods sur les noeuds Expose l'API server Que font les Marker ? Ex\u00e9cute les pods Fournit les ressources aux pods Communique avec le master (actions \u00e0 ex\u00e9cuter ...) Lister les noeuds : kubectl get nodes","title":"Nodes"},{"location":"dev/multipass/","text":"Multipass Multipass is a tool to generate cloud-style Ubuntu VMs quickly on Linux, macOS, and Windows. Commands Commands Description alias Create an alias aliases List available aliases authenticate Authenticate client delete Delete instances exec Run a command on an instance find Display available images to create instances from get Get a configuration setting help Display help about a command info Display information about instances launch Create and start an Ubuntu instance list List all available instances mount Mount a local directory in the instance networks List available network interfaces purge Purge all deleted instances permanently recover Recover deleted instances restart Restart instances set Set a configuration setting shell Open a shell on a running instance start Start instances stop Stop running instances suspend Suspend running instances transfer Transfer files between the host and instances umount Unmount a directory from an instance unalias Remove aliases version Show version details Installation brew install --cask multipass Version multipass version $ multipass version multipass 1 .11.1+mac multipassd 1 .11.1+mac Gather List Syntax : multipass list Example : $ multipass list Name State IPv4 Image test1 Running 192 .168.64.17 Ubuntu 22 .04 LTS Infos Syntax : multipass info $VM Example : $ multipass info test1 Name: test1 State: Running IPv4: 192 .168.64.17 Release: Ubuntu 22 .04.1 LTS Image hash: 8593ce1c6bbd ( Ubuntu 22 .04 LTS ) CPU ( s ) : 1 Load: 0 .32 0 .17 0 .06 Disk usage: 1 .4GiB out of 4 .7GiB Memory usage: 150 .8MiB out of 962 .7MiB Mounts: -- Launch Syntax : multipass launch -n $VM Connect to VM multipass shell $VM References https://multipass.run/docs/","title":"Multipass"},{"location":"dev/multipass/#multipass","text":"Multipass is a tool to generate cloud-style Ubuntu VMs quickly on Linux, macOS, and Windows.","title":"Multipass"},{"location":"dev/multipass/#commands","text":"Commands Description alias Create an alias aliases List available aliases authenticate Authenticate client delete Delete instances exec Run a command on an instance find Display available images to create instances from get Get a configuration setting help Display help about a command info Display information about instances launch Create and start an Ubuntu instance list List all available instances mount Mount a local directory in the instance networks List available network interfaces purge Purge all deleted instances permanently recover Recover deleted instances restart Restart instances set Set a configuration setting shell Open a shell on a running instance start Start instances stop Stop running instances suspend Suspend running instances transfer Transfer files between the host and instances umount Unmount a directory from an instance unalias Remove aliases version Show version details","title":"Commands"},{"location":"dev/multipass/#installation","text":"brew install --cask multipass","title":"Installation"},{"location":"dev/multipass/#version","text":"multipass version $ multipass version multipass 1 .11.1+mac multipassd 1 .11.1+mac","title":"Version"},{"location":"dev/multipass/#gather","text":"","title":"Gather"},{"location":"dev/multipass/#list","text":"Syntax : multipass list Example : $ multipass list Name State IPv4 Image test1 Running 192 .168.64.17 Ubuntu 22 .04 LTS","title":"List"},{"location":"dev/multipass/#infos","text":"Syntax : multipass info $VM Example : $ multipass info test1 Name: test1 State: Running IPv4: 192 .168.64.17 Release: Ubuntu 22 .04.1 LTS Image hash: 8593ce1c6bbd ( Ubuntu 22 .04 LTS ) CPU ( s ) : 1 Load: 0 .32 0 .17 0 .06 Disk usage: 1 .4GiB out of 4 .7GiB Memory usage: 150 .8MiB out of 962 .7MiB Mounts: --","title":"Infos"},{"location":"dev/multipass/#launch","text":"Syntax : multipass launch -n $VM","title":"Launch"},{"location":"dev/multipass/#connect-to-vm","text":"multipass shell $VM","title":"Connect to VM"},{"location":"dev/multipass/#references","text":"https://multipass.run/docs/","title":"References"},{"location":"dev/perl/","text":"Perl Perl tips & tricks Variable Scalaire Contenant une seule valeure : $ Liste Example : ('Toto', 'Titi', 'Tata') @ Hashs Le type de la variable hashs % Example de hashs : my %liste = ( Perl => 'Super' , Python => 'G\u00e9nial' ); print ( $liste { Python }); Fonctions split La fonction split permet de retirer un \u00e9l\u00e8ment s\u00e9parateur : my @liste = split ' ', $liste_d_element join La fonction join permet d'ins\u00e9rer un ou plusieurs \u00e9l\u00e8ment s\u00e9parateur dans une liste d'\u00e9l\u00e8ment : my @liste = join '; ', @liste_d_element Pragma Utiliser les pragma pour s\u00e9curiser son script. strict Erreur de syntaxe, avoir un code propre use strict; warning Avertissement d'erreur de syntaxe use warning; Sucre de syntaxe Afin d'\u00e9viter d'avoir un code illisible avec nos \"\" ou '', deux m\u00e9thodes sont applicables dans chacun des cas. Guillemet Pour substituer \"\" : qq/Chaine de carract\u00e8re/ Guillement Simple Pour substituer '' : q/Chaine de carract\u00e8re/ Liste Pour substituer une liste (ex : ('Toto', 'Titi', 'Tata')) : qw/Toto Titi Tata/ Here string OEF signifiant fin de ligne permet d'englober un parragraphe de donn\u00e9es : my $variable = << OEF ; ligne 1 de donn\u00e9es ligne 2 de donn\u00e9es ... EOF V\u00e9rifications Pr\u00e9dica 'if' V\u00e9rification de l'\u00e9xistance d'un \u00e9l\u00e8ment. use strict my $langages = ( Perl => 'super' , Python => 'geniale' , Ruby => 'ouais' , Pascal => 'bof' , C => 'bof, ' C ++ ' => ' bof ' ); if (exists $langages{Haskell}) { print (\"Mon langage est \", $langages{Haskell}, \"\\n\"); } elsif (exists $langages{Perl}) ( print (\"Mon langage est \", $langages{Perl}, \"\\n\"); ) else { print \"Haskell n' est pas d\u00e9fini !\\ n \" ; } Rendre son script int\u00e9ratif Standard input Chop retire le dernier carract\u00e8re Chomp retire le dernier carract\u00e8re seulement si celui-ci est un '\\n' Not\u00e9 STDIN , il sert \u00e0 poser une question \u00e0 l'utilisateur: use strict my $langages = ( Perl => 'super' , Python => 'geniale' , Ruby => 'ouais' , Pascal => 'bof' , C => 'bof, ' C ++ ' => ' bof ' ); print \"Entrer le nom d' un langage : \" chomp (my $response = <STDIN>); print (\" $response est $langages { $response } !\\ n \") if exists $langages{$response} or die \" $response n ' \u00e9xiste pas !\\ n \" ; Boucles For || Foreach For ou Foreach on la m\u00eame signification use stric my $langages = ( Perl => 'super' , Python => 'geniale' , Ruby => 'ouais' , Pascal => 'bof' , C => 'bof, ' C ++ ' => ' bof ' ); print \"Element : $_\\n\" for ( sort keys %langages ); while Tant que quoi ? while ( <STDIN> ) { chomp ; die \"Fin.\" unless $_ ; # ou 'last unless $_;' pour quitter la boucle print \"coucou $_\" ; } pseaudo case La fonction case n'\u00e9xiste pas mais un bricolage est possible : print \"Entrer un nombre entre 1 et 3 : \" ; my $response = <STDIN> ; for ( $response ) { $_ == 1 && print \"C'est un\\n\" $_ == 2 && print \"C'est deux\\n\" $_ == 3 && print \"C'est trois\\n\" } Fichier Ouvrir un Fichier 'FILE' en majuscule -> Convention de Perl - '<' = read only - '>' = write only - '+>' = read / write / del - '>>' = add only - '+>>' = read / write / add Ouvrir un fichier avec : open FILE, '<' Librairies REST CLIENT Comment afficher le token g\u00e9ner\u00e9 : print $authToken->{'authToken'}, \"\\n\";","title":"Perl"},{"location":"dev/perl/#perl","text":"Perl tips & tricks","title":"Perl"},{"location":"dev/perl/#variable","text":"","title":"Variable"},{"location":"dev/perl/#scalaire","text":"Contenant une seule valeure : $","title":"Scalaire"},{"location":"dev/perl/#liste","text":"Example : ('Toto', 'Titi', 'Tata') @","title":"Liste"},{"location":"dev/perl/#hashs","text":"Le type de la variable hashs %","title":"Hashs"},{"location":"dev/perl/#example-de-hashs","text":"my %liste = ( Perl => 'Super' , Python => 'G\u00e9nial' ); print ( $liste { Python });","title":"Example de hashs :"},{"location":"dev/perl/#fonctions","text":"","title":"Fonctions"},{"location":"dev/perl/#split","text":"La fonction split permet de retirer un \u00e9l\u00e8ment s\u00e9parateur : my @liste = split ' ', $liste_d_element","title":"split"},{"location":"dev/perl/#join","text":"La fonction join permet d'ins\u00e9rer un ou plusieurs \u00e9l\u00e8ment s\u00e9parateur dans une liste d'\u00e9l\u00e8ment : my @liste = join '; ', @liste_d_element","title":"join"},{"location":"dev/perl/#pragma","text":"Utiliser les pragma pour s\u00e9curiser son script.","title":"Pragma"},{"location":"dev/perl/#strict","text":"Erreur de syntaxe, avoir un code propre use strict;","title":"strict"},{"location":"dev/perl/#warning","text":"Avertissement d'erreur de syntaxe use warning;","title":"warning"},{"location":"dev/perl/#sucre-de-syntaxe","text":"Afin d'\u00e9viter d'avoir un code illisible avec nos \"\" ou '', deux m\u00e9thodes sont applicables dans chacun des cas.","title":"Sucre de syntaxe"},{"location":"dev/perl/#guillemet","text":"Pour substituer \"\" : qq/Chaine de carract\u00e8re/","title":"Guillemet"},{"location":"dev/perl/#guillement-simple","text":"Pour substituer '' : q/Chaine de carract\u00e8re/","title":"Guillement Simple"},{"location":"dev/perl/#liste_1","text":"Pour substituer une liste (ex : ('Toto', 'Titi', 'Tata')) : qw/Toto Titi Tata/","title":"Liste"},{"location":"dev/perl/#here-string","text":"OEF signifiant fin de ligne permet d'englober un parragraphe de donn\u00e9es : my $variable = << OEF ; ligne 1 de donn\u00e9es ligne 2 de donn\u00e9es ... EOF","title":"Here string"},{"location":"dev/perl/#verifications","text":"","title":"V\u00e9rifications"},{"location":"dev/perl/#predica-if","text":"V\u00e9rification de l'\u00e9xistance d'un \u00e9l\u00e8ment. use strict my $langages = ( Perl => 'super' , Python => 'geniale' , Ruby => 'ouais' , Pascal => 'bof' , C => 'bof, ' C ++ ' => ' bof ' ); if (exists $langages{Haskell}) { print (\"Mon langage est \", $langages{Haskell}, \"\\n\"); } elsif (exists $langages{Perl}) ( print (\"Mon langage est \", $langages{Perl}, \"\\n\"); ) else { print \"Haskell n' est pas d\u00e9fini !\\ n \" ; }","title":"Pr\u00e9dica 'if'"},{"location":"dev/perl/#rendre-son-script-interatif","text":"","title":"Rendre son script int\u00e9ratif"},{"location":"dev/perl/#standard-input","text":"Chop retire le dernier carract\u00e8re Chomp retire le dernier carract\u00e8re seulement si celui-ci est un '\\n' Not\u00e9 STDIN , il sert \u00e0 poser une question \u00e0 l'utilisateur: use strict my $langages = ( Perl => 'super' , Python => 'geniale' , Ruby => 'ouais' , Pascal => 'bof' , C => 'bof, ' C ++ ' => ' bof ' ); print \"Entrer le nom d' un langage : \" chomp (my $response = <STDIN>); print (\" $response est $langages { $response } !\\ n \") if exists $langages{$response} or die \" $response n ' \u00e9xiste pas !\\ n \" ;","title":"Standard input"},{"location":"dev/perl/#boucles","text":"","title":"Boucles"},{"location":"dev/perl/#for-foreach","text":"For ou Foreach on la m\u00eame signification use stric my $langages = ( Perl => 'super' , Python => 'geniale' , Ruby => 'ouais' , Pascal => 'bof' , C => 'bof, ' C ++ ' => ' bof ' ); print \"Element : $_\\n\" for ( sort keys %langages );","title":"For || Foreach"},{"location":"dev/perl/#while","text":"Tant que quoi ? while ( <STDIN> ) { chomp ; die \"Fin.\" unless $_ ; # ou 'last unless $_;' pour quitter la boucle print \"coucou $_\" ; }","title":"while"},{"location":"dev/perl/#pseaudo-case","text":"La fonction case n'\u00e9xiste pas mais un bricolage est possible : print \"Entrer un nombre entre 1 et 3 : \" ; my $response = <STDIN> ; for ( $response ) { $_ == 1 && print \"C'est un\\n\" $_ == 2 && print \"C'est deux\\n\" $_ == 3 && print \"C'est trois\\n\" }","title":"pseaudo case"},{"location":"dev/perl/#fichier","text":"","title":"Fichier"},{"location":"dev/perl/#ouvrir-un-fichier","text":"'FILE' en majuscule -> Convention de Perl - '<' = read only - '>' = write only - '+>' = read / write / del - '>>' = add only - '+>>' = read / write / add Ouvrir un fichier avec : open FILE, '<'","title":"Ouvrir un Fichier"},{"location":"dev/perl/#librairies","text":"","title":"Librairies"},{"location":"dev/perl/#rest","text":"","title":"REST"},{"location":"dev/perl/#client","text":"Comment afficher le token g\u00e9ner\u00e9 : print $authToken->{'authToken'}, \"\\n\";","title":"CLIENT"},{"location":"dev/readme/","text":"About DevOps is the combination of cultural philosophies, practices, and tools that increases an organization's ability to deliver applications and services at high velocity: evolving and improving products at a faster pace than organizations using traditional software development and infrastructure management processes.","title":"About"},{"location":"dev/readme/#about","text":"DevOps is the combination of cultural philosophies, practices, and tools that increases an organization's ability to deliver applications and services at high velocity: evolving and improving products at a faster pace than organizations using traditional software development and infrastructure management processes.","title":"About"},{"location":"dev/tower-cli/","text":"Tower-CLI Tower-cli is a command line tool for Ansible Tower. It allows Tower commands to be easily run from the UNIX command line. It can also be used as a client library for other python apps, or as a reference for others developing API interactions with Tower\u2019s REST API. Installation Installing the ansible tower-cli through two differents methodes. Python Virtual environenment or from git hub From Source Using the main repository : tower-cli Clone it and make the installation git clone https://github.com/ansible/tower-cli.git make install Python Venv Use python pip pip install tower-cli Configuration You can configure tower-cli from ~/.tower_cli.cfg file situated on your own home or /etc/tower-cli/tower-cli. By default, this file is about : $ tower-cli config # Defaults. verify_ssl: True username: format: human insecure: False color: True use_token: False host: 127 .0.0.1 certificate: oauth_token: password: verbose: False description_on: False Let insert element one by one like : tower-cli config username = toto or modify the configuration file. Usage Inventories List Hosts by inventory -i : inventory name -a : all (pages) tower - cli host list - i inventoriy_name - a Team Associate user to team : tower - cli team associate -- user user_name -- team team_name Group Associate user to group : tower - cli group associate -- user user_name -- group group_name Host Associate host to group : tower - cli host associate -- host host_name -- group group_name","title":"Tower-CLI"},{"location":"dev/tower-cli/#tower-cli","text":"Tower-cli is a command line tool for Ansible Tower. It allows Tower commands to be easily run from the UNIX command line. It can also be used as a client library for other python apps, or as a reference for others developing API interactions with Tower\u2019s REST API.","title":"Tower-CLI"},{"location":"dev/tower-cli/#installation","text":"Installing the ansible tower-cli through two differents methodes. Python Virtual environenment or from git hub","title":"Installation"},{"location":"dev/tower-cli/#from-source","text":"Using the main repository : tower-cli Clone it and make the installation git clone https://github.com/ansible/tower-cli.git make install","title":"From Source"},{"location":"dev/tower-cli/#python-venv","text":"Use python pip pip install tower-cli","title":"Python Venv"},{"location":"dev/tower-cli/#configuration","text":"You can configure tower-cli from ~/.tower_cli.cfg file situated on your own home or /etc/tower-cli/tower-cli. By default, this file is about : $ tower-cli config # Defaults. verify_ssl: True username: format: human insecure: False color: True use_token: False host: 127 .0.0.1 certificate: oauth_token: password: verbose: False description_on: False Let insert element one by one like : tower-cli config username = toto or modify the configuration file.","title":"Configuration"},{"location":"dev/tower-cli/#usage","text":"","title":"Usage"},{"location":"dev/tower-cli/#inventories","text":"List Hosts by inventory -i : inventory name -a : all (pages) tower - cli host list - i inventoriy_name - a","title":"Inventories"},{"location":"dev/tower-cli/#team","text":"Associate user to team : tower - cli team associate -- user user_name -- team team_name","title":"Team"},{"location":"dev/tower-cli/#group","text":"Associate user to group : tower - cli group associate -- user user_name -- group group_name","title":"Group"},{"location":"dev/tower-cli/#host","text":"Associate host to group : tower - cli host associate -- host host_name -- group group_name","title":"Host"},{"location":"dev/hashicorp/ansible/","text":"Ansible Engine List d'argument -i : Sp\u00e9cifier le fichier d'inventaire -C,--check : V\u00e9rifier la.es action.s qui sera.ont r\u00e9alis\u00e9e.s -m : Sp\u00e9cifier le module que l'on souhaite invoquer -k : Demander le mot de passe user -K : Demander le mot de passe root -b,--become : \u00c9x\u00e9cuter en tant que su (*admin) Serveur Configuration file : ansible.cgf host_key_checking = False inventory = pve.inventory Inventory file : inventory [ Groups ] ansible ansible_hosts = 0 .0.0.0 [ Groups:vars ] ansible_user = John Doe ansible_password = jdoe Remote Windows WinRM WinRM is a management protocol used by Windows to remotely communicate with another server. It is a SOAP-based protocol that communicates over HTTP/HTTPS, and is included in all recent Windows operating systems. Since Windows Server 2012, WinRM has been enabled by default, but in most cases extra configuration is required to use WinRM with Ansible. Authentification Options Option Local Accounts Active Directory Accounts Credential Delegation HTTP Encryption Basic Yes No No No Certificate Yes No No No Kerberos No Ye Ye Yes NTLM Yes Ye No Yes CredSSP Yes Ye Ye Yes Basic Basic authentication is one of the simplest authentication options to use, but is also the most insecure. ansible_user : Username ansible_password : Password ansible_connection : winrm ansible_winrm_transport : basic CredSSP CredSSP authentication is a newer authentication protocol that allows credential delegation. This is achieved by encrypting the username and password after authentication has succeeded and sending that to the server using the CredSSP protocol. To use CredSSP authentication, the host vars are configured like : ansible_user : Username ansible_password : Password ansible_connection : winrm ansible_winrm_transport : credssp There are some extra host variables that can be set as shown below ansible_winrm_credssp_disable_tlsv1_2 : when true, will not use TLS 1.2 in the CredSSP auth process CredSSP authentication is not enabled by default on a Windows host, but can be enabled by running the following in PowerShell Enable-WSManCredSSP -Role Server -Force Installing CredSSP Library The requests-credssp wrapper can be installed using pip : pip install pywinrm [ credssp ] TLS 1.2 By default the requests-credssp library is configured to authenticate over the TLS 1.2 protocol. TLS 1.2 is installed and enabled by default for Windows Server 2012 and Windows 8 and more recent releases. Certificate CredSSP works by encrypting the credentials through the TLS protocol and uses a self-signed certificate by default. The CertificateThumbprint option under the WinRM service configuration can be used to specify the thumbprint of another certificate. # Note the value $certificate_thumbprint will be different in each # situation, this needs to be set based on the cert that is used. $certificate_thumbprint = \"7C8DCBD5427AFEE6560F4AF524E325915F51172C\" # Set the thumbprint value Set-Item -Path WSMan:\\localhost\\Service\\CertificateThumbprint -Value $certificate_thumbprint [[https://docs.ansible.com/ansible/latest/os_guide/windows_winrm.html#id9]]","title":"Ansible Engine"},{"location":"dev/hashicorp/ansible/#ansible-engine","text":"","title":"Ansible Engine"},{"location":"dev/hashicorp/ansible/#list-dargument","text":"-i : Sp\u00e9cifier le fichier d'inventaire -C,--check : V\u00e9rifier la.es action.s qui sera.ont r\u00e9alis\u00e9e.s -m : Sp\u00e9cifier le module que l'on souhaite invoquer -k : Demander le mot de passe user -K : Demander le mot de passe root -b,--become : \u00c9x\u00e9cuter en tant que su (*admin)","title":"List d'argument"},{"location":"dev/hashicorp/ansible/#serveur","text":"","title":"Serveur"},{"location":"dev/hashicorp/ansible/#configuration","text":"file : ansible.cgf host_key_checking = False inventory = pve.inventory","title":"Configuration"},{"location":"dev/hashicorp/ansible/#inventory","text":"file : inventory [ Groups ] ansible ansible_hosts = 0 .0.0.0 [ Groups:vars ] ansible_user = John Doe ansible_password = jdoe","title":"Inventory"},{"location":"dev/hashicorp/ansible/#remote","text":"","title":"Remote"},{"location":"dev/hashicorp/ansible/#windows","text":"","title":"Windows"},{"location":"dev/hashicorp/ansible/#winrm","text":"WinRM is a management protocol used by Windows to remotely communicate with another server. It is a SOAP-based protocol that communicates over HTTP/HTTPS, and is included in all recent Windows operating systems. Since Windows Server 2012, WinRM has been enabled by default, but in most cases extra configuration is required to use WinRM with Ansible.","title":"WinRM"},{"location":"dev/hashicorp/ansible/#authentification-options","text":"Option Local Accounts Active Directory Accounts Credential Delegation HTTP Encryption Basic Yes No No No Certificate Yes No No No Kerberos No Ye Ye Yes NTLM Yes Ye No Yes CredSSP Yes Ye Ye Yes","title":"Authentification Options"},{"location":"dev/hashicorp/ansible/#basic","text":"Basic authentication is one of the simplest authentication options to use, but is also the most insecure. ansible_user : Username ansible_password : Password ansible_connection : winrm ansible_winrm_transport : basic","title":"Basic"},{"location":"dev/hashicorp/ansible/#credssp","text":"CredSSP authentication is a newer authentication protocol that allows credential delegation. This is achieved by encrypting the username and password after authentication has succeeded and sending that to the server using the CredSSP protocol. To use CredSSP authentication, the host vars are configured like : ansible_user : Username ansible_password : Password ansible_connection : winrm ansible_winrm_transport : credssp There are some extra host variables that can be set as shown below ansible_winrm_credssp_disable_tlsv1_2 : when true, will not use TLS 1.2 in the CredSSP auth process CredSSP authentication is not enabled by default on a Windows host, but can be enabled by running the following in PowerShell Enable-WSManCredSSP -Role Server -Force","title":"CredSSP"},{"location":"dev/hashicorp/ansible/#installing-credssp-library","text":"The requests-credssp wrapper can be installed using pip : pip install pywinrm [ credssp ]","title":"Installing CredSSP Library"},{"location":"dev/hashicorp/ansible/#tls-12","text":"By default the requests-credssp library is configured to authenticate over the TLS 1.2 protocol. TLS 1.2 is installed and enabled by default for Windows Server 2012 and Windows 8 and more recent releases.","title":"TLS 1.2"},{"location":"dev/hashicorp/ansible/#certificate","text":"CredSSP works by encrypting the credentials through the TLS protocol and uses a self-signed certificate by default. The CertificateThumbprint option under the WinRM service configuration can be used to specify the thumbprint of another certificate. # Note the value $certificate_thumbprint will be different in each # situation, this needs to be set based on the cert that is used. $certificate_thumbprint = \"7C8DCBD5427AFEE6560F4AF524E325915F51172C\" # Set the thumbprint value Set-Item -Path WSMan:\\localhost\\Service\\CertificateThumbprint -Value $certificate_thumbprint [[https://docs.ansible.com/ansible/latest/os_guide/windows_winrm.html#id9]]","title":"Certificate"},{"location":"dev/hashicorp/packer/","text":"Packer Installation Centos/Redhat/Rocky Add hashicorp repository dnf config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo Installing package dnf install packer Ubuntu/Debian Add the HashiCorp GPG key . $ curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add - Add the official HashiCorp Linux repository. $ sudo apt-add-repository \"deb [arch=amd64] https://apt.releases.hashicorp.com $( lsb_release -cs ) main\" Update and install. $ sudo apt-get update && sudo apt-get install packer Subcommands Usage: packer [ --version ] [ --help ] <command> [ <args> ] Available commands are: build build image ( s ) from template console creates a console for testing variable interpolation fix fixes templates from old versions of packer fmt Rewrites HCL2 config files to canonical format hcl2_upgrade transform a JSON template into an HCL2 configuration init Install missing plugins or upgrade plugins inspect see components of a template plugins Interact with Packer plugins and catalog validate check that a template is valid version Prints the Packer version Most of the commands accept or require flags or ags to execute the desired functionnality Install autocomplete That enable tab completion when using the CLI packer -autocomplete-install Packer Build The packer build command takes a Packer temmplate and runs all the defined builds to generate the desired artifacts. The build command provides the core functionality of Packer. Terminal packer build packer_template.hcl Important Options/Arguments -debub : enables debug mode fpr step-by-step troubleshooting - var : set a variable in the Packer template - var-file : use a separate variable file Environment variables Packer has a few environment variables : PACKER_LOG : enable Packer detailed logs (off by default) PACKER_LOG_PATH : set the path of Packer logs to specific file (rather than stderr) PKR_VAR_xxx : define a variable value using ENV rather than in a template","title":"Packer"},{"location":"dev/hashicorp/packer/#packer","text":"","title":"Packer"},{"location":"dev/hashicorp/packer/#installation","text":"","title":"Installation"},{"location":"dev/hashicorp/packer/#centosredhatrocky","text":"Add hashicorp repository dnf config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo Installing package dnf install packer","title":"Centos/Redhat/Rocky"},{"location":"dev/hashicorp/packer/#ubuntudebian","text":"Add the HashiCorp GPG key . $ curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add - Add the official HashiCorp Linux repository. $ sudo apt-add-repository \"deb [arch=amd64] https://apt.releases.hashicorp.com $( lsb_release -cs ) main\" Update and install. $ sudo apt-get update && sudo apt-get install packer","title":"Ubuntu/Debian"},{"location":"dev/hashicorp/packer/#subcommands","text":"Usage: packer [ --version ] [ --help ] <command> [ <args> ] Available commands are: build build image ( s ) from template console creates a console for testing variable interpolation fix fixes templates from old versions of packer fmt Rewrites HCL2 config files to canonical format hcl2_upgrade transform a JSON template into an HCL2 configuration init Install missing plugins or upgrade plugins inspect see components of a template plugins Interact with Packer plugins and catalog validate check that a template is valid version Prints the Packer version Most of the commands accept or require flags or ags to execute the desired functionnality","title":"Subcommands"},{"location":"dev/hashicorp/packer/#install-autocomplete","text":"That enable tab completion when using the CLI packer -autocomplete-install","title":"Install autocomplete"},{"location":"dev/hashicorp/packer/#packer-build","text":"The packer build command takes a Packer temmplate and runs all the defined builds to generate the desired artifacts. The build command provides the core functionality of Packer. Terminal packer build packer_template.hcl Important Options/Arguments -debub : enables debug mode fpr step-by-step troubleshooting - var : set a variable in the Packer template - var-file : use a separate variable file","title":"Packer Build"},{"location":"dev/hashicorp/packer/#environment-variables","text":"Packer has a few environment variables : PACKER_LOG : enable Packer detailed logs (off by default) PACKER_LOG_PATH : set the path of Packer logs to specific file (rather than stderr) PKR_VAR_xxx : define a variable value using ENV rather than in a template","title":"Environment variables"},{"location":"dev/hashicorp/vagrant/","text":"Vagrant Install from source Add hashicorp repository dnf config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo Installing package dnf install vagrant Init project vagrant init hashicorp/bionic64 A Vagrantfile has been placed in this directory. You are now ready to vagrant up your first virtual environment! Please read the comments in the Vagrantfile as well as documentation on vagrantup.com for more information on using Vagrant.","title":"Vagrant"},{"location":"dev/hashicorp/vagrant/#vagrant","text":"","title":"Vagrant"},{"location":"dev/hashicorp/vagrant/#install-from-source","text":"Add hashicorp repository dnf config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo Installing package dnf install vagrant","title":"Install from source"},{"location":"dev/hashicorp/vagrant/#init-project","text":"vagrant init hashicorp/bionic64 A Vagrantfile has been placed in this directory. You are now ready to vagrant up your first virtual environment! Please read the comments in the Vagrantfile as well as documentation on vagrantup.com for more information on using Vagrant.","title":"Init project"},{"location":"dev/hashicorp/terraform/graph/","text":"Graph terraform graph | dot -Tsvg > graph.svg Example code : digraph { compound = \"true\" newrank = \"true\" subgraph \"root\" { \"[root] aws_instance.test_ec2 (expand)\" [label = \"aws_instance.test_ec2\", shape = \"box\"] \"[root] provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\" [label = \"provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\", shape = \"diamond\"] \"[root] aws_instance.test_ec2 (expand)\" -> \"[root] provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\" \"[root] provider[\\\"registry.terraform.io/hashicorp/aws\\\"] (close)\" -> \"[root] aws_instance.test_ec2 (expand)\" \"[root] root\" -> \"[root] provider[\\\"registry.terraform.io/hashicorp/aws\\\"] (close)\" } }","title":"Graph"},{"location":"dev/hashicorp/terraform/graph/#graph","text":"terraform graph | dot -Tsvg > graph.svg Example code : digraph { compound = \"true\" newrank = \"true\" subgraph \"root\" { \"[root] aws_instance.test_ec2 (expand)\" [label = \"aws_instance.test_ec2\", shape = \"box\"] \"[root] provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\" [label = \"provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\", shape = \"diamond\"] \"[root] aws_instance.test_ec2 (expand)\" -> \"[root] provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\" \"[root] provider[\\\"registry.terraform.io/hashicorp/aws\\\"] (close)\" -> \"[root] aws_instance.test_ec2 (expand)\" \"[root] root\" -> \"[root] provider[\\\"registry.terraform.io/hashicorp/aws\\\"] (close)\" } }","title":"Graph"},{"location":"dev/hashicorp/terraform/modules/","text":"Modules tf files consolidation were ressources related Terraform module are actually ansible roles How to How to call modules ? module \"module_name\" { source = \"./dir_module_name\" } Install terraform get terraform init Manage dependances terraform apply -target = module.docker terraform apply -target = module.postgres Rq : via variables Structure simple \u251c\u2500\u2500 README.md \u251c\u2500\u2500 main.tf \u251c\u2500\u2500 variables.tf \u251c\u2500\u2500 outputs.tf complexier \u251c\u2500\u2500 README.md \u251c\u2500\u2500 main.tf \u251c\u2500\u2500 variables.tf \u251c\u2500\u2500 outputs.tf \u251c\u2500\u2500 ... \u251c\u2500\u2500 modules/ \u2502 \u251c\u2500\u2500 nestedA/ \u2502 \u2502 \u251c\u2500\u2500 README.md \u2502 \u2502 \u251c\u2500\u2500 variables.tf \u2502 \u2502 \u251c\u2500\u2500 main.tf \u2502 \u2502 \u251c\u2500\u2500 outputs.tf \u2502 \u251c\u2500\u2500 nestedB/ \u2502 \u251c\u2500\u2500 .../ \u251c\u2500\u2500 examples/ \u2502 \u251c\u2500\u2500 exampleA/ \u2502 \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 exampleB/ \u2502 \u251c\u2500\u2500 .../","title":"Modules"},{"location":"dev/hashicorp/terraform/modules/#modules","text":"tf files consolidation were ressources related Terraform module are actually ansible roles","title":"Modules"},{"location":"dev/hashicorp/terraform/modules/#how-to","text":"How to call modules ? module \"module_name\" { source = \"./dir_module_name\" }","title":"How to"},{"location":"dev/hashicorp/terraform/modules/#install","text":"terraform get terraform init","title":"Install"},{"location":"dev/hashicorp/terraform/modules/#manage-dependances","text":"terraform apply -target = module.docker terraform apply -target = module.postgres Rq : via variables","title":"Manage dependances"},{"location":"dev/hashicorp/terraform/modules/#structure","text":"simple \u251c\u2500\u2500 README.md \u251c\u2500\u2500 main.tf \u251c\u2500\u2500 variables.tf \u251c\u2500\u2500 outputs.tf complexier \u251c\u2500\u2500 README.md \u251c\u2500\u2500 main.tf \u251c\u2500\u2500 variables.tf \u251c\u2500\u2500 outputs.tf \u251c\u2500\u2500 ... \u251c\u2500\u2500 modules/ \u2502 \u251c\u2500\u2500 nestedA/ \u2502 \u2502 \u251c\u2500\u2500 README.md \u2502 \u2502 \u251c\u2500\u2500 variables.tf \u2502 \u2502 \u251c\u2500\u2500 main.tf \u2502 \u2502 \u251c\u2500\u2500 outputs.tf \u2502 \u251c\u2500\u2500 nestedB/ \u2502 \u251c\u2500\u2500 .../ \u251c\u2500\u2500 examples/ \u2502 \u251c\u2500\u2500 exampleA/ \u2502 \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 exampleB/ \u2502 \u251c\u2500\u2500 .../","title":"Structure"},{"location":"dev/hashicorp/terraform/providers/","text":"Providers AWS Prerequisites IAM Keys : Warning Copy somewhere your keys Generate keys : Create instance : Example main.tf key name = key pairs provider \"aws\" { region = \"eu-central-1\" access_key = \"*************\" secret_key = \"*******************\" } resource \"aws_instance\" \"test_ec2\" { ami = \"ami-0ec7f9846da6b0f61\" # Ubuntu Server 22.04 LTS (HVM) instance_type = \"t2.micro\" key_name = \"***********\" tags = { Name = \"test01\" } }","title":"Providers"},{"location":"dev/hashicorp/terraform/providers/#providers","text":"","title":"Providers"},{"location":"dev/hashicorp/terraform/providers/#aws","text":"","title":"AWS"},{"location":"dev/hashicorp/terraform/providers/#prerequisites","text":"","title":"Prerequisites"},{"location":"dev/hashicorp/terraform/providers/#iam","text":"Keys : Warning Copy somewhere your keys Generate keys : Create instance : Example main.tf key name = key pairs provider \"aws\" { region = \"eu-central-1\" access_key = \"*************\" secret_key = \"*******************\" } resource \"aws_instance\" \"test_ec2\" { ami = \"ami-0ec7f9846da6b0f61\" # Ubuntu Server 22.04 LTS (HVM) instance_type = \"t2.micro\" key_name = \"***********\" tags = { Name = \"test01\" } }","title":"IAM"},{"location":"dev/hashicorp/terraform/readme/","text":"About What is Terraform ? Terraform is an infrastructure as code tool that lets you build, change, and version cloud and on-prem resources safely and efficiently. How does it works ? Terraform creates and manages resources on cloud platforms and other services through their application programming interfaces (APIs). Providers enable Terraform to work with virtually any platform or service with an accessible API. The core Terraform workflow consists of three stages: Write: You define resources, which may be across multiple cloud providers and services. For example, you might create a configuration to deploy an application on virtual machines in a Virtual Private Cloud (VPC) network with security groups and a load balancer. Plan: Terraform creates an execution plan describing the infrastructure it will create, update, or destroy based on the existing infrastructure and your configuration. Apply: On approval, Terraform performs the proposed operations in the correct order, respecting any resource dependencies. For example, if you update the properties of a VPC and change the number of virtual machines in that VPC, Terraform will recreate the VPC before scaling the virtual machines.","title":"About"},{"location":"dev/hashicorp/terraform/readme/#about","text":"","title":"About"},{"location":"dev/hashicorp/terraform/readme/#what-is-terraform","text":"Terraform is an infrastructure as code tool that lets you build, change, and version cloud and on-prem resources safely and efficiently.","title":"What is Terraform ?"},{"location":"dev/hashicorp/terraform/readme/#how-does-it-works","text":"Terraform creates and manages resources on cloud platforms and other services through their application programming interfaces (APIs). Providers enable Terraform to work with virtually any platform or service with an accessible API. The core Terraform workflow consists of three stages: Write: You define resources, which may be across multiple cloud providers and services. For example, you might create a configuration to deploy an application on virtual machines in a Virtual Private Cloud (VPC) network with security groups and a load balancer. Plan: Terraform creates an execution plan describing the infrastructure it will create, update, or destroy based on the existing infrastructure and your configuration. Apply: On approval, Terraform performs the proposed operations in the correct order, respecting any resource dependencies. For example, if you update the properties of a VPC and change the number of virtual machines in that VPC, Terraform will recreate the VPC before scaling the virtual machines.","title":"How does it works ?"},{"location":"dev/hashicorp/terraform/remote-exec/","text":"Remote Exec SSH variable \"ssh_host\" { } variable \"ssh_user\" { } variable \"ssh_target\" { } resource \"null_resource\" \"ssh_target\" { connection { type = \"ssh\" user = var.ssh_user host = var.ssh_host private_key = file ( \"/home/john-doe/.ssh/id_rsa\" ) } } remote-exec resource \"xxx\" \"xxx\" { provisioner \"remote-exec\" { inline = [ \"sudo apt update -qq > /dev/null\" , \"sudo apt install nginx -qq > /dev/null\" ] } } File resource \"xxx\" \"xxx\" { provisioner \"file\" { source = \"script.sh\" destination = \"/tmp/script.sh\" } }","title":"Remote Exec"},{"location":"dev/hashicorp/terraform/remote-exec/#remote-exec","text":"","title":"Remote Exec"},{"location":"dev/hashicorp/terraform/remote-exec/#ssh","text":"variable \"ssh_host\" { } variable \"ssh_user\" { } variable \"ssh_target\" { } resource \"null_resource\" \"ssh_target\" { connection { type = \"ssh\" user = var.ssh_user host = var.ssh_host private_key = file ( \"/home/john-doe/.ssh/id_rsa\" ) } }","title":"SSH"},{"location":"dev/hashicorp/terraform/remote-exec/#remote-exec_1","text":"resource \"xxx\" \"xxx\" { provisioner \"remote-exec\" { inline = [ \"sudo apt update -qq > /dev/null\" , \"sudo apt install nginx -qq > /dev/null\" ] } }","title":"remote-exec"},{"location":"dev/hashicorp/terraform/remote-exec/#file","text":"resource \"xxx\" \"xxx\" { provisioner \"file\" { source = \"script.sh\" destination = \"/tmp/script.sh\" } }","title":"File"},{"location":"dev/hashicorp/terraform/setup/","text":"Setup Ubuntu/Debian Add keys wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg Add repo list echo \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $( lsb_release -cs ) main\" | sudo tee /etc/apt/sources.list.d/hashicorp.list Update and install sudo apt update && sudo apt install terraform","title":"Setup"},{"location":"dev/hashicorp/terraform/setup/#setup","text":"","title":"Setup"},{"location":"dev/hashicorp/terraform/setup/#ubuntudebian","text":"Add keys wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg Add repo list echo \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $( lsb_release -cs ) main\" | sudo tee /etc/apt/sources.list.d/hashicorp.list Update and install sudo apt update && sudo apt install terraform","title":"Ubuntu/Debian"},{"location":"dev/hashicorp/terraform/syntax/","text":"Syntaxe Travaillons sur un fichier main.tf Exemple output \"VAR\" { value = \"Hello World! \" } Apply terraform apply","title":"Syntaxe"},{"location":"dev/hashicorp/terraform/syntax/#syntaxe","text":"Travaillons sur un fichier main.tf","title":"Syntaxe"},{"location":"dev/hashicorp/terraform/syntax/#exemple","text":"output \"VAR\" { value = \"Hello World! \" }","title":"Exemple"},{"location":"dev/hashicorp/terraform/syntax/#apply","text":"terraform apply","title":"Apply"},{"location":"dev/hashicorp/terraform/tfstate/","text":"tfstate tfstate file is equivalent as logfile. It keeps state S Test & Apply Test terraform plan","title":"tfstate"},{"location":"dev/hashicorp/terraform/tfstate/#tfstate","text":"tfstate file is equivalent as logfile. It keeps state S","title":"tfstate"},{"location":"dev/hashicorp/terraform/tfstate/#test-apply","text":"","title":"Test &amp; Apply"},{"location":"dev/hashicorp/terraform/tfstate/#test","text":"terraform plan","title":"Test"},{"location":"dev/hashicorp/terraform/vars/","text":"Variable level(s) They are multiple variable levels as : 1: Environment 2: File (terraform.tvars) 3: Json File (terraform.tfvars.json) 4: Auto File (*.auto.tfvars or *.auto.tfvars.json) 5: CLI (-var or var-file( followed by the varfile.tfvars ) Environment EXPORT VAR_NAME_str = \"value\" Files tfvars File where terraform vars located VAR_NAME_str = \"value\" Auto File: file.auto.tfvars str = \"auto\"","title":"Variable level(s)"},{"location":"dev/hashicorp/terraform/vars/#variable-levels","text":"They are multiple variable levels as : 1: Environment 2: File (terraform.tvars) 3: Json File (terraform.tfvars.json) 4: Auto File (*.auto.tfvars or *.auto.tfvars.json) 5: CLI (-var or var-file( followed by the varfile.tfvars )","title":"Variable level(s)"},{"location":"dev/hashicorp/terraform/vars/#environment","text":"EXPORT VAR_NAME_str = \"value\"","title":"Environment"},{"location":"dev/hashicorp/terraform/vars/#files","text":"","title":"Files"},{"location":"dev/hashicorp/terraform/vars/#tfvars","text":"File where terraform vars located VAR_NAME_str = \"value\"","title":"tfvars"},{"location":"dev/hashicorp/terraform/vars/#auto","text":"File: file.auto.tfvars str = \"auto\"","title":"Auto"},{"location":"dev/python/args-and-kwargs/","text":"Python Args and Kwargs Python args and kwargs Made Easy args and *kwargs may seem scary, but the truth is that they are not that difficult to grasp and have the power to grant your functions with lots of flexibility. Read the article Python *args and **kwargs Made Easy for a more in deep introduction. Args and Kwargs *args and **kwargs allow you to pass an undefined number of arguments and keywords when calling a function. >>> def some_function ( * args , ** kwargs ): ... pass ... >>> # call some_function with any number of arguments >>> some_function ( arg1 , arg2 , arg3 ) >>> # call some_function with any number of keywords >>> some_function ( key1 = arg1 , key2 = arg2 , key3 = arg3 ) >>> # call both, arguments and keywords >>> some_function ( arg , key1 = arg1 ) >>> # or none >>> some_function () Python conventions The words args and *kwargs are conventions. They are not imposed by the interpreter, but considered good practice by the Python community. args You can access the arguments through the args variable: >>> def some_function ( * args ): ... print ( f 'Arguments passed: { args } as { type ( args ) } ' ) ... >>> some_function ( 'arg1' , 'arg2' , 'arg3' ) # Arguments passed: ('arg1', 'arg2', 'arg3') as <class 'tuple'> kwargs Keywords are accessed through the kwargs variable: >>> def some_function ( ** kwargs ): ... print ( f 'keywords: { kwargs } as { type ( kwargs ) } ' ) ... >>> some_function ( key1 = 'arg1' , key2 = 'arg2' ) # keywords: {'key1': 'arg1', 'key2': 'arg2'} as <class 'dict'>","title":"Python Args and Kwargs"},{"location":"dev/python/args-and-kwargs/#args-and-kwargs","text":"*args and **kwargs allow you to pass an undefined number of arguments and keywords when calling a function. >>> def some_function ( * args , ** kwargs ): ... pass ... >>> # call some_function with any number of arguments >>> some_function ( arg1 , arg2 , arg3 ) >>> # call some_function with any number of keywords >>> some_function ( key1 = arg1 , key2 = arg2 , key3 = arg3 ) >>> # call both, arguments and keywords >>> some_function ( arg , key1 = arg1 ) >>> # or none >>> some_function () Python conventions The words args and *kwargs are conventions. They are not imposed by the interpreter, but considered good practice by the Python community.","title":"Args and Kwargs"},{"location":"dev/python/args-and-kwargs/#args","text":"You can access the arguments through the args variable: >>> def some_function ( * args ): ... print ( f 'Arguments passed: { args } as { type ( args ) } ' ) ... >>> some_function ( 'arg1' , 'arg2' , 'arg3' ) # Arguments passed: ('arg1', 'arg2', 'arg3') as <class 'tuple'>","title":"args"},{"location":"dev/python/args-and-kwargs/#kwargs","text":"Keywords are accessed through the kwargs variable: >>> def some_function ( ** kwargs ): ... print ( f 'keywords: { kwargs } as { type ( kwargs ) } ' ) ... >>> some_function ( key1 = 'arg1' , key2 = 'arg2' ) # keywords: {'key1': 'arg1', 'key2': 'arg2'} as <class 'dict'>","title":"kwargs"},{"location":"dev/python/basics/","text":"Python Basics We all need to start somewhere, so how about doing it here. From the Python 3 tutorial Python is an easy to learn, powerful programming language [...] Python\u2019s elegant syntax and dynamic typing, together with its interpreted nature, make it an ideal language for scripting and rapid application development. Math Operators From highest to lowest precedence: Operators Operation Example ** Exponent 2 ** 3 = 8 % Modulus/Remainder 22 % 8 = 6 // Integer division 22 // 8 = 2 / Division 22 / 8 = 2.75 * Multiplication 3 * 3 = 9 - Subtraction 5 - 2 = 3 + Addition 2 + 2 = 4 Examples of expressions: >>> 2 + 3 * 6 # 20 >>> ( 2 + 3 ) * 6 # 30 >>> 2 ** 8 #256 >>> 23 // 7 # 3 >>> 23 % 7 # 2 >>> ( 5 - 1 ) * (( 7 + 1 ) / ( 3 - 1 )) # 16.0 Augmented Assignment Operators Operator Equivalent var += 1 var = var + 1 var -= 1 var = var - 1 var *= 1 var = var * 1 var /= 1 var = var / 1 var %= 1 var = var % 1 Examples: >>> greeting = 'Hello' >>> greeting += ' world!' >>> greeting # 'Hello world!' >>> number = 1 >>> number += 1 >>> number # 2 >>> my_list = [ 'item' ] >>> my_list *= 3 >>> my_list # ['item', 'item', 'item'] Data Types Data Type Examples Integers -2, -1, 0, 1, 2, 3, 4, 5 Floating-point numbers -1.25, -1.0, --0.5, 0.0, 0.5, 1.0, 1.25 Strings 'a', 'aa', 'aaa', 'Hello!', '11 cats' Concatenation and Replication String concatenation: >>> 'Alice' 'Bob' # 'AliceBob' String replication: >>> 'Alice' * 5 # 'AliceAliceAliceAliceAlice' Variables You can name a variable anything as long as it obeys the following rules: It can be only one word. >>> # bad >>> my variable = 'Hello' >>> # good >>> var = 'Hello' It can use only letters, numbers, and the underscore ( _ ) character. >>> # bad >>> % $ @variable = 'Hello' >>> # good >>> my_var = 'Hello' >>> # good >>> my_var_2 = 'Hello' It can\u2019t begin with a number. >>> # this wont work >>> 23 _var = 'hello' Variable name starting with an underscore ( _ ) are considered as \"unuseful\". >>> # _spam should not be used again in the code >>> _spam = 'Hello' Comments Inline comment: # This is a comment Multiline comment: # This is a # multiline comment Code with a comment: a = 1 # initialization Please note the two spaces in front of the comment. Function docstring: def foo (): \"\"\" This is a function docstring You can also use: ''' Function Docstring ''' \"\"\" The print() Function The print() function writes the value of the argument(s) it is given. [...] it handles multiple arguments, floating point-quantities, and strings. Strings are printed without quotes, and a space is inserted between items, so you can format things nicely: >>> print ( 'Hello world!' ) # Hello world! >>> a = 1 >>> print ( 'Hello world!' , a ) # Hello world! 1 The end keyword The keyword argument end can be used to avoid the newline after the output, or end the output with a different string: phrase = [ 'printed' , 'with' , 'a' , 'dash' , 'in' , 'between' ] >>> for word in phrase : ... print ( word , end = '-' ) ... # printed-with-a-dash-in-between- The sep keyword The keyword sep specify how to separate the objects, if there is more than one: print ( 'cats' , 'dogs' , 'mice' , sep = ',' ) # cats,dogs,mice The input() Function This function takes the input from the user and converts it into a string: >>> print ( 'What is your name?' ) # ask for their name >>> my_name = input () >>> print ( 'Hi, {} ' . format ( my_name )) # What is your name? # Martha # Hi, Martha input() can also set a default message without using print() : >>> my_name = input ( 'What is your name? ' ) # default message >>> print ( 'Hi, {} ' . format ( my_name )) # What is your name? Martha # Hi, Martha It is also possible to use formatted strings to avoid using .format: >>> my_name = input ( 'What is your name? ' ) # default message >>> print ( f 'Hi, { my_name } ' ) # What is your name? Martha # Hi, Martha The len() Function Evaluates to the integer value of the number of characters in a string, list, dictionary, etc.: >>> len ( 'hello' ) # 5 >>> len ([ 'cat' , 3 , 'dog' ]) # 3 Test of emptiness Test of emptiness of strings, lists, dictionaries, etc., should not use len , but prefer direct boolean evaluation. Test of emptiness example: >>> a = [ 1 , 2 , 3 ] # bad >>> if len ( a ) > 0 : # evaluates to True ... print ( \"the list is not empty!\" ) ... # the list is not empty! # good >>> if a : # evaluates to True ... print ( \"the list is not empty!\" ) ... # the list is not empty! The str(), int(), and float() Functions These functions allow you to change the type of variable. For example, you can transform from an integer or float to a string : >>> str ( 29 ) # '29' >>> str ( - 3.14 ) # '-3.14' Or from a string to an integer or float : >>> int ( '11' ) # 11 >>> float ( '3.14' ) # 3.14","title":"Python Basics"},{"location":"dev/python/basics/#math-operators","text":"From highest to lowest precedence: Operators Operation Example ** Exponent 2 ** 3 = 8 % Modulus/Remainder 22 % 8 = 6 // Integer division 22 // 8 = 2 / Division 22 / 8 = 2.75 * Multiplication 3 * 3 = 9 - Subtraction 5 - 2 = 3 + Addition 2 + 2 = 4 Examples of expressions: >>> 2 + 3 * 6 # 20 >>> ( 2 + 3 ) * 6 # 30 >>> 2 ** 8 #256 >>> 23 // 7 # 3 >>> 23 % 7 # 2 >>> ( 5 - 1 ) * (( 7 + 1 ) / ( 3 - 1 )) # 16.0","title":"Math Operators"},{"location":"dev/python/basics/#augmented-assignment-operators","text":"Operator Equivalent var += 1 var = var + 1 var -= 1 var = var - 1 var *= 1 var = var * 1 var /= 1 var = var / 1 var %= 1 var = var % 1 Examples: >>> greeting = 'Hello' >>> greeting += ' world!' >>> greeting # 'Hello world!' >>> number = 1 >>> number += 1 >>> number # 2 >>> my_list = [ 'item' ] >>> my_list *= 3 >>> my_list # ['item', 'item', 'item']","title":"Augmented Assignment Operators"},{"location":"dev/python/basics/#data-types","text":"Data Type Examples Integers -2, -1, 0, 1, 2, 3, 4, 5 Floating-point numbers -1.25, -1.0, --0.5, 0.0, 0.5, 1.0, 1.25 Strings 'a', 'aa', 'aaa', 'Hello!', '11 cats'","title":"Data Types"},{"location":"dev/python/basics/#concatenation-and-replication","text":"String concatenation: >>> 'Alice' 'Bob' # 'AliceBob' String replication: >>> 'Alice' * 5 # 'AliceAliceAliceAliceAlice'","title":"Concatenation and Replication"},{"location":"dev/python/basics/#variables","text":"You can name a variable anything as long as it obeys the following rules: It can be only one word. >>> # bad >>> my variable = 'Hello' >>> # good >>> var = 'Hello' It can use only letters, numbers, and the underscore ( _ ) character. >>> # bad >>> % $ @variable = 'Hello' >>> # good >>> my_var = 'Hello' >>> # good >>> my_var_2 = 'Hello' It can\u2019t begin with a number. >>> # this wont work >>> 23 _var = 'hello' Variable name starting with an underscore ( _ ) are considered as \"unuseful\". >>> # _spam should not be used again in the code >>> _spam = 'Hello'","title":"Variables"},{"location":"dev/python/basics/#comments","text":"Inline comment: # This is a comment Multiline comment: # This is a # multiline comment Code with a comment: a = 1 # initialization Please note the two spaces in front of the comment. Function docstring: def foo (): \"\"\" This is a function docstring You can also use: ''' Function Docstring ''' \"\"\"","title":"Comments"},{"location":"dev/python/basics/#the-print-function","text":"The print() function writes the value of the argument(s) it is given. [...] it handles multiple arguments, floating point-quantities, and strings. Strings are printed without quotes, and a space is inserted between items, so you can format things nicely: >>> print ( 'Hello world!' ) # Hello world! >>> a = 1 >>> print ( 'Hello world!' , a ) # Hello world! 1","title":"The print() Function"},{"location":"dev/python/basics/#the-end-keyword","text":"The keyword argument end can be used to avoid the newline after the output, or end the output with a different string: phrase = [ 'printed' , 'with' , 'a' , 'dash' , 'in' , 'between' ] >>> for word in phrase : ... print ( word , end = '-' ) ... # printed-with-a-dash-in-between-","title":"The end keyword"},{"location":"dev/python/basics/#the-sep-keyword","text":"The keyword sep specify how to separate the objects, if there is more than one: print ( 'cats' , 'dogs' , 'mice' , sep = ',' ) # cats,dogs,mice","title":"The sep keyword"},{"location":"dev/python/basics/#the-input-function","text":"This function takes the input from the user and converts it into a string: >>> print ( 'What is your name?' ) # ask for their name >>> my_name = input () >>> print ( 'Hi, {} ' . format ( my_name )) # What is your name? # Martha # Hi, Martha input() can also set a default message without using print() : >>> my_name = input ( 'What is your name? ' ) # default message >>> print ( 'Hi, {} ' . format ( my_name )) # What is your name? Martha # Hi, Martha It is also possible to use formatted strings to avoid using .format: >>> my_name = input ( 'What is your name? ' ) # default message >>> print ( f 'Hi, { my_name } ' ) # What is your name? Martha # Hi, Martha","title":"The input() Function"},{"location":"dev/python/basics/#the-len-function","text":"Evaluates to the integer value of the number of characters in a string, list, dictionary, etc.: >>> len ( 'hello' ) # 5 >>> len ([ 'cat' , 3 , 'dog' ]) # 3 Test of emptiness Test of emptiness of strings, lists, dictionaries, etc., should not use len , but prefer direct boolean evaluation. Test of emptiness example: >>> a = [ 1 , 2 , 3 ] # bad >>> if len ( a ) > 0 : # evaluates to True ... print ( \"the list is not empty!\" ) ... # the list is not empty! # good >>> if a : # evaluates to True ... print ( \"the list is not empty!\" ) ... # the list is not empty!","title":"The len() Function"},{"location":"dev/python/basics/#the-str-int-and-float-functions","text":"These functions allow you to change the type of variable. For example, you can transform from an integer or float to a string : >>> str ( 29 ) # '29' >>> str ( - 3.14 ) # '-3.14' Or from a string to an integer or float : >>> int ( '11' ) # 11 >>> float ( '3.14' ) # 3.14","title":"The str(), int(), and float() Functions"},{"location":"dev/python/built-in-functions/","text":"Python Built-in Functions The Python interpreter has a number of functions and types built into it that are always available. Python built-in Functions Function Description abs() Return the absolute value of a number. aiter() Return an asynchronous iterator for an asynchronous iterable. all() Return True if all elements of the iterable are true. any() Return True if any element of the iterable is true. ascii() Return a string with a printable representation of an object. bin() Convert an integer number to a binary string. bool() Return a Boolean value. breakpoint() Drops you into the debugger at the call site. bytearray() Return a new array of bytes. bytes() Return a new \u201cbytes\u201d object. callable() Return True if the object argument is callable, False if not. chr() Return the string representing a character. classmethod() Transform a method into a class method. compile() Compile the source into a code or AST object. complex() Return a complex number with the value real + imag*1j. delattr() Deletes the named attribute, provided the object allows it. dict() Create a new dictionary. dir() Return the list of names in the current local scope. divmod() Return a pair of numbers consisting of their quotient and remainder. enumerate() Return an enumerate object. eval() Evaluates and executes an expression. exec() This function supports dynamic execution of Python code. filter() Construct an iterator from an iterable and returns true. float() Return a floating point number from a number or string. format() Convert a value to a \u201cformatted\u201d representation. frozenset() Return a new frozenset object. getattr() Return the value of the named attribute of object. globals() Return the dictionary implementing the current module namespace. hasattr() True if the string is the name of one of the object\u2019s attributes. hash() Return the hash value of the object. help() Invoke the built-in help system. hex() Convert an integer number to a lowercase hexadecimal string. id() Return the \u201cidentity\u201d of an object. input() This function takes an input and converts it into a string. int() Return an integer object constructed from a number or string. isinstance() Return True if the object argument is an instance of an object. issubclass() Return True if class is a subclass of classinfo. iter() Return an iterator object. len() Return the length (the number of items) of an object. list() Rather than being a function, list is a mutable sequence type. locals() Update and return a dictionary with the current local symbol table. map() Return an iterator that applies function to every item of iterable. max() Return the largest item in an iterable. min() Return the smallest item in an iterable. next() Retrieve the next item from the iterator. object() Return a new featureless object. oct() Convert an integer number to an octal string. open() Open file and return a corresponding file object. ord() Return an integer representing the Unicode code point of a character. pow() Return base to the power exp. print() Print objects to the text stream file. property() Return a property attribute. repr() Return a string containing a printable representation of an object. reversed() Return a reverse iterator. round() Return number rounded to ndigits precision after the decimal point. set() Return a new set object. setattr() This is the counterpart of getattr(). slice() Return a sliced object representing a set of indices. sorted() Return a new sorted list from the items in iterable. staticmethod() Transform a method into a static method. str() Return a str version of object. sum() Sums start and the items of an iterable. super() Return a proxy object that delegates method calls to a parent or sibling. tuple() Rather than being a function, is actually an immutable sequence type. type() Return the type of an object. vars() Return the dict attribute for any other object with a dict attribute. zip() Iterate over several iterables in parallel. import () This function is invoked by the import statement.","title":"Python built-in functions"},{"location":"dev/python/built-in-functions/#python-built-in-functions","text":"Function Description abs() Return the absolute value of a number. aiter() Return an asynchronous iterator for an asynchronous iterable. all() Return True if all elements of the iterable are true. any() Return True if any element of the iterable is true. ascii() Return a string with a printable representation of an object. bin() Convert an integer number to a binary string. bool() Return a Boolean value. breakpoint() Drops you into the debugger at the call site. bytearray() Return a new array of bytes. bytes() Return a new \u201cbytes\u201d object. callable() Return True if the object argument is callable, False if not. chr() Return the string representing a character. classmethod() Transform a method into a class method. compile() Compile the source into a code or AST object. complex() Return a complex number with the value real + imag*1j. delattr() Deletes the named attribute, provided the object allows it. dict() Create a new dictionary. dir() Return the list of names in the current local scope. divmod() Return a pair of numbers consisting of their quotient and remainder. enumerate() Return an enumerate object. eval() Evaluates and executes an expression. exec() This function supports dynamic execution of Python code. filter() Construct an iterator from an iterable and returns true. float() Return a floating point number from a number or string. format() Convert a value to a \u201cformatted\u201d representation. frozenset() Return a new frozenset object. getattr() Return the value of the named attribute of object. globals() Return the dictionary implementing the current module namespace. hasattr() True if the string is the name of one of the object\u2019s attributes. hash() Return the hash value of the object. help() Invoke the built-in help system. hex() Convert an integer number to a lowercase hexadecimal string. id() Return the \u201cidentity\u201d of an object. input() This function takes an input and converts it into a string. int() Return an integer object constructed from a number or string. isinstance() Return True if the object argument is an instance of an object. issubclass() Return True if class is a subclass of classinfo. iter() Return an iterator object. len() Return the length (the number of items) of an object. list() Rather than being a function, list is a mutable sequence type. locals() Update and return a dictionary with the current local symbol table. map() Return an iterator that applies function to every item of iterable. max() Return the largest item in an iterable. min() Return the smallest item in an iterable. next() Retrieve the next item from the iterator. object() Return a new featureless object. oct() Convert an integer number to an octal string. open() Open file and return a corresponding file object. ord() Return an integer representing the Unicode code point of a character. pow() Return base to the power exp. print() Print objects to the text stream file. property() Return a property attribute. repr() Return a string containing a printable representation of an object. reversed() Return a reverse iterator. round() Return number rounded to ndigits precision after the decimal point. set() Return a new set object. setattr() This is the counterpart of getattr(). slice() Return a sliced object representing a set of indices. sorted() Return a new sorted list from the items in iterable. staticmethod() Transform a method into a static method. str() Return a str version of object. sum() Sums start and the items of an iterable. super() Return a proxy object that delegates method calls to a parent or sibling. tuple() Rather than being a function, is actually an immutable sequence type. type() Return the type of an object. vars() Return the dict attribute for any other object with a dict attribute. zip() Iterate over several iterables in parallel. import () This function is invoked by the import statement.","title":"Python built-in Functions"},{"location":"dev/python/comprehensions/","text":"Python Comprehensions List Comprehensions are a special kind of syntax that let us create lists out of other lists, and are incredibly useful when dealing with numbers and with one or two levels of nested for loops. From the Python 3 tutorial List comprehensions provide a concise way to create lists. [...] or to create a subsequence of those elements that satisfy a certain condition. Read Python Comprehensions: A step by step Introduction for a more in-deep or introduction. List comprehension This is how we create a new list from an existing collection with a For Loop: >>> names = [ 'Charles' , 'Susan' , 'Patrick' , 'George' ] >>> new_list = [] >>> for n in names : ... new_list . append ( n ) ... >>> new_list # ['Charles', 'Susan', 'Patrick', 'George'] And this is how we do the same with a List Comprehension: >>> names = [ 'Charles' , 'Susan' , 'Patrick' , 'George' ] >>> new_list = [ n for n in names ] >>> new_list # ['Charles', 'Susan', 'Patrick', 'George'] We can do the same with numbers: >>> n = [( a , b ) for a in range ( 1 , 3 ) for b in range ( 1 , 3 )] >>> n # [(1, 1), (1, 2), (2, 1), (2, 2)] Adding conditionals If we want new_list to have only the names that start with C, with a for loop, we would do it like this: >>> names = [ 'Charles' , 'Susan' , 'Patrick' , 'George' , 'Carol' ] >>> new_list = [] >>> for n in names : ... if n . startswith ( 'C' ): ... new_list . append ( n ) ... >>> print ( new_list ) # ['Charles', 'Carol'] In a List Comprehension, we add the if statement at the end: >>> new_list = [ n for n in names if n . startswith ( 'C' )] >>> print ( new_list ) # ['Charles', 'Carol'] To use an if-else statement in a List Comprehension: >>> nums = [ 1 , 2 , 3 , 4 , 5 , 6 ] >>> new_list = [ num * 2 if num % 2 == 0 else num for num in nums ] >>> print ( new_list ) # [1, 4, 3, 8, 5, 12] Set and Dict comprehensions The basics of list comprehensions also apply to sets and dictionaries . Set comprehension >>> b = { \"abc\" , \"def\" } >>> { s . upper () for s in b } { \"ABC\" , \"DEF\" } Dict comprehension >>> c = { 'name' : 'Pooka' , 'age' : 5 } >>> { v : k for k , v in c . items ()} { 'Pooka' : 'name' , 5 : 'age' } A List comprehension can be generated from a dictionary: >>> c = { 'name' : 'Pooka' , 'first_name' : 'Oooka' } >>> [ \" {} : {} \" . format ( k . upper (), v . upper ()) for k , v in c . items ()] [ 'NAME:POOKA' , 'FIRST_NAME:OOOKA' ]","title":"Python Comprehensions"},{"location":"dev/python/comprehensions/#list-comprehension","text":"This is how we create a new list from an existing collection with a For Loop: >>> names = [ 'Charles' , 'Susan' , 'Patrick' , 'George' ] >>> new_list = [] >>> for n in names : ... new_list . append ( n ) ... >>> new_list # ['Charles', 'Susan', 'Patrick', 'George'] And this is how we do the same with a List Comprehension: >>> names = [ 'Charles' , 'Susan' , 'Patrick' , 'George' ] >>> new_list = [ n for n in names ] >>> new_list # ['Charles', 'Susan', 'Patrick', 'George'] We can do the same with numbers: >>> n = [( a , b ) for a in range ( 1 , 3 ) for b in range ( 1 , 3 )] >>> n # [(1, 1), (1, 2), (2, 1), (2, 2)]","title":"List comprehension"},{"location":"dev/python/comprehensions/#adding-conditionals","text":"If we want new_list to have only the names that start with C, with a for loop, we would do it like this: >>> names = [ 'Charles' , 'Susan' , 'Patrick' , 'George' , 'Carol' ] >>> new_list = [] >>> for n in names : ... if n . startswith ( 'C' ): ... new_list . append ( n ) ... >>> print ( new_list ) # ['Charles', 'Carol'] In a List Comprehension, we add the if statement at the end: >>> new_list = [ n for n in names if n . startswith ( 'C' )] >>> print ( new_list ) # ['Charles', 'Carol'] To use an if-else statement in a List Comprehension: >>> nums = [ 1 , 2 , 3 , 4 , 5 , 6 ] >>> new_list = [ num * 2 if num % 2 == 0 else num for num in nums ] >>> print ( new_list ) # [1, 4, 3, 8, 5, 12] Set and Dict comprehensions The basics of list comprehensions also apply to sets and dictionaries .","title":"Adding conditionals"},{"location":"dev/python/comprehensions/#set-comprehension","text":">>> b = { \"abc\" , \"def\" } >>> { s . upper () for s in b } { \"ABC\" , \"DEF\" }","title":"Set comprehension"},{"location":"dev/python/comprehensions/#dict-comprehension","text":">>> c = { 'name' : 'Pooka' , 'age' : 5 } >>> { v : k for k , v in c . items ()} { 'Pooka' : 'name' , 5 : 'age' } A List comprehension can be generated from a dictionary: >>> c = { 'name' : 'Pooka' , 'first_name' : 'Oooka' } >>> [ \" {} : {} \" . format ( k . upper (), v . upper ()) for k , v in c . items ()] [ 'NAME:POOKA' , 'FIRST_NAME:OOOKA' ]","title":"Dict comprehension"},{"location":"dev/python/context-manager/","text":"Python Context Manager While Python's context managers are widely used, few understand the purpose behind their use. These statements, commonly used with reading and writing files, assist the application in conserving system memory and improve resource management by ensuring specific resources are only in use for certain processes. The with statement A context manager is an object that is notified when a context (a block of code) starts and ends. You commonly use one with the with statement. It takes care of the notifying. For example, file objects are context managers. When a context ends, the file object is closed automatically: >>> with open ( filename ) as f : ... file_contents = f . read () ... >>> # the open_file object has automatically been closed. Anything that ends execution of the block causes the context manager's exit method to be called. This includes exceptions, and can be useful when an error causes you to prematurely exit an open file or connection. Exiting a script without properly closing files/connections is a bad idea, that may cause data loss or other problems. By using a context manager, you can ensure that precautions are always taken to prevent damage or loss in this way. Writing your own context manager It is also possible to write a context manager using generator syntax thanks to the contextlib.contextmanager decorator: >>> import contextlib >>> @contextlib . contextmanager ... def context_manager ( num ): ... print ( 'Enter' ) ... yield num + 1 ... print ( 'Exit' ) ... >>> with context_manager ( 2 ) as cm : ... # the following instructions are run when ... # the 'yield' point of the context manager is ... # reached. 'cm' will have the value that was yielded ... print ( 'Right in the middle with cm = {} ' . format ( cm )) ... # Enter # Right in the middle with cm = 3 # Exit Class based context manager You can define class based context manager. The key methods are __enter__ and __exit__ class ContextManager : def __enter__ ( self , * args , ** kwargs ): print ( \"--enter--\" ) def __exit__ ( self , * args ): print ( \"--exit--\" ) with ContextManager (): print ( \"test\" ) #--enter-- #test #--exit--","title":"Python Context Manager"},{"location":"dev/python/context-manager/#the-with-statement","text":"A context manager is an object that is notified when a context (a block of code) starts and ends. You commonly use one with the with statement. It takes care of the notifying. For example, file objects are context managers. When a context ends, the file object is closed automatically: >>> with open ( filename ) as f : ... file_contents = f . read () ... >>> # the open_file object has automatically been closed. Anything that ends execution of the block causes the context manager's exit method to be called. This includes exceptions, and can be useful when an error causes you to prematurely exit an open file or connection. Exiting a script without properly closing files/connections is a bad idea, that may cause data loss or other problems. By using a context manager, you can ensure that precautions are always taken to prevent damage or loss in this way.","title":"The with statement"},{"location":"dev/python/context-manager/#writing-your-own-context-manager","text":"It is also possible to write a context manager using generator syntax thanks to the contextlib.contextmanager decorator: >>> import contextlib >>> @contextlib . contextmanager ... def context_manager ( num ): ... print ( 'Enter' ) ... yield num + 1 ... print ( 'Exit' ) ... >>> with context_manager ( 2 ) as cm : ... # the following instructions are run when ... # the 'yield' point of the context manager is ... # reached. 'cm' will have the value that was yielded ... print ( 'Right in the middle with cm = {} ' . format ( cm )) ... # Enter # Right in the middle with cm = 3 # Exit","title":"Writing your own context manager"},{"location":"dev/python/context-manager/#class-based-context-manager","text":"You can define class based context manager. The key methods are __enter__ and __exit__ class ContextManager : def __enter__ ( self , * args , ** kwargs ): print ( \"--enter--\" ) def __exit__ ( self , * args ): print ( \"--exit--\" ) with ContextManager (): print ( \"test\" ) #--enter-- #test #--exit--","title":"Class based context manager"},{"location":"dev/python/control-flow/","text":"Python Control Flow Python control flow Control flow is the order in which individual statements, instructions, or function calls are executed or evaluated. The control flow of a Python program is regulated by conditional statements, loops, and function calls. Comparison Operators Operator Meaning == Equal to != Not equal to < Less than > Greater Than <= Less than or Equal to >= Greater than or Equal to These operators evaluate to True or False depending on the values you give them. Examples: >>> 42 == 42 True >>> 40 == 42 False >>> 'hello' == 'hello' True >>> 'hello' == 'Hello' False >>> 'dog' != 'cat' True >>> 42 == 42.0 True >>> 42 == '42' False Boolean Operators There are three Boolean operators: and , or , and not . The and Operator\u2019s Truth Table: Expression Evaluates to True and True True True and False False False and True False False and False False The or Operator\u2019s Truth Table: Expression Evaluates to True or True True True or False True False or True True False or False False The not Operator\u2019s Truth Table: Expression Evaluates to not True False not False True Mixing Operators You can mix boolean and comparison operators: >>> ( 4 < 5 ) and ( 5 < 6 ) True >>> ( 4 < 5 ) and ( 9 < 6 ) False >>> ( 1 == 2 ) or ( 2 == 2 ) True Also, you can mix use multiple Boolean operators in an expression, along with the comparison operators: >>> 2 + 2 == 4 and not 2 + 2 == 5 and 2 * 2 == 2 + 2 True if Statements The if statement evaluates an expression, and if that expression is True , it then executes the following indented code: >>> name = 'Debora' >>> if name == 'Debora' : ... print ( 'Hi, Debora' ) ... # Hi, Debora >>> if name != 'George' : ... print ( 'You are not George' ) ... # You are not George The else statement executes only if the evaluation of the if and all the elif expressions are False : >>> name = 'Debora' >>> if name == 'George' : ... print ( 'Hi, George.' ) ... else : ... print ( 'You are not George' ) ... # You are not George Only after the if statement expression is False , the elif statement is evaluated and executed: >>> name = 'George' >>> if name == 'Debora' : ... print ( 'Hi Debora!' ) ... elif name == 'George' : ... print ( 'Hi George!' ) ... # Hi George! the elif and else parts are optional. >>> name = 'Antony' >>> if name == 'Debora' : ... print ( 'Hi Debora!' ) ... elif name == 'George' : ... print ( 'Hi George!' ) ... else : ... print ( 'Who are you?' ) ... # Who are you? Ternary Conditional Operator Many programming languages have a ternary operator, which define a conditional expression. The most common usage is to make a terse, simple conditional assignment statement. In other words, it offers one-line code to evaluate the first expression if the condition is true, and otherwise it evaluates the second expression. <expression1> if <condition> else <expression2> Example: >>> age = 15 >>> # this if statement: >>> if age < 18 : ... print ( 'kid' ) ... else : ... print ( 'adult' ) ... # output: kid >>> # is equivalent to this ternary operator: >>> print ( 'kid' if age < 18 else 'adult' ) # output: kid Ternary operators can be chained: >>> age = 15 >>> # this ternary operator: >>> print ( 'kid' if age < 13 else 'teen' if age < 18 else 'adult' ) >>> # is equivalent to this if statement: >>> if age < 18 : ... if age < 13 : ... print ( 'kid' ) ... else : ... print ( 'teen' ) ... else : ... print ( 'adult' ) ... # output: teen Switch-Case Statement Switch-Case statements In computer programming languages, a switch statement is a type of selection control mechanism used to allow the value of a variable or expression to change the control flow of program execution via search and map. The Switch-Case statements , or Structural Pattern Matching , was firstly introduced in 2020 via PEP 622 , and then officially released with Python 3.10 in September 2022. Official Tutorial The PEP 636 provides an official tutorial for the Python Pattern matching or Switch-Case statements. Matching single values >>> response_code = 201 >>> match response_code : ... case 200 : ... print ( \"OK\" ) ... case 201 : ... print ( \"Created\" ) ... case 300 : ... print ( \"Multiple Choices\" ) ... case 307 : ... print ( \"Temporary Redirect\" ) ... case 404 : ... print ( \"404 Not Found\" ) ... case 500 : ... print ( \"Internal Server Error\" ) ... case 502 : ... print ( \"502 Bad Gateway\" ) ... # Created Matching with the or Pattern In this example, the pipe character ( | or or ) allows python to return the same response for two or more cases. >>> response_code = 502 >>> match response_code : ... case 200 | 201 : ... print ( \"OK\" ) ... case 300 | 307 : ... print ( \"Redirect\" ) ... case 400 | 401 : ... print ( \"Bad Request\" ) ... case 500 | 502 : ... print ( \"Internal Server Error\" ) ... # Internal Server Error Matching by the length of an Iterable >>> today_responses = [ 200 , 300 , 404 , 500 ] >>> match today_responses : ... case [ a ]: ... print ( f \"One response today: { a } \" ) ... case [ a , b ]: ... print ( f \"Two responses today: { a } and { b } \" ) ... case [ a , b , * rest ]: ... print ( f \"All responses: { a } , { b } , { rest } \" ) ... # All responses: 200, 300, [404, 500] Default value The underscore symbol ( _ ) is used to define a default case: >>> response_code = 800 >>> match response_code : ... case 200 | 201 : ... print ( \"OK\" ) ... case 300 | 307 : ... print ( \"Redirect\" ) ... case 400 | 401 : ... print ( \"Bad Request\" ) ... case 500 | 502 : ... print ( \"Internal Server Error\" ) ... case _ : ... print ( \"Invalid Code\" ) ... # Invalid Code Matching Builtin Classes >>> response_code = \"300\" >>> match response_code : ... case int (): ... print ( 'Code is a number' ) ... case str (): ... print ( 'Code is a string' ) ... case _ : ... print ( 'Code is neither a string nor a number' ) ... # Code is a string Guarding Match-Case Statements >>> response_code = 300 >>> match response_code : ... case int (): ... if response_code > 99 and response_code < 500 : ... print ( 'Code is a valid number' ) ... case _ : ... print ( 'Code is an invalid number' ) ... # Code is a valid number while Loop Statements The while statement is used for repeated execution as long as an expression is True : >>> spam = 0 >>> while spam < 5 : ... print ( 'Hello, world.' ) ... spam = spam + 1 ... # Hello, world. # Hello, world. # Hello, world. # Hello, world. # Hello, world. break Statements If the execution reaches a break statement, it immediately exits the while loop\u2019s clause: >>> while True : ... name = input ( 'Please type your name: ' ) ... if name == 'your name' : ... break ... >>> print ( 'Thank you!' ) # Please type your name: your name # Thank you! continue Statements When the program execution reaches a continue statement, the program execution immediately jumps back to the start of the loop. >>> while True : ... name = input ( 'Who are you? ' ) ... if name != 'Joe' : ... continue ... password = input ( 'Password? (It is a fish.): ' ) ... if password == 'swordfish' : ... break ... >>> print ( 'Access granted.' ) # Who are you? Charles # Who are you? Debora # Who are you? Joe # Password? (It is a fish.): swordfish # Access granted. For loop The for loop iterates over a list , tuple , dictionary , set or string : >>> pets = [ 'Bella' , 'Milo' , 'Loki' ] >>> for pet in pets : ... print ( pet ) ... # Bella # Milo # Loki The range() function The range() function returns a sequence of numbers. It starts from 0, increments by 1, and stops before a specified number: >>> for i in range ( 5 ): ... print ( f 'Will stop at 5! or 4? ( { i } )' ) ... # Will stop at 5! or 4? (0) # Will stop at 5! or 4? (1) # Will stop at 5! or 4? (2) # Will stop at 5! or 4? (3) # Will stop at 5! or 4? (4) The range() function can also modify it's 3 defaults arguments. The first two will be the start and stop values, and the third will be the step argument. The step is the amount that the variable is increased by after each iteration. # range(start, stop, step) >>> for i in range ( 0 , 10 , 2 ): ... print ( i ) ... # 0 # 2 # 4 # 6 # 8 You can even use a negative number for the step argument to make the for loop count down instead of up. >>> for i in range ( 5 , - 1 , - 1 ): ... print ( i ) ... # 5 # 4 # 3 # 2 # 1 # 0 For else statement This allows to specify a statement to execute in case of the full loop has been executed. Only useful when a break condition can occur in the loop: >>> for i in [ 1 , 2 , 3 , 4 , 5 ]: ... if i == 3 : ... break ... else : ... print ( \"only executed when no item is equal to 3\" ) Ending a Program with sys.exit() exit() function allows exiting Python. >>> import sys >>> while True : ... feedback = input ( 'Type exit to exit: ' ) ... if feedback == 'exit' : ... print ( f 'You typed { feedback } .' ) ... sys . exit () ... # Type exit to exit: open # Type exit to exit: close # Type exit to exit: exit # You typed exit","title":"Python Control Flow"},{"location":"dev/python/control-flow/#comparison-operators","text":"Operator Meaning == Equal to != Not equal to < Less than > Greater Than <= Less than or Equal to >= Greater than or Equal to These operators evaluate to True or False depending on the values you give them. Examples: >>> 42 == 42 True >>> 40 == 42 False >>> 'hello' == 'hello' True >>> 'hello' == 'Hello' False >>> 'dog' != 'cat' True >>> 42 == 42.0 True >>> 42 == '42' False","title":"Comparison Operators"},{"location":"dev/python/control-flow/#boolean-operators","text":"There are three Boolean operators: and , or , and not . The and Operator\u2019s Truth Table: Expression Evaluates to True and True True True and False False False and True False False and False False The or Operator\u2019s Truth Table: Expression Evaluates to True or True True True or False True False or True True False or False False The not Operator\u2019s Truth Table: Expression Evaluates to not True False not False True","title":"Boolean Operators"},{"location":"dev/python/control-flow/#mixing-operators","text":"You can mix boolean and comparison operators: >>> ( 4 < 5 ) and ( 5 < 6 ) True >>> ( 4 < 5 ) and ( 9 < 6 ) False >>> ( 1 == 2 ) or ( 2 == 2 ) True Also, you can mix use multiple Boolean operators in an expression, along with the comparison operators: >>> 2 + 2 == 4 and not 2 + 2 == 5 and 2 * 2 == 2 + 2 True","title":"Mixing Operators"},{"location":"dev/python/control-flow/#if-statements","text":"The if statement evaluates an expression, and if that expression is True , it then executes the following indented code: >>> name = 'Debora' >>> if name == 'Debora' : ... print ( 'Hi, Debora' ) ... # Hi, Debora >>> if name != 'George' : ... print ( 'You are not George' ) ... # You are not George The else statement executes only if the evaluation of the if and all the elif expressions are False : >>> name = 'Debora' >>> if name == 'George' : ... print ( 'Hi, George.' ) ... else : ... print ( 'You are not George' ) ... # You are not George Only after the if statement expression is False , the elif statement is evaluated and executed: >>> name = 'George' >>> if name == 'Debora' : ... print ( 'Hi Debora!' ) ... elif name == 'George' : ... print ( 'Hi George!' ) ... # Hi George! the elif and else parts are optional. >>> name = 'Antony' >>> if name == 'Debora' : ... print ( 'Hi Debora!' ) ... elif name == 'George' : ... print ( 'Hi George!' ) ... else : ... print ( 'Who are you?' ) ... # Who are you?","title":"if Statements"},{"location":"dev/python/control-flow/#ternary-conditional-operator","text":"Many programming languages have a ternary operator, which define a conditional expression. The most common usage is to make a terse, simple conditional assignment statement. In other words, it offers one-line code to evaluate the first expression if the condition is true, and otherwise it evaluates the second expression. <expression1> if <condition> else <expression2> Example: >>> age = 15 >>> # this if statement: >>> if age < 18 : ... print ( 'kid' ) ... else : ... print ( 'adult' ) ... # output: kid >>> # is equivalent to this ternary operator: >>> print ( 'kid' if age < 18 else 'adult' ) # output: kid Ternary operators can be chained: >>> age = 15 >>> # this ternary operator: >>> print ( 'kid' if age < 13 else 'teen' if age < 18 else 'adult' ) >>> # is equivalent to this if statement: >>> if age < 18 : ... if age < 13 : ... print ( 'kid' ) ... else : ... print ( 'teen' ) ... else : ... print ( 'adult' ) ... # output: teen","title":"Ternary Conditional Operator"},{"location":"dev/python/control-flow/#switch-case-statement","text":"Switch-Case statements In computer programming languages, a switch statement is a type of selection control mechanism used to allow the value of a variable or expression to change the control flow of program execution via search and map. The Switch-Case statements , or Structural Pattern Matching , was firstly introduced in 2020 via PEP 622 , and then officially released with Python 3.10 in September 2022. Official Tutorial The PEP 636 provides an official tutorial for the Python Pattern matching or Switch-Case statements.","title":"Switch-Case Statement"},{"location":"dev/python/control-flow/#matching-single-values","text":">>> response_code = 201 >>> match response_code : ... case 200 : ... print ( \"OK\" ) ... case 201 : ... print ( \"Created\" ) ... case 300 : ... print ( \"Multiple Choices\" ) ... case 307 : ... print ( \"Temporary Redirect\" ) ... case 404 : ... print ( \"404 Not Found\" ) ... case 500 : ... print ( \"Internal Server Error\" ) ... case 502 : ... print ( \"502 Bad Gateway\" ) ... # Created","title":"Matching single values"},{"location":"dev/python/control-flow/#matching-with-the-or-pattern","text":"In this example, the pipe character ( | or or ) allows python to return the same response for two or more cases. >>> response_code = 502 >>> match response_code : ... case 200 | 201 : ... print ( \"OK\" ) ... case 300 | 307 : ... print ( \"Redirect\" ) ... case 400 | 401 : ... print ( \"Bad Request\" ) ... case 500 | 502 : ... print ( \"Internal Server Error\" ) ... # Internal Server Error","title":"Matching with the or Pattern"},{"location":"dev/python/control-flow/#matching-by-the-length-of-an-iterable","text":">>> today_responses = [ 200 , 300 , 404 , 500 ] >>> match today_responses : ... case [ a ]: ... print ( f \"One response today: { a } \" ) ... case [ a , b ]: ... print ( f \"Two responses today: { a } and { b } \" ) ... case [ a , b , * rest ]: ... print ( f \"All responses: { a } , { b } , { rest } \" ) ... # All responses: 200, 300, [404, 500]","title":"Matching by the length of an Iterable"},{"location":"dev/python/control-flow/#default-value","text":"The underscore symbol ( _ ) is used to define a default case: >>> response_code = 800 >>> match response_code : ... case 200 | 201 : ... print ( \"OK\" ) ... case 300 | 307 : ... print ( \"Redirect\" ) ... case 400 | 401 : ... print ( \"Bad Request\" ) ... case 500 | 502 : ... print ( \"Internal Server Error\" ) ... case _ : ... print ( \"Invalid Code\" ) ... # Invalid Code","title":"Default value"},{"location":"dev/python/control-flow/#matching-builtin-classes","text":">>> response_code = \"300\" >>> match response_code : ... case int (): ... print ( 'Code is a number' ) ... case str (): ... print ( 'Code is a string' ) ... case _ : ... print ( 'Code is neither a string nor a number' ) ... # Code is a string","title":"Matching Builtin Classes"},{"location":"dev/python/control-flow/#guarding-match-case-statements","text":">>> response_code = 300 >>> match response_code : ... case int (): ... if response_code > 99 and response_code < 500 : ... print ( 'Code is a valid number' ) ... case _ : ... print ( 'Code is an invalid number' ) ... # Code is a valid number","title":"Guarding Match-Case Statements"},{"location":"dev/python/control-flow/#while-loop-statements","text":"The while statement is used for repeated execution as long as an expression is True : >>> spam = 0 >>> while spam < 5 : ... print ( 'Hello, world.' ) ... spam = spam + 1 ... # Hello, world. # Hello, world. # Hello, world. # Hello, world. # Hello, world.","title":"while Loop Statements"},{"location":"dev/python/control-flow/#break-statements","text":"If the execution reaches a break statement, it immediately exits the while loop\u2019s clause: >>> while True : ... name = input ( 'Please type your name: ' ) ... if name == 'your name' : ... break ... >>> print ( 'Thank you!' ) # Please type your name: your name # Thank you!","title":"break Statements"},{"location":"dev/python/control-flow/#continue-statements","text":"When the program execution reaches a continue statement, the program execution immediately jumps back to the start of the loop. >>> while True : ... name = input ( 'Who are you? ' ) ... if name != 'Joe' : ... continue ... password = input ( 'Password? (It is a fish.): ' ) ... if password == 'swordfish' : ... break ... >>> print ( 'Access granted.' ) # Who are you? Charles # Who are you? Debora # Who are you? Joe # Password? (It is a fish.): swordfish # Access granted.","title":"continue Statements"},{"location":"dev/python/control-flow/#for-loop","text":"The for loop iterates over a list , tuple , dictionary , set or string : >>> pets = [ 'Bella' , 'Milo' , 'Loki' ] >>> for pet in pets : ... print ( pet ) ... # Bella # Milo # Loki","title":"For loop"},{"location":"dev/python/control-flow/#the-range-function","text":"The range() function returns a sequence of numbers. It starts from 0, increments by 1, and stops before a specified number: >>> for i in range ( 5 ): ... print ( f 'Will stop at 5! or 4? ( { i } )' ) ... # Will stop at 5! or 4? (0) # Will stop at 5! or 4? (1) # Will stop at 5! or 4? (2) # Will stop at 5! or 4? (3) # Will stop at 5! or 4? (4) The range() function can also modify it's 3 defaults arguments. The first two will be the start and stop values, and the third will be the step argument. The step is the amount that the variable is increased by after each iteration. # range(start, stop, step) >>> for i in range ( 0 , 10 , 2 ): ... print ( i ) ... # 0 # 2 # 4 # 6 # 8 You can even use a negative number for the step argument to make the for loop count down instead of up. >>> for i in range ( 5 , - 1 , - 1 ): ... print ( i ) ... # 5 # 4 # 3 # 2 # 1 # 0","title":"The range() function"},{"location":"dev/python/control-flow/#for-else-statement","text":"This allows to specify a statement to execute in case of the full loop has been executed. Only useful when a break condition can occur in the loop: >>> for i in [ 1 , 2 , 3 , 4 , 5 ]: ... if i == 3 : ... break ... else : ... print ( \"only executed when no item is equal to 3\" )","title":"For else statement"},{"location":"dev/python/control-flow/#ending-a-program-with-sysexit","text":"exit() function allows exiting Python. >>> import sys >>> while True : ... feedback = input ( 'Type exit to exit: ' ) ... if feedback == 'exit' : ... print ( f 'You typed { feedback } .' ) ... sys . exit () ... # Type exit to exit: open # Type exit to exit: close # Type exit to exit: exit # You typed exit","title":"Ending a Program with sys.exit()"},{"location":"dev/python/dataclasses/","text":"Python Dataclasses Dataclasses are python classes, but are suited for storing data objects. This module provides a decorator and functions for automatically adding generated special methods such as __init__() and __repr__() to user-defined classes. Features They store data and represent a certain data type. Ex: A number. For people familiar with ORMs, a model instance is a data object. It represents a specific kind of entity. It holds attributes that define or represent the entity. They can be compared to other objects of the same type. Ex: A number can be greater than, less than, or equal to another number. Python 3.7 provides a decorator dataclass that is used to convert a class into a dataclass. >>> class Number : ... def __init__ ( self , val ): ... self . val = val ... >>> obj = Number ( 2 ) >>> obj . val # 2 with dataclass >>> @dataclass ... class Number : ... val : int ... >>> obj = Number ( 2 ) >>> obj . val # 2 Default values It is easy to add default values to the fields of your data class. >>> @dataclass ... class Product : ... name : str ... count : int = 0 ... price : float = 0.0 ... >>> obj = Product ( \"Python\" ) >>> obj . name # Python >>> obj . count # 0 >>> obj . price # 0.0 Type hints It is mandatory to define the data type in dataclass. However, If you would rather not specify the datatype then, use typing.Any . >>> from dataclasses import dataclass >>> from typing import Any >>> @dataclass ... class WithoutExplicitTypes : ... name : Any ... value : Any = 42","title":"Python Dataclasses"},{"location":"dev/python/dataclasses/#features","text":"They store data and represent a certain data type. Ex: A number. For people familiar with ORMs, a model instance is a data object. It represents a specific kind of entity. It holds attributes that define or represent the entity. They can be compared to other objects of the same type. Ex: A number can be greater than, less than, or equal to another number. Python 3.7 provides a decorator dataclass that is used to convert a class into a dataclass. >>> class Number : ... def __init__ ( self , val ): ... self . val = val ... >>> obj = Number ( 2 ) >>> obj . val # 2 with dataclass >>> @dataclass ... class Number : ... val : int ... >>> obj = Number ( 2 ) >>> obj . val # 2","title":"Features"},{"location":"dev/python/dataclasses/#default-values","text":"It is easy to add default values to the fields of your data class. >>> @dataclass ... class Product : ... name : str ... count : int = 0 ... price : float = 0.0 ... >>> obj = Product ( \"Python\" ) >>> obj . name # Python >>> obj . count # 0 >>> obj . price # 0.0","title":"Default values"},{"location":"dev/python/dataclasses/#type-hints","text":"It is mandatory to define the data type in dataclass. However, If you would rather not specify the datatype then, use typing.Any . >>> from dataclasses import dataclass >>> from typing import Any >>> @dataclass ... class WithoutExplicitTypes : ... name : Any ... value : Any = 42","title":"Type hints"},{"location":"dev/python/debugging/","text":"Python Debugging Finding and resolving bugs In computer programming and software development, debugging is the process of finding and resolving bugs (defects or problems that prevent correct operation) within computer programs, software, or systems. Raising Exceptions Exceptions are raised with a raise statement. In code, a raise statement consists of the following: The raise keyword A call to the Exception() function A string with a helpful error message passed to the Exception() function >>> raise Exception ( 'This is the error message.' ) # Traceback (most recent call last): # File \"<pyshell#191>\", line 1, in <module> # raise Exception('This is the error message.') # Exception: This is the error message. Typically, it\u2019s the code that calls the function, not the function itself, that knows how to handle an exception. So, you will commonly see a raise statement inside a function and the try and except statements in the code calling the function. >>> def box_print ( symbol , width , height ): ... if len ( symbol ) != 1 : ... raise Exception ( 'Symbol must be a single character string.' ) ... if width <= 2 : ... raise Exception ( 'Width must be greater than 2.' ) ... if height <= 2 : ... raise Exception ( 'Height must be greater than 2.' ) ... print ( symbol * width ) ... for i in range ( height - 2 ): ... print ( symbol + ( ' ' * ( width - 2 )) + symbol ) ... print ( symbol * width ) ... >>> for sym , w , h in (( '*' , 4 , 4 ), ( 'O' , 20 , 5 ), ( 'x' , 1 , 3 ), ( 'ZZ' , 3 , 3 )): ... try : ... box_print ( sym , w , h ) ... except Exception as err : ... print ( 'An exception happened: ' + str ( err )) ... # **** # * * # * * # **** # OOOOOOOOOOOOOOOOOOOO # O O # O O # O O # OOOOOOOOOOOOOOOOOOOO # An exception happened: Width must be greater than 2. # An exception happened: Symbol must be a single character string. Read more about Exception Handling . Getting the Traceback as a string The traceback is displayed by Python whenever a raised exception goes unhandled. But can also obtain it as a string by calling traceback.format_exc(). This function is useful if you want the information from an exception\u2019s traceback but also want an except statement to gracefully handle the exception. You will need to import Python\u2019s traceback module before calling this function. >>> import traceback >>> try : ... raise Exception ( 'This is the error message.' ) >>> except : ... with open ( 'errorInfo.txt' , 'w' ) as error_file : ... error_file . write ( traceback . format_exc ()) ... print ( 'The traceback info was written to errorInfo.txt.' ) ... # 116 # The traceback info was written to errorInfo.txt. The 116 is the return value from the write() method, since 116 characters were written to the file. The traceback text was written to errorInfo.txt. Traceback (most recent call last): File \"<pyshell#28>\", line 2, in <module> Exception: This is the error message. Assertions An assertion is a sanity check to make sure your code isn\u2019t doing something obviously wrong. These sanity checks are performed by assert statements. If the sanity check fails, then an AssertionError exception is raised. In code, an assert statement consists of the following: The assert keyword A condition (that is, an expression that evaluates to True or False ) A comma A string to display when the condition is False >>> pod_bay_door_status = 'open' >>> assert pod_bay_door_status == 'open' , 'The pod bay doors need to be \"open\".' >>> pod_bay_door_status = 'I \\' m sorry, Dave. I \\' m afraid I can \\' t do that.' >>> assert pod_bay_door_status == 'open' , 'The pod bay doors need to be \"open\".' # Traceback (most recent call last): # File \"<pyshell#10>\", line 1, in <module> # assert pod_bay_door_status == 'open', 'The pod bay doors need to be \"open\".' # AssertionError: The pod bay doors need to be \"open\". In plain English, an assert statement says, \u201cI assert that this condition holds true, and if not, there is a bug somewhere in the program.\u201d Unlike exceptions, your code should not handle assert statements with try and except; if an assert fails, your program should crash. By failing fast like this, you shorten the time between the original cause of the bug and when you first notice the bug. This will reduce the amount of code you will have to check before finding the code that\u2019s causing the bug. Disabling Assertions Assertions can be disabled by passing the -O option when running Python. Logging To enable the logging module to display log messages on your screen as your program runs, copy the following to the top of your program: >>> import logging >>> logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(levelname)s - %(message)s ' ) Say you wrote a function to calculate the factorial of a number. In mathematics, factorial 4 is 1 \u00d7 2 \u00d7 3 \u00d7 4, or 24. Factorial 7 is 1 \u00d7 2 \u00d7 3 \u00d7 4 \u00d7 5 \u00d7 6 \u00d7 7, or 5,040. Open a new file editor window and enter the following code. It has a bug in it, but you will also enter several log messages to help yourself figure out what is going wrong. Save the program as factorialLog.py. >>> import logging >>> logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(levelname)s - %(message)s ' ) >>> logging . debug ( 'Start of program' ) >>> def factorial ( n ): ... logging . debug ( 'Start of factorial( %s )' % ( n )) ... total = 1 ... for i in range ( 1 , n + 1 ): ... total *= i ... logging . debug ( 'i is ' + str ( i ) + ', total is ' + str ( total )) ... logging . debug ( 'End of factorial( %s )' % ( n )) ... return total ... >>> print ( factorial ( 5 )) >>> logging . debug ( 'End of program' ) # 2015-05-23 16:20:12,664 - DEBUG - Start of program # 2015-05-23 16:20:12,664 - DEBUG - Start of factorial(5) # 2015-05-23 16:20:12,665 - DEBUG - i is 0, total is 0 # 2015-05-23 16:20:12,668 - DEBUG - i is 1, total is 0 # 2015-05-23 16:20:12,670 - DEBUG - i is 2, total is 0 # 2015-05-23 16:20:12,673 - DEBUG - i is 3, total is 0 # 2015-05-23 16:20:12,675 - DEBUG - i is 4, total is 0 # 2015-05-23 16:20:12,678 - DEBUG - i is 5, total is 0 # 2015-05-23 16:20:12,680 - DEBUG - End of factorial(5) # 0 # 2015-05-23 16:20:12,684 - DEBUG - End of program Logging Levels Logging levels provide a way to categorize your log messages by importance. There are five logging levels, described in Table 10-1 from least to most important. Messages can be logged at each level using a different logging function. Level Logging Function Description DEBUG logging.debug() The lowest level. Used for small details. Usually you care about these messages only when diagnosing problems. INFO logging.info() Used to record information on general events in your program or confirm that things are working at their point in the program. WARNING logging.warning() Used to indicate a potential problem that doesn\u2019t prevent the program from working but might do so in the future. ERROR logging.error() Used to record an error that caused the program to fail to do something. CRITICAL logging.critical() The highest level. Used to indicate a fatal error that has caused or is about to cause the program to stop running entirely. Disabling Logging After you\u2019ve debugged your program, you probably don\u2019t want all these log messages cluttering the screen. The logging.disable() function disables these so that you don\u2019t have to go into your program and remove all the logging calls by hand. >>> import logging >>> logging . basicConfig ( level = logging . INFO , format = ' %(asctime)s - %(levelname)s - %(message)s ' ) >>> logging . critical ( 'Critical error! Critical error!' ) # 2015-05-22 11:10:48,054 - CRITICAL - Critical error! Critical error! >>> logging . disable ( logging . CRITICAL ) >>> logging . critical ( 'Critical error! Critical error!' ) >>> logging . error ( 'Error! Error!' ) Logging to a File Instead of displaying the log messages to the screen, you can write them to a text file. The logging.basicConfig() function takes a filename keyword argument, like so: >>> import logging >>> logging . basicConfig ( filename = 'myProgramLog.txt' , level = logging . DEBUG , format = ' %(asctime)s - %(levelname)s - %(message)s ' )","title":"Python Debugging"},{"location":"dev/python/debugging/#raising-exceptions","text":"Exceptions are raised with a raise statement. In code, a raise statement consists of the following: The raise keyword A call to the Exception() function A string with a helpful error message passed to the Exception() function >>> raise Exception ( 'This is the error message.' ) # Traceback (most recent call last): # File \"<pyshell#191>\", line 1, in <module> # raise Exception('This is the error message.') # Exception: This is the error message. Typically, it\u2019s the code that calls the function, not the function itself, that knows how to handle an exception. So, you will commonly see a raise statement inside a function and the try and except statements in the code calling the function. >>> def box_print ( symbol , width , height ): ... if len ( symbol ) != 1 : ... raise Exception ( 'Symbol must be a single character string.' ) ... if width <= 2 : ... raise Exception ( 'Width must be greater than 2.' ) ... if height <= 2 : ... raise Exception ( 'Height must be greater than 2.' ) ... print ( symbol * width ) ... for i in range ( height - 2 ): ... print ( symbol + ( ' ' * ( width - 2 )) + symbol ) ... print ( symbol * width ) ... >>> for sym , w , h in (( '*' , 4 , 4 ), ( 'O' , 20 , 5 ), ( 'x' , 1 , 3 ), ( 'ZZ' , 3 , 3 )): ... try : ... box_print ( sym , w , h ) ... except Exception as err : ... print ( 'An exception happened: ' + str ( err )) ... # **** # * * # * * # **** # OOOOOOOOOOOOOOOOOOOO # O O # O O # O O # OOOOOOOOOOOOOOOOOOOO # An exception happened: Width must be greater than 2. # An exception happened: Symbol must be a single character string. Read more about Exception Handling .","title":"Raising Exceptions"},{"location":"dev/python/debugging/#getting-the-traceback-as-a-string","text":"The traceback is displayed by Python whenever a raised exception goes unhandled. But can also obtain it as a string by calling traceback.format_exc(). This function is useful if you want the information from an exception\u2019s traceback but also want an except statement to gracefully handle the exception. You will need to import Python\u2019s traceback module before calling this function. >>> import traceback >>> try : ... raise Exception ( 'This is the error message.' ) >>> except : ... with open ( 'errorInfo.txt' , 'w' ) as error_file : ... error_file . write ( traceback . format_exc ()) ... print ( 'The traceback info was written to errorInfo.txt.' ) ... # 116 # The traceback info was written to errorInfo.txt. The 116 is the return value from the write() method, since 116 characters were written to the file. The traceback text was written to errorInfo.txt. Traceback (most recent call last): File \"<pyshell#28>\", line 2, in <module> Exception: This is the error message.","title":"Getting the Traceback as a string"},{"location":"dev/python/debugging/#assertions","text":"An assertion is a sanity check to make sure your code isn\u2019t doing something obviously wrong. These sanity checks are performed by assert statements. If the sanity check fails, then an AssertionError exception is raised. In code, an assert statement consists of the following: The assert keyword A condition (that is, an expression that evaluates to True or False ) A comma A string to display when the condition is False >>> pod_bay_door_status = 'open' >>> assert pod_bay_door_status == 'open' , 'The pod bay doors need to be \"open\".' >>> pod_bay_door_status = 'I \\' m sorry, Dave. I \\' m afraid I can \\' t do that.' >>> assert pod_bay_door_status == 'open' , 'The pod bay doors need to be \"open\".' # Traceback (most recent call last): # File \"<pyshell#10>\", line 1, in <module> # assert pod_bay_door_status == 'open', 'The pod bay doors need to be \"open\".' # AssertionError: The pod bay doors need to be \"open\". In plain English, an assert statement says, \u201cI assert that this condition holds true, and if not, there is a bug somewhere in the program.\u201d Unlike exceptions, your code should not handle assert statements with try and except; if an assert fails, your program should crash. By failing fast like this, you shorten the time between the original cause of the bug and when you first notice the bug. This will reduce the amount of code you will have to check before finding the code that\u2019s causing the bug.","title":"Assertions"},{"location":"dev/python/debugging/#disabling-assertions","text":"Assertions can be disabled by passing the -O option when running Python.","title":"Disabling Assertions"},{"location":"dev/python/debugging/#logging","text":"To enable the logging module to display log messages on your screen as your program runs, copy the following to the top of your program: >>> import logging >>> logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(levelname)s - %(message)s ' ) Say you wrote a function to calculate the factorial of a number. In mathematics, factorial 4 is 1 \u00d7 2 \u00d7 3 \u00d7 4, or 24. Factorial 7 is 1 \u00d7 2 \u00d7 3 \u00d7 4 \u00d7 5 \u00d7 6 \u00d7 7, or 5,040. Open a new file editor window and enter the following code. It has a bug in it, but you will also enter several log messages to help yourself figure out what is going wrong. Save the program as factorialLog.py. >>> import logging >>> logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(levelname)s - %(message)s ' ) >>> logging . debug ( 'Start of program' ) >>> def factorial ( n ): ... logging . debug ( 'Start of factorial( %s )' % ( n )) ... total = 1 ... for i in range ( 1 , n + 1 ): ... total *= i ... logging . debug ( 'i is ' + str ( i ) + ', total is ' + str ( total )) ... logging . debug ( 'End of factorial( %s )' % ( n )) ... return total ... >>> print ( factorial ( 5 )) >>> logging . debug ( 'End of program' ) # 2015-05-23 16:20:12,664 - DEBUG - Start of program # 2015-05-23 16:20:12,664 - DEBUG - Start of factorial(5) # 2015-05-23 16:20:12,665 - DEBUG - i is 0, total is 0 # 2015-05-23 16:20:12,668 - DEBUG - i is 1, total is 0 # 2015-05-23 16:20:12,670 - DEBUG - i is 2, total is 0 # 2015-05-23 16:20:12,673 - DEBUG - i is 3, total is 0 # 2015-05-23 16:20:12,675 - DEBUG - i is 4, total is 0 # 2015-05-23 16:20:12,678 - DEBUG - i is 5, total is 0 # 2015-05-23 16:20:12,680 - DEBUG - End of factorial(5) # 0 # 2015-05-23 16:20:12,684 - DEBUG - End of program","title":"Logging"},{"location":"dev/python/debugging/#logging-levels","text":"Logging levels provide a way to categorize your log messages by importance. There are five logging levels, described in Table 10-1 from least to most important. Messages can be logged at each level using a different logging function. Level Logging Function Description DEBUG logging.debug() The lowest level. Used for small details. Usually you care about these messages only when diagnosing problems. INFO logging.info() Used to record information on general events in your program or confirm that things are working at their point in the program. WARNING logging.warning() Used to indicate a potential problem that doesn\u2019t prevent the program from working but might do so in the future. ERROR logging.error() Used to record an error that caused the program to fail to do something. CRITICAL logging.critical() The highest level. Used to indicate a fatal error that has caused or is about to cause the program to stop running entirely.","title":"Logging Levels"},{"location":"dev/python/debugging/#disabling-logging","text":"After you\u2019ve debugged your program, you probably don\u2019t want all these log messages cluttering the screen. The logging.disable() function disables these so that you don\u2019t have to go into your program and remove all the logging calls by hand. >>> import logging >>> logging . basicConfig ( level = logging . INFO , format = ' %(asctime)s - %(levelname)s - %(message)s ' ) >>> logging . critical ( 'Critical error! Critical error!' ) # 2015-05-22 11:10:48,054 - CRITICAL - Critical error! Critical error! >>> logging . disable ( logging . CRITICAL ) >>> logging . critical ( 'Critical error! Critical error!' ) >>> logging . error ( 'Error! Error!' )","title":"Disabling Logging"},{"location":"dev/python/debugging/#logging-to-a-file","text":"Instead of displaying the log messages to the screen, you can write them to a text file. The logging.basicConfig() function takes a filename keyword argument, like so: >>> import logging >>> logging . basicConfig ( filename = 'myProgramLog.txt' , level = logging . DEBUG , format = ' %(asctime)s - %(levelname)s - %(message)s ' )","title":"Logging to a File"},{"location":"dev/python/dictionaries/","text":"Python Dictionaries In Python, a dictionary is an ordered (from Python > 3.7) collection of key : value pairs. From the Python 3 documentation The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also possible to delete a key:value pair with del . Example Dictionary: my_cat = { 'size' : 'fat' , 'color' : 'gray' , 'disposition' : 'loud' } Set key, value using subscript operator [] >>> my_cat = { ... 'size' : 'fat' , ... 'color' : 'gray' , ... 'disposition' : 'loud' , ... } >>> my_cat [ 'age_years' ] = 2 >>> print ( my_cat ) ... # {'size': 'fat', 'color': 'gray', 'disposition': 'loud', 'age_years': 2} Get value using subscript operator [] In case the key is not present in dictionary KeyError is raised. >>> my_cat = { ... 'size' : 'fat' , ... 'color' : 'gray' , ... 'disposition' : 'loud' , ... } >>> print ( my_cat [ 'size' ]) ... # fat >>> print ( my_cat [ 'eye_color' ]) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # KeyError: 'eye_color' values() The values() method gets the values of the dictionary: >>> pet = { 'color' : 'red' , 'age' : 42 } >>> for value in pet . values (): ... print ( value ) ... # red # 42 keys() The keys() method gets the keys of the dictionary: >>> pet = { 'color' : 'red' , 'age' : 42 } >>> for key in pet . keys (): ... print ( key ) ... # color # age There is no need to use .keys() since by default you will loop through keys: >>> pet = { 'color' : 'red' , 'age' : 42 } >>> for key in pet : ... print ( key ) ... # color # age items() The items() method gets the items of a dictionary and returns them as a Tuple : >>> pet = { 'color' : 'red' , 'age' : 42 } >>> for item in pet . items (): ... print ( item ) ... # ('color', 'red') # ('age', 42) Using the keys() , values() , and items() methods, a for loop can iterate over the keys, values, or key-value pairs in a dictionary, respectively. >>> pet = { 'color' : 'red' , 'age' : 42 } >>> for key , value in pet . items (): ... print ( f 'Key: { key } Value: { value } ' ) ... # Key: color Value: red # Key: age Value: 42 get() The get() method returns the value of an item with the given key. If the key doesn't exist, it returns None : >>> wife = { 'name' : 'Rose' , 'age' : 33 } >>> f 'My wife name is { wife . get ( \"name\" ) } ' # 'My wife name is Rose' >>> f 'She is { wife . get ( \"age\" ) } years old.' # 'She is 33 years old.' >>> f 'She is deeply in love with { wife . get ( \"husband\" ) } ' # 'She is deeply in love with None' You can also change the default None value to one of your choice: >>> wife = { 'name' : 'Rose' , 'age' : 33 } >>> f 'She is deeply in love with { wife . get ( \"husband\" , \"lover\" ) } ' # 'She is deeply in love with lover' Adding items with setdefault() It's possible to add an item to a dictionary in this way: >>> wife = { 'name' : 'Rose' , 'age' : 33 } >>> if 'has_hair' not in wife : ... wife [ 'has_hair' ] = True Using the setdefault method, we can make the same code more short: >>> wife = { 'name' : 'Rose' , 'age' : 33 } >>> wife . setdefault ( 'has_hair' , True ) >>> wife # {'name': 'Rose', 'age': 33, 'has_hair': True} Removing Items pop() The pop() method removes and returns an item based on a given key. >>> wife = { 'name' : 'Rose' , 'age' : 33 , 'hair' : 'brown' } >>> wife . pop ( 'age' ) # 33 >>> wife # {'name': 'Rose', 'hair': 'brown'} popitem() The popitem() method removes the last item in a dictionary and returns it. >>> wife = { 'name' : 'Rose' , 'age' : 33 , 'hair' : 'brown' } >>> wife . popitem () # ('hair', 'brown') >>> wife # {'name': 'Rose', 'age': 33} del() The del() method removes an item based on a given key. >>> wife = { 'name' : 'Rose' , 'age' : 33 , 'hair' : 'brown' } >>> del wife [ 'age' ] >>> wife # {'name': 'Rose', 'hair': 'brown'} clear() The clear() method removes all the items in a dictionary. >>> wife = { 'name' : 'Rose' , 'age' : 33 , 'hair' : 'brown' } >>> wife . clear () >>> wife # {} Checking keys in a Dictionary >>> person = { 'name' : 'Rose' , 'age' : 33 } >>> 'name' in person . keys () # True >>> 'height' in person . keys () # False >>> 'skin' in person # You can omit keys() # False Checking values in a Dictionary >>> person = { 'name' : 'Rose' , 'age' : 33 } >>> 'Rose' in person . values () # True >>> 33 in person . values () # True Pretty Printing >>> import pprint >>> wife = { 'name' : 'Rose' , 'age' : 33 , 'has_hair' : True , 'hair_color' : 'brown' , 'height' : 1.6 , 'eye_color' : 'brown' } >>> pprint . pprint ( wife ) # {'age': 33, # 'eye_color': 'brown', # 'hair_color': 'brown', # 'has_hair': True, # 'height': 1.6, # 'name': 'Rose'} Merge two dictionaries For Python 3.5+: >>> dict_a = { 'a' : 1 , 'b' : 2 } >>> dict_b = { 'b' : 3 , 'c' : 4 } >>> dict_c = { ** dict_a , ** dict_b } >>> dict_c # {'a': 1, 'b': 3, 'c': 4}","title":"Python Dictionaries"},{"location":"dev/python/dictionaries/#set-key-value-using-subscript-operator","text":">>> my_cat = { ... 'size' : 'fat' , ... 'color' : 'gray' , ... 'disposition' : 'loud' , ... } >>> my_cat [ 'age_years' ] = 2 >>> print ( my_cat ) ... # {'size': 'fat', 'color': 'gray', 'disposition': 'loud', 'age_years': 2}","title":"Set key, value using subscript operator []"},{"location":"dev/python/dictionaries/#get-value-using-subscript-operator","text":"In case the key is not present in dictionary KeyError is raised. >>> my_cat = { ... 'size' : 'fat' , ... 'color' : 'gray' , ... 'disposition' : 'loud' , ... } >>> print ( my_cat [ 'size' ]) ... # fat >>> print ( my_cat [ 'eye_color' ]) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # KeyError: 'eye_color'","title":"Get value using subscript operator []"},{"location":"dev/python/dictionaries/#values","text":"The values() method gets the values of the dictionary: >>> pet = { 'color' : 'red' , 'age' : 42 } >>> for value in pet . values (): ... print ( value ) ... # red # 42","title":"values()"},{"location":"dev/python/dictionaries/#keys","text":"The keys() method gets the keys of the dictionary: >>> pet = { 'color' : 'red' , 'age' : 42 } >>> for key in pet . keys (): ... print ( key ) ... # color # age There is no need to use .keys() since by default you will loop through keys: >>> pet = { 'color' : 'red' , 'age' : 42 } >>> for key in pet : ... print ( key ) ... # color # age","title":"keys()"},{"location":"dev/python/dictionaries/#items","text":"The items() method gets the items of a dictionary and returns them as a Tuple : >>> pet = { 'color' : 'red' , 'age' : 42 } >>> for item in pet . items (): ... print ( item ) ... # ('color', 'red') # ('age', 42) Using the keys() , values() , and items() methods, a for loop can iterate over the keys, values, or key-value pairs in a dictionary, respectively. >>> pet = { 'color' : 'red' , 'age' : 42 } >>> for key , value in pet . items (): ... print ( f 'Key: { key } Value: { value } ' ) ... # Key: color Value: red # Key: age Value: 42","title":"items()"},{"location":"dev/python/dictionaries/#get","text":"The get() method returns the value of an item with the given key. If the key doesn't exist, it returns None : >>> wife = { 'name' : 'Rose' , 'age' : 33 } >>> f 'My wife name is { wife . get ( \"name\" ) } ' # 'My wife name is Rose' >>> f 'She is { wife . get ( \"age\" ) } years old.' # 'She is 33 years old.' >>> f 'She is deeply in love with { wife . get ( \"husband\" ) } ' # 'She is deeply in love with None' You can also change the default None value to one of your choice: >>> wife = { 'name' : 'Rose' , 'age' : 33 } >>> f 'She is deeply in love with { wife . get ( \"husband\" , \"lover\" ) } ' # 'She is deeply in love with lover'","title":"get()"},{"location":"dev/python/dictionaries/#adding-items-with-setdefault","text":"It's possible to add an item to a dictionary in this way: >>> wife = { 'name' : 'Rose' , 'age' : 33 } >>> if 'has_hair' not in wife : ... wife [ 'has_hair' ] = True Using the setdefault method, we can make the same code more short: >>> wife = { 'name' : 'Rose' , 'age' : 33 } >>> wife . setdefault ( 'has_hair' , True ) >>> wife # {'name': 'Rose', 'age': 33, 'has_hair': True}","title":"Adding items with setdefault()"},{"location":"dev/python/dictionaries/#removing-items","text":"","title":"Removing Items"},{"location":"dev/python/dictionaries/#pop","text":"The pop() method removes and returns an item based on a given key. >>> wife = { 'name' : 'Rose' , 'age' : 33 , 'hair' : 'brown' } >>> wife . pop ( 'age' ) # 33 >>> wife # {'name': 'Rose', 'hair': 'brown'}","title":"pop()"},{"location":"dev/python/dictionaries/#popitem","text":"The popitem() method removes the last item in a dictionary and returns it. >>> wife = { 'name' : 'Rose' , 'age' : 33 , 'hair' : 'brown' } >>> wife . popitem () # ('hair', 'brown') >>> wife # {'name': 'Rose', 'age': 33}","title":"popitem()"},{"location":"dev/python/dictionaries/#del","text":"The del() method removes an item based on a given key. >>> wife = { 'name' : 'Rose' , 'age' : 33 , 'hair' : 'brown' } >>> del wife [ 'age' ] >>> wife # {'name': 'Rose', 'hair': 'brown'}","title":"del()"},{"location":"dev/python/dictionaries/#clear","text":"The clear() method removes all the items in a dictionary. >>> wife = { 'name' : 'Rose' , 'age' : 33 , 'hair' : 'brown' } >>> wife . clear () >>> wife # {}","title":"clear()"},{"location":"dev/python/dictionaries/#checking-keys-in-a-dictionary","text":">>> person = { 'name' : 'Rose' , 'age' : 33 } >>> 'name' in person . keys () # True >>> 'height' in person . keys () # False >>> 'skin' in person # You can omit keys() # False","title":"Checking keys in a Dictionary"},{"location":"dev/python/dictionaries/#checking-values-in-a-dictionary","text":">>> person = { 'name' : 'Rose' , 'age' : 33 } >>> 'Rose' in person . values () # True >>> 33 in person . values () # True","title":"Checking values in a Dictionary"},{"location":"dev/python/dictionaries/#pretty-printing","text":">>> import pprint >>> wife = { 'name' : 'Rose' , 'age' : 33 , 'has_hair' : True , 'hair_color' : 'brown' , 'height' : 1.6 , 'eye_color' : 'brown' } >>> pprint . pprint ( wife ) # {'age': 33, # 'eye_color': 'brown', # 'hair_color': 'brown', # 'has_hair': True, # 'height': 1.6, # 'name': 'Rose'}","title":"Pretty Printing"},{"location":"dev/python/dictionaries/#merge-two-dictionaries","text":"For Python 3.5+: >>> dict_a = { 'a' : 1 , 'b' : 2 } >>> dict_b = { 'b' : 3 , 'c' : 4 } >>> dict_c = { ** dict_a , ** dict_b } >>> dict_c # {'a': 1, 'b': 3, 'c': 4}","title":"Merge two dictionaries"},{"location":"dev/python/exception-handling/","text":"Python Exception Handling Exception handling In computing and computer programming, exception handling is the process of responding to the occurrence of exceptions \u2013 anomalous or exceptional conditions requiring special processing. Python has many built-in exceptions that are raised when a program encounters an error, and most external libraries, like the popular Requests , include his own custom exceptions that we will need to deal to. Basic exception handling You can't divide by zero, that is a mathematical true, and if you try to do it in Python, the interpreter will raise the built-in exception ZeroDivisionError : >>> def divide ( dividend , divisor ): ... print ( dividend / divisor ) ... >>> divide ( dividend = 10 , divisor = 5 ) # 5 >>> divide ( dividend = 10 , divisor = 0 ) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # ZeroDivisionError: division by zero Let's say we don't want our program to stop its execution or show the user an output he will not understand. Say we want to print a useful and clear message, then we need to handle the exception with the try and except keywords: >>> def divide ( dividend , divisor ): ... try : ... print ( dividend / divisor ) ... except ZeroDivisionError : ... print ( 'You can not divide by 0' ) ... >>> divide ( dividend = 10 , divisor = 5 ) # 5 >>> divide ( dividend = 10 , divisor = 0 ) # You can not divide by 0 Final code in exception handling The code inside the finally section is always executed, no matter if an exception has been raised or not: >>> def divide ( dividend , divisor ): ... try : ... print ( dividend / divisor ) ... except ZeroDivisionError : ... print ( 'You can not divide by 0' ) ... finally : ... print ( 'Execution finished' ) ... >>> divide ( dividend = 10 , divisor = 5 ) # 5 # Execution finished >>> divide ( dividend = 10 , divisor = 0 ) # You can not divide by 0 # Execution finished Custom Exceptions Custom exceptions initialize by creating a class that inherits from the base Exception class of Python, and are raised using the raise keyword: >>> class MyCustomException ( Exception ): ... pass ... >>> raise MyCustomException # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # __main__.MyCustomException To declare a custom exception message, you can pass it as a parameter: >>> class MyCustomException ( Exception ): ... pass ... >>> raise MyCustomException ( 'A custom message for my custom exception' ) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # __main__.MyCustomException: A custom message for my custom exception Handling a custom exception is the same as any other: >>> try : ... raise MyCustomException ( 'A custom message for my custom exception' ) >>> except MyCustomException : ... print ( 'My custom exception was raised' ) ... # My custom exception was raised","title":"Python Exception Handling"},{"location":"dev/python/exception-handling/#basic-exception-handling","text":"You can't divide by zero, that is a mathematical true, and if you try to do it in Python, the interpreter will raise the built-in exception ZeroDivisionError : >>> def divide ( dividend , divisor ): ... print ( dividend / divisor ) ... >>> divide ( dividend = 10 , divisor = 5 ) # 5 >>> divide ( dividend = 10 , divisor = 0 ) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # ZeroDivisionError: division by zero Let's say we don't want our program to stop its execution or show the user an output he will not understand. Say we want to print a useful and clear message, then we need to handle the exception with the try and except keywords: >>> def divide ( dividend , divisor ): ... try : ... print ( dividend / divisor ) ... except ZeroDivisionError : ... print ( 'You can not divide by 0' ) ... >>> divide ( dividend = 10 , divisor = 5 ) # 5 >>> divide ( dividend = 10 , divisor = 0 ) # You can not divide by 0","title":"Basic exception handling"},{"location":"dev/python/exception-handling/#final-code-in-exception-handling","text":"The code inside the finally section is always executed, no matter if an exception has been raised or not: >>> def divide ( dividend , divisor ): ... try : ... print ( dividend / divisor ) ... except ZeroDivisionError : ... print ( 'You can not divide by 0' ) ... finally : ... print ( 'Execution finished' ) ... >>> divide ( dividend = 10 , divisor = 5 ) # 5 # Execution finished >>> divide ( dividend = 10 , divisor = 0 ) # You can not divide by 0 # Execution finished","title":"Final code in exception handling"},{"location":"dev/python/exception-handling/#custom-exceptions","text":"Custom exceptions initialize by creating a class that inherits from the base Exception class of Python, and are raised using the raise keyword: >>> class MyCustomException ( Exception ): ... pass ... >>> raise MyCustomException # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # __main__.MyCustomException To declare a custom exception message, you can pass it as a parameter: >>> class MyCustomException ( Exception ): ... pass ... >>> raise MyCustomException ( 'A custom message for my custom exception' ) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # __main__.MyCustomException: A custom message for my custom exception Handling a custom exception is the same as any other: >>> try : ... raise MyCustomException ( 'A custom message for my custom exception' ) >>> except MyCustomException : ... print ( 'My custom exception was raised' ) ... # My custom exception was raised","title":"Custom Exceptions"},{"location":"dev/python/file-directory-path/","text":"Handling file and directory Paths There are two main modules in Python that deal with path manipulation. One is the os.path module and the other is the pathlib module. os.path VS pathlib The pathlib module was added in Python 3.4, offering an object-oriented way to handle file system paths. Linux and Windows Paths On Windows, paths are written using backslashes ( \\ ) as the separator between folder names. On Unix based operating system such as macOS, Linux, and BSDs, the forward slash ( / ) is used as the path separator. Joining paths can be a headache if your code needs to work on different platforms. Fortunately, Python provides easy ways to handle this. We will showcase how to deal with both, os.path.join and pathlib.Path.joinpath Using os.path.join on Windows: >>> import os >>> os . path . join ( 'usr' , 'bin' , 'spam' ) # 'usr\\\\bin\\\\spam' And using pathlib on *nix: >>> from pathlib import Path >>> print ( Path ( 'usr' ) . joinpath ( 'bin' ) . joinpath ( 'spam' )) # usr/bin/spam pathlib also provides a shortcut to joinpath using the / operator: >>> from pathlib import Path >>> print ( Path ( 'usr' ) / 'bin' / 'spam' ) # usr/bin/spam Notice the path separator is different between Windows and Unix based operating system, that's why you want to use one of the above methods instead of adding strings together to join paths together. Joining paths is helpful if you need to create different file paths under the same directory. Using os.path.join on Windows: >>> my_files = [ 'accounts.txt' , 'details.csv' , 'invite.docx' ] >>> for filename in my_files : ... print ( os . path . join ( 'C: \\\\ Users \\\\ asweigart' , filename )) ... # C:\\Users\\asweigart\\accounts.txt # C:\\Users\\asweigart\\details.csv # C:\\Users\\asweigart\\invite.docx Using pathlib on *nix: >>> my_files = [ 'accounts.txt' , 'details.csv' , 'invite.docx' ] >>> home = Path . home () >>> for filename in my_files : ... print ( home / filename ) ... # /home/asweigart/accounts.txt # /home/asweigart/details.csv # /home/asweigart/invite.docx The current working directory Using os on Windows: >>> import os >>> os . getcwd () # 'C:\\\\Python34' >>> os . chdir ( 'C: \\\\ Windows \\\\ System32' ) >>> os . getcwd () # 'C:\\\\Windows\\\\System32' Using pathlib on *nix: >>> from pathlib import Path >>> from os import chdir >>> print ( Path . cwd ()) # /home/asweigart >>> chdir ( '/usr/lib/python3.6' ) >>> print ( Path . cwd ()) # /usr/lib/python3.6 Creating new folders Using os on Windows: >>> import os >>> os . makedirs ( 'C: \\\\ delicious \\\\ walnut \\\\ waffles' ) Using pathlib on *nix: >>> from pathlib import Path >>> cwd = Path . cwd () >>> ( cwd / 'delicious' / 'walnut' / 'waffles' ) . mkdir () # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # File \"/usr/lib/python3.6/pathlib.py\", line 1226, in mkdir # self._accessor.mkdir(self, mode) # File \"/usr/lib/python3.6/pathlib.py\", line 387, in wrapped # return strfunc(str(pathobj), *args) # FileNotFoundError: [Errno 2] No such file or directory: '/home/asweigart/delicious/walnut/waffles' Oh no, we got a nasty error! The reason is that the 'delicious' directory does not exist, so we cannot make the 'walnut' and the 'waffles' directories under it. To fix this, do: >>> from pathlib import Path >>> cwd = Path . cwd () >>> ( cwd / 'delicious' / 'walnut' / 'waffles' ) . mkdir ( parents = True ) And all is good :) Absolute vs. Relative paths There are two ways to specify a file path. An absolute path , which always begins with the root folder A relative path , which is relative to the program\u2019s current working directory There are also the dot ( . ) and dot-dot ( .. ) folders. These are not real folders, but special names that can be used in a path. A single period (\u201cdot\u201d) for a folder name is shorthand for \u201cthis directory.\u201d Two periods (\u201cdot-dot\u201d) means \u201cthe parent folder.\u201d Handling Absolute paths To see if a path is an absolute path: Using os.path on *nix: >>> import os >>> os . path . isabs ( '/' ) # True >>> os . path . isabs ( '..' ) # False Using pathlib on *nix: >>> from pathlib import Path >>> Path ( '/' ) . is_absolute () # True >>> Path ( '..' ) . is_absolute () # False You can extract an absolute path with both os.path and pathlib Using os.path on *nix: >>> import os >>> os . getcwd () '/home/asweigart' >>> os . path . abspath ( '..' ) '/home' Using pathlib on *nix: from pathlib import Path print ( Path . cwd ()) # /home/asweigart print ( Path ( '..' ) . resolve ()) # /home Handling Relative paths You can get a relative path from a starting path to another path. Using os.path on *nix: >>> import os >>> os . path . relpath ( '/etc/passwd' , '/' ) # 'etc/passwd' Using pathlib on *nix: >>> from pathlib import Path >>> print ( Path ( '/etc/passwd' ) . relative_to ( '/' )) # etc/passwd Path and File validity Checking if a file/directory exists Using os.path on *nix: >>> import os >>> os . path . exists ( '.' ) # True >>> os . path . exists ( 'setup.py' ) # True >>> os . path . exists ( '/etc' ) # True >>> os . path . exists ( 'nonexistentfile' ) # False Using pathlib on *nix: from pathlib import Path >>> Path ( '.' ) . exists () # True >>> Path ( 'setup.py' ) . exists () # True >>> Path ( '/etc' ) . exists () # True >>> Path ( 'nonexistentfile' ) . exists () # False Checking if a path is a file Using os.path on *nix: >>> import os >>> os . path . isfile ( 'setup.py' ) # True >>> os . path . isfile ( '/home' ) # False >>> os . path . isfile ( 'nonexistentfile' ) # False Using pathlib on *nix: >>> from pathlib import Path >>> Path ( 'setup.py' ) . is_file () # True >>> Path ( '/home' ) . is_file () # False >>> Path ( 'nonexistentfile' ) . is_file () # False Checking if a path is a directory Using os.path on *nix: >>> import os >>> os . path . isdir ( '/' ) # True >>> os . path . isdir ( 'setup.py' ) # False >>> os . path . isdir ( '/spam' ) # False Using pathlib on *nix: >>> from pathlib import Path >>> Path ( '/' ) . is_dir () # True >>> Path ( 'setup.py' ) . is_dir () # False >>> Path ( '/spam' ) . is_dir () # False Getting a file's size in bytes Using os.path on Windows: >>> import os >>> os . path . getsize ( 'C: \\\\ Windows \\\\ System32 \\\\ calc.exe' ) # 776192 Using pathlib on *nix: >>> from pathlib import Path >>> stat = Path ( '/bin/python3.6' ) . stat () >>> print ( stat ) # stat contains some other information about the file as well # os.stat_result(st_mode=33261, st_ino=141087, st_dev=2051, st_nlink=2, st_uid=0, # --snip-- # st_gid=0, st_size=10024, st_atime=1517725562, st_mtime=1515119809, st_ctime=1517261276) >>> print ( stat . st_size ) # size in bytes # 10024 Listing directories Listing directory contents using os.listdir on Windows: >>> import os >>> os . listdir ( 'C: \\\\ Windows \\\\ System32' ) # ['0409', '12520437.cpx', '12520850.cpx', '5U877.ax', 'aaclient.dll', # --snip-- # 'xwtpdui.dll', 'xwtpw32.dll', 'zh-CN', 'zh-HK', 'zh-TW', 'zipfldr.dll'] Listing directory contents using pathlib on *nix: >>> from pathlib import Path >>> for f in Path ( '/usr/bin' ) . iterdir (): ... print ( f ) ... # ... # /usr/bin/tiff2rgba # /usr/bin/iconv # /usr/bin/ldd # /usr/bin/cache_restore # /usr/bin/udiskie # /usr/bin/unix2dos # /usr/bin/t1reencode # /usr/bin/epstopdf # /usr/bin/idle3 # ... Directory file sizes WARNING Directories themselves also have a size! So, you might want to check for whether a path is a file or directory using the methods in the methods discussed in the above section. Using os.path.getsize() and os.listdir() together on Windows: >>> import os >>> total_size = 0 >>> for filename in os . listdir ( 'C: \\\\ Windows \\\\ System32' ): ... total_size = total_size + os . path . getsize ( os . path . join ( 'C: \\\\ Windows \\\\ System32' , filename )) ... >>> print ( total_size ) # 1117846456 Using pathlib on *nix: >>> from pathlib import Path >>> total_size = 0 >>> for sub_path in Path ( '/usr/bin' ) . iterdir (): ... total_size += sub_path . stat () . st_size ... >>> print ( total_size ) # 1903178911 Copying files and folders The shutil module provides functions for copying files, as well as entire folders. >>> import shutil , os >>> os . chdir ( 'C: \\\\ ' ) >>> shutil . copy ( 'C: \\\\ spam.txt' , 'C: \\\\ delicious' ) # C:\\\\delicious\\\\spam.txt' >>> shutil . copy ( 'eggs.txt' , 'C: \\\\ delicious \\\\ eggs2.txt' ) # 'C:\\\\delicious\\\\eggs2.txt' While shutil.copy() will copy a single file, shutil.copytree() will copy an entire folder and every folder and file contained in it: >>> import shutil , os >>> os . chdir ( 'C: \\\\ ' ) >>> shutil . copytree ( 'C: \\\\ bacon' , 'C: \\\\ bacon_backup' ) # 'C:\\\\bacon_backup' Moving and Renaming >>> import shutil >>> shutil . move ( 'C: \\\\ bacon.txt' , 'C: \\\\ eggs' ) # 'C:\\\\eggs\\\\bacon.txt' The destination path can also specify a filename. In the following example, the source file is moved and renamed: >>> shutil . move ( 'C: \\\\ bacon.txt' , 'C: \\\\ eggs \\\\ new_bacon.txt' ) # 'C:\\\\eggs\\\\new_bacon.txt' If there is no eggs folder, then move() will rename bacon.txt to a file named eggs: >>> shutil . move ( 'C: \\\\ bacon.txt' , 'C: \\\\ eggs' ) # 'C:\\\\eggs' Deleting files and folders Calling os.unlink(path) or Path.unlink() will delete the file at path. Calling os.rmdir(path) or Path.rmdir() will delete the folder at path. This folder must be empty of any files or folders. Calling shutil.rmtree(path) will remove the folder at path, and all files and folders it contains will also be deleted. Walking a Directory Tree >>> import os >>> >>> for folder_name , subfolders , filenames in os . walk ( 'C: \\\\ delicious' ): ... print ( f 'The current folder is { folder_name } ' ) ... for subfolder in subfolders : ... print ( 'SUBFOLDER OF {folder_name} : {subfolder} ' ) ... for filename in filenames : ... print ( 'FILE INSIDE {folder_name} : filename {filename} ' ) ... print ( '' ) ... # The current folder is C:\\delicious # SUBFOLDER OF C:\\delicious: cats # SUBFOLDER OF C:\\delicious: walnut # FILE INSIDE C:\\delicious: spam.txt # The current folder is C:\\delicious\\cats # FILE INSIDE C:\\delicious\\cats: catnames.txt # FILE INSIDE C:\\delicious\\cats: zophie.jpg # The current folder is C:\\delicious\\walnut # SUBFOLDER OF C:\\delicious\\walnut: waffles # The current folder is C:\\delicious\\walnut\\waffles # FILE INSIDE C:\\delicious\\walnut\\waffles: butter.txt Pathlib vs Os Module pathlib provides a lot more functionality than the ones listed above, like getting file name, getting file extension, reading/writing a file without manually opening it, etc. See the official documentation if you intend to know more.","title":"File and directory Paths"},{"location":"dev/python/file-directory-path/#linux-and-windows-paths","text":"On Windows, paths are written using backslashes ( \\ ) as the separator between folder names. On Unix based operating system such as macOS, Linux, and BSDs, the forward slash ( / ) is used as the path separator. Joining paths can be a headache if your code needs to work on different platforms. Fortunately, Python provides easy ways to handle this. We will showcase how to deal with both, os.path.join and pathlib.Path.joinpath Using os.path.join on Windows: >>> import os >>> os . path . join ( 'usr' , 'bin' , 'spam' ) # 'usr\\\\bin\\\\spam' And using pathlib on *nix: >>> from pathlib import Path >>> print ( Path ( 'usr' ) . joinpath ( 'bin' ) . joinpath ( 'spam' )) # usr/bin/spam pathlib also provides a shortcut to joinpath using the / operator: >>> from pathlib import Path >>> print ( Path ( 'usr' ) / 'bin' / 'spam' ) # usr/bin/spam Notice the path separator is different between Windows and Unix based operating system, that's why you want to use one of the above methods instead of adding strings together to join paths together. Joining paths is helpful if you need to create different file paths under the same directory. Using os.path.join on Windows: >>> my_files = [ 'accounts.txt' , 'details.csv' , 'invite.docx' ] >>> for filename in my_files : ... print ( os . path . join ( 'C: \\\\ Users \\\\ asweigart' , filename )) ... # C:\\Users\\asweigart\\accounts.txt # C:\\Users\\asweigart\\details.csv # C:\\Users\\asweigart\\invite.docx Using pathlib on *nix: >>> my_files = [ 'accounts.txt' , 'details.csv' , 'invite.docx' ] >>> home = Path . home () >>> for filename in my_files : ... print ( home / filename ) ... # /home/asweigart/accounts.txt # /home/asweigart/details.csv # /home/asweigart/invite.docx","title":"Linux and Windows Paths"},{"location":"dev/python/file-directory-path/#the-current-working-directory","text":"Using os on Windows: >>> import os >>> os . getcwd () # 'C:\\\\Python34' >>> os . chdir ( 'C: \\\\ Windows \\\\ System32' ) >>> os . getcwd () # 'C:\\\\Windows\\\\System32' Using pathlib on *nix: >>> from pathlib import Path >>> from os import chdir >>> print ( Path . cwd ()) # /home/asweigart >>> chdir ( '/usr/lib/python3.6' ) >>> print ( Path . cwd ()) # /usr/lib/python3.6","title":"The current working directory"},{"location":"dev/python/file-directory-path/#creating-new-folders","text":"Using os on Windows: >>> import os >>> os . makedirs ( 'C: \\\\ delicious \\\\ walnut \\\\ waffles' ) Using pathlib on *nix: >>> from pathlib import Path >>> cwd = Path . cwd () >>> ( cwd / 'delicious' / 'walnut' / 'waffles' ) . mkdir () # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # File \"/usr/lib/python3.6/pathlib.py\", line 1226, in mkdir # self._accessor.mkdir(self, mode) # File \"/usr/lib/python3.6/pathlib.py\", line 387, in wrapped # return strfunc(str(pathobj), *args) # FileNotFoundError: [Errno 2] No such file or directory: '/home/asweigart/delicious/walnut/waffles' Oh no, we got a nasty error! The reason is that the 'delicious' directory does not exist, so we cannot make the 'walnut' and the 'waffles' directories under it. To fix this, do: >>> from pathlib import Path >>> cwd = Path . cwd () >>> ( cwd / 'delicious' / 'walnut' / 'waffles' ) . mkdir ( parents = True ) And all is good :)","title":"Creating new folders"},{"location":"dev/python/file-directory-path/#absolute-vs-relative-paths","text":"There are two ways to specify a file path. An absolute path , which always begins with the root folder A relative path , which is relative to the program\u2019s current working directory There are also the dot ( . ) and dot-dot ( .. ) folders. These are not real folders, but special names that can be used in a path. A single period (\u201cdot\u201d) for a folder name is shorthand for \u201cthis directory.\u201d Two periods (\u201cdot-dot\u201d) means \u201cthe parent folder.\u201d","title":"Absolute vs. Relative paths"},{"location":"dev/python/file-directory-path/#handling-absolute-paths","text":"To see if a path is an absolute path: Using os.path on *nix: >>> import os >>> os . path . isabs ( '/' ) # True >>> os . path . isabs ( '..' ) # False Using pathlib on *nix: >>> from pathlib import Path >>> Path ( '/' ) . is_absolute () # True >>> Path ( '..' ) . is_absolute () # False You can extract an absolute path with both os.path and pathlib Using os.path on *nix: >>> import os >>> os . getcwd () '/home/asweigart' >>> os . path . abspath ( '..' ) '/home' Using pathlib on *nix: from pathlib import Path print ( Path . cwd ()) # /home/asweigart print ( Path ( '..' ) . resolve ()) # /home","title":"Handling Absolute paths"},{"location":"dev/python/file-directory-path/#handling-relative-paths","text":"You can get a relative path from a starting path to another path. Using os.path on *nix: >>> import os >>> os . path . relpath ( '/etc/passwd' , '/' ) # 'etc/passwd' Using pathlib on *nix: >>> from pathlib import Path >>> print ( Path ( '/etc/passwd' ) . relative_to ( '/' )) # etc/passwd","title":"Handling Relative paths"},{"location":"dev/python/file-directory-path/#path-and-file-validity","text":"","title":"Path and File validity"},{"location":"dev/python/file-directory-path/#checking-if-a-filedirectory-exists","text":"Using os.path on *nix: >>> import os >>> os . path . exists ( '.' ) # True >>> os . path . exists ( 'setup.py' ) # True >>> os . path . exists ( '/etc' ) # True >>> os . path . exists ( 'nonexistentfile' ) # False Using pathlib on *nix: from pathlib import Path >>> Path ( '.' ) . exists () # True >>> Path ( 'setup.py' ) . exists () # True >>> Path ( '/etc' ) . exists () # True >>> Path ( 'nonexistentfile' ) . exists () # False","title":"Checking if a file/directory exists"},{"location":"dev/python/file-directory-path/#checking-if-a-path-is-a-file","text":"Using os.path on *nix: >>> import os >>> os . path . isfile ( 'setup.py' ) # True >>> os . path . isfile ( '/home' ) # False >>> os . path . isfile ( 'nonexistentfile' ) # False Using pathlib on *nix: >>> from pathlib import Path >>> Path ( 'setup.py' ) . is_file () # True >>> Path ( '/home' ) . is_file () # False >>> Path ( 'nonexistentfile' ) . is_file () # False","title":"Checking if a path is a file"},{"location":"dev/python/file-directory-path/#checking-if-a-path-is-a-directory","text":"Using os.path on *nix: >>> import os >>> os . path . isdir ( '/' ) # True >>> os . path . isdir ( 'setup.py' ) # False >>> os . path . isdir ( '/spam' ) # False Using pathlib on *nix: >>> from pathlib import Path >>> Path ( '/' ) . is_dir () # True >>> Path ( 'setup.py' ) . is_dir () # False >>> Path ( '/spam' ) . is_dir () # False","title":"Checking if a path is a directory"},{"location":"dev/python/file-directory-path/#getting-a-files-size-in-bytes","text":"Using os.path on Windows: >>> import os >>> os . path . getsize ( 'C: \\\\ Windows \\\\ System32 \\\\ calc.exe' ) # 776192 Using pathlib on *nix: >>> from pathlib import Path >>> stat = Path ( '/bin/python3.6' ) . stat () >>> print ( stat ) # stat contains some other information about the file as well # os.stat_result(st_mode=33261, st_ino=141087, st_dev=2051, st_nlink=2, st_uid=0, # --snip-- # st_gid=0, st_size=10024, st_atime=1517725562, st_mtime=1515119809, st_ctime=1517261276) >>> print ( stat . st_size ) # size in bytes # 10024","title":"Getting a file's size in bytes"},{"location":"dev/python/file-directory-path/#listing-directories","text":"Listing directory contents using os.listdir on Windows: >>> import os >>> os . listdir ( 'C: \\\\ Windows \\\\ System32' ) # ['0409', '12520437.cpx', '12520850.cpx', '5U877.ax', 'aaclient.dll', # --snip-- # 'xwtpdui.dll', 'xwtpw32.dll', 'zh-CN', 'zh-HK', 'zh-TW', 'zipfldr.dll'] Listing directory contents using pathlib on *nix: >>> from pathlib import Path >>> for f in Path ( '/usr/bin' ) . iterdir (): ... print ( f ) ... # ... # /usr/bin/tiff2rgba # /usr/bin/iconv # /usr/bin/ldd # /usr/bin/cache_restore # /usr/bin/udiskie # /usr/bin/unix2dos # /usr/bin/t1reencode # /usr/bin/epstopdf # /usr/bin/idle3 # ...","title":"Listing directories"},{"location":"dev/python/file-directory-path/#directory-file-sizes","text":"WARNING Directories themselves also have a size! So, you might want to check for whether a path is a file or directory using the methods in the methods discussed in the above section. Using os.path.getsize() and os.listdir() together on Windows: >>> import os >>> total_size = 0 >>> for filename in os . listdir ( 'C: \\\\ Windows \\\\ System32' ): ... total_size = total_size + os . path . getsize ( os . path . join ( 'C: \\\\ Windows \\\\ System32' , filename )) ... >>> print ( total_size ) # 1117846456 Using pathlib on *nix: >>> from pathlib import Path >>> total_size = 0 >>> for sub_path in Path ( '/usr/bin' ) . iterdir (): ... total_size += sub_path . stat () . st_size ... >>> print ( total_size ) # 1903178911","title":"Directory file sizes"},{"location":"dev/python/file-directory-path/#copying-files-and-folders","text":"The shutil module provides functions for copying files, as well as entire folders. >>> import shutil , os >>> os . chdir ( 'C: \\\\ ' ) >>> shutil . copy ( 'C: \\\\ spam.txt' , 'C: \\\\ delicious' ) # C:\\\\delicious\\\\spam.txt' >>> shutil . copy ( 'eggs.txt' , 'C: \\\\ delicious \\\\ eggs2.txt' ) # 'C:\\\\delicious\\\\eggs2.txt' While shutil.copy() will copy a single file, shutil.copytree() will copy an entire folder and every folder and file contained in it: >>> import shutil , os >>> os . chdir ( 'C: \\\\ ' ) >>> shutil . copytree ( 'C: \\\\ bacon' , 'C: \\\\ bacon_backup' ) # 'C:\\\\bacon_backup'","title":"Copying files and folders"},{"location":"dev/python/file-directory-path/#moving-and-renaming","text":">>> import shutil >>> shutil . move ( 'C: \\\\ bacon.txt' , 'C: \\\\ eggs' ) # 'C:\\\\eggs\\\\bacon.txt' The destination path can also specify a filename. In the following example, the source file is moved and renamed: >>> shutil . move ( 'C: \\\\ bacon.txt' , 'C: \\\\ eggs \\\\ new_bacon.txt' ) # 'C:\\\\eggs\\\\new_bacon.txt' If there is no eggs folder, then move() will rename bacon.txt to a file named eggs: >>> shutil . move ( 'C: \\\\ bacon.txt' , 'C: \\\\ eggs' ) # 'C:\\\\eggs'","title":"Moving and Renaming"},{"location":"dev/python/file-directory-path/#deleting-files-and-folders","text":"Calling os.unlink(path) or Path.unlink() will delete the file at path. Calling os.rmdir(path) or Path.rmdir() will delete the folder at path. This folder must be empty of any files or folders. Calling shutil.rmtree(path) will remove the folder at path, and all files and folders it contains will also be deleted.","title":"Deleting files and folders"},{"location":"dev/python/file-directory-path/#walking-a-directory-tree","text":">>> import os >>> >>> for folder_name , subfolders , filenames in os . walk ( 'C: \\\\ delicious' ): ... print ( f 'The current folder is { folder_name } ' ) ... for subfolder in subfolders : ... print ( 'SUBFOLDER OF {folder_name} : {subfolder} ' ) ... for filename in filenames : ... print ( 'FILE INSIDE {folder_name} : filename {filename} ' ) ... print ( '' ) ... # The current folder is C:\\delicious # SUBFOLDER OF C:\\delicious: cats # SUBFOLDER OF C:\\delicious: walnut # FILE INSIDE C:\\delicious: spam.txt # The current folder is C:\\delicious\\cats # FILE INSIDE C:\\delicious\\cats: catnames.txt # FILE INSIDE C:\\delicious\\cats: zophie.jpg # The current folder is C:\\delicious\\walnut # SUBFOLDER OF C:\\delicious\\walnut: waffles # The current folder is C:\\delicious\\walnut\\waffles # FILE INSIDE C:\\delicious\\walnut\\waffles: butter.txt Pathlib vs Os Module pathlib provides a lot more functionality than the ones listed above, like getting file name, getting file extension, reading/writing a file without manually opening it, etc. See the official documentation if you intend to know more.","title":"Walking a Directory Tree"},{"location":"dev/python/functions/","text":"Python Functions Programming Functions A function is a block of organized code that is used to perform a single task. They provide better modularity for your application and reuse-ability. Function Arguments A function can take arguments and return values : In the following example, the function say_hello receives the argument \"name\" and prints a greeting: >>> def say_hello ( name ): ... print ( f 'Hello { name } ' ) ... >>> say_hello ( 'Carlos' ) # Hello Carlos >>> say_hello ( 'Wanda' ) # Hello Wanda >>> say_hello ( 'Rose' ) # Hello Rose Keyword Arguments To improve code readability, we should be as explicit as possible. We can achieve this in our functions by using Keyword Arguments : >>> def say_hi ( name , greeting ): ... print ( f \" { greeting } { name } \" ) ... >>> # without keyword arguments >>> say_hi ( 'John' , 'Hello' ) # Hello John >>> # with keyword arguments >>> say_hi ( name = 'Anna' , greeting = 'Hi' ) # Hi Anna Return Values When creating a function using the def statement, you can specify what the return value should be with a return statement. A return statement consists of the following: The return keyword. The value or expression that the function should return. >>> def sum_two_numbers ( number_1 , number_2 ): ... return number_1 + number_2 ... >>> result = sum_two_numbers ( 7 , 8 ) >>> print ( result ) # 15 Local and Global Scope Code in the global scope cannot use any local variables. However, a local scope can access global variables. Code in a function\u2019s local scope cannot use variables in any other local scope. You can use the same name for different variables if they are in different scopes. That is, there can be a local variable named spam and a global variable also named spam. global_variable = 'I am available everywhere' >>> def some_function (): ... print ( global_variable ) # because is global ... local_variable = \"only available within this function\" ... print ( local_variable ) ... >>> # the following code will throw error because >>> # 'local_variable' only exists inside 'some_function' >>> print ( local_variable ) Traceback ( most recent call last ): File \"<stdin>\" , line 10 , in < module > NameError : name 'local_variable' is not defined The global Statement If you need to modify a global variable from within a function, use the global statement: >>> def spam (): ... global eggs ... eggs = 'spam' ... >>> eggs = 'global' >>> spam () >>> print ( eggs ) There are four rules to tell whether a variable is in a local scope or global scope: If a variable is being used in the global scope (that is, outside all functions), then it is always a global variable. If there is a global statement for that variable in a function, it is a global variable. Otherwise, if the variable is used in an assignment statement in the function, it is a local variable. But if the variable is not used in an assignment statement, it is a global variable. Lambda Functions In Python, a lambda function is a single-line, anonymous function, which can have any number of arguments, but it can only have one expression. From the Python 3 Tutorial lambda is a minimal function definition that can be used inside an expression. Unlike FunctionDef, body holds a single node. Single line expression Lambda functions can only evaluate an expression, like a single line of code. This function: >>> def add ( x , y ): ... return x + y ... >>> add ( 5 , 3 ) # 8 Is equivalent to the lambda function: >>> add = lambda x , y : x + y >>> add ( 5 , 3 ) # 8 Like regular nested functions, lambdas also work as lexical closures: >>> def make_adder ( n ): ... return lambda x : x + n ... >>> plus_3 = make_adder ( 3 ) >>> plus_5 = make_adder ( 5 ) >>> plus_3 ( 4 ) # 7 >>> plus_5 ( 4 ) # 9","title":"Python Functions"},{"location":"dev/python/functions/#function-arguments","text":"A function can take arguments and return values : In the following example, the function say_hello receives the argument \"name\" and prints a greeting: >>> def say_hello ( name ): ... print ( f 'Hello { name } ' ) ... >>> say_hello ( 'Carlos' ) # Hello Carlos >>> say_hello ( 'Wanda' ) # Hello Wanda >>> say_hello ( 'Rose' ) # Hello Rose","title":"Function Arguments"},{"location":"dev/python/functions/#keyword-arguments","text":"To improve code readability, we should be as explicit as possible. We can achieve this in our functions by using Keyword Arguments : >>> def say_hi ( name , greeting ): ... print ( f \" { greeting } { name } \" ) ... >>> # without keyword arguments >>> say_hi ( 'John' , 'Hello' ) # Hello John >>> # with keyword arguments >>> say_hi ( name = 'Anna' , greeting = 'Hi' ) # Hi Anna","title":"Keyword Arguments"},{"location":"dev/python/functions/#return-values","text":"When creating a function using the def statement, you can specify what the return value should be with a return statement. A return statement consists of the following: The return keyword. The value or expression that the function should return. >>> def sum_two_numbers ( number_1 , number_2 ): ... return number_1 + number_2 ... >>> result = sum_two_numbers ( 7 , 8 ) >>> print ( result ) # 15","title":"Return Values"},{"location":"dev/python/functions/#local-and-global-scope","text":"Code in the global scope cannot use any local variables. However, a local scope can access global variables. Code in a function\u2019s local scope cannot use variables in any other local scope. You can use the same name for different variables if they are in different scopes. That is, there can be a local variable named spam and a global variable also named spam. global_variable = 'I am available everywhere' >>> def some_function (): ... print ( global_variable ) # because is global ... local_variable = \"only available within this function\" ... print ( local_variable ) ... >>> # the following code will throw error because >>> # 'local_variable' only exists inside 'some_function' >>> print ( local_variable ) Traceback ( most recent call last ): File \"<stdin>\" , line 10 , in < module > NameError : name 'local_variable' is not defined","title":"Local and Global Scope"},{"location":"dev/python/functions/#the-global-statement","text":"If you need to modify a global variable from within a function, use the global statement: >>> def spam (): ... global eggs ... eggs = 'spam' ... >>> eggs = 'global' >>> spam () >>> print ( eggs ) There are four rules to tell whether a variable is in a local scope or global scope: If a variable is being used in the global scope (that is, outside all functions), then it is always a global variable. If there is a global statement for that variable in a function, it is a global variable. Otherwise, if the variable is used in an assignment statement in the function, it is a local variable. But if the variable is not used in an assignment statement, it is a global variable.","title":"The global Statement"},{"location":"dev/python/functions/#lambda-functions","text":"In Python, a lambda function is a single-line, anonymous function, which can have any number of arguments, but it can only have one expression. From the Python 3 Tutorial lambda is a minimal function definition that can be used inside an expression. Unlike FunctionDef, body holds a single node. Single line expression Lambda functions can only evaluate an expression, like a single line of code. This function: >>> def add ( x , y ): ... return x + y ... >>> add ( 5 , 3 ) # 8 Is equivalent to the lambda function: >>> add = lambda x , y : x + y >>> add ( 5 , 3 ) # 8 Like regular nested functions, lambdas also work as lexical closures: >>> def make_adder ( n ): ... return lambda x : x + n ... >>> plus_3 = make_adder ( 3 ) >>> plus_5 = make_adder ( 5 ) >>> plus_3 ( 4 ) # 7 >>> plus_5 ( 4 ) # 9","title":"Lambda Functions"},{"location":"dev/python/json-yaml/","text":"JSON and YAML JSON JSON stands for JavaScript Object Notation and is a lightweight format for storing and transporting data. Json is often used when data is sent from a server to a web page. >>> import json >>> with open ( \"filename.json\" , \"r\" ) as f : ... content = json . load ( f ) Write a JSON file with: >>> import json >>> content = { \"name\" : \"Joe\" , \"age\" : 20 } >>> with open ( \"filename.json\" , \"w\" ) as f : ... json . dump ( content , f , indent = 2 ) YAML Compared to JSON, YAML allows a much better human maintainability and gives ability to add comments. It is a convenient choice for configuration files where a human will have to edit. There are two main libraries allowing to access to YAML files: PyYaml Ruamel.yaml Install them using pip install in your virtual environment. The first one is easier to use but the second one, Ruamel, implements much better the YAML specification, and allow for example to modify a YAML content without altering comments. Open a YAML file with: >>> from ruamel.yaml import YAML >>> with open ( \"filename.yaml\" ) as f : ... yaml = YAML () ... yaml . load ( f ) Anyconfig Anyconfig is a very handy package, allowing to abstract completely the underlying configuration file format. It allows to load a Python dictionary from JSON, YAML, TOML, and so on. Install it with: pip install anyconfig Usage: >>> import anyconfig >>> conf1 = anyconfig . load ( \"/path/to/foo/conf.d/a.yml\" )","title":"Python Json and YAML"},{"location":"dev/python/json-yaml/#json","text":"JSON stands for JavaScript Object Notation and is a lightweight format for storing and transporting data. Json is often used when data is sent from a server to a web page. >>> import json >>> with open ( \"filename.json\" , \"r\" ) as f : ... content = json . load ( f ) Write a JSON file with: >>> import json >>> content = { \"name\" : \"Joe\" , \"age\" : 20 } >>> with open ( \"filename.json\" , \"w\" ) as f : ... json . dump ( content , f , indent = 2 )","title":"JSON"},{"location":"dev/python/json-yaml/#yaml","text":"Compared to JSON, YAML allows a much better human maintainability and gives ability to add comments. It is a convenient choice for configuration files where a human will have to edit. There are two main libraries allowing to access to YAML files: PyYaml Ruamel.yaml Install them using pip install in your virtual environment. The first one is easier to use but the second one, Ruamel, implements much better the YAML specification, and allow for example to modify a YAML content without altering comments. Open a YAML file with: >>> from ruamel.yaml import YAML >>> with open ( \"filename.yaml\" ) as f : ... yaml = YAML () ... yaml . load ( f )","title":"YAML"},{"location":"dev/python/json-yaml/#anyconfig","text":"Anyconfig is a very handy package, allowing to abstract completely the underlying configuration file format. It allows to load a Python dictionary from JSON, YAML, TOML, and so on. Install it with: pip install anyconfig Usage: >>> import anyconfig >>> conf1 = anyconfig . load ( \"/path/to/foo/conf.d/a.yml\" )","title":"Anyconfig"},{"location":"dev/python/lists-and-tuples/","text":"Python Lists Lists are one of the 4 data types in Python used to store collections of data. [ 'John' , 'Peter' , 'Debora' , 'Charles' ] Getting values with indexes >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture [ 0 ] # 'table' >>> furniture [ 1 ] # 'chair' >>> furniture [ 2 ] # 'rack' >>> furniture [ 3 ] # 'shelf' Negative indexes >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture [ - 1 ] # 'shelf' >>> furniture [ - 3 ] # 'chair' >>> f 'The { furniture [ - 1 ] } is bigger than the { furniture [ - 3 ] } ' # 'The shelf is bigger than the chair' Getting sublists with Slices >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture [ 0 : 4 ] # ['table', 'chair', 'rack', 'shelf'] >>> furniture [ 1 : 3 ] # ['chair', 'rack'] >>> furniture [ 0 : - 1 ] # ['table', 'chair', 'rack'] >>> furniture [: 2 ] # ['table', 'chair'] >>> furniture [ 1 :] # ['chair', 'rack', 'shelf'] >>> furniture [:] # ['table', 'chair', 'rack', 'shelf'] Slicing the complete list will perform a copy: >>> spam2 = spam [:] # ['cat', 'bat', 'rat', 'elephant'] >>> spam . append ( 'dog' ) >>> spam # ['cat', 'bat', 'rat', 'elephant', 'dog'] >>> spam2 # ['cat', 'bat', 'rat', 'elephant'] Getting a list length with len() >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> len ( furniture ) # 4 Changing values with indexes >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture [ 0 ] = 'desk' >>> furniture # ['desk', 'chair', 'rack', 'shelf'] >>> furniture [ 2 ] = furniture [ 1 ] >>> furniture # ['desk', 'chair', 'chair', 'shelf'] >>> furniture [ - 1 ] = 'bed' >>> furniture # ['desk', 'chair', 'chair', 'bed'] Concatenation and Replication >>> [ 1 , 2 , 3 ] + [ 'A' , 'B' , 'C' ] # [1, 2, 3, 'A', 'B', 'C'] >>> [ 'X' , 'Y' , 'Z' ] * 3 # ['X', 'Y', 'Z', 'X', 'Y', 'Z', 'X', 'Y', 'Z'] >>> my_list = [ 1 , 2 , 3 ] >>> my_list = my_list + [ 'A' , 'B' , 'C' ] >>> my_list # [1, 2, 3, 'A', 'B', 'C'] Using for loops with Lists >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> for item in furniture : ... print ( item ) # table # chair # rack # shelf Getting the index in a loop with enumerate() >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> for index , item in enumerate ( furniture ): ... print ( f 'index: { index } - item: { item } ' ) # index: 0 - item: table # index: 1 - item: chair # index: 2 - item: rack # index: 3 - item: shelf Loop in Multiple Lists with zip() >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> price = [ 100 , 50 , 80 , 40 ] >>> for item , amount in zip ( furniture , price ): ... print ( f 'The { item } costs $ { amount } ' ) # The table costs $100 # The chair costs $50 # The rack costs $80 # The shelf costs $40 The in and not in operators >>> 'rack' in [ 'table' , 'chair' , 'rack' , 'shelf' ] # True >>> 'bed' in [ 'table' , 'chair' , 'rack' , 'shelf' ] # False >>> 'bed' not in furniture # True >>> 'rack' not in furniture # False The Multiple Assignment Trick The multiple assignment trick is a shortcut that lets you assign multiple variables with the values in a list in one line of code. So instead of doing this: >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> table = furniture [ 0 ] >>> chair = furniture [ 1 ] >>> rack = furniture [ 2 ] >>> shelf = furniture [ 3 ] You could type this line of code: >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> table , chair , rack , shelf = furniture >>> table # 'table' >>> chair # 'chair' >>> rack # 'rack' >>> shelf # 'shelf' The multiple assignment trick can also be used to swap the values in two variables: >>> a , b = 'table' , 'chair' >>> a , b = b , a >>> print ( a ) # chair >>> print ( b ) # table The index Method The index method allows you to find the index of a value by passing its name: >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture . index ( 'chair' ) # 1 Adding Values append() append adds an element to the end of a list : >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture . append ( 'bed' ) >>> furniture # ['table', 'chair', 'rack', 'shelf', 'bed'] insert() insert adds an element to a list at a given position: >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture . insert ( 1 , 'bed' ) >>> furniture # ['table', 'bed', 'chair', 'rack', 'shelf'] Removing Values del() del removes an item using the index: >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> del furniture [ 2 ] >>> furniture # ['table', 'chair', 'shelf'] >>> del furniture [ 2 ] >>> furniture # ['table', 'chair'] remove() remove removes an item with using actual value of it: >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture . remove ( 'chair' ) >>> furniture # ['table', 'rack', 'shelf'] Removing repeated items If the value appears multiple times in the list, only the first instance of the value will be removed. pop() By default, pop will remove and return the last item of the list. You can also pass the index of the element as an optional parameter: >>> animals = [ 'cat' , 'bat' , 'rat' , 'elephant' ] >>> animals . pop () 'elephant' >>> animals [ 'cat' , 'bat' , 'rat' ] >>> animals . pop ( 0 ) 'cat' >>> animals [ 'bat' , 'rat' ] Sorting values with sort() >>> numbers = [ 2 , 5 , 3.14 , 1 , - 7 ] >>> numbers . sort () >>> numbers # [-7, 1, 2, 3.14, 5] furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] furniture . sort () furniture # ['chair', 'rack', 'shelf', 'table'] You can also pass True for the reverse keyword argument to have sort() sort the values in reverse order: >>> furniture . sort ( reverse = True ) >>> furniture # ['table', 'shelf', 'rack', 'chair'] If you need to sort the values in regular alphabetical order, pass str.lower for the key keyword argument in the sort() method call: >>> letters = [ 'a' , 'z' , 'A' , 'Z' ] >>> letters . sort ( key = str . lower ) >>> letters # ['a', 'A', 'z', 'Z'] You can use the built-in function sorted to return a new list: >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> sorted ( furniture ) # ['chair', 'rack', 'shelf', 'table'] The Tuple data type Tuples vs Lists The key difference between tuples and lists is that, while tuples are immutable objects, lists are mutable . This means that tuples cannot be changed while the lists can be modified. Tuples are more memory efficient than the lists. >>> furniture = ( 'table' , 'chair' , 'rack' , 'shelf' ) >>> furniture [ 0 ] # 'table' >>> furniture [ 1 : 3 ] # ('chair', 'rack') >>> len ( furniture ) # 4 The main way that tuples are different from lists is that tuples, like strings, are immutable. Converting between list() and tuple() >>> tuple ([ 'cat' , 'dog' , 5 ]) # ('cat', 'dog', 5) >>> list (( 'cat' , 'dog' , 5 )) # ['cat', 'dog', 5] >>> list ( 'hello' ) # ['h', 'e', 'l', 'l', 'o']","title":"Python Lists and Tuples"},{"location":"dev/python/lists-and-tuples/#getting-values-with-indexes","text":">>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture [ 0 ] # 'table' >>> furniture [ 1 ] # 'chair' >>> furniture [ 2 ] # 'rack' >>> furniture [ 3 ] # 'shelf'","title":"Getting values with indexes"},{"location":"dev/python/lists-and-tuples/#negative-indexes","text":">>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture [ - 1 ] # 'shelf' >>> furniture [ - 3 ] # 'chair' >>> f 'The { furniture [ - 1 ] } is bigger than the { furniture [ - 3 ] } ' # 'The shelf is bigger than the chair'","title":"Negative indexes"},{"location":"dev/python/lists-and-tuples/#getting-sublists-with-slices","text":">>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture [ 0 : 4 ] # ['table', 'chair', 'rack', 'shelf'] >>> furniture [ 1 : 3 ] # ['chair', 'rack'] >>> furniture [ 0 : - 1 ] # ['table', 'chair', 'rack'] >>> furniture [: 2 ] # ['table', 'chair'] >>> furniture [ 1 :] # ['chair', 'rack', 'shelf'] >>> furniture [:] # ['table', 'chair', 'rack', 'shelf'] Slicing the complete list will perform a copy: >>> spam2 = spam [:] # ['cat', 'bat', 'rat', 'elephant'] >>> spam . append ( 'dog' ) >>> spam # ['cat', 'bat', 'rat', 'elephant', 'dog'] >>> spam2 # ['cat', 'bat', 'rat', 'elephant']","title":"Getting sublists with Slices"},{"location":"dev/python/lists-and-tuples/#getting-a-list-length-with-len","text":">>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> len ( furniture ) # 4","title":"Getting a list length with len()"},{"location":"dev/python/lists-and-tuples/#changing-values-with-indexes","text":">>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture [ 0 ] = 'desk' >>> furniture # ['desk', 'chair', 'rack', 'shelf'] >>> furniture [ 2 ] = furniture [ 1 ] >>> furniture # ['desk', 'chair', 'chair', 'shelf'] >>> furniture [ - 1 ] = 'bed' >>> furniture # ['desk', 'chair', 'chair', 'bed']","title":"Changing values with indexes"},{"location":"dev/python/lists-and-tuples/#concatenation-and-replication","text":">>> [ 1 , 2 , 3 ] + [ 'A' , 'B' , 'C' ] # [1, 2, 3, 'A', 'B', 'C'] >>> [ 'X' , 'Y' , 'Z' ] * 3 # ['X', 'Y', 'Z', 'X', 'Y', 'Z', 'X', 'Y', 'Z'] >>> my_list = [ 1 , 2 , 3 ] >>> my_list = my_list + [ 'A' , 'B' , 'C' ] >>> my_list # [1, 2, 3, 'A', 'B', 'C']","title":"Concatenation and Replication"},{"location":"dev/python/lists-and-tuples/#using-for-loops-with-lists","text":">>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> for item in furniture : ... print ( item ) # table # chair # rack # shelf","title":"Using for loops with Lists"},{"location":"dev/python/lists-and-tuples/#getting-the-index-in-a-loop-with-enumerate","text":">>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> for index , item in enumerate ( furniture ): ... print ( f 'index: { index } - item: { item } ' ) # index: 0 - item: table # index: 1 - item: chair # index: 2 - item: rack # index: 3 - item: shelf","title":"Getting the index in a loop with enumerate()"},{"location":"dev/python/lists-and-tuples/#loop-in-multiple-lists-with-zip","text":">>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> price = [ 100 , 50 , 80 , 40 ] >>> for item , amount in zip ( furniture , price ): ... print ( f 'The { item } costs $ { amount } ' ) # The table costs $100 # The chair costs $50 # The rack costs $80 # The shelf costs $40","title":"Loop in Multiple Lists with zip()"},{"location":"dev/python/lists-and-tuples/#the-in-and-not-in-operators","text":">>> 'rack' in [ 'table' , 'chair' , 'rack' , 'shelf' ] # True >>> 'bed' in [ 'table' , 'chair' , 'rack' , 'shelf' ] # False >>> 'bed' not in furniture # True >>> 'rack' not in furniture # False","title":"The in and not in operators"},{"location":"dev/python/lists-and-tuples/#the-multiple-assignment-trick","text":"The multiple assignment trick is a shortcut that lets you assign multiple variables with the values in a list in one line of code. So instead of doing this: >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> table = furniture [ 0 ] >>> chair = furniture [ 1 ] >>> rack = furniture [ 2 ] >>> shelf = furniture [ 3 ] You could type this line of code: >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> table , chair , rack , shelf = furniture >>> table # 'table' >>> chair # 'chair' >>> rack # 'rack' >>> shelf # 'shelf' The multiple assignment trick can also be used to swap the values in two variables: >>> a , b = 'table' , 'chair' >>> a , b = b , a >>> print ( a ) # chair >>> print ( b ) # table","title":"The Multiple Assignment Trick"},{"location":"dev/python/lists-and-tuples/#the-index-method","text":"The index method allows you to find the index of a value by passing its name: >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture . index ( 'chair' ) # 1","title":"The index Method"},{"location":"dev/python/lists-and-tuples/#adding-values","text":"","title":"Adding Values"},{"location":"dev/python/lists-and-tuples/#append","text":"append adds an element to the end of a list : >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture . append ( 'bed' ) >>> furniture # ['table', 'chair', 'rack', 'shelf', 'bed']","title":"append()"},{"location":"dev/python/lists-and-tuples/#insert","text":"insert adds an element to a list at a given position: >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture . insert ( 1 , 'bed' ) >>> furniture # ['table', 'bed', 'chair', 'rack', 'shelf']","title":"insert()"},{"location":"dev/python/lists-and-tuples/#removing-values","text":"","title":"Removing Values"},{"location":"dev/python/lists-and-tuples/#del","text":"del removes an item using the index: >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> del furniture [ 2 ] >>> furniture # ['table', 'chair', 'shelf'] >>> del furniture [ 2 ] >>> furniture # ['table', 'chair']","title":"del()"},{"location":"dev/python/lists-and-tuples/#remove","text":"remove removes an item with using actual value of it: >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> furniture . remove ( 'chair' ) >>> furniture # ['table', 'rack', 'shelf'] Removing repeated items If the value appears multiple times in the list, only the first instance of the value will be removed.","title":"remove()"},{"location":"dev/python/lists-and-tuples/#pop","text":"By default, pop will remove and return the last item of the list. You can also pass the index of the element as an optional parameter: >>> animals = [ 'cat' , 'bat' , 'rat' , 'elephant' ] >>> animals . pop () 'elephant' >>> animals [ 'cat' , 'bat' , 'rat' ] >>> animals . pop ( 0 ) 'cat' >>> animals [ 'bat' , 'rat' ]","title":"pop()"},{"location":"dev/python/lists-and-tuples/#sorting-values-with-sort","text":">>> numbers = [ 2 , 5 , 3.14 , 1 , - 7 ] >>> numbers . sort () >>> numbers # [-7, 1, 2, 3.14, 5] furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] furniture . sort () furniture # ['chair', 'rack', 'shelf', 'table'] You can also pass True for the reverse keyword argument to have sort() sort the values in reverse order: >>> furniture . sort ( reverse = True ) >>> furniture # ['table', 'shelf', 'rack', 'chair'] If you need to sort the values in regular alphabetical order, pass str.lower for the key keyword argument in the sort() method call: >>> letters = [ 'a' , 'z' , 'A' , 'Z' ] >>> letters . sort ( key = str . lower ) >>> letters # ['a', 'A', 'z', 'Z'] You can use the built-in function sorted to return a new list: >>> furniture = [ 'table' , 'chair' , 'rack' , 'shelf' ] >>> sorted ( furniture ) # ['chair', 'rack', 'shelf', 'table']","title":"Sorting values with sort()"},{"location":"dev/python/lists-and-tuples/#the-tuple-data-type","text":"Tuples vs Lists The key difference between tuples and lists is that, while tuples are immutable objects, lists are mutable . This means that tuples cannot be changed while the lists can be modified. Tuples are more memory efficient than the lists. >>> furniture = ( 'table' , 'chair' , 'rack' , 'shelf' ) >>> furniture [ 0 ] # 'table' >>> furniture [ 1 : 3 ] # ('chair', 'rack') >>> len ( furniture ) # 4 The main way that tuples are different from lists is that tuples, like strings, are immutable.","title":"The Tuple data type"},{"location":"dev/python/lists-and-tuples/#converting-between-list-and-tuple","text":">>> tuple ([ 'cat' , 'dog' , 5 ]) # ('cat', 'dog', 5) >>> list (( 'cat' , 'dog' , 5 )) # ['cat', 'dog', 5] >>> list ( 'hello' ) # ['h', 'e', 'l', 'l', 'o']","title":"Converting between list() and tuple()"},{"location":"dev/python/main/","text":"Main top-level script environment What is it __main__ is the name of the scope in which top-level code executes. A module\u2019s name is set equal to __main__ when read from standard input, a script, or from an interactive prompt. A module can discover whether it is running in the main scope by checking its own __name__ , which allows a common idiom for conditionally executing code in a module. When it is run as a script or with python -m but not when it is imported: >>> if __name__ == \"__main__\" : ... # execute only if run as a script ... main () For a package, the same effect can be achieved by including a main .py module, the contents of which will be executed when the module is run with -m. For example, we are developing a script designed to be used as a module, we should do: >>> def add ( a , b ): ... return a + b ... >>> if __name__ == \"__main__\" : ... add ( 3 , 5 ) Advantages Every Python module has it\u2019s __name__ defined and if this is __main__ , it implies that the module is run standalone by the user, and we can do corresponding appropriate actions. If you import this script as a module in another script, the name is set to the name of the script/module. Python files can act as either reusable modules, or as standalone programs. if __name__ == \u201cmain\u201d: is used to execute some code only if the file run directly, and is not being imported.","title":"Python Main function"},{"location":"dev/python/main/#what-is-it","text":"__main__ is the name of the scope in which top-level code executes. A module\u2019s name is set equal to __main__ when read from standard input, a script, or from an interactive prompt. A module can discover whether it is running in the main scope by checking its own __name__ , which allows a common idiom for conditionally executing code in a module. When it is run as a script or with python -m but not when it is imported: >>> if __name__ == \"__main__\" : ... # execute only if run as a script ... main () For a package, the same effect can be achieved by including a main .py module, the contents of which will be executed when the module is run with -m. For example, we are developing a script designed to be used as a module, we should do: >>> def add ( a , b ): ... return a + b ... >>> if __name__ == \"__main__\" : ... add ( 3 , 5 )","title":"What is it"},{"location":"dev/python/main/#advantages","text":"Every Python module has it\u2019s __name__ defined and if this is __main__ , it implies that the module is run standalone by the user, and we can do corresponding appropriate actions. If you import this script as a module in another script, the name is set to the name of the script/module. Python files can act as either reusable modules, or as standalone programs. if __name__ == \u201cmain\u201d: is used to execute some code only if the file run directly, and is not being imported.","title":"Advantages"},{"location":"dev/python/manipulating-strings/","text":"Manipulating Strings Escape characters An escape character is created by typing a backslash \\ followed by the character you want to insert. Escape character Prints as \\' Single quote \\\" Double quote \\t Tab \\n Newline (line break) \\\\ Backslash \\b Backspace \\ooo Octal value \\r Carriage Return >>> print ( \"Hello there! \\n How are you? \\n I \\' m doing fine.\" ) # Hello there! # How are you? # I'm doing fine. Raw strings A raw string entirely ignores all escape characters and prints any backslash that appears in the string. >>> print ( r \"Hello there!\\nHow are you?\\nI\\'m doing fine.\" ) # Hello there!\\nHow are you?\\nI\\'m doing fine. Raw strings are mostly used for regular expression definition. Multiline Strings >>> print ( ... \"\"\"Dear Alice, ... ... Eve's cat has been arrested for catnapping, ... cat burglary, and extortion. ... ... Sincerely, ... Bob\"\"\" ... ) # Dear Alice, # Eve's cat has been arrested for catnapping, # cat burglary, and extortion. # Sincerely, # Bob Indexing and Slicing strings H e l l o w o r l d ! 0 1 2 3 4 5 6 7 8 9 10 11 Indexing >>> spam = 'Hello world!' >>> spam [ 0 ] # 'H' >>> spam [ 4 ] # 'o' >>> spam [ - 1 ] # '!' Slicing >>> spam = 'Hello world!' >>> spam [ 0 : 5 ] # 'Hello' >>> spam [: 5 ] # 'Hello' >>> spam [ 6 :] # 'world!' >>> spam [ 6 : - 1 ] # 'world' >>> spam [: - 1 ] # 'Hello world' >>> spam [:: - 1 ] # '!dlrow olleH' >>> fizz = spam [ 0 : 5 ] >>> fizz # 'Hello' The in and not in operators >>> 'Hello' in 'Hello World' # True >>> 'Hello' in 'Hello' # True >>> 'HELLO' in 'Hello World' # False >>> '' in 'spam' # True >>> 'cats' not in 'cats and dogs' # False upper(), lower() and title() Transforms a string to upper, lower and title case: >>> greet = 'Hello world!' >>> greet . upper () # 'HELLO WORLD!' >>> greet . lower () # 'hello world!' >>> greet . title () # 'Hello World!' isupper() and islower() methods Returns True or False after evaluating if a string is in upper or lower case: >>> spam = 'Hello world!' >>> spam . islower () # False >>> spam . isupper () # False >>> 'HELLO' . isupper () # True >>> 'abc12345' . islower () # True >>> '12345' . islower () # False >>> '12345' . isupper () # False The isX string methods Method Description isalpha() returns True if the string consists only of letters. isalnum() returns True if the string consists only of letters and numbers. isdecimal() returns True if the string consists only of numbers. isspace() returns True if the string consists only of spaces, tabs, and new-lines. istitle() returns True if the string consists only of words that begin with an uppercase letter followed by only lowercase characters. startswith() and endswith() >>> 'Hello world!' . startswith ( 'Hello' ) # True >>> 'Hello world!' . endswith ( 'world!' ) # True >>> 'abc123' . startswith ( 'abcdef' ) # False >>> 'abc123' . endswith ( '12' ) # False >>> 'Hello world!' . startswith ( 'Hello world!' ) # True >>> 'Hello world!' . endswith ( 'Hello world!' ) # True join() and split() join() The join() method takes all the items in an iterable, like a list , dictionary , tuple or set , and joins them into a string. You can also specify a separator. >>> '' . join ([ 'My' , 'name' , 'is' , 'Simon' ]) 'MynameisSimon' >>> ', ' . join ([ 'cats' , 'rats' , 'bats' ]) # 'cats, rats, bats' >>> ' ' . join ([ 'My' , 'name' , 'is' , 'Simon' ]) # 'My name is Simon' >>> 'ABC' . join ([ 'My' , 'name' , 'is' , 'Simon' ]) # 'MyABCnameABCisABCSimon' split() The split() method splits a string into a list . By default, it will use whitespace to separate the items, but you can also set another character of choice: >>> 'My name is Simon' . split () # ['My', 'name', 'is', 'Simon'] >>> 'MyABCnameABCisABCSimon' . split ( 'ABC' ) # ['My', 'name', 'is', 'Simon'] >>> 'My name is Simon' . split ( 'm' ) # ['My na', 'e is Si', 'on'] >>> ' My name is Simon' . split () # ['My', 'name', 'is', 'Simon'] >>> ' My name is Simon' . split ( ' ' ) # ['', 'My', '', 'name', 'is', '', 'Simon'] Justifying text with rjust(), ljust() and center() >>> 'Hello' . rjust ( 10 ) # ' Hello' >>> 'Hello' . rjust ( 20 ) # ' Hello' >>> 'Hello World' . rjust ( 20 ) # ' Hello World' >>> 'Hello' . ljust ( 10 ) # 'Hello ' >>> 'Hello' . center ( 20 ) # ' Hello ' An optional second argument to rjust() and ljust() will specify a fill character apart from a space character: >>> 'Hello' . rjust ( 20 , '*' ) # '***************Hello' >>> 'Hello' . ljust ( 20 , '-' ) # 'Hello---------------' >>> 'Hello' . center ( 20 , '=' ) # '=======Hello========' Removing whitespace with strip(), rstrip(), and lstrip() >>> spam = ' Hello World ' >>> spam . strip () # 'Hello World' >>> spam . lstrip () # 'Hello World ' >>> spam . rstrip () # ' Hello World' >>> spam = 'SpamSpamBaconSpamEggsSpamSpam' >>> spam . strip ( 'ampS' ) # 'BaconSpamEggs'","title":"Manipulating strings"},{"location":"dev/python/manipulating-strings/#escape-characters","text":"An escape character is created by typing a backslash \\ followed by the character you want to insert. Escape character Prints as \\' Single quote \\\" Double quote \\t Tab \\n Newline (line break) \\\\ Backslash \\b Backspace \\ooo Octal value \\r Carriage Return >>> print ( \"Hello there! \\n How are you? \\n I \\' m doing fine.\" ) # Hello there! # How are you? # I'm doing fine.","title":"Escape characters"},{"location":"dev/python/manipulating-strings/#raw-strings","text":"A raw string entirely ignores all escape characters and prints any backslash that appears in the string. >>> print ( r \"Hello there!\\nHow are you?\\nI\\'m doing fine.\" ) # Hello there!\\nHow are you?\\nI\\'m doing fine. Raw strings are mostly used for regular expression definition.","title":"Raw strings"},{"location":"dev/python/manipulating-strings/#multiline-strings","text":">>> print ( ... \"\"\"Dear Alice, ... ... Eve's cat has been arrested for catnapping, ... cat burglary, and extortion. ... ... Sincerely, ... Bob\"\"\" ... ) # Dear Alice, # Eve's cat has been arrested for catnapping, # cat burglary, and extortion. # Sincerely, # Bob","title":"Multiline Strings"},{"location":"dev/python/manipulating-strings/#indexing-and-slicing-strings","text":"H e l l o w o r l d ! 0 1 2 3 4 5 6 7 8 9 10 11","title":"Indexing and Slicing strings"},{"location":"dev/python/manipulating-strings/#indexing","text":">>> spam = 'Hello world!' >>> spam [ 0 ] # 'H' >>> spam [ 4 ] # 'o' >>> spam [ - 1 ] # '!'","title":"Indexing"},{"location":"dev/python/manipulating-strings/#slicing","text":">>> spam = 'Hello world!' >>> spam [ 0 : 5 ] # 'Hello' >>> spam [: 5 ] # 'Hello' >>> spam [ 6 :] # 'world!' >>> spam [ 6 : - 1 ] # 'world' >>> spam [: - 1 ] # 'Hello world' >>> spam [:: - 1 ] # '!dlrow olleH' >>> fizz = spam [ 0 : 5 ] >>> fizz # 'Hello'","title":"Slicing"},{"location":"dev/python/manipulating-strings/#the-in-and-not-in-operators","text":">>> 'Hello' in 'Hello World' # True >>> 'Hello' in 'Hello' # True >>> 'HELLO' in 'Hello World' # False >>> '' in 'spam' # True >>> 'cats' not in 'cats and dogs' # False","title":"The in and not in operators"},{"location":"dev/python/manipulating-strings/#upper-lower-and-title","text":"Transforms a string to upper, lower and title case: >>> greet = 'Hello world!' >>> greet . upper () # 'HELLO WORLD!' >>> greet . lower () # 'hello world!' >>> greet . title () # 'Hello World!'","title":"upper(), lower() and title()"},{"location":"dev/python/manipulating-strings/#isupper-and-islower-methods","text":"Returns True or False after evaluating if a string is in upper or lower case: >>> spam = 'Hello world!' >>> spam . islower () # False >>> spam . isupper () # False >>> 'HELLO' . isupper () # True >>> 'abc12345' . islower () # True >>> '12345' . islower () # False >>> '12345' . isupper () # False","title":"isupper() and islower() methods"},{"location":"dev/python/manipulating-strings/#the-isx-string-methods","text":"Method Description isalpha() returns True if the string consists only of letters. isalnum() returns True if the string consists only of letters and numbers. isdecimal() returns True if the string consists only of numbers. isspace() returns True if the string consists only of spaces, tabs, and new-lines. istitle() returns True if the string consists only of words that begin with an uppercase letter followed by only lowercase characters.","title":"The isX string methods"},{"location":"dev/python/manipulating-strings/#startswith-and-endswith","text":">>> 'Hello world!' . startswith ( 'Hello' ) # True >>> 'Hello world!' . endswith ( 'world!' ) # True >>> 'abc123' . startswith ( 'abcdef' ) # False >>> 'abc123' . endswith ( '12' ) # False >>> 'Hello world!' . startswith ( 'Hello world!' ) # True >>> 'Hello world!' . endswith ( 'Hello world!' ) # True","title":"startswith() and endswith()"},{"location":"dev/python/manipulating-strings/#join-and-split","text":"","title":"join() and split()"},{"location":"dev/python/manipulating-strings/#join","text":"The join() method takes all the items in an iterable, like a list , dictionary , tuple or set , and joins them into a string. You can also specify a separator. >>> '' . join ([ 'My' , 'name' , 'is' , 'Simon' ]) 'MynameisSimon' >>> ', ' . join ([ 'cats' , 'rats' , 'bats' ]) # 'cats, rats, bats' >>> ' ' . join ([ 'My' , 'name' , 'is' , 'Simon' ]) # 'My name is Simon' >>> 'ABC' . join ([ 'My' , 'name' , 'is' , 'Simon' ]) # 'MyABCnameABCisABCSimon'","title":"join()"},{"location":"dev/python/manipulating-strings/#split","text":"The split() method splits a string into a list . By default, it will use whitespace to separate the items, but you can also set another character of choice: >>> 'My name is Simon' . split () # ['My', 'name', 'is', 'Simon'] >>> 'MyABCnameABCisABCSimon' . split ( 'ABC' ) # ['My', 'name', 'is', 'Simon'] >>> 'My name is Simon' . split ( 'm' ) # ['My na', 'e is Si', 'on'] >>> ' My name is Simon' . split () # ['My', 'name', 'is', 'Simon'] >>> ' My name is Simon' . split ( ' ' ) # ['', 'My', '', 'name', 'is', '', 'Simon']","title":"split()"},{"location":"dev/python/manipulating-strings/#justifying-text-with-rjust-ljust-and-center","text":">>> 'Hello' . rjust ( 10 ) # ' Hello' >>> 'Hello' . rjust ( 20 ) # ' Hello' >>> 'Hello World' . rjust ( 20 ) # ' Hello World' >>> 'Hello' . ljust ( 10 ) # 'Hello ' >>> 'Hello' . center ( 20 ) # ' Hello ' An optional second argument to rjust() and ljust() will specify a fill character apart from a space character: >>> 'Hello' . rjust ( 20 , '*' ) # '***************Hello' >>> 'Hello' . ljust ( 20 , '-' ) # 'Hello---------------' >>> 'Hello' . center ( 20 , '=' ) # '=======Hello========'","title":"Justifying text with rjust(), ljust() and center()"},{"location":"dev/python/manipulating-strings/#removing-whitespace-with-strip-rstrip-and-lstrip","text":">>> spam = ' Hello World ' >>> spam . strip () # 'Hello World' >>> spam . lstrip () # 'Hello World ' >>> spam . rstrip () # ' Hello World' >>> spam = 'SpamSpamBaconSpamEggsSpamSpam' >>> spam . strip ( 'ampS' ) # 'BaconSpamEggs'","title":"Removing whitespace with strip(), rstrip(), and lstrip()"},{"location":"dev/python/oop-basics/","text":"title: Python OOP Basics description: Object-Oriented Programming (OOP) is a programming paradigm that revolves around the concept of objects, which are instances of classes. OOP principles are fundamental concepts that guide the design and development of software in an object-oriented way. In Python, OOP is supported by the use of classes and objects. Here are some of the basic OOP principles in Python Python OOP Basics Object-Oriented Programming Object-oriented programming (OOP) is a programming paradigm based on the concept of \"objects\", which can contain data and code. The data is in the form of fields (often known as attributes or properties), and the code is in the form of procedures (often known as methods). Encapsulation Encapsulation is one of the fundamental concepts of object-oriented programming, which helps to protect the data and methods of an object from unauthorized access and modification. It is a way to achieve data abstraction, which means that the implementation details of an object are hidden from the outside world, and only the essential information is exposed. In Python, encapsulation can be achieved by using access modifiers. Access modifiers are keywords that define the accessibility of attributes and methods in a class. The three access modifiers available in Python are public, private, and protected. However, Python does not have an explicit way of defining access modifiers like some other programming languages such as Java and C++. Instead, it uses a convention of using underscore prefixes to indicate the access level. In the given code example, the class MyClass has two attributes, _protected_var and __private_var. The _protected_var is marked as protected by using a single underscore prefix. This means that the attribute can be accessed within the class and its subclasses but not outside the class. The __private_var is marked as private by using two underscore prefixes. This means that the attribute can only be accessed within the class and not outside the class, not even in its subclasses. When we create an object of the MyClass class, we can access the _protected_var attribute using the object name with a single underscore prefix. However, we cannot access the __private_var attribute using the object name, as it is hidden from the outside world. If we try to access the __private_var attribute, we will get an AttributeError as shown in the code. In summary, encapsulation is an important concept in object-oriented programming that helps to protect the implementation details of an object. In Python, we can achieve encapsulation by using access modifiers and using underscore prefixes to indicate the access level. # Define a class named MyClass class MyClass : # Constructor method that initializes the class object def __init__ ( self ): # Define a protected variable with an initial value of 10 # The variable name starts with a single underscore, which indicates protected access self . _protected_var = 10 # Define a private variable with an initial value of 20 # The variable name starts with two underscores, which indicates private access self . __private_var = 20 # Create an object of MyClass class obj = MyClass () # Access the protected variable using the object name and print its value # The protected variable can be accessed outside the class but # it is intended to be used within the class or its subclasses print ( obj . _protected_var ) # output: 10 # Try to access the private variable using the object name and print its value # The private variable cannot be accessed outside the class, even by its subclasses # This will raise an AttributeError because the variable is not accessible outside the class print ( obj . __private_var ) # AttributeError: 'MyClass' object has no attribute '__private_var' Inheritance Inheritance promotes code reuse and allows you to create a hierarchy of classes that share common attributes and methods. It helps in creating clean and organized code by keeping related functionality in one place and promoting the concept of modularity. The base class from which a new class is derived is also known as a parent class, and the new class is known as the child class or subclass. In the code, we define a class named Animal which has a constructor method that initializes the class object with a name attribute and a method named speak. The speak method is defined in the Animal class but does not have a body. We then define two subclasses named Dog and Cat which inherit from the Animal class. These subclasses override the speak method of the Animal class. We create a Dog object with a name attribute \"Rover\" and a Cat object with a name attribute \"Whiskers\". We call the speak method of the Dog object using dog.speak(), and it prints \"Woof!\" because the speak method of the Dog class overrides the speak method of the Animal class. Similarly, we call the speak method of the Cat object using cat.speak(), and it prints \"Meow!\" because the speak method of the Cat class overrides the speak method of the Animal class. # Define a class named Animal class Animal : # Constructor method that initializes the class object with a name attribute def __init__ ( self , name ): self . name = name # Method that is defined in the Animal class but does not have a body # This method will be overridden in the subclasses of Animal def speak ( self ): print ( \"\" ) # Define a subclass named Dog that inherits from the Animal class class Dog ( Animal ): # Override the speak method of the Animal class def speak ( self ): print ( \"Woof!\" ) # Define a subclass named Cat that inherits from the Animal class class Cat ( Animal ): # Override the speak method of the Animal class def speak ( self ): print ( \"Meow!\" ) # Create a Dog object with a name attribute \"Rover\" dog = Dog ( \"Rover\" ) # Create a Cat object with a name attribute \"Whiskers\" cat = Cat ( \"Whiskers\" ) # Call the speak method of the Dog class and print the output # The speak method of the Dog class overrides the speak method of the Animal class # Therefore, when we call the speak method of the Dog object, it will print \"Woof!\" dog . speak () # output: Woof! # Call the speak method of the Cat class and print the output # The speak method of the Cat class overrides the speak method of the Animal class # Therefore, when we call the speak method of the Cat object, it will print \"Meow!\" cat . speak () # output: Meow! Polymorphism Polymorphism is an important concept in object-oriented programming that allows you to write code that can work with objects of different classes in a uniform way. In Python, polymorphism is achieved by using method overriding or method overloading. Method overriding is when a subclass provides its own implementation of a method that is already defined in its parent class. This allows the subclass to modify the behavior of the method without changing its name or signature. Method overloading is when multiple methods have the same name but different parameters. Python does not support method overloading directly, but it can be achieved using default arguments or variable-length arguments. Polymorphism makes it easier to write flexible and reusable code. It allows you to write code that can work with different objects without needing to know their specific types. #The Shape class is defined with an abstract area method, which is intended to be overridden by subclasses. class Shape : def area ( self ): pass class Rectangle ( Shape ): # The Rectangle class is defined with an __init__ method that initializes # width and height instance variables. # It also defines an area method that calculates and returns # the area of a rectangle using the width and height instance variables. def __init__ ( self , width , height ): self . width = width # Initialize width instance variable self . height = height # Initialize height instance variable def area ( self ): return self . width * self . height # Return area of rectangle # The Circle class is defined with an __init__ method # that initializes a radius instance variable. # It also defines an area method that calculates and # returns the area of a circle using the radius instance variable. class Circle ( Shape ): def __init__ ( self , radius ): self . radius = radius # Initialize radius instance variable def area ( self ): return 3.14 * self . radius ** 2 # Return area of circle using pi * r^2 # The shapes list is created with one Rectangle object and one Circle object. The for # loop iterates over each object in the list and calls the area method of each object # The output will be the area of the rectangle (20) and the area of the circle (153.86). shapes = [ Rectangle ( 4 , 5 ), Circle ( 7 )] # Create a list of Shape objects for shape in shapes : print ( shape . area ()) # Output the area of each Shape object Abstraction Abstraction is an important concept in object-oriented programming (OOP) because it allows you to focus on the essential features of an object or system while ignoring the details that aren't relevant to the current context. By reducing complexity and hiding unnecessary details, abstraction can make code more modular, easier to read, and easier to maintain. In Python, abstraction can be achieved by using abstract classes or interfaces. An abstract class is a class that cannot be instantiated directly, but is meant to be subclassed by other classes. It often includes abstract methods that have no implementation, but provide a template for how the subclass should be implemented. This allows the programmer to define a common interface for a group of related classes, while still allowing each class to have its own specific behavior. An interface, on the other hand, is a collection of method signatures that a class must implement in order to be considered \"compatible\" with the interface. Interfaces are often used to define a common set of methods that multiple classes can implement, allowing them to be used interchangeably in certain contexts. Python does not have built-in support for abstract classes or interfaces, but they can be implemented using the abc (abstract base class) module. This module provides the ABC class and the abstractmethod decorator, which can be used to define abstract classes and methods. Overall, abstraction is a powerful tool for managing complexity and improving code quality in object-oriented programming, and Python provides a range of options for achieving abstraction in your code. # Import the abc module to define abstract classes and methods from abc import ABC , abstractmethod # Define an abstract class called Shape that has an abstract method called area class Shape ( ABC ): @abstractmethod def area ( self ): pass # Define a Rectangle class that inherits from Shape class Rectangle ( Shape ): def __init__ ( self , width , height ): self . width = width self . height = height # Implement the area method for Rectangles def area ( self ): return self . width * self . height # Define a Circle class that also inherits from Shape class Circle ( Shape ): def __init__ ( self , radius ): self . radius = radius # Implement the area method for Circles def area ( self ): return 3.14 * self . radius ** 2 # Create a list of shapes that includes both Rectangles and Circles shapes = [ Rectangle ( 4 , 5 ), Circle ( 7 )] # Loop through each shape in the list and print its area for shape in shapes : print ( shape . area ()) These are some of the basic OOP principles in Python. This page is currently in progress and more detailed examples and explanations will be coming soon.","title":"Oop basics"},{"location":"dev/python/oop-basics/#description-object-oriented-programming-oop-is-a-programming-paradigm-that-revolves-around-the-concept-of-objects-which-are-instances-of-classes-oop-principles-are-fundamental-concepts-that-guide-the-design-and-development-of-software-in-an-object-oriented-way-in-python-oop-is-supported-by-the-use-of-classes-and-objects-here-are-some-of-the-basic-oop-principles-in-python","text":"Python OOP Basics Object-Oriented Programming Object-oriented programming (OOP) is a programming paradigm based on the concept of \"objects\", which can contain data and code. The data is in the form of fields (often known as attributes or properties), and the code is in the form of procedures (often known as methods).","title":"description: Object-Oriented Programming (OOP) is a programming paradigm that revolves around the concept of objects, which are instances of classes. OOP principles are fundamental concepts that guide the design and development of software in an object-oriented way. In Python, OOP is supported by the use of classes and objects. Here are some of the basic OOP principles in Python"},{"location":"dev/python/oop-basics/#encapsulation","text":"Encapsulation is one of the fundamental concepts of object-oriented programming, which helps to protect the data and methods of an object from unauthorized access and modification. It is a way to achieve data abstraction, which means that the implementation details of an object are hidden from the outside world, and only the essential information is exposed. In Python, encapsulation can be achieved by using access modifiers. Access modifiers are keywords that define the accessibility of attributes and methods in a class. The three access modifiers available in Python are public, private, and protected. However, Python does not have an explicit way of defining access modifiers like some other programming languages such as Java and C++. Instead, it uses a convention of using underscore prefixes to indicate the access level. In the given code example, the class MyClass has two attributes, _protected_var and __private_var. The _protected_var is marked as protected by using a single underscore prefix. This means that the attribute can be accessed within the class and its subclasses but not outside the class. The __private_var is marked as private by using two underscore prefixes. This means that the attribute can only be accessed within the class and not outside the class, not even in its subclasses. When we create an object of the MyClass class, we can access the _protected_var attribute using the object name with a single underscore prefix. However, we cannot access the __private_var attribute using the object name, as it is hidden from the outside world. If we try to access the __private_var attribute, we will get an AttributeError as shown in the code. In summary, encapsulation is an important concept in object-oriented programming that helps to protect the implementation details of an object. In Python, we can achieve encapsulation by using access modifiers and using underscore prefixes to indicate the access level. # Define a class named MyClass class MyClass : # Constructor method that initializes the class object def __init__ ( self ): # Define a protected variable with an initial value of 10 # The variable name starts with a single underscore, which indicates protected access self . _protected_var = 10 # Define a private variable with an initial value of 20 # The variable name starts with two underscores, which indicates private access self . __private_var = 20 # Create an object of MyClass class obj = MyClass () # Access the protected variable using the object name and print its value # The protected variable can be accessed outside the class but # it is intended to be used within the class or its subclasses print ( obj . _protected_var ) # output: 10 # Try to access the private variable using the object name and print its value # The private variable cannot be accessed outside the class, even by its subclasses # This will raise an AttributeError because the variable is not accessible outside the class print ( obj . __private_var ) # AttributeError: 'MyClass' object has no attribute '__private_var'","title":"Encapsulation"},{"location":"dev/python/oop-basics/#inheritance","text":"Inheritance promotes code reuse and allows you to create a hierarchy of classes that share common attributes and methods. It helps in creating clean and organized code by keeping related functionality in one place and promoting the concept of modularity. The base class from which a new class is derived is also known as a parent class, and the new class is known as the child class or subclass. In the code, we define a class named Animal which has a constructor method that initializes the class object with a name attribute and a method named speak. The speak method is defined in the Animal class but does not have a body. We then define two subclasses named Dog and Cat which inherit from the Animal class. These subclasses override the speak method of the Animal class. We create a Dog object with a name attribute \"Rover\" and a Cat object with a name attribute \"Whiskers\". We call the speak method of the Dog object using dog.speak(), and it prints \"Woof!\" because the speak method of the Dog class overrides the speak method of the Animal class. Similarly, we call the speak method of the Cat object using cat.speak(), and it prints \"Meow!\" because the speak method of the Cat class overrides the speak method of the Animal class. # Define a class named Animal class Animal : # Constructor method that initializes the class object with a name attribute def __init__ ( self , name ): self . name = name # Method that is defined in the Animal class but does not have a body # This method will be overridden in the subclasses of Animal def speak ( self ): print ( \"\" ) # Define a subclass named Dog that inherits from the Animal class class Dog ( Animal ): # Override the speak method of the Animal class def speak ( self ): print ( \"Woof!\" ) # Define a subclass named Cat that inherits from the Animal class class Cat ( Animal ): # Override the speak method of the Animal class def speak ( self ): print ( \"Meow!\" ) # Create a Dog object with a name attribute \"Rover\" dog = Dog ( \"Rover\" ) # Create a Cat object with a name attribute \"Whiskers\" cat = Cat ( \"Whiskers\" ) # Call the speak method of the Dog class and print the output # The speak method of the Dog class overrides the speak method of the Animal class # Therefore, when we call the speak method of the Dog object, it will print \"Woof!\" dog . speak () # output: Woof! # Call the speak method of the Cat class and print the output # The speak method of the Cat class overrides the speak method of the Animal class # Therefore, when we call the speak method of the Cat object, it will print \"Meow!\" cat . speak () # output: Meow!","title":"Inheritance"},{"location":"dev/python/oop-basics/#polymorphism","text":"Polymorphism is an important concept in object-oriented programming that allows you to write code that can work with objects of different classes in a uniform way. In Python, polymorphism is achieved by using method overriding or method overloading. Method overriding is when a subclass provides its own implementation of a method that is already defined in its parent class. This allows the subclass to modify the behavior of the method without changing its name or signature. Method overloading is when multiple methods have the same name but different parameters. Python does not support method overloading directly, but it can be achieved using default arguments or variable-length arguments. Polymorphism makes it easier to write flexible and reusable code. It allows you to write code that can work with different objects without needing to know their specific types. #The Shape class is defined with an abstract area method, which is intended to be overridden by subclasses. class Shape : def area ( self ): pass class Rectangle ( Shape ): # The Rectangle class is defined with an __init__ method that initializes # width and height instance variables. # It also defines an area method that calculates and returns # the area of a rectangle using the width and height instance variables. def __init__ ( self , width , height ): self . width = width # Initialize width instance variable self . height = height # Initialize height instance variable def area ( self ): return self . width * self . height # Return area of rectangle # The Circle class is defined with an __init__ method # that initializes a radius instance variable. # It also defines an area method that calculates and # returns the area of a circle using the radius instance variable. class Circle ( Shape ): def __init__ ( self , radius ): self . radius = radius # Initialize radius instance variable def area ( self ): return 3.14 * self . radius ** 2 # Return area of circle using pi * r^2 # The shapes list is created with one Rectangle object and one Circle object. The for # loop iterates over each object in the list and calls the area method of each object # The output will be the area of the rectangle (20) and the area of the circle (153.86). shapes = [ Rectangle ( 4 , 5 ), Circle ( 7 )] # Create a list of Shape objects for shape in shapes : print ( shape . area ()) # Output the area of each Shape object","title":"Polymorphism"},{"location":"dev/python/oop-basics/#abstraction","text":"Abstraction is an important concept in object-oriented programming (OOP) because it allows you to focus on the essential features of an object or system while ignoring the details that aren't relevant to the current context. By reducing complexity and hiding unnecessary details, abstraction can make code more modular, easier to read, and easier to maintain. In Python, abstraction can be achieved by using abstract classes or interfaces. An abstract class is a class that cannot be instantiated directly, but is meant to be subclassed by other classes. It often includes abstract methods that have no implementation, but provide a template for how the subclass should be implemented. This allows the programmer to define a common interface for a group of related classes, while still allowing each class to have its own specific behavior. An interface, on the other hand, is a collection of method signatures that a class must implement in order to be considered \"compatible\" with the interface. Interfaces are often used to define a common set of methods that multiple classes can implement, allowing them to be used interchangeably in certain contexts. Python does not have built-in support for abstract classes or interfaces, but they can be implemented using the abc (abstract base class) module. This module provides the ABC class and the abstractmethod decorator, which can be used to define abstract classes and methods. Overall, abstraction is a powerful tool for managing complexity and improving code quality in object-oriented programming, and Python provides a range of options for achieving abstraction in your code. # Import the abc module to define abstract classes and methods from abc import ABC , abstractmethod # Define an abstract class called Shape that has an abstract method called area class Shape ( ABC ): @abstractmethod def area ( self ): pass # Define a Rectangle class that inherits from Shape class Rectangle ( Shape ): def __init__ ( self , width , height ): self . width = width self . height = height # Implement the area method for Rectangles def area ( self ): return self . width * self . height # Define a Circle class that also inherits from Shape class Circle ( Shape ): def __init__ ( self , radius ): self . radius = radius # Implement the area method for Circles def area ( self ): return 3.14 * self . radius ** 2 # Create a list of shapes that includes both Rectangles and Circles shapes = [ Rectangle ( 4 , 5 ), Circle ( 7 )] # Loop through each shape in the list and print its area for shape in shapes : print ( shape . area ()) These are some of the basic OOP principles in Python. This page is currently in progress and more detailed examples and explanations will be coming soon.","title":"Abstraction"},{"location":"dev/python/python/","text":"Python Python tips & tricks Syntaxe Coding: Format UTF-8 : ## -*- coding:Utf-8 -*- Shebang: #!/usr/bin/env python3 Librairy Import You can import a single module from a library: from LIBRAIRIE import module You can also import full library: from LIBRAIRIE import * From python.py file: from fichier import classe Keys How to use keys from list ? print ( \"My name is %s !\" % liste_nom [ 'name' ]) print ( \"My name is %(name)s !\" % d ) print ( \"My name is {0} !\" . format ( d [ 'name' ])) Check Use try to verify block try : ## V\u00e9rifier ce bloc file = open ( 'infos.txt' , 'r' ) print ( file . read ()) except : ## Si erreur se trouve dans try print ( \"erreur\" ) finally : ## Qui s'\u00e9xecutera quoi qu'il arrive des blocs pr\u00e9c\u00e9dents file . close The verification can take the form of several methods: execpt IOError ## Pour se qui concerne les fichier ou \u00e9l\u00e8ments en dur except ValueError ## Qui concernera les \u00e9rreurs de conversions The safest method remains the 'with' option: try : ## V\u00e9rifier ce bloc with open ( 'infox.txt' , 'r' ) as file : ## Avec le fichier, l'ouvrir en var file for line in file . readlines (): print ( int ( line . strip ())) except IOError as err : print ( \"Erreur de fichier\" , err ) except ValueError : print ( \"Erreur de conversion\" ) except : print ( \"Erreur inconnue, tous aux abris.\" ) else : print ( \"Fichier connue de tous wallah\" ) Conparators Operators Operator Description == Equal to > Greater then >= Greter than or equal < Less then <= Less then or equal != Not equal Example #!/usr/bin/env python3 age = 99 if age <= 35 : print ( 'You are old enough to be a Representative, Senator, or the President.' ) elif age >= 30 : print ( 'You are old enough to be a Senator.' ) elif age >= 25 : print ( 'You are old enough to be a Representative.' ) else : print ( 'You are not old enough to be a Representativen Senator or the President.' ) print ( 'Have a nice day!' ) Result : You are old enough to be a Senator . Have a nice day ! Boolean Operators Operator Description and Evalutates to True if both statements are true, otherwiser evaluates to False . or Evaluates to True if either of the statements is true, otherwise evaluates to False . not Evaluates to the opposite of the statement. Numbers How to work betwen numbers variables ? For example, we gona talking about age age = 18 So tu use age into operators, you have to format the age var using int int ( age ) Python Tips If you need to use the age var along your script convert this var to an interger age = 18 # or age = input('Tell me your age please? ') age = int ( age ) Functions Mindset of functions : Don't Repeat Yourselft Write one tim, use many times Example of function code block def function_name (): # code block as def say_hi (): print ( 'Hi!' ) To run any function, just have to call it like : def say_hi (): print ( 'Hi!' ) say_hi () # < run the function say_hi Warning Keep inmind that any function must be defined before to be next called Parameters Example of parameters using def function # functions def say_hi ( name ): print ( 'Hi {} !' . format ( name )) # vars name = input ( 'Fill your name: ' ) # run functions say_hi ( 'Toto' ) say_hi ( 'Peoples' ) say_hi ( name ) Result : Fill your name: Toto Hi Toto! Hi Peoples! Hi Sam! Default value In case that the parameter is missing, we can suggest default value parameters def say_hi ( name = 'there' ): print ( 'Hi {} !' . format ( name )) say_hi () say_hi ( 'Toto' ) Result: Hi there ! Hi Toto ! Example of more complexe parameters. Both of them are named as 'Doe' by default : def say_hi ( first , last = 'Doe' ): print ( 'Hi {} {} !' . format ( first , last )) say_hi ( last = 'Doe' , first = 'Jane' ) say_hi ( first = 'John' ) say_hi ( 'Janie' , 'Doe' ) say_hi ( 'Johnny' ) Result: Hi Jane Doe ! Hi John Doe ! Hi Janie Doe ! Hi Johnny Doe ! Returning data Into your function, it could be clever to add like comment as : \"\"\"Def function usage/utility\"\"\" def say_hi ( first , last = 'Doe' ): \"\"\"Say Hi using firstname and lastname when default one isn't used\"\"\" print ( 'Hi {} {} !' . format ( first , last )) Example of returning satus True or False def true_or_false ( number ): \"\"\"Determine if a number is true or false.\"\"\" if number % 2 == 0 : return True else : return False print ( true_or_false ( 7 )) In this case False Use multiple functions nested #!/usr/env/bin python3 # define functions def get_name (): firstname = input ( \"What's U'r firstname ? \" ) lastname = input ( \"What's U'r lastname ? \" ) return firstname return lastname def say_name ( firstname , lastname = 'Doe' ): print ( \"U'r name is {} {} .\" . format ( firstname , lastname )) print ( \"Yes I know I'm mentalist.\" ) def get_and_say_name (): \"\"\"Get and display name\"\"\" Identity = get_name () say_name ( Identity ) # run function.s get_and_say_name () Result : What 's U' r firstname ? Sam What 's U' r lastname ? U 'r name is Toto Doe. Yes I know I 'm mentalist Virtual venv AKA venv , that is better to use venv to allow using multiple versions and avoid to pollute your machine Info A virtual environement ne require privileges Create python venv Here name defined is : pyvenv python3 -m venv pyvenv Source it source pyvenv/bin/active Download module.s mkdir module ; cd module pip download module_name Using file Requirements.txt Requierements You have to fill the module name wished to the requierements.txt file. This file is used to build your envirement echo \"module_name\" >> requirements.txt Install virtual environement pip install --no-index --find-links module/ -r requirements.txt Lists List Lists are created using comma separated values between square brackets. The format is : list = [ item_1 , item2 , item_X ] Items in a list can be accessed by index. Warning Lists are zero based Access items from the end of the list by using negative indice The last item in a list is : list = [ - 1 ] Add items to a list by using the append() or extend() list methods. Example of code animals = [ 'man' , 'bear' , 'pig' ] print ( animals [ 0 ]) # print the fist item of the index animals [ 0 ] = 'cat' # susbtitute man by cat print ( animals [ 0 ]) # reassigned variable print ( animals [ - 3 ]) # Negative index (pig man to man<cat) animals . append ( 'cow' ) # add cow to the index more_animals = [ 'horse' , 'turtle' ] # agrement the animals index animals . extend ( more_animals ) # insert the more_animals list into the animals print ( animals [ - 1 ]) # display the first item from the reverse reading animals . insert ( 0 , 'dog' ) # insert a new item to the first entry print ( animals ) # display index Output : man cat cat turtle [ 'dog' , 'cat' , 'bear' , 'pig' , 'cow' , 'horse' , 'turtle' Slices Access a portion of a list using a slice. The format is : list [ start , stop ] The list index() method accepts a value as a parameter and returns the index of the first value in the list or an exception if the value is not in the list animals = [ 'man' , 'bear' , 'pig' , 'cow' , 'duck' , 'horse' ] # Positions man:1, bear:2, pig:3, cow:4, duck:5, horse:6 some_animals = animals [ 1 : 4 ] # display from item 1 to item 4 print ( 'Some animals: {} ' . format ( some_animals )) first_two = animals [ 0 : 2 ] # display the two first items print ( 'Some animals: {} ' . format ( first_two )) first_two_again = animals [: 2 ] # display the two first items print ( 'Some animals: {} ' . format ( first_two_again )) last_two = animals [ - 2 :] # display the two last items print ( 'Some animals: {} ' . format ( last_two )) part_of_horse = 'horse' [ 1 : 3 ] # display from the first excluded to the third included print ( part_of_horse ) prepart_of_horse = 'horse' [: 3 ] # display from the first included to the third included print ( prepart_of_horse ) Output : Some animals : [ 'bear' , 'pig' , 'cow' ] Some animals : [ 'man' , 'bear' ] Some animals : [ 'man' , 'bear' ] Some animals : [ 'duck' , 'horse' ] or hor Exception Handing animals = [ 'man' , 'bear' , 'pig' ] bear_index = animals . index ( 'bear' ) # display the bear item position print ( bear_index ) # Searching for 'cat' into the animals index try : cat_index = animals . index ( 'cat' ) except : cat_index = 'No cats found.' print ( cat_index ) Output : 1 No cats found . Loops Loop through a list using a for loop. The format is : for item_var in list : # block of code animals = [ 'man' , 'bear' , 'pig' ] for animal in animals : print ( animal ) print ( animal . upper ()) # to UPPER list While The code block in a while loop executes as long as the condition evaluates to true. The format is : while condition : # block of code animals = [ 'man' , 'bear' , 'pig' ] while animals : print ( animals ) # while there is an item into the animal intex, print-it animals = [ 'man' , 'bear' , 'pig' , 'cow' , 'duck' , 'horse' ] animal_index = 0 # defined var to loop the animals index while animal_index < len ( animals ): # len = output the number of item.s print ( animals [ animal_index ]) animal_index += 1 # increment this variable by listing of the animals index Sorting To sort a list, use the sort() list method or the built-in sorted() function. animals = [ 'man' , 'bear' , 'pig' ] sorted_animals = sorted ( animals ) # sorted() = to sort sorted_animals var print ( 'Animals list: {} ' . format ( animals )) print ( 'Sorted animals list: {} ' . format ( sorted_animals )) animals . sort () # .sort() = to globaly sort animals var print ( 'Animals after sort method: {} ' . format ( animals )) Concatenate two list animals = [ 'man' , 'bear' , 'pig' ] more_animals = [ 'cow' , 'duck' , 'horse' ] all_animals = animals + more_animals print ( all_animals ) To determine the number of any item of list animals = [ 'man' , 'bear' , 'pig' ] print ( len ( animals )) # print the number of items animals . append ( 'cow' ) # add cow item into animals print ( len ( animals )) # print the number of items (+ cow for now) Ranges The built-in range() function generates a list of numbers. The format is : range ( start , stop , step ) Range from the list : for number in range ( 3 ): # From 0 included to 3 excluded = 0, 1, 2 print ( number ) for number in range ( 1 , 3 ): # From 1 included to 3 excluded = 1, 2 print ( number ) for number in range ( 1 , 10 , 2 ): # From 1 included to 1O excluded steped by 2 = 1, 3, 5, 7, 9 print ( number ) Based on the item position : animals = [ 'man' , 'bear' , 'pig' , 'cow' , 'duck' , 'horse' , 'dog' ] for number in range ( 0 , len ( animals ), 2 ): # from 0 to animals item numbers steped by 2 = man, pig, duck, dog print ( animals [ number ]) Conclusion Example of code with sections of Lists merged #!/usr/bin/env python # var todo_index = [] done = False # while done var is 'False' while not done : new_task = input ( 'Enter a task for your to-do list. Press <enter> when done: ' ) if len ( new_task ) == 0 : # if len of new_task is equal to 0 done = True else : todo_index . append ( new_task ) # add entry to the index print ( 'Task has been added.' ) # display print () print ( 'Your To-Do list:' ) print ( '-' * 16 ) for task in todo_index : # From index, get items print ( task ) Dictionaries the dictionary is a data type that Hold key-value pairs called items. AKA associative arrays, has tables and hases. Creating Items Dictionary referred to as associative arrays hases or hash tables dictionaries using comma-separated items between curly braces > $ node at_inventory_hosts.js byt byt_inventory all Test Syntax dictionary_name = { key_1 : value_1 , key_X : value_X } dictionary_name = {} dictionary_name [ key ] Value from Key contacts = { 'Jason' : '555-0123' , 'Carl' : '555-0987' } jasons_phone = contacts [ 'Jason' ] carls_phone = contacts [ 'Carl' ] print ( 'Dial {} to call Jason.' format ( jasons_phone )) print ( 'Dial {} to call Carl.' format ( carls_phone )) Adding Replace Key value from dictionary contacts = { 'Jason' : '555-0123' , 'Carl' : '555-0987' } contacts [ 'Jason' ] = '555-0000' jasons_phone = contacts [ 'Jason' ] print ( 'Dial {} to call Jason.' format ( jasons_phone )) Add Key from dictionary contacts = { 'Jason' : '555-0123' , 'Carl' : '555-0987' } contacts = [ 'Tony' ] = '555-0570' Removing Remove key from dictionary using del contacts = { 'Jason' : '555-0123' , 'Carl' : '555-0987' } del contacts [ 'Jason' ] Searching To verify if certain key is existing into a dictionary contacts = { 'Jason' : [ '555-0123' , '555-0000' ], 'Carl' : '555-0987' } if 'Jason' in contacts . keys (): print ( \"Jason's phone number is:\" ) print ( contacts [ 'Jason' ][ 0 ]) if 'Tony' in contacts . keys (): print ( \"Tony's phone number is:\" ) print ( contacts [ 'Tony' ][ 0 ]) Output : Jason 's phone number is: 555 - 0123 Does it exist ? True or false will be returned contacts = { 'Jason' : [ '555-0123' , '555-0000' ], 'Carl' : '555-0987' } print ( '555-0987' in contacts . values ()) Output : True Nesting Find multiple items attached to a key from list contacts = { 'Jason' : [ '555-0123' , '555-0000' ], 'Carl' : '555-0987' } for number in contacts [ 'Jason' ]: print ( 'Phone number: {} ' . format ( number )) Output : Phone number : 555 - 0123 Phone number : 555 - 0000 Looping There is the syntax : for key_variable in dictionary_name : # code block # dictionary_name[key_variable] for contact in contacts : # code block for person in people : # code block Example : contacts = { 'Jason' : [ '555-0123' , '555-0000' ], 'Carl' : '555-0987' } for contact in contacts : print ( 'The number for {0} is {1} .' . format ( contact , contacts [ contact ])) Output : The number for Jason is [ '555-0123' , '555-0000' ] . The number for Carl is 555 - 0987. Equivalent to previous example : contacts = { 'Jason' : [ '555-0123' , '555-0000' ], 'Carl' : '555-0987' } for person , phone_number in contacts . items (): print ( 'The number for {0} is {1} .' . format ( person , phone_number )) Index nested : contacts = { 'Jason' : { 'phone' : [ '555-0123' , '555-0000' ], 'email' : 'jsaon@example.com' }, 'Carl' : { 'phone' : '555-0987' , 'email' : 'carl@example.com' } } for contact in contacts : print ( \" {} 's contact info:\" . format ( contact )) print ( contacts [ contact ][ 'phone' ]) print ( contacts [ contact ][ 'email' ]) # or for person in contacts : print ( \"The {0} 's phone number is {1} . His mail is {2} \" . format ( person , contacts [ person ][ 'phone' ], contacts [ person ][ 'email' ])) Output : Jason 's contact info: [ '555-0123' , '555-0000' ] jsaon @example . com Carl 's contact info: 555 - 0987 carl @example . com # or The Jason 's phone number is [' 555 - 0123 ', ' 555 - 0000 ']. His mail is jsaon@example.com The Carl 's phone number is 555-0987. His mail is carl@example.com Conclusion Dictionnaries hold key-value pairs, called items dictionary_name = { key_1 : value_1 , key_X : value_X } Access the values stored in a dictionary by key dictionary_name [ key ] Determine if a value exists use the value in dictionary_name.values() , wtich returns a boolean . The values() dictionary method returns a list of the values stored in that dictionary. TKinter TKinter is a library to manage window.s Example of code : from Tkinter import * fenetre = Tk () label = Label ( fenetre , text = \"Exmple de coprs de fen\u00eatre\" ) label . pack () fenetre . mainloop () Customize window List of elements used to customize a window window = Tk()* window.title(\" My application \") window.geometry(\"720x480\") window.minsize(700, 300) window.iconbitmap(\"image.ico\") window.config(background='#CC0000') Widget Checkboxes Checkbox list : caseACocher1 = Checkbutton ( window , text = \"Box N\u00b01\" ) . pack () caseACocher2 = Checkbutton ( window , text = \"Box N\u00b02\" ) . pack () ... Input field value = StringVar () value . set ( \"Text zone\" ) entree = Entry ( window , textvariable = value , width = 30 ) entree . pack () Menu bar File menu : file_menu = Menu ( menu_bar , tearoff = 0 ) file_menu . add_command ( label = \"New\" , command = generate_password ) file_menu . add_command ( label = \"Quit\" , command = window . quit ) menu_bar . add_cascade ( label = \"File\" , menu = file_menu )","title":"Python"},{"location":"dev/python/python/#python","text":"Python tips & tricks","title":"Python"},{"location":"dev/python/python/#syntaxe","text":"Coding: Format UTF-8 : ## -*- coding:Utf-8 -*- Shebang: #!/usr/bin/env python3","title":"Syntaxe"},{"location":"dev/python/python/#librairy","text":"","title":"Librairy"},{"location":"dev/python/python/#import","text":"You can import a single module from a library: from LIBRAIRIE import module You can also import full library: from LIBRAIRIE import * From python.py file: from fichier import classe","title":"Import"},{"location":"dev/python/python/#keys","text":"How to use keys from list ? print ( \"My name is %s !\" % liste_nom [ 'name' ]) print ( \"My name is %(name)s !\" % d ) print ( \"My name is {0} !\" . format ( d [ 'name' ]))","title":"Keys"},{"location":"dev/python/python/#check","text":"Use try to verify block try : ## V\u00e9rifier ce bloc file = open ( 'infos.txt' , 'r' ) print ( file . read ()) except : ## Si erreur se trouve dans try print ( \"erreur\" ) finally : ## Qui s'\u00e9xecutera quoi qu'il arrive des blocs pr\u00e9c\u00e9dents file . close The verification can take the form of several methods: execpt IOError ## Pour se qui concerne les fichier ou \u00e9l\u00e8ments en dur except ValueError ## Qui concernera les \u00e9rreurs de conversions The safest method remains the 'with' option: try : ## V\u00e9rifier ce bloc with open ( 'infox.txt' , 'r' ) as file : ## Avec le fichier, l'ouvrir en var file for line in file . readlines (): print ( int ( line . strip ())) except IOError as err : print ( \"Erreur de fichier\" , err ) except ValueError : print ( \"Erreur de conversion\" ) except : print ( \"Erreur inconnue, tous aux abris.\" ) else : print ( \"Fichier connue de tous wallah\" )","title":"Check"},{"location":"dev/python/python/#conparators","text":"","title":"Conparators"},{"location":"dev/python/python/#operators","text":"Operator Description == Equal to > Greater then >= Greter than or equal < Less then <= Less then or equal != Not equal","title":"Operators"},{"location":"dev/python/python/#example","text":"#!/usr/bin/env python3 age = 99 if age <= 35 : print ( 'You are old enough to be a Representative, Senator, or the President.' ) elif age >= 30 : print ( 'You are old enough to be a Senator.' ) elif age >= 25 : print ( 'You are old enough to be a Representative.' ) else : print ( 'You are not old enough to be a Representativen Senator or the President.' ) print ( 'Have a nice day!' ) Result : You are old enough to be a Senator . Have a nice day !","title":"Example"},{"location":"dev/python/python/#boolean-operators","text":"Operator Description and Evalutates to True if both statements are true, otherwiser evaluates to False . or Evaluates to True if either of the statements is true, otherwise evaluates to False . not Evaluates to the opposite of the statement.","title":"Boolean Operators"},{"location":"dev/python/python/#numbers","text":"How to work betwen numbers variables ? For example, we gona talking about age age = 18 So tu use age into operators, you have to format the age var using int int ( age ) Python Tips If you need to use the age var along your script convert this var to an interger age = 18 # or age = input('Tell me your age please? ') age = int ( age )","title":"Numbers"},{"location":"dev/python/python/#functions","text":"Mindset of functions : Don't Repeat Yourselft Write one tim, use many times Example of function code block def function_name (): # code block as def say_hi (): print ( 'Hi!' ) To run any function, just have to call it like : def say_hi (): print ( 'Hi!' ) say_hi () # < run the function say_hi Warning Keep inmind that any function must be defined before to be next called","title":"Functions"},{"location":"dev/python/python/#parameters","text":"Example of parameters using def function # functions def say_hi ( name ): print ( 'Hi {} !' . format ( name )) # vars name = input ( 'Fill your name: ' ) # run functions say_hi ( 'Toto' ) say_hi ( 'Peoples' ) say_hi ( name ) Result : Fill your name: Toto Hi Toto! Hi Peoples! Hi Sam!","title":"Parameters"},{"location":"dev/python/python/#default-value","text":"In case that the parameter is missing, we can suggest default value parameters def say_hi ( name = 'there' ): print ( 'Hi {} !' . format ( name )) say_hi () say_hi ( 'Toto' ) Result: Hi there ! Hi Toto ! Example of more complexe parameters. Both of them are named as 'Doe' by default : def say_hi ( first , last = 'Doe' ): print ( 'Hi {} {} !' . format ( first , last )) say_hi ( last = 'Doe' , first = 'Jane' ) say_hi ( first = 'John' ) say_hi ( 'Janie' , 'Doe' ) say_hi ( 'Johnny' ) Result: Hi Jane Doe ! Hi John Doe ! Hi Janie Doe ! Hi Johnny Doe !","title":"Default value"},{"location":"dev/python/python/#returning-data","text":"Into your function, it could be clever to add like comment as : \"\"\"Def function usage/utility\"\"\" def say_hi ( first , last = 'Doe' ): \"\"\"Say Hi using firstname and lastname when default one isn't used\"\"\" print ( 'Hi {} {} !' . format ( first , last )) Example of returning satus True or False def true_or_false ( number ): \"\"\"Determine if a number is true or false.\"\"\" if number % 2 == 0 : return True else : return False print ( true_or_false ( 7 )) In this case False Use multiple functions nested #!/usr/env/bin python3 # define functions def get_name (): firstname = input ( \"What's U'r firstname ? \" ) lastname = input ( \"What's U'r lastname ? \" ) return firstname return lastname def say_name ( firstname , lastname = 'Doe' ): print ( \"U'r name is {} {} .\" . format ( firstname , lastname )) print ( \"Yes I know I'm mentalist.\" ) def get_and_say_name (): \"\"\"Get and display name\"\"\" Identity = get_name () say_name ( Identity ) # run function.s get_and_say_name () Result : What 's U' r firstname ? Sam What 's U' r lastname ? U 'r name is Toto Doe. Yes I know I 'm mentalist","title":"Returning data"},{"location":"dev/python/python/#virtual-venv","text":"AKA venv , that is better to use venv to allow using multiple versions and avoid to pollute your machine Info A virtual environement ne require privileges","title":"Virtual venv"},{"location":"dev/python/python/#create-python-venv","text":"Here name defined is : pyvenv python3 -m venv pyvenv","title":"Create python venv"},{"location":"dev/python/python/#source-it","text":"source pyvenv/bin/active","title":"Source it"},{"location":"dev/python/python/#download-modules","text":"mkdir module ; cd module pip download module_name","title":"Download module.s"},{"location":"dev/python/python/#using-file","text":"Requirements.txt","title":"Using file"},{"location":"dev/python/python/#requierements","text":"You have to fill the module name wished to the requierements.txt file. This file is used to build your envirement echo \"module_name\" >> requirements.txt","title":"Requierements"},{"location":"dev/python/python/#install-virtual-environement","text":"pip install --no-index --find-links module/ -r requirements.txt","title":"Install virtual environement"},{"location":"dev/python/python/#lists","text":"","title":"Lists"},{"location":"dev/python/python/#list","text":"Lists are created using comma separated values between square brackets. The format is : list = [ item_1 , item2 , item_X ] Items in a list can be accessed by index. Warning Lists are zero based Access items from the end of the list by using negative indice The last item in a list is : list = [ - 1 ] Add items to a list by using the append() or extend() list methods. Example of code animals = [ 'man' , 'bear' , 'pig' ] print ( animals [ 0 ]) # print the fist item of the index animals [ 0 ] = 'cat' # susbtitute man by cat print ( animals [ 0 ]) # reassigned variable print ( animals [ - 3 ]) # Negative index (pig man to man<cat) animals . append ( 'cow' ) # add cow to the index more_animals = [ 'horse' , 'turtle' ] # agrement the animals index animals . extend ( more_animals ) # insert the more_animals list into the animals print ( animals [ - 1 ]) # display the first item from the reverse reading animals . insert ( 0 , 'dog' ) # insert a new item to the first entry print ( animals ) # display index Output : man cat cat turtle [ 'dog' , 'cat' , 'bear' , 'pig' , 'cow' , 'horse' , 'turtle'","title":"List"},{"location":"dev/python/python/#slices","text":"Access a portion of a list using a slice. The format is : list [ start , stop ] The list index() method accepts a value as a parameter and returns the index of the first value in the list or an exception if the value is not in the list animals = [ 'man' , 'bear' , 'pig' , 'cow' , 'duck' , 'horse' ] # Positions man:1, bear:2, pig:3, cow:4, duck:5, horse:6 some_animals = animals [ 1 : 4 ] # display from item 1 to item 4 print ( 'Some animals: {} ' . format ( some_animals )) first_two = animals [ 0 : 2 ] # display the two first items print ( 'Some animals: {} ' . format ( first_two )) first_two_again = animals [: 2 ] # display the two first items print ( 'Some animals: {} ' . format ( first_two_again )) last_two = animals [ - 2 :] # display the two last items print ( 'Some animals: {} ' . format ( last_two )) part_of_horse = 'horse' [ 1 : 3 ] # display from the first excluded to the third included print ( part_of_horse ) prepart_of_horse = 'horse' [: 3 ] # display from the first included to the third included print ( prepart_of_horse ) Output : Some animals : [ 'bear' , 'pig' , 'cow' ] Some animals : [ 'man' , 'bear' ] Some animals : [ 'man' , 'bear' ] Some animals : [ 'duck' , 'horse' ] or hor","title":"Slices"},{"location":"dev/python/python/#exception-handing","text":"animals = [ 'man' , 'bear' , 'pig' ] bear_index = animals . index ( 'bear' ) # display the bear item position print ( bear_index ) # Searching for 'cat' into the animals index try : cat_index = animals . index ( 'cat' ) except : cat_index = 'No cats found.' print ( cat_index ) Output : 1 No cats found .","title":"Exception Handing"},{"location":"dev/python/python/#loops","text":"Loop through a list using a for loop. The format is : for item_var in list : # block of code animals = [ 'man' , 'bear' , 'pig' ] for animal in animals : print ( animal ) print ( animal . upper ()) # to UPPER list","title":"Loops"},{"location":"dev/python/python/#while","text":"The code block in a while loop executes as long as the condition evaluates to true. The format is : while condition : # block of code animals = [ 'man' , 'bear' , 'pig' ] while animals : print ( animals ) # while there is an item into the animal intex, print-it animals = [ 'man' , 'bear' , 'pig' , 'cow' , 'duck' , 'horse' ] animal_index = 0 # defined var to loop the animals index while animal_index < len ( animals ): # len = output the number of item.s print ( animals [ animal_index ]) animal_index += 1 # increment this variable by listing of the animals index","title":"While"},{"location":"dev/python/python/#sorting","text":"To sort a list, use the sort() list method or the built-in sorted() function. animals = [ 'man' , 'bear' , 'pig' ] sorted_animals = sorted ( animals ) # sorted() = to sort sorted_animals var print ( 'Animals list: {} ' . format ( animals )) print ( 'Sorted animals list: {} ' . format ( sorted_animals )) animals . sort () # .sort() = to globaly sort animals var print ( 'Animals after sort method: {} ' . format ( animals )) Concatenate two list animals = [ 'man' , 'bear' , 'pig' ] more_animals = [ 'cow' , 'duck' , 'horse' ] all_animals = animals + more_animals print ( all_animals ) To determine the number of any item of list animals = [ 'man' , 'bear' , 'pig' ] print ( len ( animals )) # print the number of items animals . append ( 'cow' ) # add cow item into animals print ( len ( animals )) # print the number of items (+ cow for now)","title":"Sorting"},{"location":"dev/python/python/#ranges","text":"The built-in range() function generates a list of numbers. The format is : range ( start , stop , step ) Range from the list : for number in range ( 3 ): # From 0 included to 3 excluded = 0, 1, 2 print ( number ) for number in range ( 1 , 3 ): # From 1 included to 3 excluded = 1, 2 print ( number ) for number in range ( 1 , 10 , 2 ): # From 1 included to 1O excluded steped by 2 = 1, 3, 5, 7, 9 print ( number ) Based on the item position : animals = [ 'man' , 'bear' , 'pig' , 'cow' , 'duck' , 'horse' , 'dog' ] for number in range ( 0 , len ( animals ), 2 ): # from 0 to animals item numbers steped by 2 = man, pig, duck, dog print ( animals [ number ])","title":"Ranges"},{"location":"dev/python/python/#conclusion","text":"Example of code with sections of Lists merged #!/usr/bin/env python # var todo_index = [] done = False # while done var is 'False' while not done : new_task = input ( 'Enter a task for your to-do list. Press <enter> when done: ' ) if len ( new_task ) == 0 : # if len of new_task is equal to 0 done = True else : todo_index . append ( new_task ) # add entry to the index print ( 'Task has been added.' ) # display print () print ( 'Your To-Do list:' ) print ( '-' * 16 ) for task in todo_index : # From index, get items print ( task )","title":"Conclusion"},{"location":"dev/python/python/#dictionaries","text":"the dictionary is a data type that Hold key-value pairs called items. AKA associative arrays, has tables and hases.","title":"Dictionaries"},{"location":"dev/python/python/#creating","text":"","title":"Creating"},{"location":"dev/python/python/#items","text":"Dictionary referred to as associative arrays hases or hash tables dictionaries using comma-separated items between curly braces > $ node at_inventory_hosts.js byt byt_inventory all Test Syntax dictionary_name = { key_1 : value_1 , key_X : value_X } dictionary_name = {} dictionary_name [ key ] Value from Key contacts = { 'Jason' : '555-0123' , 'Carl' : '555-0987' } jasons_phone = contacts [ 'Jason' ] carls_phone = contacts [ 'Carl' ] print ( 'Dial {} to call Jason.' format ( jasons_phone )) print ( 'Dial {} to call Carl.' format ( carls_phone ))","title":"Items"},{"location":"dev/python/python/#adding","text":"Replace Key value from dictionary contacts = { 'Jason' : '555-0123' , 'Carl' : '555-0987' } contacts [ 'Jason' ] = '555-0000' jasons_phone = contacts [ 'Jason' ] print ( 'Dial {} to call Jason.' format ( jasons_phone )) Add Key from dictionary contacts = { 'Jason' : '555-0123' , 'Carl' : '555-0987' } contacts = [ 'Tony' ] = '555-0570'","title":"Adding"},{"location":"dev/python/python/#removing","text":"Remove key from dictionary using del contacts = { 'Jason' : '555-0123' , 'Carl' : '555-0987' } del contacts [ 'Jason' ]","title":"Removing"},{"location":"dev/python/python/#searching","text":"To verify if certain key is existing into a dictionary contacts = { 'Jason' : [ '555-0123' , '555-0000' ], 'Carl' : '555-0987' } if 'Jason' in contacts . keys (): print ( \"Jason's phone number is:\" ) print ( contacts [ 'Jason' ][ 0 ]) if 'Tony' in contacts . keys (): print ( \"Tony's phone number is:\" ) print ( contacts [ 'Tony' ][ 0 ]) Output : Jason 's phone number is: 555 - 0123","title":"Searching"},{"location":"dev/python/python/#does-it-exist","text":"True or false will be returned contacts = { 'Jason' : [ '555-0123' , '555-0000' ], 'Carl' : '555-0987' } print ( '555-0987' in contacts . values ()) Output : True","title":"Does it exist ?"},{"location":"dev/python/python/#nesting","text":"Find multiple items attached to a key from list contacts = { 'Jason' : [ '555-0123' , '555-0000' ], 'Carl' : '555-0987' } for number in contacts [ 'Jason' ]: print ( 'Phone number: {} ' . format ( number )) Output : Phone number : 555 - 0123 Phone number : 555 - 0000","title":"Nesting"},{"location":"dev/python/python/#looping","text":"There is the syntax : for key_variable in dictionary_name : # code block # dictionary_name[key_variable] for contact in contacts : # code block for person in people : # code block Example : contacts = { 'Jason' : [ '555-0123' , '555-0000' ], 'Carl' : '555-0987' } for contact in contacts : print ( 'The number for {0} is {1} .' . format ( contact , contacts [ contact ])) Output : The number for Jason is [ '555-0123' , '555-0000' ] . The number for Carl is 555 - 0987. Equivalent to previous example : contacts = { 'Jason' : [ '555-0123' , '555-0000' ], 'Carl' : '555-0987' } for person , phone_number in contacts . items (): print ( 'The number for {0} is {1} .' . format ( person , phone_number )) Index nested : contacts = { 'Jason' : { 'phone' : [ '555-0123' , '555-0000' ], 'email' : 'jsaon@example.com' }, 'Carl' : { 'phone' : '555-0987' , 'email' : 'carl@example.com' } } for contact in contacts : print ( \" {} 's contact info:\" . format ( contact )) print ( contacts [ contact ][ 'phone' ]) print ( contacts [ contact ][ 'email' ]) # or for person in contacts : print ( \"The {0} 's phone number is {1} . His mail is {2} \" . format ( person , contacts [ person ][ 'phone' ], contacts [ person ][ 'email' ])) Output : Jason 's contact info: [ '555-0123' , '555-0000' ] jsaon @example . com Carl 's contact info: 555 - 0987 carl @example . com # or The Jason 's phone number is [' 555 - 0123 ', ' 555 - 0000 ']. His mail is jsaon@example.com The Carl 's phone number is 555-0987. His mail is carl@example.com","title":"Looping"},{"location":"dev/python/python/#conclusion_1","text":"Dictionnaries hold key-value pairs, called items dictionary_name = { key_1 : value_1 , key_X : value_X } Access the values stored in a dictionary by key dictionary_name [ key ] Determine if a value exists use the value in dictionary_name.values() , wtich returns a boolean . The values() dictionary method returns a list of the values stored in that dictionary.","title":"Conclusion"},{"location":"dev/python/python/#tkinter","text":"TKinter is a library to manage window.s Example of code : from Tkinter import * fenetre = Tk () label = Label ( fenetre , text = \"Exmple de coprs de fen\u00eatre\" ) label . pack () fenetre . mainloop ()","title":"TKinter"},{"location":"dev/python/python/#customize-window","text":"List of elements used to customize a window window = Tk()* window.title(\" My application \") window.geometry(\"720x480\") window.minsize(700, 300) window.iconbitmap(\"image.ico\") window.config(background='#CC0000')","title":"Customize window"},{"location":"dev/python/python/#widget","text":"","title":"Widget"},{"location":"dev/python/python/#checkboxes","text":"Checkbox list : caseACocher1 = Checkbutton ( window , text = \"Box N\u00b01\" ) . pack () caseACocher2 = Checkbutton ( window , text = \"Box N\u00b02\" ) . pack () ...","title":"Checkboxes"},{"location":"dev/python/python/#input-field","text":"value = StringVar () value . set ( \"Text zone\" ) entree = Entry ( window , textvariable = value , width = 30 ) entree . pack ()","title":"Input field"},{"location":"dev/python/python/#menu-bar","text":"File menu : file_menu = Menu ( menu_bar , tearoff = 0 ) file_menu . add_command ( label = \"New\" , command = generate_password ) file_menu . add_command ( label = \"Quit\" , command = window . quit ) menu_bar . add_cascade ( label = \"File\" , menu = file_menu )","title":"Menu bar"},{"location":"dev/python/reading-and-writing-files/","text":"Reading and Writing Files The file Reading/Writing process To read/write to a file in Python, you will want to use the with statement, which will close the file for you after you are done, managing the available resources for you. Opening and reading files The open function opens a file and return a corresponding file object. >>> with open ( 'C: \\\\ Users \\\\ your_home_folder \\\\ hi.txt' ) as hello_file : ... hello_content = hello_file . read () ... >>> hello_content 'Hello World!' Alternatively, you can use the readlines() method to get a list of string values from the file, one string for each line of text: >>> with open ( 'sonnet29.txt' ) as sonnet_file : ... sonnet_file . readlines () ... # [When, in disgrace with fortune and men's eyes,\\n', # ' I all alone beweep my outcast state,\\n', # And trouble deaf heaven with my bootless cries,\\n', And # look upon myself and curse my fate,'] You can also iterate through the file line by line: >>> with open ( 'sonnet29.txt' ) as sonnet_file : ... for line in sonnet_file : ... print ( line , end = '' ) ... # When, in disgrace with fortune and men's eyes, # I all alone beweep my outcast state, # And trouble deaf heaven with my bootless cries, # And look upon myself and curse my fate, Writing to files >>> with open ( 'bacon.txt' , 'w' ) as bacon_file : ... bacon_file . write ( 'Hello world! \\n ' ) ... # 13 >>> with open ( 'bacon.txt' , 'a' ) as bacon_file : ... bacon_file . write ( 'Bacon is not a vegetable.' ) ... # 25 >>> with open ( 'bacon.txt' ) as bacon_file : ... content = bacon_file . read () ... >>> print ( content ) # Hello world! # Bacon is not a vegetable.","title":"Reading and writing files"},{"location":"dev/python/reading-and-writing-files/#the-file-readingwriting-process","text":"To read/write to a file in Python, you will want to use the with statement, which will close the file for you after you are done, managing the available resources for you.","title":"The file Reading/Writing process"},{"location":"dev/python/reading-and-writing-files/#opening-and-reading-files","text":"The open function opens a file and return a corresponding file object. >>> with open ( 'C: \\\\ Users \\\\ your_home_folder \\\\ hi.txt' ) as hello_file : ... hello_content = hello_file . read () ... >>> hello_content 'Hello World!' Alternatively, you can use the readlines() method to get a list of string values from the file, one string for each line of text: >>> with open ( 'sonnet29.txt' ) as sonnet_file : ... sonnet_file . readlines () ... # [When, in disgrace with fortune and men's eyes,\\n', # ' I all alone beweep my outcast state,\\n', # And trouble deaf heaven with my bootless cries,\\n', And # look upon myself and curse my fate,'] You can also iterate through the file line by line: >>> with open ( 'sonnet29.txt' ) as sonnet_file : ... for line in sonnet_file : ... print ( line , end = '' ) ... # When, in disgrace with fortune and men's eyes, # I all alone beweep my outcast state, # And trouble deaf heaven with my bootless cries, # And look upon myself and curse my fate,","title":"Opening and reading files"},{"location":"dev/python/reading-and-writing-files/#writing-to-files","text":">>> with open ( 'bacon.txt' , 'w' ) as bacon_file : ... bacon_file . write ( 'Hello world! \\n ' ) ... # 13 >>> with open ( 'bacon.txt' , 'a' ) as bacon_file : ... bacon_file . write ( 'Bacon is not a vegetable.' ) ... # 25 >>> with open ( 'bacon.txt' ) as bacon_file : ... content = bacon_file . read () ... >>> print ( content ) # Hello world! # Bacon is not a vegetable.","title":"Writing to files"},{"location":"dev/python/regular-expressions/","text":"Regular Expressions Regular expressions A regular expression (shortened as regex [...]) is a sequence of characters that specifies a search pattern in text. [...] used by string-searching algorithms for \"find\" or \"find and replace\" operations on strings, or for input validation. Import the regex module with import re . Create a Regex object with the re.compile() function. (Remember to use a raw string.) Pass the string you want to search into the Regex object\u2019s search() method. This returns a Match object. Call the Match object\u2019s group() method to return a string of the actual matched text. All the regex functions in Python are in the re module: >>> import re Regex symbols Symbol Matches ? zero or one of the preceding group. * zero or more of the preceding group. + one or more of the preceding group. {n} exactly n of the preceding group. {n,} n or more of the preceding group. {,m} 0 to m of the preceding group. {n,m} at least n and at most m of the preceding p. {n,m}? or *? or +? performs a non-greedy match of the preceding p. ^spam means the string must begin with spam. spam$ means the string must end with spam. . any character, except newline characters. \\d , \\w , and \\s a digit, word, or space character, respectively. \\D , \\W , and \\S anything except a digit, word, or space, respectively. [abc] any character between the brackets (such as a, b, ). [^abc] any character that isn\u2019t between the brackets. Matching regex objects >>> phone_num_regex = re . compile ( r '\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d' ) >>> mo = phone_num_regex . search ( 'My number is 415-555-4242.' ) >>> print ( f 'Phone number found: { mo . group () } ' ) # Phone number found: 415-555-4242 Grouping with parentheses >>> phone_num_regex = re . compile ( r '(\\d\\d\\d)-(\\d\\d\\d-\\d\\d\\d\\d)' ) >>> mo = phone_num_regex . search ( 'My number is 415-555-4242.' ) >>> mo . group ( 1 ) # '415' >>> mo . group ( 2 ) # '555-4242' >>> mo . group ( 0 ) # '415-555-4242' >>> mo . group () # '415-555-4242' To retrieve all the groups at once use the groups() method: >>> mo . groups () ( '415' , '555-4242' ) >>> area_code , main_number = mo . groups () >>> print ( area_code ) 415 >>> print ( main_number ) 555 - 4242 Multiple groups with Pipe You can use the | character anywhere you want to match one of many expressions. >>> hero_regex = re . compile ( r 'Batman|Tina Fey' ) >>> mo1 = hero_regex . search ( 'Batman and Tina Fey.' ) >>> mo1 . group () # 'Batman' >>> mo2 = hero_regex . search ( 'Tina Fey and Batman.' ) >>> mo2 . group () # 'Tina Fey' You can also use the pipe to match one of several patterns as part of your regex: >>> bat_regex = re . compile ( r 'Bat(man|mobile|copter|bat)' ) >>> mo = bat_regex . search ( 'Batmobile lost a wheel' ) >>> mo . group () # 'Batmobile' >>> mo . group ( 1 ) # 'mobile' Optional matching with the Question Mark The ? character flags the group that precedes it as an optional part of the pattern. >>> bat_regex = re . compile ( r 'Bat(wo)?man' ) >>> mo1 = bat_regex . search ( 'The Adventures of Batman' ) >>> mo1 . group () # 'Batman' >>> mo2 = bat_regex . search ( 'The Adventures of Batwoman' ) >>> mo2 . group () # 'Batwoman' Matching zero or more with the Star The * (star or asterisk) means \u201cmatch zero or more\u201d. The group that precedes the star can occur any number of times in the text. >>> bat_regex = re . compile ( r 'Bat(wo)*man' ) >>> mo1 = bat_regex . search ( 'The Adventures of Batman' ) >>> mo1 . group () 'Batman' >>> mo2 = bat_regex . search ( 'The Adventures of Batwoman' ) >>> mo2 . group () 'Batwoman' >>> mo3 = bat_regex . search ( 'The Adventures of Batwowowowoman' ) >>> mo3 . group () 'Batwowowowoman' Matching one or more with the Plus The + (or plus) means match one or more . The group preceding a plus must appear at least once: >>> bat_regex = re . compile ( r 'Bat(wo)+man' ) >>> mo1 = bat_regex . search ( 'The Adventures of Batwoman' ) >>> mo1 . group () # 'Batwoman' >>> mo2 = bat_regex . search ( 'The Adventures of Batwowowowoman' ) >>> mo2 . group () # 'Batwowowowoman' >>> mo3 = bat_regex . search ( 'The Adventures of Batman' ) >>> mo3 is None # True Matching specific repetitions with Curly Brackets If you have a group that you want to repeat a specific number of times, follow the group in your regex with a number in curly brackets: >>> ha_regex = re . compile ( r '(Ha) {3} ' ) >>> mo1 = ha_regex . search ( 'HaHaHa' ) >>> mo1 . group () # 'HaHaHa' >>> mo2 = ha_regex . search ( 'Ha' ) >>> mo2 is None # True Instead of one number, you can specify a range with minimum and a maximum in between the curly brackets. For example, the regex (Ha){3,5} will match 'HaHaHa', 'HaHaHaHa', and 'HaHaHaHaHa'. >>> ha_regex = re . compile ( r '(Ha){2,3}' ) >>> mo1 = ha_regex . search ( 'HaHaHaHa' ) >>> mo1 . group () # 'HaHaHa' Greedy and non-greedy matching Python\u2019s regular expressions are greedy by default: in ambiguous situations they will match the longest string possible. The non-greedy version of the curly brackets, which matches the shortest string possible, has the closing curly bracket followed by a question mark. >>> greedy_ha_regex = re . compile ( r '(Ha){3,5}' ) >>> mo1 = greedy_ha_regex . search ( 'HaHaHaHaHa' ) >>> mo1 . group () # 'HaHaHaHaHa' >>> non_greedy_ha_regex = re . compile ( r '(Ha){3,5}?' ) >>> mo2 = non_greedy_ha_regex . search ( 'HaHaHaHaHa' ) >>> mo2 . group () # 'HaHaHa' The findall() method The findall() method will return the strings of every match in the searched string. >>> phone_num_regex = re . compile ( r '\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d' ) # has no groups >>> phone_num_regex . findall ( 'Cell: 415-555-9999 Work: 212-555-0000' ) # ['415-555-9999', '212-555-0000'] Making your own character classes You can define your own character class using square brackets. For example, the character class [aeiouAEIOU] will match any vowel, both lowercase and uppercase. >>> vowel_regex = re . compile ( r '[aeiouAEIOU]' ) >>> vowel_regex . findall ( 'Robocop eats baby food. BABY FOOD.' ) # ['o', 'o', 'o', 'e', 'a', 'a', 'o', 'o', 'A', 'O', 'O'] You can also include ranges of letters or numbers by using a hyphen. For example, the character class [a-zA-Z0-9] will match all lowercase letters, uppercase letters, and numbers. By placing a caret character ( ^ ) just after the character class\u2019s opening bracket, you can make a negative character class that will match all the characters that are not in the character class: >>> consonant_regex = re . compile ( r '[^aeiouAEIOU]' ) >>> consonant_regex . findall ( 'Robocop eats baby food. BABY FOOD.' ) # ['R', 'b', 'c', 'p', ' ', 't', 's', ' ', 'b', 'b', 'y', ' ', 'f', 'd', '.', ' # ', 'B', 'B', 'Y', ' ', 'F', 'D', '.'] The Caret and Dollar sign characters You can also use the caret symbol ^ at the start of a regex to indicate that a match must occur at the beginning of the searched text. Likewise, you can put a dollar sign $ at the end of the regex to indicate the string must end with this regex pattern. And you can use the ^ and $ together to indicate that the entire string must match the regex. The r'^Hello ' regular expression string matches strings that begin with 'Hello': >>> begins_with_hello = re . compile ( r '^Hello' ) >>> begins_with_hello . search ( 'Hello world!' ) # <_sre.SRE_Match object; span=(0, 5), match='Hello'> >>> begins_with_hello . search ( 'He said hello.' ) is None # True The r'\\d\\$' regular expression string matches strings that end with a numeric character from 0 to 9: >>> whole_string_is_num = re . compile ( r '^\\d+$' ) >>> whole_string_is_num . search ( '1234567890' ) # <_sre.SRE_Match object; span=(0, 10), match='1234567890'> >>> whole_string_is_num . search ( '12345xyz67890' ) is None # True >>> whole_string_is_num . search ( '12 34567890' ) is None # True The Wildcard character The . (or dot) character in a regular expression will match any character except for a newline: >>> at_regex = re . compile ( r '.at' ) >>> at_regex . findall ( 'The cat in the hat sat on the flat mat.' ) [ 'cat' , 'hat' , 'sat' , 'lat' , 'mat' ] Matching everything with Dot-Star >>> name_regex = re . compile ( r 'First Name: (.*) Last Name: (.*)' ) >>> mo = name_regex . search ( 'First Name: Al Last Name: Sweigart' ) >>> mo . group ( 1 ) # 'Al' >>> mo . group ( 2 ) 'Sweigart' The .* uses greedy mode: It will always try to match as much text as possible. To match any and all text in a non-greedy fashion, use the dot, star, and question mark ( .*? ). The question mark tells Python to match in a non-greedy way: >>> non_greedy_regex = re . compile ( r '<.*?>' ) >>> mo = non_greedy_regex . search ( '<To serve man> for dinner.>' ) >>> mo . group () # '<To serve man>' >>> greedy_regex = re . compile ( r '<.*>' ) >>> mo = greedy_regex . search ( '<To serve man> for dinner.>' ) >>> mo . group () # '<To serve man> for dinner.>' Matching newlines with the Dot character The dot-star will match everything except a newline. By passing re.DOTALL as the second argument to re.compile() , you can make the dot character match all characters, including the newline character: >>> no_newline_regex = re . compile ( '.*' ) >>> no_newline_regex . search ( 'Serve the public trust. \\n Protect the innocent. \\n Uphold the law.' ) . group () # 'Serve the public trust.' >>> newline_regex = re . compile ( '.*' , re . DOTALL ) >>> newline_regex . search ( 'Serve the public trust. \\n Protect the innocent. \\n Uphold the law.' ) . group () # 'Serve the public trust.\\nProtect the innocent.\\nUphold the law.' Case-Insensitive matching To make your regex case-insensitive, you can pass re.IGNORECASE or re.I as a second argument to re.compile() : >>> robocop = re . compile ( r 'robocop' , re . I ) >>> robocop . search ( 'Robocop is part man, part machine, all cop.' ) . group () # 'Robocop' >>> robocop . search ( 'ROBOCOP protects the innocent.' ) . group () # 'ROBOCOP' >>> robocop . search ( 'Al, why does your programming book talk about robocop so much?' ) . group () # 'robocop' Substituting strings with the sub() method The sub() method for Regex objects is passed two arguments: The first argument is a string to replace any matches. The second is the string for the regular expression. The sub() method returns a string with the substitutions applied: >>> names_regex = re . compile ( r 'Agent \\w+' ) >>> names_regex . sub ( 'CENSORED' , 'Agent Alice gave the secret documents to Agent Bob.' ) # 'CENSORED gave the secret documents to CENSORED.' Managing complex Regexes To tell the re.compile() function to ignore whitespace and comments inside the regular expression string, \u201cverbose mode\u201d can be enabled by passing the variable re.VERBOSE as the second argument to re.compile() . Now instead of a hard-to-read regular expression like this: phone_regex = re . compile ( r '((\\d {3} |\\(\\d {3} \\))?(\\s|-|\\.)?\\d {3} (\\s|-|\\.)\\d {4} (\\s*(ext|x|ext.)\\s*\\d{2,5})?)' ) you can spread the regular expression over multiple lines with comments like this: phone_regex = re . compile ( r '''( (\\d {3} |\\(\\d {3} \\))? # area code (\\s|-|\\.)? # separator \\d {3} # first 3 digits (\\s|-|\\.) # separator \\d {4} # last 4 digits (\\s*(ext|x|ext.)\\s*\\d{2,5})? # extension )''' , re . VERBOSE )","title":"Python Regular Expressions"},{"location":"dev/python/regular-expressions/#regex-symbols","text":"Symbol Matches ? zero or one of the preceding group. * zero or more of the preceding group. + one or more of the preceding group. {n} exactly n of the preceding group. {n,} n or more of the preceding group. {,m} 0 to m of the preceding group. {n,m} at least n and at most m of the preceding p. {n,m}? or *? or +? performs a non-greedy match of the preceding p. ^spam means the string must begin with spam. spam$ means the string must end with spam. . any character, except newline characters. \\d , \\w , and \\s a digit, word, or space character, respectively. \\D , \\W , and \\S anything except a digit, word, or space, respectively. [abc] any character between the brackets (such as a, b, ). [^abc] any character that isn\u2019t between the brackets.","title":"Regex symbols"},{"location":"dev/python/regular-expressions/#matching-regex-objects","text":">>> phone_num_regex = re . compile ( r '\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d' ) >>> mo = phone_num_regex . search ( 'My number is 415-555-4242.' ) >>> print ( f 'Phone number found: { mo . group () } ' ) # Phone number found: 415-555-4242","title":"Matching regex objects"},{"location":"dev/python/regular-expressions/#grouping-with-parentheses","text":">>> phone_num_regex = re . compile ( r '(\\d\\d\\d)-(\\d\\d\\d-\\d\\d\\d\\d)' ) >>> mo = phone_num_regex . search ( 'My number is 415-555-4242.' ) >>> mo . group ( 1 ) # '415' >>> mo . group ( 2 ) # '555-4242' >>> mo . group ( 0 ) # '415-555-4242' >>> mo . group () # '415-555-4242' To retrieve all the groups at once use the groups() method: >>> mo . groups () ( '415' , '555-4242' ) >>> area_code , main_number = mo . groups () >>> print ( area_code ) 415 >>> print ( main_number ) 555 - 4242","title":"Grouping with parentheses"},{"location":"dev/python/regular-expressions/#multiple-groups-with-pipe","text":"You can use the | character anywhere you want to match one of many expressions. >>> hero_regex = re . compile ( r 'Batman|Tina Fey' ) >>> mo1 = hero_regex . search ( 'Batman and Tina Fey.' ) >>> mo1 . group () # 'Batman' >>> mo2 = hero_regex . search ( 'Tina Fey and Batman.' ) >>> mo2 . group () # 'Tina Fey' You can also use the pipe to match one of several patterns as part of your regex: >>> bat_regex = re . compile ( r 'Bat(man|mobile|copter|bat)' ) >>> mo = bat_regex . search ( 'Batmobile lost a wheel' ) >>> mo . group () # 'Batmobile' >>> mo . group ( 1 ) # 'mobile'","title":"Multiple groups with Pipe"},{"location":"dev/python/regular-expressions/#optional-matching-with-the-question-mark","text":"The ? character flags the group that precedes it as an optional part of the pattern. >>> bat_regex = re . compile ( r 'Bat(wo)?man' ) >>> mo1 = bat_regex . search ( 'The Adventures of Batman' ) >>> mo1 . group () # 'Batman' >>> mo2 = bat_regex . search ( 'The Adventures of Batwoman' ) >>> mo2 . group () # 'Batwoman'","title":"Optional matching with the Question Mark"},{"location":"dev/python/regular-expressions/#matching-zero-or-more-with-the-star","text":"The * (star or asterisk) means \u201cmatch zero or more\u201d. The group that precedes the star can occur any number of times in the text. >>> bat_regex = re . compile ( r 'Bat(wo)*man' ) >>> mo1 = bat_regex . search ( 'The Adventures of Batman' ) >>> mo1 . group () 'Batman' >>> mo2 = bat_regex . search ( 'The Adventures of Batwoman' ) >>> mo2 . group () 'Batwoman' >>> mo3 = bat_regex . search ( 'The Adventures of Batwowowowoman' ) >>> mo3 . group () 'Batwowowowoman'","title":"Matching zero or more with the Star"},{"location":"dev/python/regular-expressions/#matching-one-or-more-with-the-plus","text":"The + (or plus) means match one or more . The group preceding a plus must appear at least once: >>> bat_regex = re . compile ( r 'Bat(wo)+man' ) >>> mo1 = bat_regex . search ( 'The Adventures of Batwoman' ) >>> mo1 . group () # 'Batwoman' >>> mo2 = bat_regex . search ( 'The Adventures of Batwowowowoman' ) >>> mo2 . group () # 'Batwowowowoman' >>> mo3 = bat_regex . search ( 'The Adventures of Batman' ) >>> mo3 is None # True","title":"Matching one or more with the Plus"},{"location":"dev/python/regular-expressions/#matching-specific-repetitions-with-curly-brackets","text":"If you have a group that you want to repeat a specific number of times, follow the group in your regex with a number in curly brackets: >>> ha_regex = re . compile ( r '(Ha) {3} ' ) >>> mo1 = ha_regex . search ( 'HaHaHa' ) >>> mo1 . group () # 'HaHaHa' >>> mo2 = ha_regex . search ( 'Ha' ) >>> mo2 is None # True Instead of one number, you can specify a range with minimum and a maximum in between the curly brackets. For example, the regex (Ha){3,5} will match 'HaHaHa', 'HaHaHaHa', and 'HaHaHaHaHa'. >>> ha_regex = re . compile ( r '(Ha){2,3}' ) >>> mo1 = ha_regex . search ( 'HaHaHaHa' ) >>> mo1 . group () # 'HaHaHa'","title":"Matching specific repetitions with Curly Brackets"},{"location":"dev/python/regular-expressions/#greedy-and-non-greedy-matching","text":"Python\u2019s regular expressions are greedy by default: in ambiguous situations they will match the longest string possible. The non-greedy version of the curly brackets, which matches the shortest string possible, has the closing curly bracket followed by a question mark. >>> greedy_ha_regex = re . compile ( r '(Ha){3,5}' ) >>> mo1 = greedy_ha_regex . search ( 'HaHaHaHaHa' ) >>> mo1 . group () # 'HaHaHaHaHa' >>> non_greedy_ha_regex = re . compile ( r '(Ha){3,5}?' ) >>> mo2 = non_greedy_ha_regex . search ( 'HaHaHaHaHa' ) >>> mo2 . group () # 'HaHaHa'","title":"Greedy and non-greedy matching"},{"location":"dev/python/regular-expressions/#the-findall-method","text":"The findall() method will return the strings of every match in the searched string. >>> phone_num_regex = re . compile ( r '\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d' ) # has no groups >>> phone_num_regex . findall ( 'Cell: 415-555-9999 Work: 212-555-0000' ) # ['415-555-9999', '212-555-0000']","title":"The findall() method"},{"location":"dev/python/regular-expressions/#making-your-own-character-classes","text":"You can define your own character class using square brackets. For example, the character class [aeiouAEIOU] will match any vowel, both lowercase and uppercase. >>> vowel_regex = re . compile ( r '[aeiouAEIOU]' ) >>> vowel_regex . findall ( 'Robocop eats baby food. BABY FOOD.' ) # ['o', 'o', 'o', 'e', 'a', 'a', 'o', 'o', 'A', 'O', 'O'] You can also include ranges of letters or numbers by using a hyphen. For example, the character class [a-zA-Z0-9] will match all lowercase letters, uppercase letters, and numbers. By placing a caret character ( ^ ) just after the character class\u2019s opening bracket, you can make a negative character class that will match all the characters that are not in the character class: >>> consonant_regex = re . compile ( r '[^aeiouAEIOU]' ) >>> consonant_regex . findall ( 'Robocop eats baby food. BABY FOOD.' ) # ['R', 'b', 'c', 'p', ' ', 't', 's', ' ', 'b', 'b', 'y', ' ', 'f', 'd', '.', ' # ', 'B', 'B', 'Y', ' ', 'F', 'D', '.']","title":"Making your own character classes"},{"location":"dev/python/regular-expressions/#the-caret-and-dollar-sign-characters","text":"You can also use the caret symbol ^ at the start of a regex to indicate that a match must occur at the beginning of the searched text. Likewise, you can put a dollar sign $ at the end of the regex to indicate the string must end with this regex pattern. And you can use the ^ and $ together to indicate that the entire string must match the regex. The r'^Hello ' regular expression string matches strings that begin with 'Hello': >>> begins_with_hello = re . compile ( r '^Hello' ) >>> begins_with_hello . search ( 'Hello world!' ) # <_sre.SRE_Match object; span=(0, 5), match='Hello'> >>> begins_with_hello . search ( 'He said hello.' ) is None # True The r'\\d\\$' regular expression string matches strings that end with a numeric character from 0 to 9: >>> whole_string_is_num = re . compile ( r '^\\d+$' ) >>> whole_string_is_num . search ( '1234567890' ) # <_sre.SRE_Match object; span=(0, 10), match='1234567890'> >>> whole_string_is_num . search ( '12345xyz67890' ) is None # True >>> whole_string_is_num . search ( '12 34567890' ) is None # True","title":"The Caret and Dollar sign characters"},{"location":"dev/python/regular-expressions/#the-wildcard-character","text":"The . (or dot) character in a regular expression will match any character except for a newline: >>> at_regex = re . compile ( r '.at' ) >>> at_regex . findall ( 'The cat in the hat sat on the flat mat.' ) [ 'cat' , 'hat' , 'sat' , 'lat' , 'mat' ]","title":"The Wildcard character"},{"location":"dev/python/regular-expressions/#matching-everything-with-dot-star","text":">>> name_regex = re . compile ( r 'First Name: (.*) Last Name: (.*)' ) >>> mo = name_regex . search ( 'First Name: Al Last Name: Sweigart' ) >>> mo . group ( 1 ) # 'Al' >>> mo . group ( 2 ) 'Sweigart' The .* uses greedy mode: It will always try to match as much text as possible. To match any and all text in a non-greedy fashion, use the dot, star, and question mark ( .*? ). The question mark tells Python to match in a non-greedy way: >>> non_greedy_regex = re . compile ( r '<.*?>' ) >>> mo = non_greedy_regex . search ( '<To serve man> for dinner.>' ) >>> mo . group () # '<To serve man>' >>> greedy_regex = re . compile ( r '<.*>' ) >>> mo = greedy_regex . search ( '<To serve man> for dinner.>' ) >>> mo . group () # '<To serve man> for dinner.>'","title":"Matching everything with Dot-Star"},{"location":"dev/python/regular-expressions/#matching-newlines-with-the-dot-character","text":"The dot-star will match everything except a newline. By passing re.DOTALL as the second argument to re.compile() , you can make the dot character match all characters, including the newline character: >>> no_newline_regex = re . compile ( '.*' ) >>> no_newline_regex . search ( 'Serve the public trust. \\n Protect the innocent. \\n Uphold the law.' ) . group () # 'Serve the public trust.' >>> newline_regex = re . compile ( '.*' , re . DOTALL ) >>> newline_regex . search ( 'Serve the public trust. \\n Protect the innocent. \\n Uphold the law.' ) . group () # 'Serve the public trust.\\nProtect the innocent.\\nUphold the law.'","title":"Matching newlines with the Dot character"},{"location":"dev/python/regular-expressions/#case-insensitive-matching","text":"To make your regex case-insensitive, you can pass re.IGNORECASE or re.I as a second argument to re.compile() : >>> robocop = re . compile ( r 'robocop' , re . I ) >>> robocop . search ( 'Robocop is part man, part machine, all cop.' ) . group () # 'Robocop' >>> robocop . search ( 'ROBOCOP protects the innocent.' ) . group () # 'ROBOCOP' >>> robocop . search ( 'Al, why does your programming book talk about robocop so much?' ) . group () # 'robocop'","title":"Case-Insensitive matching"},{"location":"dev/python/regular-expressions/#substituting-strings-with-the-sub-method","text":"The sub() method for Regex objects is passed two arguments: The first argument is a string to replace any matches. The second is the string for the regular expression. The sub() method returns a string with the substitutions applied: >>> names_regex = re . compile ( r 'Agent \\w+' ) >>> names_regex . sub ( 'CENSORED' , 'Agent Alice gave the secret documents to Agent Bob.' ) # 'CENSORED gave the secret documents to CENSORED.'","title":"Substituting strings with the sub() method"},{"location":"dev/python/regular-expressions/#managing-complex-regexes","text":"To tell the re.compile() function to ignore whitespace and comments inside the regular expression string, \u201cverbose mode\u201d can be enabled by passing the variable re.VERBOSE as the second argument to re.compile() . Now instead of a hard-to-read regular expression like this: phone_regex = re . compile ( r '((\\d {3} |\\(\\d {3} \\))?(\\s|-|\\.)?\\d {3} (\\s|-|\\.)\\d {4} (\\s*(ext|x|ext.)\\s*\\d{2,5})?)' ) you can spread the regular expression over multiple lines with comments like this: phone_regex = re . compile ( r '''( (\\d {3} |\\(\\d {3} \\))? # area code (\\s|-|\\.)? # separator \\d {3} # first 3 digits (\\s|-|\\.) # separator \\d {4} # last 4 digits (\\s*(ext|x|ext.)\\s*\\d{2,5})? # extension )''' , re . VERBOSE )","title":"Managing complex Regexes"},{"location":"dev/python/sets/","text":"Python Sets Python comes equipped with several built-in data types to help us organize our data. These structures include lists, dictionaries, tuples and sets . From the Python 3 documentation A set is an unordered collection with no duplicate elements. Basic uses include membership testing and eliminating duplicate entries. Read Python Sets: What, Why and How for a more in-deep reference. Initializing a set There are two ways to create sets: using curly braces {} and the built-in function set() Empty Sets When creating set, be sure to not use empty curly braces {} or you will get an empty dictionary instead. >>> s = { 1 , 2 , 3 } >>> s = set ([ 1 , 2 , 3 ]) >>> s = {} # this will create a dictionary instead of a set >>> type ( s ) # <class 'dict'> Unordered collections of unique elements A set automatically remove all the duplicate values. >>> s = { 1 , 2 , 3 , 2 , 3 , 4 } >>> s # {1, 2, 3, 4} And as an unordered data type, they can't be indexed. >>> s = { 1 , 2 , 3 } >>> s [ 0 ] # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # TypeError: 'set' object does not support indexing set add() and update() Using the add() method we can add a single element to the set. >>> s = { 1 , 2 , 3 } >>> s . add ( 4 ) >>> s # {1, 2, 3, 4} And with update() , multiple ones: >>> s = { 1 , 2 , 3 } >>> s . update ([ 2 , 3 , 4 , 5 , 6 ]) >>> s # {1, 2, 3, 4, 5, 6} set remove() and discard() Both methods will remove an element from the set, but remove() will raise a key error if the value doesn't exist. >>> s = { 1 , 2 , 3 } >>> s . remove ( 3 ) >>> s # {1, 2} >>> s . remove ( 3 ) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # KeyError: 3 discard() won't raise any errors. >>> s = { 1 , 2 , 3 } >>> s . discard ( 3 ) >>> s # {1, 2} >>> s . discard ( 3 ) set union() union() or | will create a new set that with all the elements from the sets provided. >>> s1 = { 1 , 2 , 3 } >>> s2 = { 3 , 4 , 5 } >>> s1 . union ( s2 ) # or 's1 | s2' # {1, 2, 3, 4, 5} set intersection intersection or & will return a set with only the elements that are common to all of them. >>> s1 = { 1 , 2 , 3 } >>> s2 = { 2 , 3 , 4 } >>> s3 = { 3 , 4 , 5 } >>> s1 . intersection ( s2 , s3 ) # or 's1 & s2 & s3' # {3} set difference difference or - will return only the elements that are unique to the first set (invoked set). >>> s1 = { 1 , 2 , 3 } >>> s2 = { 2 , 3 , 4 } >>> s1 . difference ( s2 ) # or 's1 - s2' # {1} >>> s2 . difference ( s1 ) # or 's2 - s1' # {4} set symetric_difference symetric_difference or ^ will return all the elements that are not common between them. >>> s1 = { 1 , 2 , 3 } >>> s2 = { 2 , 3 , 4 } >>> s1 . symmetric_difference ( s2 ) # or 's1 ^ s2' # {1, 4}","title":"Python Sets"},{"location":"dev/python/sets/#initializing-a-set","text":"There are two ways to create sets: using curly braces {} and the built-in function set() Empty Sets When creating set, be sure to not use empty curly braces {} or you will get an empty dictionary instead. >>> s = { 1 , 2 , 3 } >>> s = set ([ 1 , 2 , 3 ]) >>> s = {} # this will create a dictionary instead of a set >>> type ( s ) # <class 'dict'>","title":"Initializing a set"},{"location":"dev/python/sets/#unordered-collections-of-unique-elements","text":"A set automatically remove all the duplicate values. >>> s = { 1 , 2 , 3 , 2 , 3 , 4 } >>> s # {1, 2, 3, 4} And as an unordered data type, they can't be indexed. >>> s = { 1 , 2 , 3 } >>> s [ 0 ] # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # TypeError: 'set' object does not support indexing","title":"Unordered collections of unique elements"},{"location":"dev/python/sets/#set-add-and-update","text":"Using the add() method we can add a single element to the set. >>> s = { 1 , 2 , 3 } >>> s . add ( 4 ) >>> s # {1, 2, 3, 4} And with update() , multiple ones: >>> s = { 1 , 2 , 3 } >>> s . update ([ 2 , 3 , 4 , 5 , 6 ]) >>> s # {1, 2, 3, 4, 5, 6}","title":"set add() and update()"},{"location":"dev/python/sets/#set-remove-and-discard","text":"Both methods will remove an element from the set, but remove() will raise a key error if the value doesn't exist. >>> s = { 1 , 2 , 3 } >>> s . remove ( 3 ) >>> s # {1, 2} >>> s . remove ( 3 ) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # KeyError: 3 discard() won't raise any errors. >>> s = { 1 , 2 , 3 } >>> s . discard ( 3 ) >>> s # {1, 2} >>> s . discard ( 3 )","title":"set remove() and discard()"},{"location":"dev/python/sets/#set-union","text":"union() or | will create a new set that with all the elements from the sets provided. >>> s1 = { 1 , 2 , 3 } >>> s2 = { 3 , 4 , 5 } >>> s1 . union ( s2 ) # or 's1 | s2' # {1, 2, 3, 4, 5}","title":"set union()"},{"location":"dev/python/sets/#set-intersection","text":"intersection or & will return a set with only the elements that are common to all of them. >>> s1 = { 1 , 2 , 3 } >>> s2 = { 2 , 3 , 4 } >>> s3 = { 3 , 4 , 5 } >>> s1 . intersection ( s2 , s3 ) # or 's1 & s2 & s3' # {3}","title":"set intersection"},{"location":"dev/python/sets/#set-difference","text":"difference or - will return only the elements that are unique to the first set (invoked set). >>> s1 = { 1 , 2 , 3 } >>> s2 = { 2 , 3 , 4 } >>> s1 . difference ( s2 ) # or 's1 - s2' # {1} >>> s2 . difference ( s1 ) # or 's2 - s1' # {4}","title":"set difference"},{"location":"dev/python/sets/#set-symetric_difference","text":"symetric_difference or ^ will return all the elements that are not common between them. >>> s1 = { 1 , 2 , 3 } >>> s2 = { 2 , 3 , 4 } >>> s1 . symmetric_difference ( s2 ) # or 's1 ^ s2' # {1, 4}","title":"set symetric_difference"},{"location":"dev/python/setup-py/","text":"Python setup.py A 'controversial' opinion Using setup.py to pack and distribute your python packages can be quite challenging every so often. Tools like Poetry make not only the packaging a lot easier , but also help you to manage your dependencies in a very convenient way. If you want more information about Poetry you can read the following articles: Python projects with Poetry and VSCode. Part 1 Python projects with Poetry and VSCode. Part 2 Python projects with Poetry and VSCode. Part 3 Introduction The setup script is the center of all activity in building, distributing, and installing modules using the Distutils. The main purpose of the setup script is to describe your module distribution to the Distutils, so that the various commands that operate on your modules do the right thing. The setup.py file is at the heart of a Python project. It describes all the metadata about your project. There are quite a few fields you can add to a project to give it a rich set of metadata describing the project. However, there are only three required fields: name, version, and packages. The name field must be unique if you wish to publish your package on the Python Package Index (PyPI). The version field keeps track of different releases of the project. The package's field describes where you\u2019ve put the Python source code within your project. This allows you to easily install Python packages. Often it's enough to write: python setup.py install and module will install itself. Example Our initial setup.py will also include information about the license and will re-use the README.txt file for the long_description field. This will look like: from distutils.core import setup setup ( name = 'pythonCheatsheet' , version = '0.1' , packages = [ 'pipenv' ,], license = 'MIT' , long_description = open ( 'README.txt' ) . read (), ) Find more information visit the official documentation .","title":"Python Setup.py"},{"location":"dev/python/setup-py/#introduction","text":"The setup script is the center of all activity in building, distributing, and installing modules using the Distutils. The main purpose of the setup script is to describe your module distribution to the Distutils, so that the various commands that operate on your modules do the right thing. The setup.py file is at the heart of a Python project. It describes all the metadata about your project. There are quite a few fields you can add to a project to give it a rich set of metadata describing the project. However, there are only three required fields: name, version, and packages. The name field must be unique if you wish to publish your package on the Python Package Index (PyPI). The version field keeps track of different releases of the project. The package's field describes where you\u2019ve put the Python source code within your project. This allows you to easily install Python packages. Often it's enough to write: python setup.py install and module will install itself.","title":"Introduction"},{"location":"dev/python/setup-py/#example","text":"Our initial setup.py will also include information about the license and will re-use the README.txt file for the long_description field. This will look like: from distutils.core import setup setup ( name = 'pythonCheatsheet' , version = '0.1' , packages = [ 'pipenv' ,], license = 'MIT' , long_description = open ( 'README.txt' ) . read (), ) Find more information visit the official documentation .","title":"Example"},{"location":"dev/python/string-formatting/","text":"Python String Formatting From the Python 3 documentation The formatting operations described here ( % operator ) exhibit a variety of quirks that lead to a number of common errors [...]. Using the newer formatted string literals [...] helps avoid these errors. These alternatives also provide more powerful, flexible and extensible approaches to formatting text. % operator Prefer String Literals For new code, using str.format , or formatted string literals (Python 3.6+) over the % operator is strongly recommended. >>> name = 'Pete' >>> 'Hello %s ' % name # \"Hello Pete\" We can use the %d format specifier to convert an int value to a string: >>> num = 5 >>> 'I have %d apples' % num # \"I have 5 apples\" str.format Python 3 introduced a new way to do string formatting that was later back-ported to Python 2.7. This makes the syntax for string formatting more regular. >>> name = 'John' >>> age = 20 >>> \"Hello I'm {} , my age is {} \" . format ( name , age ) # \"Hello I'm John, my age is 20\" >>> \"Hello I'm {0} , my age is {1} \" . format ( name , age ) # \"Hello I'm John, my age is 20\" Formatted String Literals or f-Strings If your are using Python 3.6+, string f-Strings are the recommended way to format strings. From the Python 3 documentation A formatted string literal or f-string is a string literal that is prefixed with f or F . These strings may contain replacement fields, which are expressions delimited by curly braces {}. While other string literals always have a constant value, formatted strings are really expressions evaluated at run time. >>> name = 'Elizabeth' >>> f 'Hello { name } !' # 'Hello Elizabeth!' It is even possible to do inline arithmetic with it: >>> a = 5 >>> b = 10 >>> f 'Five plus ten is { a + b } and not { 2 * ( a + b ) } .' # 'Five plus ten is 15 and not 30.' Multiline f-Strings >>> name = 'Robert' >>> messages = 12 >>> ( ... f 'Hi, { name } . ' ... f 'You have { messages } unread messages' ... ) # 'Hi, Robert. You have 12 unread messages' The = specifier This will print the expression and its value: >>> from datetime import datetime >>> now = datetime . now () . strftime ( \"%b/ %d /%Y - %H:%M:%S\" ) >>> f 'date and time: { now =} ' # \"date and time: now='Nov/14/2022 - 20:50:01'\" Adding spaces or characters >>> f \" { name . upper () = : -^20 } \" # 'name.upper() = -------ROBERT-------' >>> >>> f \" { name . upper () = : ^20 } \" # 'name.upper() = ROBERT ' >>> >>> f \" { name . upper () = : 20 } \" # 'name.upper() = ROBERT ' Formatting Digits Adding thousands separator >>> a = 10000000 >>> f \" { a : , } \" # '10,000,000' Rounding >>> a = 3.1415926 >>> f \" { a : .2f } \" # '3.14' Showing as Percentage >>> a = 0.816562 >>> f \" { a : .2% } \" # '81.66%' Number formatting table Number Format Output description 3.1415926 {:.2f} 3.14 Format float 2 decimal places 3.1415926 {:+.2f} +3.14 Format float 2 decimal places with sign -1 {:+.2f} -1.00 Format float 2 decimal places with sign 2.71828 {:.0f} 3 Format float with no decimal places 4 {:0>2d} 04 Pad number with zeros (left padding, width 2) 4 {:x<4d} 4xxx Pad number with x\u2019s (right padding, width 4) 10 {:x<4d} 10xx Pad number with x\u2019s (right padding, width 4) 1000000 {:,} 1,000,000 Number format with comma separator 0.35 {:.2%} 35.00% Format percentage 1000000000 {:.2e} 1.00e+09 Exponent notation 11 {:11d} 11 Right-aligned (default, width 10) 11 {:<11d} 11 Left-aligned (width 10) 11 {:^11d} 11 Center aligned (width 10) Template Strings A simpler and less powerful mechanism, but it is recommended when handling strings generated by users. Due to their reduced complexity, template strings are a safer choice. >>> from string import Template >>> name = 'Elizabeth' >>> t = Template ( 'Hey $name!' ) >>> t . substitute ( name = name ) # 'Hey Elizabeth!'","title":"Python String Formatting"},{"location":"dev/python/string-formatting/#operator","text":"Prefer String Literals For new code, using str.format , or formatted string literals (Python 3.6+) over the % operator is strongly recommended. >>> name = 'Pete' >>> 'Hello %s ' % name # \"Hello Pete\" We can use the %d format specifier to convert an int value to a string: >>> num = 5 >>> 'I have %d apples' % num # \"I have 5 apples\"","title":"% operator"},{"location":"dev/python/string-formatting/#strformat","text":"Python 3 introduced a new way to do string formatting that was later back-ported to Python 2.7. This makes the syntax for string formatting more regular. >>> name = 'John' >>> age = 20 >>> \"Hello I'm {} , my age is {} \" . format ( name , age ) # \"Hello I'm John, my age is 20\" >>> \"Hello I'm {0} , my age is {1} \" . format ( name , age ) # \"Hello I'm John, my age is 20\"","title":"str.format"},{"location":"dev/python/string-formatting/#formatted-string-literals-or-f-strings","text":"If your are using Python 3.6+, string f-Strings are the recommended way to format strings. From the Python 3 documentation A formatted string literal or f-string is a string literal that is prefixed with f or F . These strings may contain replacement fields, which are expressions delimited by curly braces {}. While other string literals always have a constant value, formatted strings are really expressions evaluated at run time. >>> name = 'Elizabeth' >>> f 'Hello { name } !' # 'Hello Elizabeth!' It is even possible to do inline arithmetic with it: >>> a = 5 >>> b = 10 >>> f 'Five plus ten is { a + b } and not { 2 * ( a + b ) } .' # 'Five plus ten is 15 and not 30.'","title":"Formatted String Literals or f-Strings"},{"location":"dev/python/string-formatting/#multiline-f-strings","text":">>> name = 'Robert' >>> messages = 12 >>> ( ... f 'Hi, { name } . ' ... f 'You have { messages } unread messages' ... ) # 'Hi, Robert. You have 12 unread messages'","title":"Multiline f-Strings"},{"location":"dev/python/string-formatting/#the-specifier","text":"This will print the expression and its value: >>> from datetime import datetime >>> now = datetime . now () . strftime ( \"%b/ %d /%Y - %H:%M:%S\" ) >>> f 'date and time: { now =} ' # \"date and time: now='Nov/14/2022 - 20:50:01'\"","title":"The = specifier"},{"location":"dev/python/string-formatting/#adding-spaces-or-characters","text":">>> f \" { name . upper () = : -^20 } \" # 'name.upper() = -------ROBERT-------' >>> >>> f \" { name . upper () = : ^20 } \" # 'name.upper() = ROBERT ' >>> >>> f \" { name . upper () = : 20 } \" # 'name.upper() = ROBERT '","title":"Adding spaces or characters"},{"location":"dev/python/string-formatting/#formatting-digits","text":"Adding thousands separator >>> a = 10000000 >>> f \" { a : , } \" # '10,000,000' Rounding >>> a = 3.1415926 >>> f \" { a : .2f } \" # '3.14' Showing as Percentage >>> a = 0.816562 >>> f \" { a : .2% } \" # '81.66%'","title":"Formatting Digits"},{"location":"dev/python/string-formatting/#number-formatting-table","text":"Number Format Output description 3.1415926 {:.2f} 3.14 Format float 2 decimal places 3.1415926 {:+.2f} +3.14 Format float 2 decimal places with sign -1 {:+.2f} -1.00 Format float 2 decimal places with sign 2.71828 {:.0f} 3 Format float with no decimal places 4 {:0>2d} 04 Pad number with zeros (left padding, width 2) 4 {:x<4d} 4xxx Pad number with x\u2019s (right padding, width 4) 10 {:x<4d} 10xx Pad number with x\u2019s (right padding, width 4) 1000000 {:,} 1,000,000 Number format with comma separator 0.35 {:.2%} 35.00% Format percentage 1000000000 {:.2e} 1.00e+09 Exponent notation 11 {:11d} 11 Right-aligned (default, width 10) 11 {:<11d} 11 Left-aligned (width 10) 11 {:^11d} 11 Center aligned (width 10)","title":"Number formatting table"},{"location":"dev/python/string-formatting/#template-strings","text":"A simpler and less powerful mechanism, but it is recommended when handling strings generated by users. Due to their reduced complexity, template strings are a safer choice. >>> from string import Template >>> name = 'Elizabeth' >>> t = Template ( 'Hey $name!' ) >>> t . substitute ( name = name ) # 'Hey Elizabeth!'","title":"Template Strings"},{"location":"dev/python/virtual-environments/","text":"Virtual Environment The use of a Virtual Environment is to test python code in encapsulated environments, and to also avoid filling the base Python installation with libraries we might use for only one project. virtualenv Install virtualenv pip install virtualenv Install virtualenvwrapper-win (Windows) pip install virtualenvwrapper-win Usage: Make a Virtual Environment named HelloWorld mkvirtualenv HelloWorld Anything we install now will be specific to this project. And available to the projects we connect to this environment. Set Project Directory To bind our virtualenv with our current working directory we simply enter: setprojectdir . Deactivate To move onto something else in the command line type deactivate to deactivate your environment. deactivate Notice how the parenthesis disappear. Workon Open up the command prompt and type workon HelloWorld to activate the environment and move into your root project folder workon HelloWorld Poetry From Poetry website Poetry is a tool for dependency management and packaging in Python. It allows you to declare the libraries your project depends on and it will manage (install/update) them for you. Install Poetry pip install --user poetry Create a new project poetry new my-project This will create a my-project directory: my-project \u251c\u2500\u2500 pyproject.toml \u251c\u2500\u2500 README.rst \u251c\u2500\u2500 poetry_demo \u2502 \u2514\u2500\u2500 __init__.py \u2514\u2500\u2500 tests \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 test_poetry_demo.py The pyproject.toml file will orchestrate your project and its dependencies: [tool.poetry] name = \"my-project\" version = \"0.1.0\" description = \"\" authors = [\"your name <your@mail.com>\"] [tool.poetry.dependencies] python = \"*\" [tool.poetry.dev-dependencies] pytest = \"^3.4\" Packages To add dependencies to your project, you can specify them in the tool.poetry.dependencies section: [tool.poetry.dependencies] pendulum = \"^1.4\" Also, instead of modifying the pyproject.toml file by hand, you can use the add command and it will automatically find a suitable version constraint. $ poetry add pendulum To install the dependencies listed in the pyproject.toml: poetry install To remove dependencies: poetry remove pendulum For more information, check the documentation or read here: Python projects with Poetry and VSCode. Part 1 Python projects with Poetry and VSCode. Part 2 Python projects with Poetry and VSCode. Part 3 Pipenv From Pipenv website Pipenv is a tool that aims to bring the best of all packaging worlds (bundler, composer, npm, cargo, yarn, etc.) to the Python world. Windows is a first-class citizen, in our world. Install pipenv pip install pipenv Enter your Project directory and install the Packages for your project cd my_project pipenv install <package> Pipenv will install your package and create a Pipfile for you in your project\u2019s directory. The Pipfile is used to track which dependencies your project needs in case you need to re-install them. Uninstall Packages pipenv uninstall <package> Activate the Virtual Environment associated with your Python project pipenv shell Exit the Virtual Environment exit Find more information and a video in docs.pipenv.org . Anaconda Anaconda is another popular tool to manage python packages. Where packages, notebooks, projects and environments are shared. Your place for free public conda package hosting. Usage: Make a Virtual Environment conda create -n HelloWorld To use the Virtual Environment, activate it by: conda activate HelloWorld Anything installed now will be specific to the project HelloWorld Exit the Virtual Environment conda deactivate","title":"Python Virtual environments"},{"location":"dev/python/virtual-environments/#virtualenv","text":"Install virtualenv pip install virtualenv Install virtualenvwrapper-win (Windows) pip install virtualenvwrapper-win Usage: Make a Virtual Environment named HelloWorld mkvirtualenv HelloWorld Anything we install now will be specific to this project. And available to the projects we connect to this environment. Set Project Directory To bind our virtualenv with our current working directory we simply enter: setprojectdir . Deactivate To move onto something else in the command line type deactivate to deactivate your environment. deactivate Notice how the parenthesis disappear. Workon Open up the command prompt and type workon HelloWorld to activate the environment and move into your root project folder workon HelloWorld","title":"virtualenv"},{"location":"dev/python/virtual-environments/#poetry","text":"From Poetry website Poetry is a tool for dependency management and packaging in Python. It allows you to declare the libraries your project depends on and it will manage (install/update) them for you. Install Poetry pip install --user poetry Create a new project poetry new my-project This will create a my-project directory: my-project \u251c\u2500\u2500 pyproject.toml \u251c\u2500\u2500 README.rst \u251c\u2500\u2500 poetry_demo \u2502 \u2514\u2500\u2500 __init__.py \u2514\u2500\u2500 tests \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 test_poetry_demo.py The pyproject.toml file will orchestrate your project and its dependencies: [tool.poetry] name = \"my-project\" version = \"0.1.0\" description = \"\" authors = [\"your name <your@mail.com>\"] [tool.poetry.dependencies] python = \"*\" [tool.poetry.dev-dependencies] pytest = \"^3.4\" Packages To add dependencies to your project, you can specify them in the tool.poetry.dependencies section: [tool.poetry.dependencies] pendulum = \"^1.4\" Also, instead of modifying the pyproject.toml file by hand, you can use the add command and it will automatically find a suitable version constraint. $ poetry add pendulum To install the dependencies listed in the pyproject.toml: poetry install To remove dependencies: poetry remove pendulum For more information, check the documentation or read here: Python projects with Poetry and VSCode. Part 1 Python projects with Poetry and VSCode. Part 2 Python projects with Poetry and VSCode. Part 3","title":"Poetry"},{"location":"dev/python/virtual-environments/#pipenv","text":"From Pipenv website Pipenv is a tool that aims to bring the best of all packaging worlds (bundler, composer, npm, cargo, yarn, etc.) to the Python world. Windows is a first-class citizen, in our world. Install pipenv pip install pipenv Enter your Project directory and install the Packages for your project cd my_project pipenv install <package> Pipenv will install your package and create a Pipfile for you in your project\u2019s directory. The Pipfile is used to track which dependencies your project needs in case you need to re-install them. Uninstall Packages pipenv uninstall <package> Activate the Virtual Environment associated with your Python project pipenv shell Exit the Virtual Environment exit Find more information and a video in docs.pipenv.org .","title":"Pipenv"},{"location":"dev/python/virtual-environments/#anaconda","text":"Anaconda is another popular tool to manage python packages. Where packages, notebooks, projects and environments are shared. Your place for free public conda package hosting. Usage: Make a Virtual Environment conda create -n HelloWorld To use the Virtual Environment, activate it by: conda activate HelloWorld Anything installed now will be specific to the project HelloWorld Exit the Virtual Environment conda deactivate","title":"Anaconda"},{"location":"linux/account/","text":"Account List account : find /home -maxdepth 1 -type d -group users | cut -d '/' -f3 Useradd How to adding user ? useradd -s /sbin/nologin -G $GRP useradd -m -G wheel -s /bin/bash $account Lock / Unlock Check password status : passwd -S $USER Status list : LK: Password locked NP: No password PS: Password set Unlock Use the -u to unlock account: passwd -u $USER Lock Use the -L to lock account: passwd -L $USER Time life password Show the account password information: chage -l $USER Set minimum day: chage -m ${ NOMBER OF DAY } ${ USER } Sudoers Autorisation de l\u2019utilisateur max de supprimer dans le dossier. max ALL = NOPASSWD:/bin/rm -rf $CHEMIN_de_DOSSIER /* Autorisation pour l\u2019utilisateur matry_mc_fly de lire les fichiers dans le dossier. marty_mc_fly ALL = NOPASSWD:/usr/bin/cat /var/log/mariadb/* Last connection Check last user connection : last -15 -aFw For DEB packages only : cat /var/log/auth.log","title":"Account"},{"location":"linux/account/#account","text":"List account : find /home -maxdepth 1 -type d -group users | cut -d '/' -f3","title":"Account"},{"location":"linux/account/#useradd","text":"How to adding user ? useradd -s /sbin/nologin -G $GRP useradd -m -G wheel -s /bin/bash $account","title":"Useradd"},{"location":"linux/account/#lock-unlock","text":"Check password status : passwd -S $USER Status list : LK: Password locked NP: No password PS: Password set","title":"Lock / Unlock"},{"location":"linux/account/#unlock","text":"Use the -u to unlock account: passwd -u $USER","title":"Unlock"},{"location":"linux/account/#lock","text":"Use the -L to lock account: passwd -L $USER","title":"Lock"},{"location":"linux/account/#time-life-password","text":"Show the account password information: chage -l $USER Set minimum day: chage -m ${ NOMBER OF DAY } ${ USER }","title":"Time life password"},{"location":"linux/account/#sudoers","text":"Autorisation de l\u2019utilisateur max de supprimer dans le dossier. max ALL = NOPASSWD:/bin/rm -rf $CHEMIN_de_DOSSIER /* Autorisation pour l\u2019utilisateur matry_mc_fly de lire les fichiers dans le dossier. marty_mc_fly ALL = NOPASSWD:/usr/bin/cat /var/log/mariadb/*","title":"Sudoers"},{"location":"linux/account/#last-connection","text":"Check last user connection : last -15 -aFw For DEB packages only : cat /var/log/auth.log","title":"Last connection"},{"location":"linux/apps/","text":"Apps bpytop How to isntall bpytop based on APT : apt install python3-pip pip3 install psutil pip3 install bpytop","title":"Apps"},{"location":"linux/apps/#apps","text":"","title":"Apps"},{"location":"linux/apps/#bpytop","text":"How to isntall bpytop based on APT : apt install python3-pip pip3 install psutil pip3 install bpytop","title":"bpytop"},{"location":"linux/cron/","text":"cron A CRON expression is simply a string consisting of six fields that each define a specific unit of time. They are written in the following format: { second } { minute } { hour } { day } { month } { day of the week } Values The following values are allowed within each date/time unit placeholder. Field Allowed Values Description {second} 0-59 Trigger every {second} second(s) {minute} 0-59 Trigger every {minute} minute(s) {hour} 0-23 Trigger every {hour} hour(s) {day} 1-31 Trigger every {day} day(s) of month {month} 1-12 Trigger every {month} month(s) {day of week} 0-6 MON-SUN Trigger on specific {day of week} Special Characters Additionally you can also use the following special characters to build more advanced expressions: Special Character Description * Trigger on tick of every time unit , List separator \u2013 Specifies a range / Defines an increment Examples Scheduel Description 0 * * * * * Executes every minute 0 0 * * * * Executes every hour 0 0 0 * * * Executes every day 0 0 0 0 * * Executes every month 0 0 0 1 1 * Executes on first day of Jan each year 30 20 * * SAT Executes at 08:30pm every Saturday 30 20 * * 6 Executes at 08:30pm every Saturday 0 */5 * * * * Executes every five minutes 0 0 8-10/1 * * * Executes every hour between 8am and 10am","title":"cron"},{"location":"linux/cron/#cron","text":"A CRON expression is simply a string consisting of six fields that each define a specific unit of time. They are written in the following format: { second } { minute } { hour } { day } { month } { day of the week }","title":"cron"},{"location":"linux/cron/#values","text":"The following values are allowed within each date/time unit placeholder. Field Allowed Values Description {second} 0-59 Trigger every {second} second(s) {minute} 0-59 Trigger every {minute} minute(s) {hour} 0-23 Trigger every {hour} hour(s) {day} 1-31 Trigger every {day} day(s) of month {month} 1-12 Trigger every {month} month(s) {day of week} 0-6 MON-SUN Trigger on specific {day of week}","title":"Values"},{"location":"linux/cron/#special-characters","text":"Additionally you can also use the following special characters to build more advanced expressions: Special Character Description * Trigger on tick of every time unit , List separator \u2013 Specifies a range / Defines an increment","title":"Special Characters"},{"location":"linux/cron/#examples","text":"Scheduel Description 0 * * * * * Executes every minute 0 0 * * * * Executes every hour 0 0 0 * * * Executes every day 0 0 0 0 * * Executes every month 0 0 0 1 1 * Executes on first day of Jan each year 30 20 * * SAT Executes at 08:30pm every Saturday 30 20 * * 6 Executes at 08:30pm every Saturday 0 */5 * * * * Executes every five minutes 0 0 8-10/1 * * * Executes every hour between 8am and 10am","title":"Examples"},{"location":"linux/desktop/","text":"Desktop Desktop Environement Here are somes Desktop Environement tips & tricks Gnome Ajouter une application dans gnom shell Ajouter un fichier .desktop dans /usr/share/appliations/MONAPPLI.desktop : [ Desktop Entry ] Name = MonAppli Comment = Descritpion de l ' appli Exec = MonAppli.sh %U Icon = /usr/share/icons/monappli.svg Terminal = false Type = Application Encoding = UTF-8 Categories = Network ; Application Modifier une application \u00e9xistante Trouver le fichier de l'application choisie, ici VirtualBox Un soucis connu sur Gnome et virtualbox est que l'interface soit broken. On vient alors corrig\u00e9 ceci en changeant le style de celui-ci via la commande : VirtualBox -style Adwaita On vient alors modifier le fichier /usr/share/applications/virtualbox.desktop On remplace la ligne 10 Exec=VirtualBox %U par Exec=VirtualBox -style Adwaita . Desktop Manager Lightdm Autologin Editer le fichier de configuration suivant : /etc/lightdm/lightdm.conf Compl\u00e9ter les informations attendues : autologin-user = jdoe","title":"Desktop"},{"location":"linux/desktop/#desktop","text":"","title":"Desktop"},{"location":"linux/desktop/#desktop-environement","text":"Here are somes Desktop Environement tips & tricks","title":"Desktop Environement"},{"location":"linux/desktop/#gnome","text":"","title":"Gnome"},{"location":"linux/desktop/#ajouter-une-application-dans-gnom-shell","text":"Ajouter un fichier .desktop dans /usr/share/appliations/MONAPPLI.desktop : [ Desktop Entry ] Name = MonAppli Comment = Descritpion de l ' appli Exec = MonAppli.sh %U Icon = /usr/share/icons/monappli.svg Terminal = false Type = Application Encoding = UTF-8 Categories = Network ; Application","title":"Ajouter une application dans gnom shell"},{"location":"linux/desktop/#modifier-une-application-existante","text":"Trouver le fichier de l'application choisie, ici VirtualBox Un soucis connu sur Gnome et virtualbox est que l'interface soit broken. On vient alors corrig\u00e9 ceci en changeant le style de celui-ci via la commande : VirtualBox -style Adwaita On vient alors modifier le fichier /usr/share/applications/virtualbox.desktop On remplace la ligne 10 Exec=VirtualBox %U par Exec=VirtualBox -style Adwaita .","title":"Modifier une application \u00e9xistante"},{"location":"linux/desktop/#desktop-manager","text":"","title":"Desktop Manager"},{"location":"linux/desktop/#lightdm","text":"","title":"Lightdm"},{"location":"linux/desktop/#autologin","text":"Editer le fichier de configuration suivant : /etc/lightdm/lightdm.conf Compl\u00e9ter les informations attendues : autologin-user = jdoe","title":"Autologin"},{"location":"linux/disk/","text":"Storage Compressed files Voici le d\u00e9tail des options : c : cr\u00e9e un archive. z : compresse l\u2019archive avec gzip. v : mode verbeux, affiche la progression. f : permet de sp\u00e9cifier le nom du fichier d\u2019archive. Compresser Compresser des fichiers : tar -czvf nom-de-l-archive.tar.gz /chemin/vers/r\u00e9pertoire-ou-fichier D\u00e9compresser Pour d\u00e9compresser le rar avec son passwd : rar x -hP { MOT DE PASSE } { FICHIER.RAR } rar x -hPTEST test2.rar DD dd n\u00e9cessite de droits super utilisateur : sudo dd bs = 4M if = $chemin /fichier.iso of = /dev/ $disk && sync Create 1 file heavy as 1G dd if = /dev/urandom of = tempfile bs = 1M count = 1024 LVM - Logical Volume Manager Extend partition fdisk dev/sdX echo 1 > /sys/block/sdX/device/rescan pvresize /dev/sdX2 Make FS XFS mkfs.xfs -d su = 64k,sw = 4 /dev/mapper/ EXT4 mkfs.ext4 -L Label /dev/block_device Scan Disk Rescan disk echo 1 > /sys/class/scsi_disk/1 \\[ :TAB: ] /device/rescan Extend volumes lvextend -L+<<>>G /dev/mapper/VOLUME Apply modifications resize2fs /dev/mapper/VOLUME Reducing an LVM2 Swap Logical Volume Disable swapping for the associated logical volume: swapoff -v /dev/VolGroup00/LogVol01 Reduce the LVM2 logical volume by 512 MB: lvreduce /dev/VolGroup00/LogVol01 -L -512M Format the new swap space: mkswap /dev/VolGroup00/LogVol01 Activate swap on the logical volume: swapon -v /dev/VolGroup00/LogVol01 To test if the swap logical volume was successfully reduced, inspect active swap space: cat /proc/swaps Label Block Device e4label <block_device> new-label","title":"Storage"},{"location":"linux/disk/#storage","text":"","title":"Storage"},{"location":"linux/disk/#compressed-files","text":"Voici le d\u00e9tail des options : c : cr\u00e9e un archive. z : compresse l\u2019archive avec gzip. v : mode verbeux, affiche la progression. f : permet de sp\u00e9cifier le nom du fichier d\u2019archive.","title":"Compressed files"},{"location":"linux/disk/#compresser","text":"Compresser des fichiers : tar -czvf nom-de-l-archive.tar.gz /chemin/vers/r\u00e9pertoire-ou-fichier","title":"Compresser"},{"location":"linux/disk/#decompresser","text":"Pour d\u00e9compresser le rar avec son passwd : rar x -hP { MOT DE PASSE } { FICHIER.RAR } rar x -hPTEST test2.rar","title":"D\u00e9compresser"},{"location":"linux/disk/#dd","text":"dd n\u00e9cessite de droits super utilisateur : sudo dd bs = 4M if = $chemin /fichier.iso of = /dev/ $disk && sync","title":"DD"},{"location":"linux/disk/#create-1-file-heavy-as-1g","text":"dd if = /dev/urandom of = tempfile bs = 1M count = 1024","title":"Create 1 file heavy as 1G"},{"location":"linux/disk/#lvm-logical-volume-manager","text":"","title":"LVM - Logical Volume Manager"},{"location":"linux/disk/#extend-partition","text":"fdisk dev/sdX echo 1 > /sys/block/sdX/device/rescan pvresize /dev/sdX2","title":"Extend partition"},{"location":"linux/disk/#make-fs","text":"","title":"Make FS"},{"location":"linux/disk/#xfs","text":"mkfs.xfs -d su = 64k,sw = 4 /dev/mapper/","title":"XFS"},{"location":"linux/disk/#ext4","text":"mkfs.ext4 -L Label /dev/block_device","title":"EXT4"},{"location":"linux/disk/#scan-disk","text":"Rescan disk echo 1 > /sys/class/scsi_disk/1 \\[ :TAB: ] /device/rescan","title":"Scan Disk"},{"location":"linux/disk/#extend-volumes","text":"lvextend -L+<<>>G /dev/mapper/VOLUME","title":"Extend volumes"},{"location":"linux/disk/#apply-modifications","text":"resize2fs /dev/mapper/VOLUME","title":"Apply modifications"},{"location":"linux/disk/#reducing-an-lvm2-swap-logical-volume","text":"Disable swapping for the associated logical volume: swapoff -v /dev/VolGroup00/LogVol01 Reduce the LVM2 logical volume by 512 MB: lvreduce /dev/VolGroup00/LogVol01 -L -512M Format the new swap space: mkswap /dev/VolGroup00/LogVol01 Activate swap on the logical volume: swapon -v /dev/VolGroup00/LogVol01 To test if the swap logical volume was successfully reduced, inspect active swap space: cat /proc/swaps","title":"Reducing an LVM2 Swap Logical Volume"},{"location":"linux/disk/#label-block-device","text":"e4label <block_device> new-label","title":"Label Block Device"},{"location":"linux/exit-codes/","text":"Exit codes Contient le nom du script tel qu'il a \u00e9t\u00e9 invoqu\u00e9: $0 L'ensembles des param\u00e8tres sous la forme d'un seul argument: $* L'ensemble des arguments, un argument par param\u00e8tre: $@ Le nombre de param\u00e8tres pass\u00e9s au script: $# Le code retour de la derni\u00e8re commande: $? Le PID su shell qui ex\u00e9cute le script: $$ Le PID du dernier processus lanc\u00e9 en arri\u00e8re-plan: $!","title":"Exit codes"},{"location":"linux/exit-codes/#exit-codes","text":"Contient le nom du script tel qu'il a \u00e9t\u00e9 invoqu\u00e9: $0 L'ensembles des param\u00e8tres sous la forme d'un seul argument: $* L'ensemble des arguments, un argument par param\u00e8tre: $@ Le nombre de param\u00e8tres pass\u00e9s au script: $# Le code retour de la derni\u00e8re commande: $? Le PID su shell qui ex\u00e9cute le script: $$ Le PID du dernier processus lanc\u00e9 en arri\u00e8re-plan: $!","title":"Exit codes"},{"location":"linux/firewalld/","text":"Firewall Default Configuration of Firewalld Zones Zone name Default configuration trusted Allow all incoming traffic. home Reject incoming traffic unless related to outgoing traffic or matching the ssh, mdns, ipp-client, samba-client, or dhcpv6-client pre-defined services. internal Reject incoming traffic unless related to outgoing traffic or matching the ssh, mdns, ipp-client, samba-client, or dhcpv6-client pre-defined services (same as the home zone to start with). work Reject incoming traffic unless related to outgoing traffic or matching the ssh, ipp-client, or dhcpv6-client pre-defined services. public Reject incoming traffic unless related to outgoing traffic or matching the ssh or dhcpv6-client pre-defined services. The default zone for newly added network interfaces. external Reject incoming traffic unless related to outgoing traffic or matching the ssh pre-defined service. Outgoing IPv4 traffic forwarded through this zone is masqueraded to look like it originated from the IPv4 address of the outgoing network interface. dmz Reject incoming traffic unless related to outgoing traffic or matching the ssh pre-defined service. block Reject all incoming traffic unless related to outgoing traffic. drop Drop all incoming traffic unless related to outgoing traffic (do not even respond with ICMP errors). For a list of available pre-defined zones and intended use, see firewalld.zones(5). Configuring the Firewall from the Command Line The firewall-cmd command interacts with the firewalld dynamic firewall manager. It is installed as part of the main firewalld package and is available for administrators who prefer to work on the command line, for working on systems without a graphical environment, or for scripting a firewall setup. The following table lists a number of frequently used firewall-cmd commands, along with an explanation. Note that unless otherwise specified, almost all commands will work on the runtime configuration, unless the --permanent option is specified. If the --permanent option is specified, you must activate the setting by also running the firewall-cmd --reload command, which reads the current permanent configuration and applies it as the new runtime configuration. Many of the commands listed take the --zone=ZONE option to determine which zone they affect. Where a netmask is required, use CIDR notation, such as 192.168.1/24. firewall-cmd commands Explanation --get-default-zone Query the current default zone. --set-default-zone=ZONE Set the default zone. This changes both the runtime and the permanent configuration. --get-zones List all available zones. --get-active-zones List all zones currently in use (have an interface or source tied to them), along with their interface and source information. --add-source=CIDR [--zone=ZONE] Route all traffic coming from the IP address or network/netmask to the specified zone. If no --zone= option is provided, the default zone is used. --remove-source=CIDR [--zone=ZONE] Remove the rule routing all traffic from the zone coming from the IP address or network/netmask network. If no --zone= option is provided, the default zone is used. --add-interface=INTERFACE [--zone=ZONE] Route all traffic coming from INTERFACE to the specified zone. If no --zone= option is provided, the default zone is used. --change-interface=INTERFACE [--zone=ZONE] Associate the interface with ZONE instead of its current zone. If no --zone= option is provided, the default zone is used. --list-all [--zone=ZONE] List all configured interfaces, sources, services, and ports for ZONE. If no --zone= option is provided, the default zone is used. --list-all-zones Retrieve all information for all zones (interfaces, sources, ports, services). --add-service=SERVICE [--zone=ZONE] Allow traffic to SERVICE. If no --zone= option is provided, the default zone is used. --add-port=PORT/PROTOCOL [--zone=ZONE] Allow traffic to the PORT/PROTOCOL port(s). If no --zone= option is provided, the default zone is used. --remove-service=SERVICE [--zone=ZONE] Remove SERVICE from the allowed list for the zone. If no --zone= option is provided, the default zone is used. --remove-port=PORT/PROTOCOL [--zone=ZONE] Remove the PORT/PROTOCOL port(s) from the allowed list for the zone. If no --zone= option is provided, the default zone is used. --reload Drop the runtime configuration and apply the persistent configuration. The example commands below set the default zone to dmz, assign all traffic coming from the 192.168.0.0/24 network to the internal zone, and open the network ports for the mysql service on the internal zone. [ root@host ~ ] # firewall-cmd --set-default-zone=dmz [ root@host ~ ] # firewall-cmd --permanent --zone=internal --add-source=192.168.0.0/24 [ root@host ~ ] # firewall-cmd --permanent --zone=internal --add-service=mysql [ root@host ~ ] # firewall-cmd --reload","title":"Firewall"},{"location":"linux/firewalld/#firewall","text":"","title":"Firewall"},{"location":"linux/firewalld/#default-configuration-of-firewalld-zones","text":"Zone name Default configuration trusted Allow all incoming traffic. home Reject incoming traffic unless related to outgoing traffic or matching the ssh, mdns, ipp-client, samba-client, or dhcpv6-client pre-defined services. internal Reject incoming traffic unless related to outgoing traffic or matching the ssh, mdns, ipp-client, samba-client, or dhcpv6-client pre-defined services (same as the home zone to start with). work Reject incoming traffic unless related to outgoing traffic or matching the ssh, ipp-client, or dhcpv6-client pre-defined services. public Reject incoming traffic unless related to outgoing traffic or matching the ssh or dhcpv6-client pre-defined services. The default zone for newly added network interfaces. external Reject incoming traffic unless related to outgoing traffic or matching the ssh pre-defined service. Outgoing IPv4 traffic forwarded through this zone is masqueraded to look like it originated from the IPv4 address of the outgoing network interface. dmz Reject incoming traffic unless related to outgoing traffic or matching the ssh pre-defined service. block Reject all incoming traffic unless related to outgoing traffic. drop Drop all incoming traffic unless related to outgoing traffic (do not even respond with ICMP errors). For a list of available pre-defined zones and intended use, see firewalld.zones(5).","title":"Default Configuration of Firewalld Zones"},{"location":"linux/firewalld/#configuring-the-firewall-from-the-command-line","text":"The firewall-cmd command interacts with the firewalld dynamic firewall manager. It is installed as part of the main firewalld package and is available for administrators who prefer to work on the command line, for working on systems without a graphical environment, or for scripting a firewall setup. The following table lists a number of frequently used firewall-cmd commands, along with an explanation. Note that unless otherwise specified, almost all commands will work on the runtime configuration, unless the --permanent option is specified. If the --permanent option is specified, you must activate the setting by also running the firewall-cmd --reload command, which reads the current permanent configuration and applies it as the new runtime configuration. Many of the commands listed take the --zone=ZONE option to determine which zone they affect. Where a netmask is required, use CIDR notation, such as 192.168.1/24. firewall-cmd commands Explanation --get-default-zone Query the current default zone. --set-default-zone=ZONE Set the default zone. This changes both the runtime and the permanent configuration. --get-zones List all available zones. --get-active-zones List all zones currently in use (have an interface or source tied to them), along with their interface and source information. --add-source=CIDR [--zone=ZONE] Route all traffic coming from the IP address or network/netmask to the specified zone. If no --zone= option is provided, the default zone is used. --remove-source=CIDR [--zone=ZONE] Remove the rule routing all traffic from the zone coming from the IP address or network/netmask network. If no --zone= option is provided, the default zone is used. --add-interface=INTERFACE [--zone=ZONE] Route all traffic coming from INTERFACE to the specified zone. If no --zone= option is provided, the default zone is used. --change-interface=INTERFACE [--zone=ZONE] Associate the interface with ZONE instead of its current zone. If no --zone= option is provided, the default zone is used. --list-all [--zone=ZONE] List all configured interfaces, sources, services, and ports for ZONE. If no --zone= option is provided, the default zone is used. --list-all-zones Retrieve all information for all zones (interfaces, sources, ports, services). --add-service=SERVICE [--zone=ZONE] Allow traffic to SERVICE. If no --zone= option is provided, the default zone is used. --add-port=PORT/PROTOCOL [--zone=ZONE] Allow traffic to the PORT/PROTOCOL port(s). If no --zone= option is provided, the default zone is used. --remove-service=SERVICE [--zone=ZONE] Remove SERVICE from the allowed list for the zone. If no --zone= option is provided, the default zone is used. --remove-port=PORT/PROTOCOL [--zone=ZONE] Remove the PORT/PROTOCOL port(s) from the allowed list for the zone. If no --zone= option is provided, the default zone is used. --reload Drop the runtime configuration and apply the persistent configuration. The example commands below set the default zone to dmz, assign all traffic coming from the 192.168.0.0/24 network to the internal zone, and open the network ports for the mysql service on the internal zone. [ root@host ~ ] # firewall-cmd --set-default-zone=dmz [ root@host ~ ] # firewall-cmd --permanent --zone=internal --add-source=192.168.0.0/24 [ root@host ~ ] # firewall-cmd --permanent --zone=internal --add-service=mysql [ root@host ~ ] # firewall-cmd --reload","title":"Configuring the Firewall from the Command Line"},{"location":"linux/fstab/","text":"Filesystem table AKA fstab It is a set of rules used to control how different filesystems are treated each time they are introduced to a system. Structure The table itself is a 6 column structure, where each column designates a specific parameter and must be set up in the correct order. The columns of the table are as follows from left to right # <file system> <mount point> <type> <options> <dump> <pass> Device Usually the given name or UUID of the mounted device (sda1/sda2/etc). Mount Point: designates the directory where the device is/will be mounted. File System Type Nothing trick here, shows the type of filesystem in use. Options Lists any active mount options. If using multiple options they must be separated by commas. Backup Operation (the first digit) This is a binary system where 1 = dump utility backup of a partition. 0 = no backup. This is an outdated backup method and should NOT be used. File System Check Order (second digit) Here we can see three possible outcomes. 0 means that fsck will not check the filesystem. > Numbers higher than this represent the check order. The root filesystem should be set to 1 and other partitions set to 2.","title":"Filesystem table AKA fstab"},{"location":"linux/fstab/#filesystem-table-aka-fstab","text":"It is a set of rules used to control how different filesystems are treated each time they are introduced to a system.","title":"Filesystem table AKA fstab"},{"location":"linux/fstab/#structure","text":"The table itself is a 6 column structure, where each column designates a specific parameter and must be set up in the correct order. The columns of the table are as follows from left to right # <file system> <mount point> <type> <options> <dump> <pass>","title":"Structure"},{"location":"linux/fstab/#device","text":"Usually the given name or UUID of the mounted device (sda1/sda2/etc). Mount Point: designates the directory where the device is/will be mounted.","title":"Device"},{"location":"linux/fstab/#file-system-type","text":"Nothing trick here, shows the type of filesystem in use.","title":"File System Type"},{"location":"linux/fstab/#options","text":"Lists any active mount options. If using multiple options they must be separated by commas.","title":"Options"},{"location":"linux/fstab/#backup-operation-the-first-digit","text":"This is a binary system where 1 = dump utility backup of a partition. 0 = no backup. This is an outdated backup method and should NOT be used.","title":"Backup Operation (the first digit)"},{"location":"linux/fstab/#file-system-check-order-second-digit","text":"Here we can see three possible outcomes. 0 means that fsck will not check the filesystem. > Numbers higher than this represent the check order. The root filesystem should be set to 1 and other partitions set to 2.","title":"File System Check Order (second digit)"},{"location":"linux/gawk/","text":"GWAK Arnold Robbins , an Atlanta native, is a professional programmer and technical author. He has been a heavy AWK user since 1987, when he became involved with gawk , the GNU project's version of AWK. Sed Add item to certain line sed -i '20 a nouvel \u00e9l\u00e8ment' FICHIER Remove saut de ligne sed '/^$/d' sed '/^:space:*$/d' AWK Awk command : Command - Example grep /word/ awk '/data/ {gsub(\"\\\"\",\"\"); print $2}' gsub thing to remove awk '{gsub(\"\\\"\",\"\"); print $2}' TR Remove space : tr -d '[:blank:]' FIND Files Find all 'jacquet' file from $PLACE : find $PLACE -name \"jacquet\" Directory Find all files older than 90 days in /var/log/httpd/ directory find /var/log/httpd/ -type f -name \"*\" -mtime +90 -exec rm -f {} \\; Exclude How to exclude directory.ies ? Use the ! -path '*$THING*' syntax find $PLACE -type f -name $SOMETING ! -path '*NOT_THIS_ONE*' Note {} is the resutl of find command Grep That is a command-line utility for searching plain-text data sets for lines that match a regular expression. Its name comes from the ed command g/re/p ( globally search for a regular expression and print matching lines ). grep thing file.txt grep \"searching elements\" -A $NUMBER_OF_LINE -B $NUMBER_OF_LINE Catch something from multiple files grep -ari copyright /var/www/html/","title":"GWAK"},{"location":"linux/gawk/#gwak","text":"Arnold Robbins , an Atlanta native, is a professional programmer and technical author. He has been a heavy AWK user since 1987, when he became involved with gawk , the GNU project's version of AWK.","title":"GWAK"},{"location":"linux/gawk/#sed","text":"Add item to certain line sed -i '20 a nouvel \u00e9l\u00e8ment' FICHIER","title":"Sed"},{"location":"linux/gawk/#remove-saut-de-ligne","text":"sed '/^$/d' sed '/^:space:*$/d'","title":"Remove saut de ligne"},{"location":"linux/gawk/#awk","text":"Awk command : Command - Example grep /word/ awk '/data/ {gsub(\"\\\"\",\"\"); print $2}' gsub thing to remove awk '{gsub(\"\\\"\",\"\"); print $2}'","title":"AWK"},{"location":"linux/gawk/#tr","text":"Remove space : tr -d '[:blank:]'","title":"TR"},{"location":"linux/gawk/#find","text":"","title":"FIND"},{"location":"linux/gawk/#files","text":"Find all 'jacquet' file from $PLACE : find $PLACE -name \"jacquet\"","title":"Files"},{"location":"linux/gawk/#directory","text":"Find all files older than 90 days in /var/log/httpd/ directory find /var/log/httpd/ -type f -name \"*\" -mtime +90 -exec rm -f {} \\;","title":"Directory"},{"location":"linux/gawk/#exclude","text":"How to exclude directory.ies ? Use the ! -path '*$THING*' syntax find $PLACE -type f -name $SOMETING ! -path '*NOT_THIS_ONE*' Note {} is the resutl of find command","title":"Exclude"},{"location":"linux/gawk/#grep","text":"That is a command-line utility for searching plain-text data sets for lines that match a regular expression. Its name comes from the ed command g/re/p ( globally search for a regular expression and print matching lines ). grep thing file.txt grep \"searching elements\" -A $NUMBER_OF_LINE -B $NUMBER_OF_LINE Catch something from multiple files grep -ari copyright /var/www/html/","title":"Grep"},{"location":"linux/getops/","text":"Getops getopts processes the positional parameters of the parent command. In bash, this is stored in the shell variable \"$@\". Positional parameters A positional parameter is an argument specified on the command line, used to launch the current process in a shell. Positional parameter values are stored in a special set of variables maintained by the shell. mycmd -a argument1 -b argument2 EXAMPLES The following code fragment shows how one might process the arguments for a command that can take the options -a and -b, and the option -o, which requires an argument. args = ` getopt abo: $* ` # you should not use `getopt abo: \"$@\"` since that would parse # the arguments differently from what the set command below does. if [ $? -ne 0 ] ; then echo 'Usage: ...' exit 2 fi set -- $args # You cannot use the set command with a backquoted getopt directly, # since the exit code from getopt would be shadowed by those of set, # which is zero by definition. while : ; do case \" $1 \" in -a | -b ) echo \"flag $1 set\" ; sflags = \" ${ 1 #- } $sflags \" shift ;; -o ) echo \"oarg is ' $2 '\" ; oarg = \" $2 \" shift ; shift ;; -- ) shift ; break ;; esac done echo \"single-char flags: ' $sflags '\" echo \"oarg is ' $oarg '\"","title":"Getops"},{"location":"linux/getops/#getops","text":"getopts processes the positional parameters of the parent command. In bash, this is stored in the shell variable \"$@\".","title":"Getops"},{"location":"linux/getops/#positional-parameters","text":"A positional parameter is an argument specified on the command line, used to launch the current process in a shell. Positional parameter values are stored in a special set of variables maintained by the shell. mycmd -a argument1 -b argument2","title":"Positional parameters"},{"location":"linux/getops/#examples","text":"The following code fragment shows how one might process the arguments for a command that can take the options -a and -b, and the option -o, which requires an argument. args = ` getopt abo: $* ` # you should not use `getopt abo: \"$@\"` since that would parse # the arguments differently from what the set command below does. if [ $? -ne 0 ] ; then echo 'Usage: ...' exit 2 fi set -- $args # You cannot use the set command with a backquoted getopt directly, # since the exit code from getopt would be shadowed by those of set, # which is zero by definition. while : ; do case \" $1 \" in -a | -b ) echo \"flag $1 set\" ; sflags = \" ${ 1 #- } $sflags \" shift ;; -o ) echo \"oarg is ' $2 '\" ; oarg = \" $2 \" shift ; shift ;; -- ) shift ; break ;; esac done echo \"single-char flags: ' $sflags '\" echo \"oarg is ' $oarg '\"","title":"EXAMPLES"},{"location":"linux/keymaps/","text":"Keymap Liste: D\u00e9but du mot : b D\u00e9but du dexi\u00e8me mot en partant du mot d'origin : 3B Fin du mot suivant : e Mot suivant : w Replace : r Supprimer carract\u00e8re par carract\u00e8re : x Supprimer \u00e0 reculon carract\u00e8re par carract\u00e8re : c Changer (ce -> changer jusqu'\u00e0 la fin du mot ) : c Enregister les modifications : ZZ Enregistrer les modifications et quiter le fichier : ZQ R\u00e9peter la derni\u00e8re actions effectu\u00e9e : .","title":"Keymap"},{"location":"linux/keymaps/#keymap","text":"Liste: D\u00e9but du mot : b D\u00e9but du dexi\u00e8me mot en partant du mot d'origin : 3B Fin du mot suivant : e Mot suivant : w Replace : r Supprimer carract\u00e8re par carract\u00e8re : x Supprimer \u00e0 reculon carract\u00e8re par carract\u00e8re : c Changer (ce -> changer jusqu'\u00e0 la fin du mot ) : c Enregister les modifications : ZZ Enregistrer les modifications et quiter le fichier : ZQ R\u00e9peter la derni\u00e8re actions effectu\u00e9e : .","title":"Keymap"},{"location":"linux/kickstart/","text":"Kickstart File Commands Installation Commands Define the installation source and how to perform the installation. Each is followed by an example. url: Specifies the URL pointing to the installation media. url --url = \"http://classroom.example.com/content/rhel8.2/x86_64/dvd/\" repo: Specifies where to find additional packages for installation . This option must point to a valid yum repository. repo --name = \"appstream\" --baseurl = http://classroom.example.com/content/rhel8.2/x86_64/dvd/AppStream/ text: Forces a text mode install. vnc: Allows the graphical installation to be viewed remotely over VNC. vnc --password = redhat Partitioning Commands Define the devices and partitioning scheme to be used. clearpart: Removes partitions from the system prior to creation of new partitions. By default, no partitions are removed. clearpart --all --drives = sda,sdb --initlabel part: Specifies the size, format, and name of a partition. part /home --fstype = ext4 --label = homes --size = 4096 --maxsize = 8192 --grow autopart: Automatically creates a root partition, a swap partition, and an appropriate boot partition for the architecture. On large enough drives, this also creates a /home partition. ignoredisk: Controls Anaconda's access to disks attached to the system. ignoredisk --drives = sdc bootloader: Defines where to install the bootloader. bootloader --location = mbr --boot-drive = sda volgroup, logvol: Creates LVM volume groups and logical volumes. part pv.01 --size = 8192 volgroup myvg pv.01 logvol / --vgname = myvg --fstype = xfs --size = 2048 --name = rootvol --grow logvol /var --vgname = myvg --fstype = xfs --size = 4096 --name = varvol zerombr: Initialize disks whose formatting is unrecognized. Network Commands Define the network features used by the host. network: Configures network information for target system. Activates network devices in installer environment. network --device = eth0 --bootproto = dhcp firewall: Defines the firewall configuration for the target system. firewall --enabled --service=ssh,http Location and Security Commands Configure settings related to security, language, and regions. lang: Sets the language to use during installation and the default language of the installed system. Required. lang en_US.UTF-8 keyboard: Sets the system keyboard type. Required. keyboard --vckeymap = us --xlayouts = '' timezone: Defines the timezone, NTP servers, and whether the hardware clock uses UTC. timezone --utc --ntpservers = time.example.com Europe/Amsterdam authselect: Sets up authentication options. Options recognized by authselect are valid for this command. rootpw: Defines the initial root password. rootpw --plaintext redhat or rootpw --iscrypted $6$KUnFfrTzO8jv .PiH $YlBbOtXBkWzoMuRfb0 .SpbQ....XDR1UuchoMG1 selinux: Sets the SELinux mode for the installed system. selinux --enforcing services: Modifies the default set of services to run under the default systemd target. services --disabled = network,iptables,ip6tables --enabled = NetworkManager,firewalld group, user: Create a local group or user on the system. group --name = admins --gid = 10001 user --name = jdoe --gecos = \"John Doe\" --groups = admins --password = changeme --plaintext Miscellaneous Commands Configure miscellaneous items related to logging during the installation and the host power state at completion. logging: This command defines how Anaconda will perform logging during the installation. logging --host = loghost.example.com --level = info firstboot: If enabled, the Setup Agent starts the first time the system boots. The initial-setup package must be installed. firstboot --disabled reboot, poweroff, halt: Specify the final action to take when the installation completes. Info The ksverdiff utility from the pykickstart package is useful for identifying changes in Kickstart file syntax between two versions of Red Hat Enterprise Linux or Fedora. For example, ksverdiff -f RHEL7 -t RHEL8 identifies changes in syntax from RHEL 7 to RHEL 8. Available versions are listed in the top of the file /usr/lib/python3.6/site-packages/pykickstart/version.py. Example Kickstart File The first part of the file consists of the installation commands, such as disk partitioning and installation source. #version=RHEL8 ignoredisk --only-use = vda # System bootloader configuration bootloader --append = \"console=ttyS0 console=ttyS0,115200n8 no_timer_check net.ifnames=0 crashkernel=auto\" --location = mbr --timeout = 1 --boot-drive = vda # Clear the Master Boot Record zerombr # Partition clearing information clearpart --all --initlabel # Use text mode install text repo --name = \"appstream\" --baseurl = http://classroom.example.com/content/rhel8.2/x86_64/dvd/AppStream/ # Use network installation url --url = \"http://classroom.example.com/content/rhel8.2/x86_64/dvd/\" # Keyboard layouts # old format: keyboard us # new format: keyboard --vckeymap = us --xlayouts = '' # System language lang en_US.UTF-8 # Root password rootpw --plaintext redhat # System authorization information auth --enableshadow --passalgo = sha512 # SELinux configuration selinux --enforcing firstboot --disable # Do not configure the X Window System skipx # System services services --disabled = \"kdump,rhsmcertd\" --enabled = \"sshd,rngd,chronyd\" # System timezone timezone America/New_York --isUtc # Disk partitioning information part / --fstype = \"xfs\" --ondisk = vda --size = 10000 The second part contains the %packages section, detailing which packages and package groups should be installed, and which packages should not be installed. %packages @core chrony cloud-init dracut-config-generic dracut-norescue firewalld grub2 kernel rsync tar -plymouth %end The last part contains any %pre and %post installation scripts. %post --erroronfail # For cloud images, 'eth0' _is_ the predictable device name, since # we don't want to be tied to specific virtual (!) hardware rm -f /etc/udev/rules.d/70* ln -s /dev/null /etc/udev/rules.d/80-net-name-slot.rules # simple eth0 config, again not hard-coded to the build hardware cat > /etc/sysconfig/network-scripts/ifcfg-eth0 << EOF DEVICE=\"eth0\" BOOTPROTO=\"dhcp\" ONBOOT=\"yes\" TYPE=\"Ethernet\" USERCTL=\"yes\" PEERDNS=\"yes\" IPV6INIT=\"no\" EOF %end Creating a Kickstart File Use either of these methods to create a Kickstart file: Use the Kickstart Generator website. Use a text editor. The Kickstart Generator website at https://access.redhat.com/labs/kickstartconfig/ presents dialog boxes for user inputs, and creates a Kickstart directives text file with the user's choices. Each dialog box corresponds to the configurable items in the Anaconda installer. Creating a Kickstart file from scratch is typically too complex, but editing an existing Kickstart file is common and useful. Every installation creates a /root/anaconda-ks.cfg file containing the Kickstart directives used in the installation. This file makes a good starting point when creating Kickstart file manually. ksvalidator is a utility that checks for syntax errors in a Kickstart file. It ensures that keywords and options are properly used, but it does not validate that URL paths, individual packages, or groups, nor any part of %post or %pre scripts will succeed. For instance, if the firewall --disabled directive is misspelled, ksvalidator could produce one of the following errors: ```shell [user@host ~]$ ksvalidator /tmp/anaconda-ks.cfg The following problem occurred on line 10 of the kickstart file: Unknown command: frewall [user@host ~]$ ksvalidator /tmp/anaconda-ks.cfg The following problem occurred on line 10 of the kickstart file: no such option: --dsabled ```` The pykickstart package provides ksvalidator. Publish the Kickstart File to Anaconda Make the Kickstart file available to the installer by placing it in one of these locations: A network server available at install time using FTP, HTTP, or NFS. An available USB disk or CD-ROM. A local hard disk on the system to be installed. The installer must access the Kickstart file to begin an automated installation. The most common automation method uses a network server such as an FTP, web, or NFS server. Network servers facilitate Kickstart file maintenance because changes can be made once, and then immediately used for multiple future installations. Providing Kickstart files on USB or CD-ROM is also convenient. The Kickstart file can be embedded on the boot media used to start the installation. However, when the Kickstart file is changed, you must generate new installation media. Providing the Kickstart file on a local disk allows you to quickly rebuild a system. Boot Anaconda and Point it to the Kickstart File Once a Kickstart method is chosen, the installer is told where to locate the Kickstart file by passing the inst.ks=LOCATION parameter to the installation kernel. Some examples: inst.ks= http://server/dir/file inst.ks= ftp://server/dir/file inst.ks= nfs:server:/dir/file inst.ks= hd:device:/dir/file inst.ks= cdrom:device For virtual machine installations using the Virtual Machine Manager or virt-manager, the Kickstart URL can be specified in a box under URL Options. When installing physical machines, boot using installation media and press the Tab key to interrupt the boot process. Add an inst.ks=LOCATION parameter to the installation kernel. Reference Red Hat System Administration II","title":"Kickstart File Commands"},{"location":"linux/kickstart/#kickstart-file-commands","text":"","title":"Kickstart File Commands"},{"location":"linux/kickstart/#installation-commands","text":"Define the installation source and how to perform the installation. Each is followed by an example. url: Specifies the URL pointing to the installation media. url --url = \"http://classroom.example.com/content/rhel8.2/x86_64/dvd/\" repo: Specifies where to find additional packages for installation . This option must point to a valid yum repository. repo --name = \"appstream\" --baseurl = http://classroom.example.com/content/rhel8.2/x86_64/dvd/AppStream/ text: Forces a text mode install. vnc: Allows the graphical installation to be viewed remotely over VNC. vnc --password = redhat","title":"Installation Commands"},{"location":"linux/kickstart/#partitioning-commands","text":"Define the devices and partitioning scheme to be used. clearpart: Removes partitions from the system prior to creation of new partitions. By default, no partitions are removed. clearpart --all --drives = sda,sdb --initlabel part: Specifies the size, format, and name of a partition. part /home --fstype = ext4 --label = homes --size = 4096 --maxsize = 8192 --grow autopart: Automatically creates a root partition, a swap partition, and an appropriate boot partition for the architecture. On large enough drives, this also creates a /home partition. ignoredisk: Controls Anaconda's access to disks attached to the system. ignoredisk --drives = sdc bootloader: Defines where to install the bootloader. bootloader --location = mbr --boot-drive = sda volgroup, logvol: Creates LVM volume groups and logical volumes. part pv.01 --size = 8192 volgroup myvg pv.01 logvol / --vgname = myvg --fstype = xfs --size = 2048 --name = rootvol --grow logvol /var --vgname = myvg --fstype = xfs --size = 4096 --name = varvol zerombr: Initialize disks whose formatting is unrecognized.","title":"Partitioning Commands"},{"location":"linux/kickstart/#network-commands","text":"Define the network features used by the host. network: Configures network information for target system. Activates network devices in installer environment. network --device = eth0 --bootproto = dhcp firewall: Defines the firewall configuration for the target system. firewall --enabled --service=ssh,http Location and Security Commands Configure settings related to security, language, and regions. lang: Sets the language to use during installation and the default language of the installed system. Required. lang en_US.UTF-8 keyboard: Sets the system keyboard type. Required. keyboard --vckeymap = us --xlayouts = '' timezone: Defines the timezone, NTP servers, and whether the hardware clock uses UTC. timezone --utc --ntpservers = time.example.com Europe/Amsterdam authselect: Sets up authentication options. Options recognized by authselect are valid for this command. rootpw: Defines the initial root password. rootpw --plaintext redhat or rootpw --iscrypted $6$KUnFfrTzO8jv .PiH $YlBbOtXBkWzoMuRfb0 .SpbQ....XDR1UuchoMG1 selinux: Sets the SELinux mode for the installed system. selinux --enforcing services: Modifies the default set of services to run under the default systemd target. services --disabled = network,iptables,ip6tables --enabled = NetworkManager,firewalld group, user: Create a local group or user on the system. group --name = admins --gid = 10001 user --name = jdoe --gecos = \"John Doe\" --groups = admins --password = changeme --plaintext","title":"Network Commands"},{"location":"linux/kickstart/#miscellaneous-commands","text":"Configure miscellaneous items related to logging during the installation and the host power state at completion. logging: This command defines how Anaconda will perform logging during the installation. logging --host = loghost.example.com --level = info firstboot: If enabled, the Setup Agent starts the first time the system boots. The initial-setup package must be installed. firstboot --disabled reboot, poweroff, halt: Specify the final action to take when the installation completes. Info The ksverdiff utility from the pykickstart package is useful for identifying changes in Kickstart file syntax between two versions of Red Hat Enterprise Linux or Fedora. For example, ksverdiff -f RHEL7 -t RHEL8 identifies changes in syntax from RHEL 7 to RHEL 8. Available versions are listed in the top of the file /usr/lib/python3.6/site-packages/pykickstart/version.py.","title":"Miscellaneous Commands"},{"location":"linux/kickstart/#example-kickstart-file","text":"The first part of the file consists of the installation commands, such as disk partitioning and installation source. #version=RHEL8 ignoredisk --only-use = vda # System bootloader configuration bootloader --append = \"console=ttyS0 console=ttyS0,115200n8 no_timer_check net.ifnames=0 crashkernel=auto\" --location = mbr --timeout = 1 --boot-drive = vda # Clear the Master Boot Record zerombr # Partition clearing information clearpart --all --initlabel # Use text mode install text repo --name = \"appstream\" --baseurl = http://classroom.example.com/content/rhel8.2/x86_64/dvd/AppStream/ # Use network installation url --url = \"http://classroom.example.com/content/rhel8.2/x86_64/dvd/\" # Keyboard layouts # old format: keyboard us # new format: keyboard --vckeymap = us --xlayouts = '' # System language lang en_US.UTF-8 # Root password rootpw --plaintext redhat # System authorization information auth --enableshadow --passalgo = sha512 # SELinux configuration selinux --enforcing firstboot --disable # Do not configure the X Window System skipx # System services services --disabled = \"kdump,rhsmcertd\" --enabled = \"sshd,rngd,chronyd\" # System timezone timezone America/New_York --isUtc # Disk partitioning information part / --fstype = \"xfs\" --ondisk = vda --size = 10000 The second part contains the %packages section, detailing which packages and package groups should be installed, and which packages should not be installed. %packages @core chrony cloud-init dracut-config-generic dracut-norescue firewalld grub2 kernel rsync tar -plymouth %end The last part contains any %pre and %post installation scripts. %post --erroronfail # For cloud images, 'eth0' _is_ the predictable device name, since # we don't want to be tied to specific virtual (!) hardware rm -f /etc/udev/rules.d/70* ln -s /dev/null /etc/udev/rules.d/80-net-name-slot.rules # simple eth0 config, again not hard-coded to the build hardware cat > /etc/sysconfig/network-scripts/ifcfg-eth0 << EOF DEVICE=\"eth0\" BOOTPROTO=\"dhcp\" ONBOOT=\"yes\" TYPE=\"Ethernet\" USERCTL=\"yes\" PEERDNS=\"yes\" IPV6INIT=\"no\" EOF %end","title":"Example Kickstart File"},{"location":"linux/kickstart/#creating-a-kickstart-file","text":"Use either of these methods to create a Kickstart file: Use the Kickstart Generator website. Use a text editor. The Kickstart Generator website at https://access.redhat.com/labs/kickstartconfig/ presents dialog boxes for user inputs, and creates a Kickstart directives text file with the user's choices. Each dialog box corresponds to the configurable items in the Anaconda installer. Creating a Kickstart file from scratch is typically too complex, but editing an existing Kickstart file is common and useful. Every installation creates a /root/anaconda-ks.cfg file containing the Kickstart directives used in the installation. This file makes a good starting point when creating Kickstart file manually. ksvalidator is a utility that checks for syntax errors in a Kickstart file. It ensures that keywords and options are properly used, but it does not validate that URL paths, individual packages, or groups, nor any part of %post or %pre scripts will succeed. For instance, if the firewall --disabled directive is misspelled, ksvalidator could produce one of the following errors: ```shell [user@host ~]$ ksvalidator /tmp/anaconda-ks.cfg The following problem occurred on line 10 of the kickstart file: Unknown command: frewall [user@host ~]$ ksvalidator /tmp/anaconda-ks.cfg The following problem occurred on line 10 of the kickstart file: no such option: --dsabled ```` The pykickstart package provides ksvalidator.","title":"Creating a Kickstart File"},{"location":"linux/kickstart/#publish-the-kickstart-file-to-anaconda","text":"Make the Kickstart file available to the installer by placing it in one of these locations: A network server available at install time using FTP, HTTP, or NFS. An available USB disk or CD-ROM. A local hard disk on the system to be installed. The installer must access the Kickstart file to begin an automated installation. The most common automation method uses a network server such as an FTP, web, or NFS server. Network servers facilitate Kickstart file maintenance because changes can be made once, and then immediately used for multiple future installations. Providing Kickstart files on USB or CD-ROM is also convenient. The Kickstart file can be embedded on the boot media used to start the installation. However, when the Kickstart file is changed, you must generate new installation media. Providing the Kickstart file on a local disk allows you to quickly rebuild a system. Boot Anaconda and Point it to the Kickstart File Once a Kickstart method is chosen, the installer is told where to locate the Kickstart file by passing the inst.ks=LOCATION parameter to the installation kernel. Some examples: inst.ks= http://server/dir/file inst.ks= ftp://server/dir/file inst.ks= nfs:server:/dir/file inst.ks= hd:device:/dir/file inst.ks= cdrom:device For virtual machine installations using the Virtual Machine Manager or virt-manager, the Kickstart URL can be specified in a box under URL Options. When installing physical machines, boot using installation media and press the Tab key to interrupt the boot process. Add an inst.ks=LOCATION parameter to the installation kernel.","title":"Publish the Kickstart File to Anaconda"},{"location":"linux/kickstart/#reference","text":"Red Hat System Administration II","title":"Reference"},{"location":"linux/logfile/","text":"Logrotate Check logrotate -d /etc/logrotate.d/httpd Apply logrotate -vf /etc/logrotate.d/httpd","title":"Logfile"},{"location":"linux/logfile/#logrotate","text":"","title":"Logrotate"},{"location":"linux/logfile/#check","text":"logrotate -d /etc/logrotate.d/httpd","title":"Check"},{"location":"linux/logfile/#apply","text":"logrotate -vf /etc/logrotate.d/httpd","title":"Apply"},{"location":"linux/memory/","text":"RAM List detailes : ps axo rss, comm,pid,command | cat","title":"RAM"},{"location":"linux/memory/#ram","text":"List detailes : ps axo rss, comm,pid,command | cat","title":"RAM"},{"location":"linux/network/","text":"Network Network files (depend of distro) DEB /etc/network/interfaces ## This file describes the network interfaces available on your system ## and how to activate them. For more information, see interfaces(5). ## The loopback network interface auto lo iface lo inet loopback ## The primary network interface auto eth0 iface eth0 inet static address 10 .0.0.41 netmask 24 gateway 10 .0.0.0 dns-nameservers 10 .0.0.1 8 .8.8.8 /etc/netplan/00-installer-config.yaml # This is the network config written by 'subiquity' network: ethernets: ens18: addresses: - 10 .0.0.107/24 nameservers: addresses: - 10 .0.0.1 search: - 10 .0.0.1 routes: - to: default via: 10 .0.0.1 version: 2 RPM /etc/sysconfig/network-scripts/ifcfg-eth0 TYPE = Ethernet PROXY_METHOD = none BROWSER_ONLY = no BOOTPROTO = none DEFROUTE = yes IPV4_FAILURE_FATAL = no IPV6INIT = no NAME = eth0 UUID = 67c4................f5d569 DEVICE = eth0 ONBOOT = yes IPV6_DISABLED = yes IPADDR = 0 .0.0.0 PREFIX = 24 GATEWAY = 0 .0.0.0","title":"Network"},{"location":"linux/network/#network","text":"Network files (depend of distro)","title":"Network"},{"location":"linux/network/#deb","text":"/etc/network/interfaces ## This file describes the network interfaces available on your system ## and how to activate them. For more information, see interfaces(5). ## The loopback network interface auto lo iface lo inet loopback ## The primary network interface auto eth0 iface eth0 inet static address 10 .0.0.41 netmask 24 gateway 10 .0.0.0 dns-nameservers 10 .0.0.1 8 .8.8.8 /etc/netplan/00-installer-config.yaml # This is the network config written by 'subiquity' network: ethernets: ens18: addresses: - 10 .0.0.107/24 nameservers: addresses: - 10 .0.0.1 search: - 10 .0.0.1 routes: - to: default via: 10 .0.0.1 version: 2","title":"DEB"},{"location":"linux/network/#rpm","text":"/etc/sysconfig/network-scripts/ifcfg-eth0 TYPE = Ethernet PROXY_METHOD = none BROWSER_ONLY = no BOOTPROTO = none DEFROUTE = yes IPV4_FAILURE_FATAL = no IPV6INIT = no NAME = eth0 UUID = 67c4................f5d569 DEVICE = eth0 ONBOOT = yes IPV6_DISABLED = yes IPADDR = 0 .0.0.0 PREFIX = 24 GATEWAY = 0 .0.0.0","title":"RPM"},{"location":"linux/package-manager/","text":"Package manager RPM How to force installation without depedency. rpm -Uvh Debian Repository bullseye 11 sources.list deb http://deb.debian.org/debian bullseye main deb-src http://deb.debian.org/debian bullseye main deb http://deb.debian.org/debian-security/ bullseye-security main deb-src http://deb.debian.org/debian-security/ bullseye-security main deb http://deb.debian.org/debian bullseye-updates main deb-src http://deb.debian.org/debian bullseye-updates main","title":"Package manager"},{"location":"linux/package-manager/#package-manager","text":"","title":"Package manager"},{"location":"linux/package-manager/#rpm","text":"How to force installation without depedency. rpm -Uvh","title":"RPM"},{"location":"linux/package-manager/#debian","text":"","title":"Debian"},{"location":"linux/package-manager/#repository","text":"bullseye 11 sources.list deb http://deb.debian.org/debian bullseye main deb-src http://deb.debian.org/debian bullseye main deb http://deb.debian.org/debian-security/ bullseye-security main deb-src http://deb.debian.org/debian-security/ bullseye-security main deb http://deb.debian.org/debian bullseye-updates main deb-src http://deb.debian.org/debian bullseye-updates main","title":"Repository"},{"location":"linux/proc/","text":"Process Lister tout les processus : a : Ayant un terminal de contr\u00f4le u : Lanc\u00e9s par l'/es utilisateur(s) x : N'ayant pas de terminal de contr\u00f4le (TTY) e : Tout les processe d : Tout les processes sauf ceux de la session courante l : Liste longue f : Full -> Avoir le nom complet du processus CPU Lister le nombre de processeur : nproc Load Check the load average fixed by the system: cat /proc/loadavg Verify time since the system is up: uptime You could check your system processes by top/htop or glances and more one else: top You can folow your CPU in real time by this command: vmstat -w 1","title":"Process"},{"location":"linux/proc/#process","text":"Lister tout les processus : a : Ayant un terminal de contr\u00f4le u : Lanc\u00e9s par l'/es utilisateur(s) x : N'ayant pas de terminal de contr\u00f4le (TTY) e : Tout les processe d : Tout les processes sauf ceux de la session courante l : Liste longue f : Full -> Avoir le nom complet du processus","title":"Process"},{"location":"linux/proc/#cpu","text":"Lister le nombre de processeur : nproc","title":"CPU"},{"location":"linux/proc/#load","text":"Check the load average fixed by the system: cat /proc/loadavg Verify time since the system is up: uptime You could check your system processes by top/htop or glances and more one else: top You can folow your CPU in real time by this command: vmstat -w 1","title":"Load"},{"location":"linux/readme/","text":"README Linux\u00ae is an open source operating system (OS). An operating system is the software that directly manages a system\u2019s hardware and resources, like CPU, memory, and storage. The OS sits between applications and hardware and makes the connections between all of your software and the physical resources that do the work.","title":"README"},{"location":"linux/readme/#readme","text":"Linux\u00ae is an open source operating system (OS). An operating system is the software that directly manages a system\u2019s hardware and resources, like CPU, memory, and storage. The OS sits between applications and hardware and makes the connections between all of your software and the physical resources that do the work.","title":"README"},{"location":"linux/regular-expressions/","text":"Regular Expression Option Description . The period (.) matches any single character. ? The preceding item is optional and will be matched at most once. * The preceding item will be matched zero or more times. + The preceding item will be matched one or more times. {n} The preceding item is matched exactly n times. {n,} The preceding item is matched n or more times. {,m} The preceding item is matched at most m times. {n,m} The preceding item is matched at least n times, but not more than m times. [:alnum:] Alphanumeric characters: '[:alpha:]' and '[:digit:]'; in the 'C' locale and ASCII character encoding, this is the same as '[0-9A-Za-z]'. [:alpha:] Alphabetic characters: '[:lower:]' and '[:upper:]'; in the 'C' locale and ASCII character encoding, this is the same as '[A-Za-z]'. [:blank:] Blank characters: space and tab. [:cntrl:] Control characters. In ASCII, these characters have octal codes 000 through 037, and 177 (DEL). In other character sets, these are the equivalent characters, if any. [:digit:] Digits: 0 1 2 3 4 5 6 7 8 9. [:graph:] Graphical characters: '[:alnum:]' and '[:punct:]'. [:lower:] Lower-case letters; in the 'C' locale and ASCII character encoding, this is a b c d e f g h i j k l m n o p q r s t u v w x y z. [:print:] Printable characters: '[:alnum:]', '[:punct:]', and space. [:punct:] Punctuation characters; in the 'C' locale and ASCII character encoding, this is! \" # $ % & ' ( ) * + , - . / : ; < = > ? @ [ \\ ] ^ _ ' { [:space:] Space characters: in the 'C' locale, this is tab, newline, vertical tab, form feed,carriage return, and space. [:upper:] Upper-case letters: in the 'C' locale and ASCII character encoding, this is A B C D E F G H I J K L M N O P Q R S T U V W X Y Z. [:xdigit:] Hexadecimal digits: 0 1 2 3 4 5 6 7 8 9 A B C D E F a b c d e f. \\b Match the empty string at the edge of a word. \\B Match the empty string provided it is not at the edge of a word. \\< Match the empty string at the beginning of word. > Match the empty string at the end of word. \\w Match word constituent. Synonym for '[_[:alnum:]]'. \\W Match non-word constituent. Synonym for '[\\^_[:alnum:]]'. \\s Match white space. Synonym for '[[:space:]]'. \\S Match non-whitespace. Synonym for '[^[:space:]]'.","title":"Regular Expression"},{"location":"linux/regular-expressions/#regular-expression","text":"Option Description . The period (.) matches any single character. ? The preceding item is optional and will be matched at most once. * The preceding item will be matched zero or more times. + The preceding item will be matched one or more times. {n} The preceding item is matched exactly n times. {n,} The preceding item is matched n or more times. {,m} The preceding item is matched at most m times. {n,m} The preceding item is matched at least n times, but not more than m times. [:alnum:] Alphanumeric characters: '[:alpha:]' and '[:digit:]'; in the 'C' locale and ASCII character encoding, this is the same as '[0-9A-Za-z]'. [:alpha:] Alphabetic characters: '[:lower:]' and '[:upper:]'; in the 'C' locale and ASCII character encoding, this is the same as '[A-Za-z]'. [:blank:] Blank characters: space and tab. [:cntrl:] Control characters. In ASCII, these characters have octal codes 000 through 037, and 177 (DEL). In other character sets, these are the equivalent characters, if any. [:digit:] Digits: 0 1 2 3 4 5 6 7 8 9. [:graph:] Graphical characters: '[:alnum:]' and '[:punct:]'. [:lower:] Lower-case letters; in the 'C' locale and ASCII character encoding, this is a b c d e f g h i j k l m n o p q r s t u v w x y z. [:print:] Printable characters: '[:alnum:]', '[:punct:]', and space. [:punct:] Punctuation characters; in the 'C' locale and ASCII character encoding, this is! \" # $ % & ' ( ) * + , - . / : ; < = > ? @ [ \\ ] ^ _ ' { [:space:] Space characters: in the 'C' locale, this is tab, newline, vertical tab, form feed,carriage return, and space. [:upper:] Upper-case letters: in the 'C' locale and ASCII character encoding, this is A B C D E F G H I J K L M N O P Q R S T U V W X Y Z. [:xdigit:] Hexadecimal digits: 0 1 2 3 4 5 6 7 8 9 A B C D E F a b c d e f. \\b Match the empty string at the edge of a word. \\B Match the empty string provided it is not at the edge of a word. \\< Match the empty string at the beginning of word. > Match the empty string at the end of word. \\w Match word constituent. Synonym for '[_[:alnum:]]'. \\W Match non-word constituent. Synonym for '[\\^_[:alnum:]]'. \\s Match white space. Synonym for '[[:space:]]'. \\S Match non-whitespace. Synonym for '[^[:space:]]'.","title":"Regular Expression"},{"location":"linux/rhel-sysadmin-II/","text":"Red Hat System Administration II Tuning System Performance ** ` tuned-adm list ` ** Available profiles: - balanced - desktop - latency-performance - network-latency - network-throughput - powersave - sap - throughput-performance - virtual-guest - virtual-host Profiles Distributed with Rhel 8 Tuned Profile Purpose balanced Ideal for systems that require a compromise between power saving and performance. desktop Derived from the balanced profile. Provides faster response of interactive applications. throughput-performance Tunes the system for maximum throughput. latency-performance Ideal for server systems that require low latency at the expense of power consumption. network-latency Derived from the latency-performance profile. It enables additional network tuning parameters to provide low network latency. network-throughput Derived from the throughput-performance profile. Additional network tuning parameters are applied for maximum network throughput. powersave Tunes the system for maximum power saving. oracle Optimized for Oracle database loads based on the throughput-performance profile. virtual-guest Tunes the system for maximum performance if it runs on a virtual machine. virtual-host Tunes the system for maximum performance if it acts as a host for virtual machines. The tuned service automatically modifies device settings to meet specific system needs based on a pre-defined selected tuning profile. To revert all changes made to system settings by a selected profile, either switch to another profile or deactivate the tuned service. The system assigns a relative priority to a process to determine its CPU access. This priority is called the nice value of a process. The nice command assigns a priority to a process when it starts. The renice command modifies the priority of a running process. Access Control Lists ACLs provide fine-grained access control to files and directories. The getfacl command displays the ACLs on a file or directory. The setfacl command sets, modifies, and removes default and standard ACLs on files and directories. Use default ACLs for controlling new files and directories permissions. Red Hat Enterprise Linux uses systemd and udev to apply predefined ACLs on devices, folders, and files. Managing SELinux Security The getenforce and setenforce commands are used to manage the SELinux mode of a system. The semanage command is used to manage SELinux policy rules. The restorecon command applies the context defined by the policy. Booleans are switches that change the behavior of the SELinux policy. They can be enabled or disabled and are used to tune the policy. The sealert displays useful information to help with SELinux troubleshooting. Managing Storage Basic You use the parted command to add, modify, and remove partitions on disks with the MBR or the GPT partitioning scheme. You use the mkfs.xfs command to create XFS file systems on disk partitions. You need to add file-system mount commands to /etc/fstab to make those mounts persistent. You use the mkswap command to initialize swap spaces. Advanced The Stratis storage management solution implements flexible file systems that grow dynamically with data. The Stratis storage management solution supports thin provisioning, snapshotting, and monitoring. The Virtual Data Optimizer (VDO) aims to reduce the cost of data storage. The Virtual Data Optimizer applies zero-block elimination, data deduplication, and data compression to optimize disk space efficiency. title: pool list max number file supported You can create multiple pools from different storage devices. From each pool, you can create one or more file systems. Currently, you can create up to **2^24** file systems per pool. Managing Logical Volumes Allows you to create flexible storage by allocating space on multiple storage devices. Physical volumes, volume groups, and logical volumes are managed by a variety of tools such as pvcreate , vgreduce , and lvextend . Logical volumes can be formatted with a file system or swap space, and they can be mounted persistently. Additional storage can be added to volume groups and logical volumes can be extended dynamically. Accessing Network-Attached Storage Mount and unmount an NFS export from the command line. Configure an NFS export to automatically mount at startup. Configure the automounter with direct and indirect maps, and describe their differences. Controlling the Boot Process systemctl reboot and systemctl poweroff reboot and power down a system, respectively. systemctl isolate target-name .target switches to a new target at runtime. systemctl get-default and systemctl set-default can be used to query and set the default target. Use rd.break on the kernel command line to interrupt the boot process before control is handed over from the initramfs . The root file system is mounted read-only under /sysroot . The emergency target can be used to diagnose and fix file-system issues. Managing Network Security The netfilter subsystem allows kernel modules to inspect every packet traversing the system. All incoming, outgoing or forwarded network packets are inspected. The use of firewalld has simplified management by classifying all network traffic into zones. Each zone has its own list of ports and services. The public zone is set as the default zone. The firewalld service ships with a number of pre-defined services. They can be listed using the firewall-cmd --get-services command. Network traffic is tightly controlled by the SELinux policy. Network ports are labeled. For example, port 22/TCP has the label ssh_port_t associated with it. When a process wants to listen on a port, SELinux checks to see whether the label associated with it is allowed to bind that port label. The semanage command is used to add, delete, and modify labels. Managing Virtual Machines with Cockpit Required package name : cockpit-machines Install the cockpit-machines package to add the Virtual Machines menu to Cockpit. [ root@host ~ ] # yum install cockpit-machines If Cockpit is not already running, start and enable it. [ root@host ~ ] # systemctl enable --now cockpit.socket Containers Containers provide a lightweight way to distribute and run an application and its dependencies that may conflict with software installed on the host. Containers run from container images that you can download from a container registry or create yourself. Podman, provided by Red Hat Enterprise Linux, directly runs and manages containers and container images on a single host. Containers can be run as root , or as non-privileged rootless containers for increased security. You can map network ports on the container host to pass traffic to services running in its containers. You can also use environment variables to configure the software in containers. Container storage is temporary, but you can attach persistent storage to a container using the contents of a directory on the container host, for example. You can configure Systemd to automatically run containers when the system starts up. Red Hat Enterprise Linux implements Linux Containers using core technologies such as Control Groups (Cgroups) for Resource Management, Namespaces for Process Isolation, SELinux for Security , enabling secure multi-tenancy and reducing the risk of security exploits.","title":"Red Hat System Administration II"},{"location":"linux/rhel-sysadmin-II/#red-hat-system-administration-ii","text":"","title":"Red Hat System Administration II"},{"location":"linux/rhel-sysadmin-II/#tuning-system-performance","text":"** ` tuned-adm list ` ** Available profiles: - balanced - desktop - latency-performance - network-latency - network-throughput - powersave - sap - throughput-performance - virtual-guest - virtual-host","title":"Tuning System Performance"},{"location":"linux/rhel-sysadmin-II/#profiles-distributed-with-rhel-8","text":"Tuned Profile Purpose balanced Ideal for systems that require a compromise between power saving and performance. desktop Derived from the balanced profile. Provides faster response of interactive applications. throughput-performance Tunes the system for maximum throughput. latency-performance Ideal for server systems that require low latency at the expense of power consumption. network-latency Derived from the latency-performance profile. It enables additional network tuning parameters to provide low network latency. network-throughput Derived from the throughput-performance profile. Additional network tuning parameters are applied for maximum network throughput. powersave Tunes the system for maximum power saving. oracle Optimized for Oracle database loads based on the throughput-performance profile. virtual-guest Tunes the system for maximum performance if it runs on a virtual machine. virtual-host Tunes the system for maximum performance if it acts as a host for virtual machines. The tuned service automatically modifies device settings to meet specific system needs based on a pre-defined selected tuning profile. To revert all changes made to system settings by a selected profile, either switch to another profile or deactivate the tuned service. The system assigns a relative priority to a process to determine its CPU access. This priority is called the nice value of a process. The nice command assigns a priority to a process when it starts. The renice command modifies the priority of a running process.","title":"Profiles Distributed with Rhel 8"},{"location":"linux/rhel-sysadmin-II/#access-control-lists","text":"ACLs provide fine-grained access control to files and directories. The getfacl command displays the ACLs on a file or directory. The setfacl command sets, modifies, and removes default and standard ACLs on files and directories. Use default ACLs for controlling new files and directories permissions. Red Hat Enterprise Linux uses systemd and udev to apply predefined ACLs on devices, folders, and files.","title":"Access Control Lists"},{"location":"linux/rhel-sysadmin-II/#managing-selinux-security","text":"The getenforce and setenforce commands are used to manage the SELinux mode of a system. The semanage command is used to manage SELinux policy rules. The restorecon command applies the context defined by the policy. Booleans are switches that change the behavior of the SELinux policy. They can be enabled or disabled and are used to tune the policy. The sealert displays useful information to help with SELinux troubleshooting.","title":"Managing SELinux Security"},{"location":"linux/rhel-sysadmin-II/#managing-storage","text":"","title":"Managing Storage"},{"location":"linux/rhel-sysadmin-II/#basic","text":"You use the parted command to add, modify, and remove partitions on disks with the MBR or the GPT partitioning scheme. You use the mkfs.xfs command to create XFS file systems on disk partitions. You need to add file-system mount commands to /etc/fstab to make those mounts persistent. You use the mkswap command to initialize swap spaces.","title":"Basic"},{"location":"linux/rhel-sysadmin-II/#advanced","text":"The Stratis storage management solution implements flexible file systems that grow dynamically with data. The Stratis storage management solution supports thin provisioning, snapshotting, and monitoring. The Virtual Data Optimizer (VDO) aims to reduce the cost of data storage. The Virtual Data Optimizer applies zero-block elimination, data deduplication, and data compression to optimize disk space efficiency. title: pool list max number file supported You can create multiple pools from different storage devices. From each pool, you can create one or more file systems. Currently, you can create up to **2^24** file systems per pool.","title":"Advanced"},{"location":"linux/rhel-sysadmin-II/#managing-logical-volumes","text":"Allows you to create flexible storage by allocating space on multiple storage devices. Physical volumes, volume groups, and logical volumes are managed by a variety of tools such as pvcreate , vgreduce , and lvextend . Logical volumes can be formatted with a file system or swap space, and they can be mounted persistently. Additional storage can be added to volume groups and logical volumes can be extended dynamically.","title":"Managing Logical Volumes"},{"location":"linux/rhel-sysadmin-II/#accessing-network-attached-storage","text":"Mount and unmount an NFS export from the command line. Configure an NFS export to automatically mount at startup. Configure the automounter with direct and indirect maps, and describe their differences.","title":"Accessing Network-Attached Storage"},{"location":"linux/rhel-sysadmin-II/#controlling-the-boot-process","text":"systemctl reboot and systemctl poweroff reboot and power down a system, respectively. systemctl isolate target-name .target switches to a new target at runtime. systemctl get-default and systemctl set-default can be used to query and set the default target. Use rd.break on the kernel command line to interrupt the boot process before control is handed over from the initramfs . The root file system is mounted read-only under /sysroot . The emergency target can be used to diagnose and fix file-system issues.","title":"Controlling the Boot Process"},{"location":"linux/rhel-sysadmin-II/#managing-network-security","text":"The netfilter subsystem allows kernel modules to inspect every packet traversing the system. All incoming, outgoing or forwarded network packets are inspected. The use of firewalld has simplified management by classifying all network traffic into zones. Each zone has its own list of ports and services. The public zone is set as the default zone. The firewalld service ships with a number of pre-defined services. They can be listed using the firewall-cmd --get-services command. Network traffic is tightly controlled by the SELinux policy. Network ports are labeled. For example, port 22/TCP has the label ssh_port_t associated with it. When a process wants to listen on a port, SELinux checks to see whether the label associated with it is allowed to bind that port label. The semanage command is used to add, delete, and modify labels.","title":"Managing Network Security"},{"location":"linux/rhel-sysadmin-II/#managing-virtual-machines-with-cockpit","text":"Required package name : cockpit-machines Install the cockpit-machines package to add the Virtual Machines menu to Cockpit. [ root@host ~ ] # yum install cockpit-machines If Cockpit is not already running, start and enable it. [ root@host ~ ] # systemctl enable --now cockpit.socket","title":"Managing Virtual Machines with Cockpit"},{"location":"linux/rhel-sysadmin-II/#containers","text":"Containers provide a lightweight way to distribute and run an application and its dependencies that may conflict with software installed on the host. Containers run from container images that you can download from a container registry or create yourself. Podman, provided by Red Hat Enterprise Linux, directly runs and manages containers and container images on a single host. Containers can be run as root , or as non-privileged rootless containers for increased security. You can map network ports on the container host to pass traffic to services running in its containers. You can also use environment variables to configure the software in containers. Container storage is temporary, but you can attach persistent storage to a container using the contents of a directory on the container host, for example. You can configure Systemd to automatically run containers when the system starts up. Red Hat Enterprise Linux implements Linux Containers using core technologies such as Control Groups (Cgroups) for Resource Management, Namespaces for Process Isolation, SELinux for Security , enabling secure multi-tenancy and reducing the risk of security exploits.","title":"Containers"},{"location":"linux/root-rescue/","text":"Emergency Grub Reach the grub and chose the first line Use 'e' to edit Go to the \"vmlinux\" line to add ' rd.break' at the end (This change is temporary) Press 'CTRL+x' to exit an run it Rescue Send a Ctrl+Alt+Del to your system using the relevant button or menu entry. When the boot-loader menu appears, press any key to interrupt the countdown, except Enter. Use the cursor keys to highlight the default boot loader entry. Press e to edit the current entry. Use the cursor keys to navigate to the line that starts with linux. Press End to move the cursor to the end of the line. Append rd.break to the end of the line. Press Ctrl+x to boot using the modified configuration. At the switch_root prompt, remount the /sysroot file system read/write, then use chroot to go into a chroot jail at /sysroot. switch_root:/# mount -o remount,rw /sysroot switch_root:/# chroot /sysroot Set the root password to redhat. sh-4.4# passwd root Changing password for user root. New password: redhat BAD PASSWORD: The password is shorter than 8 characters Retype new password: redhat passwd: all authentication tokens updated successfully. Configure the system to automatically perform a full SELinux relabel after boot. sh-4.4# touch /.autorelabel Type exit twice to continue booting your system. The system fails to boot because of an issue you resolve in the next step. Selinux \u26a0 Make sure SELinux allows the file changed touch .autorelabel This will signal SELinux on the next reboot that the filesystem has changed (the changed password) and allow the change to be loaded. Type 'exit' then 'reboot'","title":"Emergency"},{"location":"linux/root-rescue/#emergency","text":"","title":"Emergency"},{"location":"linux/root-rescue/#grub","text":"Reach the grub and chose the first line Use 'e' to edit Go to the \"vmlinux\" line to add ' rd.break' at the end (This change is temporary) Press 'CTRL+x' to exit an run it","title":"Grub"},{"location":"linux/root-rescue/#rescue","text":"Send a Ctrl+Alt+Del to your system using the relevant button or menu entry. When the boot-loader menu appears, press any key to interrupt the countdown, except Enter. Use the cursor keys to highlight the default boot loader entry. Press e to edit the current entry. Use the cursor keys to navigate to the line that starts with linux. Press End to move the cursor to the end of the line. Append rd.break to the end of the line. Press Ctrl+x to boot using the modified configuration. At the switch_root prompt, remount the /sysroot file system read/write, then use chroot to go into a chroot jail at /sysroot. switch_root:/# mount -o remount,rw /sysroot switch_root:/# chroot /sysroot Set the root password to redhat. sh-4.4# passwd root Changing password for user root. New password: redhat BAD PASSWORD: The password is shorter than 8 characters Retype new password: redhat passwd: all authentication tokens updated successfully. Configure the system to automatically perform a full SELinux relabel after boot. sh-4.4# touch /.autorelabel Type exit twice to continue booting your system. The system fails to boot because of an issue you resolve in the next step.","title":"Rescue"},{"location":"linux/root-rescue/#selinux","text":"\u26a0 Make sure SELinux allows the file changed touch .autorelabel This will signal SELinux on the next reboot that the filesystem has changed (the changed password) and allow the change to be loaded. Type 'exit' then 'reboot'","title":"Selinux"},{"location":"linux/sar/","text":"SAR On trouvera les fichier de log de l'outil sysstat dans : /var/log/sysstat/ Chacun des fichier dans ce dossier sera norm\u00e9 par sa$JOUR_DU_MOIS . Liste des param\u00e8tres : S : swap r : RAM R : Caches u : Utilisateur","title":"SAR"},{"location":"linux/sar/#sar","text":"On trouvera les fichier de log de l'outil sysstat dans : /var/log/sysstat/ Chacun des fichier dans ce dossier sera norm\u00e9 par sa$JOUR_DU_MOIS . Liste des param\u00e8tres : S : swap r : RAM R : Caches u : Utilisateur","title":"SAR"},{"location":"linux/screen/","text":"Touchscreen How to disable touchscreen at start ? Create a new file as /etc/X11/xorg.conf.d/01-no_touchscreen.conf as 664 : ## Written by systemd-localed(8), read by systemd-localed and Xorg. Its ## probably wise not to edit this file manually. use localectl(1) to ## instruct systemd-localed to update it Section \"InputClass\" Identifier \"Raydium catchall\" MatchIsTouchscreen \"on\" Option \"Ignore\" \"on\" EndSection Using command line : xinput disable $( xinput list | awk '/Touchscreen/ {print $5}' | cut -d \"=\" -f2 ) Blank Screen logind est le composant en charge de la gestion des sessions sur les syst\u00e8mes avec systemd. Il d\u00e9termine le comportement d\u2019un ordinateur portable lorsque l\u2019on ferme l\u2019\u00e9cran (Lid Switch) via la variable HandleLidSwitch de son fichier de configuration : /etc/systemd/logind.conf . Sa valeur par d\u00e9faut est suspend (mise en veille). Les valeurs accept\u00e9es pour la variable HandleLidSwitch: ignore (ne fait rien) poweroff (arr\u00eat) reboot (red\u00e9marrage) halt (arr\u00eat) kexec suspend (veille, le comportement par d\u00e9faut) hibernate (hibernation) hybrid-sleep (hibernation avec conservation des donn\u00e9es en m\u00e9moire) lock (Verrouille de la session) Donc si je souhaite que mon portable reste actif lorsque l\u2019\u00e9cran est ferm\u00e9: vim /etc/systemd/logind.conf Puis on modifie le param\u00e8tre HandleLidSwitch de cette fa\u00e7on: #HandleLidSwitch=suspend devient HandleLidSwitch = ignore Et on termine par un petit red\u00e9marrage: reboot Retirer la mise en veille lors de la fermeture du capot de l\u2019ordinateur portable. setterm-powersave off -blank 0 systemctl mask sleep.target suspend.target hibernate.target hybrid-sleep.target","title":"Touchscreen"},{"location":"linux/screen/#touchscreen","text":"How to disable touchscreen at start ? Create a new file as /etc/X11/xorg.conf.d/01-no_touchscreen.conf as 664 : ## Written by systemd-localed(8), read by systemd-localed and Xorg. Its ## probably wise not to edit this file manually. use localectl(1) to ## instruct systemd-localed to update it Section \"InputClass\" Identifier \"Raydium catchall\" MatchIsTouchscreen \"on\" Option \"Ignore\" \"on\" EndSection Using command line : xinput disable $( xinput list | awk '/Touchscreen/ {print $5}' | cut -d \"=\" -f2 )","title":"Touchscreen"},{"location":"linux/screen/#blank-screen","text":"logind est le composant en charge de la gestion des sessions sur les syst\u00e8mes avec systemd. Il d\u00e9termine le comportement d\u2019un ordinateur portable lorsque l\u2019on ferme l\u2019\u00e9cran (Lid Switch) via la variable HandleLidSwitch de son fichier de configuration : /etc/systemd/logind.conf . Sa valeur par d\u00e9faut est suspend (mise en veille). Les valeurs accept\u00e9es pour la variable HandleLidSwitch: ignore (ne fait rien) poweroff (arr\u00eat) reboot (red\u00e9marrage) halt (arr\u00eat) kexec suspend (veille, le comportement par d\u00e9faut) hibernate (hibernation) hybrid-sleep (hibernation avec conservation des donn\u00e9es en m\u00e9moire) lock (Verrouille de la session) Donc si je souhaite que mon portable reste actif lorsque l\u2019\u00e9cran est ferm\u00e9: vim /etc/systemd/logind.conf Puis on modifie le param\u00e8tre HandleLidSwitch de cette fa\u00e7on: #HandleLidSwitch=suspend devient HandleLidSwitch = ignore Et on termine par un petit red\u00e9marrage: reboot Retirer la mise en veille lors de la fermeture du capot de l\u2019ordinateur portable. setterm-powersave off -blank 0 systemctl mask sleep.target suspend.target hibernate.target hybrid-sleep.target","title":"Blank Screen"},{"location":"linux/selinux/","text":"Selinux Basic SELinux security concepts SELinux is a set of security rules that determine which process can access which files, directories, and ports. Every file, process, directory, and port has a special security label called an SELinux context. A context is a name used by the SELinux policy to determine whether a process can access a file, directory, or port. By default, the policy does not allow any interaction unless an explicit rule grants access. If there is no allow rule, no access is allowed. SELinux labels have several contexts: user role type sensitivity The targeted policy, which is the default policy enabled in Red Hat Enterprise Linux, bases its rules on the third context: the type context usually named end with _t . Setting the default SELinux mode You can also configure SELinux persistently using the /etc/selinux/config file. In the example below (the default configuration), the configuration file sets SELinux to enforcing. The comments also show the other valid values: permissive and disabled. # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX = enforcing # SELINUXTYPE= can take one of these two values: # targeted - Targeted processes are protected, # minimum - Modification of targeted policy. Only selected processes # are protected. # mls - Multi Level Security protection. SELINUXTYPE = targeted The system reads this file at boot time and configures SELinux as shown. Kernel arguments ( selinux=0|1 and enforcing=0|1 ) override this configuration. Changing the current SELinux mode The SELinux subsystem provides tools to display and change modes. To determine the current SELinux mode, run the getenforce command. To set SELinux to a different mode, use the setenforce command: [ user@host ~ ] # getenforce Enforcing [ user@host ~ ] # setenforce usage: setenforce [ Enforcing | Permissive | 1 | 0 ] [ user@host ~ ] # setenforce 0 [ user@host ~ ] # getenforce Permissive [ user@host ~ ] # setenforce Enforcing [ user@host ~ ] # getenforce Enforcing Alternatively, you can set the SELinux mode at boot time by passing a parameter to the kernel: the kernel argument of enforcing=0 boots the system into permissive mode; a value of enforcing=1 sets enforcing mode. You can also disable SELinux completely by passing on the kernel parameter selinux=0. A value of selinux=1 enables SELinux. Basic file context operations To ensure that you have the tools to manage SELinux contexts, install these packages : policycoreutils policycoreutils-python These contain the restorecon command and semanage command, respectively. To ensure that all files in a directory have the correct file context run the semanage fcontext -l followed by the restorecon command. In the following example, note the file context of each file before and after the semanage and restorecon commands run. [ root@host ~ ] # ls -Z /var/www/html/file* unconfined_u:object_r:user_tmp_t:s0 /var/www/html/file1 unconfined_u:object_r:httpd_sys_content_t:s0 /var/www/html/file2 [ root@host ~ ] # semanage fcontext -l ...output omitted... /var/www ( /.* ) ? all files system_u:object_r:httpd_sys_content_t:s0 ...output omitted... [ root@host ; ~ ] # restorecon -Rv /var/www/ Relabeled /var/www/html/file1 from unconfined_u:object_r:user_tmp_t:s0 to unconfined_u:object_r:httpd_sys_content_t:s0 [ root@host ~ ] # ls -Z /var/www/html/file* unconfined_u:object_r:httpd_sys_content_t:s0 /var/www/html/file1 unconfined_u:object_r:httpd_sys_content_t:s0 /var/www/html/file2 The following example shows how to use semanage to add a context for a new directory. [ root@host ~ ] # mkdir /virtual [ root@host ~ ] # touch /virtual/index.html [ root@host ~ ] # ls -Zd /virtual/ drwxr-xr-x. root root unconfined_u:object_r:default_t:s0 /virtual/ [ root@host ~ ] # ls -Z /virtual/ -rw-r--r--. root root unconfined_u:object_r:default_t:s0 index.html [ root@host ~ ] # semanage fcontext -a -t httpd_sys_content_t '/virtual(/.*)?' [ root@host ~ ] # restorecon -RFvv /virtual [ root@host ~ ] # ls -Zd /virtual/ drwxr-xr-x. root root system_u:object_r:httpd_sys_content_t:s0 /virtual/ [ root@host ~ ] # ls -Z /virtual/ -rw-r--r--. root root system_u:object_r:httpd_sys_content_t:s0 index.html","title":"Selinux"},{"location":"linux/selinux/#selinux","text":"","title":"Selinux"},{"location":"linux/selinux/#basic-selinux-security-concepts","text":"SELinux is a set of security rules that determine which process can access which files, directories, and ports. Every file, process, directory, and port has a special security label called an SELinux context. A context is a name used by the SELinux policy to determine whether a process can access a file, directory, or port. By default, the policy does not allow any interaction unless an explicit rule grants access. If there is no allow rule, no access is allowed. SELinux labels have several contexts: user role type sensitivity The targeted policy, which is the default policy enabled in Red Hat Enterprise Linux, bases its rules on the third context: the type context usually named end with _t .","title":"Basic SELinux security concepts"},{"location":"linux/selinux/#setting-the-default-selinux-mode","text":"You can also configure SELinux persistently using the /etc/selinux/config file. In the example below (the default configuration), the configuration file sets SELinux to enforcing. The comments also show the other valid values: permissive and disabled. # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX = enforcing # SELINUXTYPE= can take one of these two values: # targeted - Targeted processes are protected, # minimum - Modification of targeted policy. Only selected processes # are protected. # mls - Multi Level Security protection. SELINUXTYPE = targeted The system reads this file at boot time and configures SELinux as shown. Kernel arguments ( selinux=0|1 and enforcing=0|1 ) override this configuration.","title":"Setting the default SELinux mode"},{"location":"linux/selinux/#changing-the-current-selinux-mode","text":"The SELinux subsystem provides tools to display and change modes. To determine the current SELinux mode, run the getenforce command. To set SELinux to a different mode, use the setenforce command: [ user@host ~ ] # getenforce Enforcing [ user@host ~ ] # setenforce usage: setenforce [ Enforcing | Permissive | 1 | 0 ] [ user@host ~ ] # setenforce 0 [ user@host ~ ] # getenforce Permissive [ user@host ~ ] # setenforce Enforcing [ user@host ~ ] # getenforce Enforcing Alternatively, you can set the SELinux mode at boot time by passing a parameter to the kernel: the kernel argument of enforcing=0 boots the system into permissive mode; a value of enforcing=1 sets enforcing mode. You can also disable SELinux completely by passing on the kernel parameter selinux=0. A value of selinux=1 enables SELinux.","title":"Changing the current SELinux mode"},{"location":"linux/selinux/#basic-file-context-operations","text":"To ensure that you have the tools to manage SELinux contexts, install these packages : policycoreutils policycoreutils-python These contain the restorecon command and semanage command, respectively. To ensure that all files in a directory have the correct file context run the semanage fcontext -l followed by the restorecon command. In the following example, note the file context of each file before and after the semanage and restorecon commands run. [ root@host ~ ] # ls -Z /var/www/html/file* unconfined_u:object_r:user_tmp_t:s0 /var/www/html/file1 unconfined_u:object_r:httpd_sys_content_t:s0 /var/www/html/file2 [ root@host ~ ] # semanage fcontext -l ...output omitted... /var/www ( /.* ) ? all files system_u:object_r:httpd_sys_content_t:s0 ...output omitted... [ root@host ; ~ ] # restorecon -Rv /var/www/ Relabeled /var/www/html/file1 from unconfined_u:object_r:user_tmp_t:s0 to unconfined_u:object_r:httpd_sys_content_t:s0 [ root@host ~ ] # ls -Z /var/www/html/file* unconfined_u:object_r:httpd_sys_content_t:s0 /var/www/html/file1 unconfined_u:object_r:httpd_sys_content_t:s0 /var/www/html/file2 The following example shows how to use semanage to add a context for a new directory. [ root@host ~ ] # mkdir /virtual [ root@host ~ ] # touch /virtual/index.html [ root@host ~ ] # ls -Zd /virtual/ drwxr-xr-x. root root unconfined_u:object_r:default_t:s0 /virtual/ [ root@host ~ ] # ls -Z /virtual/ -rw-r--r--. root root unconfined_u:object_r:default_t:s0 index.html [ root@host ~ ] # semanage fcontext -a -t httpd_sys_content_t '/virtual(/.*)?' [ root@host ~ ] # restorecon -RFvv /virtual [ root@host ~ ] # ls -Zd /virtual/ drwxr-xr-x. root root system_u:object_r:httpd_sys_content_t:s0 /virtual/ [ root@host ~ ] # ls -Z /virtual/ -rw-r--r--. root root system_u:object_r:httpd_sys_content_t:s0 index.html","title":"Basic file context operations"},{"location":"linux/service/","text":"Service Systemctl How to list enabled unit-file. systemctl list-unit-files | grep enabled","title":"Service"},{"location":"linux/service/#service","text":"","title":"Service"},{"location":"linux/service/#systemctl","text":"How to list enabled unit-file. systemctl list-unit-files | grep enabled","title":"Systemctl"},{"location":"linux/smtp/","text":"SMTP Troubleshooting TLS Prepare encoded strings for your mail username and password echo -ne \"mail@example.net\" | base64 Connect to mail server openssl s_client -starttls smtp -connect smtp.example.com:587 Send HELO EHLO Authenticate AUTH LOGIN <your-encoded-username> <your-encoded-password> If that's successful the mail server should return 235 2.7.0 Authentication successful .","title":"SMTP"},{"location":"linux/smtp/#smtp","text":"","title":"SMTP"},{"location":"linux/smtp/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"linux/smtp/#tls","text":"Prepare encoded strings for your mail username and password echo -ne \"mail@example.net\" | base64 Connect to mail server openssl s_client -starttls smtp -connect smtp.example.com:587 Send HELO EHLO Authenticate AUTH LOGIN <your-encoded-username> <your-encoded-password> If that's successful the mail server should return 235 2.7.0 Authentication successful .","title":"TLS"},{"location":"linux/stratis/","text":"Describing the Architecture of Stratis Stratis is a new local storage-management solution for Linux. Stratis is designed to make it easier to perform initial configuration of storage, make changes to the storage configuration, and use advanced storage features. Stratis runs as a service that manages pools of physical storage devices and transparently creates and manages volumes for the newly created file systems. In Stratis, file systems are built from shared pools of disk devices using a concept known as thin provisioning. You can create multiple pools from different storage devices. From each pool, you can create one or more file systems. Currently, you can create up to 224 file systems per pool. The components that make up a Stratis-managed file system are built from standard Linux components. Internally, Stratis is implemented using the Device Mapper infrastructure that is also used to implement LVM , and Stratis-managed file systems are formatted using XFS . The following diagram illustrates how the elements of the Stratis storage management solution are assembled. Block storage devices such as hard disks or SSDs are assigned to pools, each contributing some physical storage to the pool. File systems are created from the pools, and physical storage is mapped to each file system as it is needed. Working with Stratis Storage To manage file systems with the Stratis storage management solution, install theses packages : stratis-cli stratisd packages The stratis-cli package provides the stratis command, which sends reconfiguration requests to the stratisd system daemon. The stratisd package provides the stratisd service, which handles reconfiguration requests and manages and monitors block devices, pools, and file systems that Stratis uses. Installing and Enabling Stratis To use Stratis, make sure that the software is installed and the stratisd service is running. Install stratis-cli and stratisd using the yum install command [ root@host ~ ] # yum install stratis-cli stratisd ...output omitted... Is this ok [ y/N ] : y ...output omitted... Complete! Activate the stratisd service using the systemctl command. [ root@host ~ ] # systemctl enable --now stratisd Assembling Block Storage into Stratis Pools The following are common management operations performed using the Stratis storage management solution. Create pools of one or more block devices using the stratis pool create command. [ root@host ~ ] # stratis pool create pool1 /dev/vdb Each pool is a subdirectory under the /stratis directory. Use the stratis pool list command to view the list of available pools. [ root@host ~ ] # stratis pool list Name Total Physical Size Total Physical Used pool1 5 GiB 52 MiB Warning The stratis pool list command is very important because it shows you how much storage space is in use (and therefore how much is still available) in the pools. If a pool runs out of storage, further data written to file systems belonging to that pool is quietly lost. Use the stratis pool add-data command to add additional block devices to a pool. [ root@host ~ ] # stratis pool add-data pool1 /dev/vdc Use the stratis blockdev list command to view the block devices of a pool. [ root@host ~ ] # stratis blockdev list pool1 Pool Name Device Node Physical Size State Tier pool1 /dev/vdb 5 GiB In-use Data pool1 /dev/vdc 5 GiB In-use Data Managing Stratis File Systems Use the stratis filesystem create command to create a file system from a pool. [ root@host ~ ] # stratis filesystem create pool1 fs1 The links to the Stratis file systems are in the /stratis/pool1 directory. Use the stratis filesystem list command to view the list of available file systems. [ root@host ~ ] # stratis filesystem list Pool Name Name Used Created Device UUID pool1 fs1 546 MiB Sep 23 2020 13 :11 /stratis/pool1/fs1 31b9363badd... Use stratis pool list to monitor the remaining real storage available to the Stratis pools. You can create a snapshot of a Stratis-managed file system with the stratis filesystem snapshot command Snapshots are independent of the source file systems. [ root@host ~ ] # stratis filesystem snapshot pool1 fs1 snapshot1 Persistently Mounting Stratis File Systems To ensure that the Stratis file systems are persistently mounted, edit /etc/fstab and specify the details of the file system. The following command displays the UUID of the file system that you should use in /etc/fstab to identify the file system. [ root@host ~ ] # lsblk --output=UUID /stratis/pool1/fs1 UUID 31b9363.................478c55 The following is an example entry in the /etc/fstab file to persistently mount a Stratis file system. This example entry is a single long line in the file. UUID = 31b9363b-add8-4b46-a4bf-c199cd478c55 /dir1 xfs defaults,x-systemd.requires = stratisd.service 0 0 The x-systemd.requires=stratisd.service mount option delays mounting the file system until after systemd starts the stratisd.service during the boot process. References Red Hat System Administration II","title":"Describing the Architecture of Stratis"},{"location":"linux/stratis/#describing-the-architecture-of-stratis","text":"Stratis is a new local storage-management solution for Linux. Stratis is designed to make it easier to perform initial configuration of storage, make changes to the storage configuration, and use advanced storage features. Stratis runs as a service that manages pools of physical storage devices and transparently creates and manages volumes for the newly created file systems. In Stratis, file systems are built from shared pools of disk devices using a concept known as thin provisioning. You can create multiple pools from different storage devices. From each pool, you can create one or more file systems. Currently, you can create up to 224 file systems per pool. The components that make up a Stratis-managed file system are built from standard Linux components. Internally, Stratis is implemented using the Device Mapper infrastructure that is also used to implement LVM , and Stratis-managed file systems are formatted using XFS . The following diagram illustrates how the elements of the Stratis storage management solution are assembled. Block storage devices such as hard disks or SSDs are assigned to pools, each contributing some physical storage to the pool. File systems are created from the pools, and physical storage is mapped to each file system as it is needed.","title":"Describing the Architecture of Stratis"},{"location":"linux/stratis/#working-with-stratis-storage","text":"To manage file systems with the Stratis storage management solution, install theses packages : stratis-cli stratisd packages The stratis-cli package provides the stratis command, which sends reconfiguration requests to the stratisd system daemon. The stratisd package provides the stratisd service, which handles reconfiguration requests and manages and monitors block devices, pools, and file systems that Stratis uses.","title":"Working with Stratis Storage"},{"location":"linux/stratis/#installing-and-enabling-stratis","text":"To use Stratis, make sure that the software is installed and the stratisd service is running. Install stratis-cli and stratisd using the yum install command [ root@host ~ ] # yum install stratis-cli stratisd ...output omitted... Is this ok [ y/N ] : y ...output omitted... Complete! Activate the stratisd service using the systemctl command. [ root@host ~ ] # systemctl enable --now stratisd","title":"Installing and Enabling Stratis"},{"location":"linux/stratis/#assembling-block-storage-into-stratis-pools","text":"The following are common management operations performed using the Stratis storage management solution. Create pools of one or more block devices using the stratis pool create command. [ root@host ~ ] # stratis pool create pool1 /dev/vdb Each pool is a subdirectory under the /stratis directory. Use the stratis pool list command to view the list of available pools. [ root@host ~ ] # stratis pool list Name Total Physical Size Total Physical Used pool1 5 GiB 52 MiB Warning The stratis pool list command is very important because it shows you how much storage space is in use (and therefore how much is still available) in the pools. If a pool runs out of storage, further data written to file systems belonging to that pool is quietly lost. Use the stratis pool add-data command to add additional block devices to a pool. [ root@host ~ ] # stratis pool add-data pool1 /dev/vdc Use the stratis blockdev list command to view the block devices of a pool. [ root@host ~ ] # stratis blockdev list pool1 Pool Name Device Node Physical Size State Tier pool1 /dev/vdb 5 GiB In-use Data pool1 /dev/vdc 5 GiB In-use Data","title":"Assembling Block Storage into Stratis Pools"},{"location":"linux/stratis/#managing-stratis-file-systems","text":"Use the stratis filesystem create command to create a file system from a pool. [ root@host ~ ] # stratis filesystem create pool1 fs1 The links to the Stratis file systems are in the /stratis/pool1 directory. Use the stratis filesystem list command to view the list of available file systems. [ root@host ~ ] # stratis filesystem list Pool Name Name Used Created Device UUID pool1 fs1 546 MiB Sep 23 2020 13 :11 /stratis/pool1/fs1 31b9363badd... Use stratis pool list to monitor the remaining real storage available to the Stratis pools. You can create a snapshot of a Stratis-managed file system with the stratis filesystem snapshot command Snapshots are independent of the source file systems. [ root@host ~ ] # stratis filesystem snapshot pool1 fs1 snapshot1","title":"Managing Stratis File Systems"},{"location":"linux/stratis/#persistently-mounting-stratis-file-systems","text":"To ensure that the Stratis file systems are persistently mounted, edit /etc/fstab and specify the details of the file system. The following command displays the UUID of the file system that you should use in /etc/fstab to identify the file system. [ root@host ~ ] # lsblk --output=UUID /stratis/pool1/fs1 UUID 31b9363.................478c55 The following is an example entry in the /etc/fstab file to persistently mount a Stratis file system. This example entry is a single long line in the file. UUID = 31b9363b-add8-4b46-a4bf-c199cd478c55 /dir1 xfs defaults,x-systemd.requires = stratisd.service 0 0 The x-systemd.requires=stratisd.service mount option delays mounting the file system until after systemd starts the stratisd.service during the boot process.","title":"Persistently Mounting Stratis File Systems"},{"location":"linux/stratis/#references","text":"Red Hat System Administration II","title":"References"},{"location":"linux/time/","text":"Clock How to mod sys clock ? mv /etc/localtime /etc/localtime.backup ln -s /usr/share/zoneinfo/Europe/Paris /etc/localtime echo \"Europe/Paris\" | tee /etc/timezone timedatectl set-timezone Europe/Paris hwclock -s","title":"Clock"},{"location":"linux/time/#clock","text":"How to mod sys clock ? mv /etc/localtime /etc/localtime.backup ln -s /usr/share/zoneinfo/Europe/Paris /etc/localtime echo \"Europe/Paris\" | tee /etc/timezone timedatectl set-timezone Europe/Paris hwclock -s","title":"Clock"},{"location":"linux/vim/","text":"VIM D\u00e9but ou fin de fichier : Go to the top : gg Go to the buttom : G Descendre \u00e0 la ligne 34 : 34 G D\u00e9but ou fin de ligne : Fin de la ligne o\u00f9 se trouve le dernier carract\u00e8re : $ D\u00e9but de la ligne o\u00f9 se trouve le premier carract\u00e8re : 0 (shift+\u00e0) Dans vim : :%s /foo/newfoo/g Tooling Sed Faire du sed dans vim :%s /foo/newfoo/g ` Highlithing Word Retirer le surlignage : :noh","title":"VIM"},{"location":"linux/vim/#vim","text":"D\u00e9but ou fin de fichier : Go to the top : gg Go to the buttom : G Descendre \u00e0 la ligne 34 : 34 G D\u00e9but ou fin de ligne : Fin de la ligne o\u00f9 se trouve le dernier carract\u00e8re : $ D\u00e9but de la ligne o\u00f9 se trouve le premier carract\u00e8re : 0 (shift+\u00e0) Dans vim : :%s /foo/newfoo/g","title":"VIM"},{"location":"linux/vim/#tooling","text":"","title":"Tooling"},{"location":"linux/vim/#sed","text":"Faire du sed dans vim :%s /foo/newfoo/g `","title":"Sed"},{"location":"linux/vim/#highlithing-word","text":"Retirer le surlignage : :noh","title":"Highlithing Word"},{"location":"linux/web/","text":"Web lamp Apache check config : /opt/lampp/bin/httpd -t Apache restart : /opt/lampp/bin/httpd -k restart Postfix Basic postfix configuration /etc/postfix/main.cf : relayhost = [ smtp.gmail.com ] :587 smtp_sasl_auth_enable = yes smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd smtp_sasl_security_options = noanonymous","title":"Web"},{"location":"linux/web/#web","text":"","title":"Web"},{"location":"linux/web/#lamp","text":"Apache check config : /opt/lampp/bin/httpd -t Apache restart : /opt/lampp/bin/httpd -k restart","title":"lamp"},{"location":"linux/web/#postfix","text":"Basic postfix configuration /etc/postfix/main.cf : relayhost = [ smtp.gmail.com ] :587 smtp_sasl_auth_enable = yes smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd smtp_sasl_security_options = noanonymous","title":"Postfix"},{"location":"mac/cheatsheet/","text":"CheatSheet Just hold the \u2318-Key a bit longer to get a list of all active shortcuts of the current application. It's as simple as that. Download page More : mac tooltips","title":"CheatSheet"},{"location":"mac/cheatsheet/#cheatsheet","text":"Just hold the \u2318-Key a bit longer to get a list of all active shortcuts of the current application. It's as simple as that. Download page More : mac tooltips","title":"CheatSheet"},{"location":"mac/clipboard-manager/","text":"Clipboard Manager How to copy from terminal using pbcopy ? echo \"Hello Word!\" | pbcopy How to paste ? ~ $ pbpaste Tue Dec 27 15 :41:22 CET 2022 Maccy Maccy is a lightweight clipboard manager for macOS. It keeps the history of what you copy and lets you quickly navigate, search, and use previous clipboard contents. Repository link : https://github.com/p0deje/Maccy Installation : brew install --cask maccy","title":"Clipboard Manager"},{"location":"mac/clipboard-manager/#clipboard-manager","text":"How to copy from terminal using pbcopy ? echo \"Hello Word!\" | pbcopy How to paste ? ~ $ pbpaste Tue Dec 27 15 :41:22 CET 2022","title":"Clipboard Manager"},{"location":"mac/clipboard-manager/#maccy","text":"Maccy is a lightweight clipboard manager for macOS. It keeps the history of what you copy and lets you quickly navigate, search, and use previous clipboard contents. Repository link : https://github.com/p0deje/Maccy Installation : brew install --cask maccy","title":"Maccy"},{"location":"mac/dock/","text":"Dock Space How to add space on dock as an application ? This command will add a new blank application into your dock. defaults write com.apple.dock persistent-apps -array-add '{tile-type=\"spacer-tile\";}' To take it into account, restart your dock killall Dock To force start dock, minimise an application Delay Fortunately, many hidden options in macOS can be set with a command-line utility called defaults. To trigger the fade-in animation of the Dock immediately you can do the following: defaults write com.apple.dock autohide-delay -float 0 killall Dock After executing this command the Dock needs to be restarted (killall Dock). If you want to switch back to the standard behavior, you can simply delete the corresponding configuration key: defaults delete com.apple.dock autohide-delay killall Dock You can also control the duration of the fade-in and fade-out animation itself. For example, to set the animation duration to half a second, you can enter the following commands. defaults write com.apple.dock autohide-time-modifier -float 0 .5 killall Dock My default : defaults write com.apple.dock autohide-time-modifier -float 0 .3 ; killall Doc","title":"Dock"},{"location":"mac/dock/#dock","text":"","title":"Dock"},{"location":"mac/dock/#space","text":"How to add space on dock as an application ? This command will add a new blank application into your dock. defaults write com.apple.dock persistent-apps -array-add '{tile-type=\"spacer-tile\";}' To take it into account, restart your dock killall Dock To force start dock, minimise an application","title":"Space"},{"location":"mac/dock/#delay","text":"Fortunately, many hidden options in macOS can be set with a command-line utility called defaults. To trigger the fade-in animation of the Dock immediately you can do the following: defaults write com.apple.dock autohide-delay -float 0 killall Dock After executing this command the Dock needs to be restarted (killall Dock). If you want to switch back to the standard behavior, you can simply delete the corresponding configuration key: defaults delete com.apple.dock autohide-delay killall Dock You can also control the duration of the fade-in and fade-out animation itself. For example, to set the animation duration to half a second, you can enter the following commands. defaults write com.apple.dock autohide-time-modifier -float 0 .5 killall Dock My default : defaults write com.apple.dock autohide-time-modifier -float 0 .3 ; killall Doc","title":"Delay"},{"location":"mac/ds_store/","text":"What is a .DS_Store file? A .DS_Store, short for Desktop Services Store, is an invisible file on the macOS operating system that gets automatically created anytime you look into a folder with \u2018Finder.\u2019 This file will then follow the folder everywhere it goes, including when archived, like in \u2018 ZIP .\u2019 If you\u2019re a developer or system administrator and still transferring files from your computer to your server or don\u2019t take the necessary precautions with your automated deployment process, you could be putting these files on the server where your site or application lives unconsciously. Why should you know about them? This file stores custom attributes/metadata of its containing folder and the names of other files around it. Exposing this information could potentially allow hackers to act maliciously and let them see private files. Back in 2015, a .DS_Store file was exploited and used to gain access to an admin portal of the TCL Corporation, a multinational Chinese electronics company. The entire backend and database of the application were exposed to anyone that accessed the .DS_Store file. See Bug Report (Translation needed): https://web.archive.org/web/20190105043001/https://bugs.shuimugan.com/bug/view?bug_no=91869 How to prevent this? The people who want to prevent security breaches through .DS_Store files are developers and system administrators. Finding .DS_Store files in random folders in your server is not fun. You could be leaking information you don\u2019t intend to. If you do find one, simply delete the file with the command \u2018rm .DS_Store\u2019 and it will be resolved. The easiest way to prevent this problem from happening is to completely turn off the automatic creation of these files. Follow the steps below to do so: Open Terminal Then copy/paste this command and press enter: defaults write com.apple.desktopservices DSDontWriteNetworkStores true To reverse this if ever needed in the future, just change true to false: ```zsh defaults write com.apple.desktopservices DSDontWriteNetworkStores false ```` Info After running one of these commands, reboot your machine. You\u2019re set up & secure! For developers, you can use Git to solve this problem by doing the following: Place ' .DS_Store ' in your ' .gitignore ' file. That way, any .DS_Store file will be ignored and not be pushed with the rest of your code.","title":"What is a .DS_Store file?"},{"location":"mac/ds_store/#what-is-a-ds_store-file","text":"A .DS_Store, short for Desktop Services Store, is an invisible file on the macOS operating system that gets automatically created anytime you look into a folder with \u2018Finder.\u2019 This file will then follow the folder everywhere it goes, including when archived, like in \u2018 ZIP .\u2019 If you\u2019re a developer or system administrator and still transferring files from your computer to your server or don\u2019t take the necessary precautions with your automated deployment process, you could be putting these files on the server where your site or application lives unconsciously.","title":"What is a .DS_Store file?"},{"location":"mac/ds_store/#why-should-you-know-about-them","text":"This file stores custom attributes/metadata of its containing folder and the names of other files around it. Exposing this information could potentially allow hackers to act maliciously and let them see private files. Back in 2015, a .DS_Store file was exploited and used to gain access to an admin portal of the TCL Corporation, a multinational Chinese electronics company. The entire backend and database of the application were exposed to anyone that accessed the .DS_Store file. See Bug Report (Translation needed): https://web.archive.org/web/20190105043001/https://bugs.shuimugan.com/bug/view?bug_no=91869","title":"Why should you know about them?"},{"location":"mac/ds_store/#how-to-prevent-this","text":"The people who want to prevent security breaches through .DS_Store files are developers and system administrators. Finding .DS_Store files in random folders in your server is not fun. You could be leaking information you don\u2019t intend to. If you do find one, simply delete the file with the command \u2018rm .DS_Store\u2019 and it will be resolved. The easiest way to prevent this problem from happening is to completely turn off the automatic creation of these files. Follow the steps below to do so: Open Terminal Then copy/paste this command and press enter: defaults write com.apple.desktopservices DSDontWriteNetworkStores true To reverse this if ever needed in the future, just change true to false: ```zsh defaults write com.apple.desktopservices DSDontWriteNetworkStores false ```` Info After running one of these commands, reboot your machine. You\u2019re set up & secure! For developers, you can use Git to solve this problem by doing the following: Place ' .DS_Store ' in your ' .gitignore ' file. That way, any .DS_Store file will be ignored and not be pushed with the rest of your code.","title":"How to prevent this?"},{"location":"mac/iterm2/","text":"iTerm2 Tabs and Windows Shortcut Description [\u2318 Command] + [T] New Tab [\u2318 Command] + [\u27f6 Right] Next Tab [\u2318 Command] + [\u27f5 Left] Previous Tab [\u2318 Command] + [W] Close Window or Tab [\u21e7 Shift] + [\u2318 Command] + [\u27f6 Right] Move Tab right [\u21e7 Shift] + [\u2318 Command] + [\u27f5 Left] Move Tab left [\u2318 Command] + [1], [2], ... Go to Tab 1,2,... [\u2318 Command] + [D] Split Window Vertically [\u21e7 Shift] + [\u2318 Command] + [D] Split Window Horizontally [\u2318 Command] + [\u21b5 Enter] Toggle Fullscreen [\u21e7 Shift] + [\u2318 Command] + [\u21b5 Enter] Maximize Cursor and selection Shortcut Description [\u02c4 Control] + [B] Move back one character [\u02c4 Control] + [F] Move forward one character [\u02c4 Control] + [D] Delete current character [\u02c4 Control] + [W] Delete previous word (in shell) [\u02c4 Control] + [A] Move to the start of line [\u02c4 Control] + [E] Move to the end of line","title":"iTerm2"},{"location":"mac/iterm2/#iterm2","text":"","title":"iTerm2"},{"location":"mac/iterm2/#tabs-and-windows","text":"Shortcut Description [\u2318 Command] + [T] New Tab [\u2318 Command] + [\u27f6 Right] Next Tab [\u2318 Command] + [\u27f5 Left] Previous Tab [\u2318 Command] + [W] Close Window or Tab [\u21e7 Shift] + [\u2318 Command] + [\u27f6 Right] Move Tab right [\u21e7 Shift] + [\u2318 Command] + [\u27f5 Left] Move Tab left [\u2318 Command] + [1], [2], ... Go to Tab 1,2,... [\u2318 Command] + [D] Split Window Vertically [\u21e7 Shift] + [\u2318 Command] + [D] Split Window Horizontally [\u2318 Command] + [\u21b5 Enter] Toggle Fullscreen [\u21e7 Shift] + [\u2318 Command] + [\u21b5 Enter] Maximize","title":"Tabs and Windows"},{"location":"mac/iterm2/#cursor-and-selection","text":"Shortcut Description [\u02c4 Control] + [B] Move back one character [\u02c4 Control] + [F] Move forward one character [\u02c4 Control] + [D] Delete current character [\u02c4 Control] + [W] Delete previous word (in shell) [\u02c4 Control] + [A] Move to the start of line [\u02c4 Control] + [E] Move to the end of line","title":"Cursor and selection"},{"location":"mac/keybinds/","text":"Keybinds Command (ou Cmd) \u2318 Maj \u21e7 Option (or Alt) \u2325 Contr\u00f4le (or Ctrl) \u2303 Hidden files How to unhide .folder names ? \u21e7 + \u2318 + . Path Bring the path to the buttom of your finder window \u2325 + \u2318 + P Go How to go to specified directory \u2325 + \u2318 + G","title":"Keybinds"},{"location":"mac/keybinds/#keybinds","text":"Command (ou Cmd) \u2318 Maj \u21e7 Option (or Alt) \u2325 Contr\u00f4le (or Ctrl) \u2303","title":"Keybinds"},{"location":"mac/keybinds/#hidden-files","text":"How to unhide .folder names ? \u21e7 + \u2318 + .","title":"Hidden files"},{"location":"mac/keybinds/#path","text":"Bring the path to the buttom of your finder window \u2325 + \u2318 + P","title":"Path"},{"location":"mac/keybinds/#go","text":"How to go to specified directory \u2325 + \u2318 + G","title":"Go"},{"location":"mac/package-manager/","text":"Package Manager Homebrew Homebrew installe les paquets dans leurs propres r\u00e9pertoires et cr\u00e9e des liens symboliques de leurs fichiers vers /usr/local . ``` bash /bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh ) \"","title":"Package Manager"},{"location":"mac/package-manager/#package-manager","text":"","title":"Package Manager"},{"location":"mac/package-manager/#homebrew","text":"Homebrew installe les paquets dans leurs propres r\u00e9pertoires et cr\u00e9e des liens symboliques de leurs fichiers vers /usr/local . ``` bash /bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh ) \"","title":"Homebrew"},{"location":"mac/readme/","text":"README macOS is a Unix operating system developed and marketed by Apple Inc. since 2001. It is the primary operating system for Apple's Mac computers. Within the market of desktop and laptop computers, it is the second most widely used desktop OS, after Microsoft Windows and ahead of ChromeOS.","title":"README"},{"location":"mac/readme/#readme","text":"macOS is a Unix operating system developed and marketed by Apple Inc. since 2001. It is the primary operating system for Apple's Mac computers. Within the market of desktop and laptop computers, it is the second most widely used desktop OS, after Microsoft Windows and ahead of ChromeOS.","title":"README"},{"location":"mac/remote-session/","text":"Remote Connection SSH Proxy settings Into my ssh configuration file, I added the nc command like : ProxyCommand /usr/bin/nc -x $PROXY_iP %h %p As Example : ## Customer Host customer1 Hostname 1 **.**.***.*0 User toto ProxyCommand /usr/bin/nc -x $PROXY_iP %h %p sshs sshs is kind of bastion based on ssh config file brew install sshs Repository link : https://github.com/quantumsheep/sshs sshpass How to let easier your life First, install-it with homebrew if it dont installed yet. /bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh ) \" Next, install sshpass brew install hudochenkov/sshpass/sshpass Then, use it dude sshpass -f LOCAIONT/FILENAME ssh user@iP fingerprint \u2139\ufe0f Don't forget you need to accept the remote fingerprint before any sshpass connection RDP Royal TSX I personaly use Royal TSX, and didn't find better for the moment https://royaltsx-v5.royalapps.com/updates/royaltsx_5.1.2.1000.dmg","title":"Remote Connection"},{"location":"mac/remote-session/#remote-connection","text":"","title":"Remote Connection"},{"location":"mac/remote-session/#ssh","text":"","title":"SSH"},{"location":"mac/remote-session/#proxy-settings","text":"Into my ssh configuration file, I added the nc command like : ProxyCommand /usr/bin/nc -x $PROXY_iP %h %p As Example : ## Customer Host customer1 Hostname 1 **.**.***.*0 User toto ProxyCommand /usr/bin/nc -x $PROXY_iP %h %p","title":"Proxy settings"},{"location":"mac/remote-session/#sshs","text":"sshs is kind of bastion based on ssh config file brew install sshs Repository link : https://github.com/quantumsheep/sshs","title":"sshs"},{"location":"mac/remote-session/#sshpass","text":"How to let easier your life First, install-it with homebrew if it dont installed yet. /bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh ) \" Next, install sshpass brew install hudochenkov/sshpass/sshpass Then, use it dude sshpass -f LOCAIONT/FILENAME ssh user@iP","title":"sshpass"},{"location":"mac/remote-session/#fingerprint","text":"\u2139\ufe0f Don't forget you need to accept the remote fingerprint before any sshpass connection","title":"fingerprint"},{"location":"mac/remote-session/#rdp","text":"","title":"RDP"},{"location":"mac/remote-session/#royal-tsx","text":"I personaly use Royal TSX, and didn't find better for the moment https://royaltsx-v5.royalapps.com/updates/royaltsx_5.1.2.1000.dmg","title":"Royal TSX"},{"location":"mac/screenshots/","text":"ScreenShots Default On mac use \u21e7+\u2318+5 to launch th default tool Preview: Flamshot You can also use flameshot brew install flameshot Preview :","title":"ScreenShots"},{"location":"mac/screenshots/#screenshots","text":"","title":"ScreenShots"},{"location":"mac/screenshots/#default","text":"On mac use \u21e7+\u2318+5 to launch th default tool Preview:","title":"Default"},{"location":"mac/screenshots/#flamshot","text":"You can also use flameshot brew install flameshot Preview :","title":"Flamshot"},{"location":"mac/sensors/","text":"Sensors Get Temperature Intel chipset sudo powermetrics -n 1 --samplers smc | egrep -i \"FAN|CPU die|GPU die\"","title":"Sensors"},{"location":"mac/sensors/#sensors","text":"","title":"Sensors"},{"location":"mac/sensors/#get-temperature","text":"","title":"Get Temperature"},{"location":"mac/sensors/#intel-chipset","text":"sudo powermetrics -n 1 --samplers smc | egrep -i \"FAN|CPU die|GPU die\"","title":"Intel chipset"},{"location":"mac/shurtcuts/","text":"MacOS keyboard shortcuts Mac Keyboard Modifier keys key description \u2318 \u2318 + / Cmd \u2303 Control / Ctrl \u2325 \u2325 + s / Alt \u21e7 Shift \u21ea Caps Lock Fn Function key - On Windows keyboards use the Alt key instead of \u2325 + , and the Windows logo key instead of \u2318 + . Cut, copy, paste, and other common shortcuts keys description \u2318 + x Cut the selected item and copy it to the Clipboard \u2318 + c Copy the selected item to the Clipboard. This also works for files in the Finder \u2318 + v Paste the contents of the Clipboard into the current document or app. This also works for files in the Finder \u2318 + z Undo the previous comamnd \u21e7 + \u2318 + z Redo, reversing the undo command \u2318 + a Select All items \u2318 + f Find items in a document or open a Find window \u2318 + g Find Again: Find the next occurrence of the item previously found \u21e7 + \u2318 + G Find the previous occurrence \u2318 + h Hide the windows of the front app \u2325 + \u2318 + h View the front app but hide all other apps \u2318 + m Minimize the front window to the Dock \u2325 + \u2318 + m Minimize all windows of the front app \u2318 + o Open the selected item, or open a dialog to select a file to open \u2318 + p Print the current document \u2318 + s Save the current document \u2318 + t Open a new tab \u2318 + w Close the front window \u2325 + \u2318 + w Close all windows of the app \u2325 + \u2318 + Esc Force quit an app \u2318 + Space Show or hide the Spotlight search field \u2318 + \u2325 + Space Perform a Spotlight search from a Finder window \u2303 + \u2318 + Space Show the Character Viewer, from which you can choose emoji and other symbols \u2303 + \u2318 + f Use the app in full screen, if supported by the app Space Use Quick Look to preview the selected item \u2318 + Tab Switch to the next most recently used app among your open apps \u21e7 + \u2318 + 5 In macOS Mojave or later, take a screenshot or make a screen recording \u21e7 + \u2318 + 3 Take whole display screenshot \u21e7 + \u2318 + 4 Take custom screenshot \u21e7 + \u2318 + n Create a new folder in the Finder \u2318 + , Open preferences for the front app Sleep, log out, and shut down shortcuts * You might need to press and hold some of these shortcuts for slightly longer than other shortcuts. This helps you to avoid using them unintentionally. keys description Power button Press to turn on your Mac or wake it from sleep Power button Press and hold for 1.5 seconds to put your Mac to sleep Power button Press and continue holding to force your Mac to turn off \u2325 + \u2318 + Power Put your Mac to sleep \u2325 + \u2318 + Eject Put your Mac to sleep \u2303 + \u21e7 + Power Put your displays to sleep \u2303 + \u21e7 + Eject Put your displays to sleep \u2303 + Power Display a dialog asking whether you want to restart, sleep, or shut down \u2303 + Eject Display a dialog asking whether you want to restart, sleep, or shut down \u2303 + \u2318 + Power Force your Mac to restart, without prompting to save any open and unsaved documents \u2303 + \u2318 + Eject Quit all apps, then restart your Mac \u2303 + \u2325 + \u2318 + Power Quit all apps, then shut down your Mac \u2303 \u2325 + \u2318 + Eject Quit all apps, then shut down your Mac \u2303 + \u2318 + q Immediately lock your screen \u21e7 + \u2318 + q Log out of your macOS user account. You will be asked to confirm \u2325 + \u21e7 + \u2318 + q Log out immediately without confirming Finder and system shortcuts keys description \u2318 + d Duplicate the selected files \u2318 + e Eject the selected disk or volume \u2318 + f Start a Spotlight search in the Finder window \u2318 + i Show the Get Info window for a selected file \u2318 + r (1) When an alias is selected in the Finder: show the original file for the selected alias \u2318 + r (2) In some apps, such as Calendar or Safari, refresh or reload the page \u2318 + r (3) In Software Update preferences, check for software updates again \u21e7 + \u2318 + c Open the Computer window \u21e7 + \u2318 + d Open the desktop folder \u21e7 + \u2318 + f Open the Recents window, showing all of the files you viewed or changed recently \u21e7 + \u2318 + g Open a Go to Folder window \u21e7 + \u2318 + h Open the Home folder of the current macOS user account \u21e7 + \u2318 + i Open iCloud Drive \u21e7 + \u2318 + k Open the Network window \u2325 + \u2318 + l Open the Downloads folder \u21e7 + \u2318 + n Create a new folder \u21e7 + \u2318 + o Open the Documents folder \u21e7 + \u2318 + p Show or hide the Preview pane in Finder windows \u21e7 + \u2318 + r Open the AirDrop window \u21e7 + \u2318 + t Show or hide the tab bar in Finder windows \u2303 + \u21e7 + \u2318 + t Add selected Finder item to the Dock (OS X Mavericks or later) \u21e7 + \u2318 + u Open the Utilities folder \u2325 + \u2318 + d Show or hide the Dock \u2303 + \u2318 + t Add the selected item to the sidebar (OS X Mavericks or later) \u2325 + \u2318 + p Hide or show the path bar in Finder windows \u2325 + \u2318 + s Hide or show the Sidebar in Finder windows \u2318 + / Hide or show the status bar in Finder windows \u2318 + j Show View Options \u2318 + k Open the Connect to Server window \u2303 + \u2318 + a Make an alias of the selected item \u2318 + n Open a new Finder window \u2325 + \u2318 + n Create a new Smart Folder \u2318 + t Show or hide the tab bar when a single tab is open in the current Finder window \u2325 + \u2318 + t Show or hide the toolbar when a single tab is open in the current Finder window \u2325 + \u2318 + v Move the files in the Clipboard from their original location to the current location \u2318 + y Use Quick Look to preview the selected files \u2325 + \u2318 + v View a Quick Look slideshow of the selected files \u2318 + 1 View the items in the Finder window as icons \u2318 + 2 View the items in a Finder window as a list \u2318 + 3 View the items in a Finder window in columns \u2318 + 4 View the items in a Finder window in a gallery \u2318 + [ Go to the previous folder \u2318 + ] Go to the next folder \u2318 + \u2191 Open the folder that contains the current folder \u2303 + \u2318 + \u2191 Open the folder that contains the current folder in a new window \u2318 + \u2193 Open the selected item \u2192 Open the selected folder. This works only when in list view \u2190 Close the selected folder. This works only when in list view \u2318 + Delete Move the selected item to the Trash \u21e7 + \u2318 + Delete Empty the Trash \u2325 + \u21e7 + \u2318 + Delete Empty the Trash without confirmation dialog \u2318 + Brightness Down Turn video mirroring on or off when your Mac is connected to more than one display \u2325 + Brightness Up Open Displays preferences. This works with either Brightness key \u2303 + Brightness Up/Down Adjust brightness of your external display, if supported by your display \u2325 + \u21e7 + Brightness Up/Down Adjust display brightness in smaller steps \u2303 + \u2325 + \u21e7 + Brightness Up/Down Adjust external display brightness in smaller steps, if supported by display \u2325 + Mission Control Open Mission Control preferences \u2303 + Mission Control Show the desktop \u2303 + \u2193 Show all windows of the front app \u2325 + Volume Up Open Sound preferences. This works with any of the volume keys \u2325 + \u21e7 + Volume up/Down Adjust the sound volume in smaller steps \u2325 + Brightness Up Open Keyboard preferences. This works with either Keyboard Brightness key \u2325 + \u21e7 + Brightness Up/Down Adjust the keyboard brightness in smaller steps \u2325 + double-clicking Open the item in a separate window, then close the original window \u2318 + double-clicking Open a folder in a separate tab or window \u2318 + dragging to another volume Move the dragged item to the other volume, instead of copying it \u2325 + dragging Copy the dragged item. The pointer changes while you drag the item \u2325 + \u2318 + while dragging Make an alias of the dragged item. The pointer changes while you drag the item \u2325 + click a disclosure triangle Open all folders within the selected folder. This works only when in list view \u2318 + click a window title See the folders that contain the current folder Document shortcuts *The behavior of these shortcuts may vary with the app you're using keys description \u2318 + b Boldface the selected text, or turn boldfacing on or off \u2318 + i Italicize the selected text, or turn italics on or off \u2318 + k Add a web link \u2318 + u Underline the selected text, or turn underlining on or off \u2318 + t Show or hide the Fonts window \u2318 + d Select the Desktop folder from within an Open dialog or Save dialog \u2303 + \u2318 + d Show or hide the definition of the selected word \u21e7 + \u2318 + : Display the Spelling and Grammar window \u2318 + ; Find misspelled words in the document \u2325 + Delete Delete the word to the left of the insertion point \u2303 + h Delete the character to the left of the insertion point. Or use Delete \u2303 + d Delete the character to the right of the insertion point Fn + Delete Forward delete on keyboards that don't have a Forward Delete key \u2303 + k Delete the text between the insertion point and the end of the line or paragraph Fn + \u2191 Page Up: Scroll up one page Fn + \u2193 Page Down: Scroll down one page. Fn + \u2190 Home: Scroll to the beginning of a document. Fn + \u2192 End: Scroll to the end of a document. \u2318 + \u2191 Move the insertion point to the beginning of the document \u2318 + \u2193 Move the insertion point to the end of the document. \u2318 + \u2190 Move the insertion point to the beginning of the current line. \u2318 + \u2192 Move the insertion point to the end of the current line. \u2325 + \u2190 Move the insertion point to the beginning of the previous word \u2325 + \u2192 Move the insertion point to the end of the next word \u21e7 + \u2318 + \u2191 Select the text between the insertion point and the beginning of the document \u21e7 + \u2318 + \u2193 Select the text between the insertion point and the end of the document \u21e7 + \u2318 + \u2190 Select the text between the insertion point and the beginning of the current line \u21e7 + \u2318 + \u2192 Select the text between the insertion point and the end of the current line \u21e7 + \u2191 Extend text selection to the nearest character at the same horizontal location on the line above \u21e7 + \u2193 Extend text selection to the nearest character at the same horizontal location on the line below \u21e7 + \u2190 Extend text selection one character to the left \u21e7 + \u2192 Extend text selection one character to the right \u2325 + \u21e7 + \u2191 Extend text selection to the beginning of the current paragraph, then to the beginning of the following paragraph if pressed again \u2325 + \u21e7 + \u2193 Extend text selection to the end of the current paragraph, then to the end of the following paragraph if pressed again \u2325 + \u21e7 + \u2190 Extend text selection to the beginning of the current word, then to the beginning of the following word if pressed again \u2325 + \u21e7 + \u2192 Extend text selection to the end of the current word, then to the end of the following word if pressed again \u2303 + a Move to the beginning of the line or paragraph \u2303 + e Move to the end of a line or paragraph \u2303 + f Move one character forward \u2303 + b Move one character backward \u2303 + l Center the cursor or selection in the visible area \u2303 + p Move up one line \u2303 + n Move down one line \u2303 + o Insert a new line after the insertion point \u2303 + t Swap the character behind the insertion point with the character in front of the insertion point \u2318 + { Left align \u2318 + } Right align \u21e7 + \u2318 + | Center align \u2325 + \u2318 + f Go to the search field \u2325 + \u2318 + t Show or hide a toolbar in the app \u2325 + \u2318 + c Copy Style: Copy the formatting settings of the selected item to the Clipboard \u2325 + \u2318 + v Paste Style: Apply the copied style to the selected item \u2325 + \u21e7 + \u2318 + v Paste and Match Style: Apply the style of the surrounding content to the item pasted within that content \u2325 + \u2318 + i Show or hide the inspector window \u21e7 + \u2318 + p Page setup: Display a window for selecting document settings \u21e7 + \u2318 + s Display the Save As dialog, or duplicate the current document \u21e7 + \u2318 + (-) Decrease the size of the selected item \u21e7 + \u2318 + (+) Increase the size of the selected item \u2318 + = performs the same function \u21e7 + \u2318 + ? Open the Help menu","title":"MacOS keyboard shortcuts"},{"location":"mac/shurtcuts/#macos-keyboard-shortcuts","text":"","title":"MacOS keyboard shortcuts"},{"location":"mac/shurtcuts/#mac-keyboard-modifier-keys","text":"key description \u2318 \u2318 + / Cmd \u2303 Control / Ctrl \u2325 \u2325 + s / Alt \u21e7 Shift \u21ea Caps Lock Fn Function key - On Windows keyboards use the Alt key instead of \u2325 + , and the Windows logo key instead of \u2318 + .","title":"Mac Keyboard Modifier keys"},{"location":"mac/shurtcuts/#cut-copy-paste-and-other-common-shortcuts","text":"keys description \u2318 + x Cut the selected item and copy it to the Clipboard \u2318 + c Copy the selected item to the Clipboard. This also works for files in the Finder \u2318 + v Paste the contents of the Clipboard into the current document or app. This also works for files in the Finder \u2318 + z Undo the previous comamnd \u21e7 + \u2318 + z Redo, reversing the undo command \u2318 + a Select All items \u2318 + f Find items in a document or open a Find window \u2318 + g Find Again: Find the next occurrence of the item previously found \u21e7 + \u2318 + G Find the previous occurrence \u2318 + h Hide the windows of the front app \u2325 + \u2318 + h View the front app but hide all other apps \u2318 + m Minimize the front window to the Dock \u2325 + \u2318 + m Minimize all windows of the front app \u2318 + o Open the selected item, or open a dialog to select a file to open \u2318 + p Print the current document \u2318 + s Save the current document \u2318 + t Open a new tab \u2318 + w Close the front window \u2325 + \u2318 + w Close all windows of the app \u2325 + \u2318 + Esc Force quit an app \u2318 + Space Show or hide the Spotlight search field \u2318 + \u2325 + Space Perform a Spotlight search from a Finder window \u2303 + \u2318 + Space Show the Character Viewer, from which you can choose emoji and other symbols \u2303 + \u2318 + f Use the app in full screen, if supported by the app Space Use Quick Look to preview the selected item \u2318 + Tab Switch to the next most recently used app among your open apps \u21e7 + \u2318 + 5 In macOS Mojave or later, take a screenshot or make a screen recording \u21e7 + \u2318 + 3 Take whole display screenshot \u21e7 + \u2318 + 4 Take custom screenshot \u21e7 + \u2318 + n Create a new folder in the Finder \u2318 + , Open preferences for the front app","title":"Cut, copy, paste, and other common shortcuts"},{"location":"mac/shurtcuts/#sleep-log-out-and-shut-down-shortcuts","text":"* You might need to press and hold some of these shortcuts for slightly longer than other shortcuts. This helps you to avoid using them unintentionally. keys description Power button Press to turn on your Mac or wake it from sleep Power button Press and hold for 1.5 seconds to put your Mac to sleep Power button Press and continue holding to force your Mac to turn off \u2325 + \u2318 + Power Put your Mac to sleep \u2325 + \u2318 + Eject Put your Mac to sleep \u2303 + \u21e7 + Power Put your displays to sleep \u2303 + \u21e7 + Eject Put your displays to sleep \u2303 + Power Display a dialog asking whether you want to restart, sleep, or shut down \u2303 + Eject Display a dialog asking whether you want to restart, sleep, or shut down \u2303 + \u2318 + Power Force your Mac to restart, without prompting to save any open and unsaved documents \u2303 + \u2318 + Eject Quit all apps, then restart your Mac \u2303 + \u2325 + \u2318 + Power Quit all apps, then shut down your Mac \u2303 \u2325 + \u2318 + Eject Quit all apps, then shut down your Mac \u2303 + \u2318 + q Immediately lock your screen \u21e7 + \u2318 + q Log out of your macOS user account. You will be asked to confirm \u2325 + \u21e7 + \u2318 + q Log out immediately without confirming","title":"Sleep, log out, and shut down shortcuts"},{"location":"mac/shurtcuts/#finder-and-system-shortcuts","text":"keys description \u2318 + d Duplicate the selected files \u2318 + e Eject the selected disk or volume \u2318 + f Start a Spotlight search in the Finder window \u2318 + i Show the Get Info window for a selected file \u2318 + r (1) When an alias is selected in the Finder: show the original file for the selected alias \u2318 + r (2) In some apps, such as Calendar or Safari, refresh or reload the page \u2318 + r (3) In Software Update preferences, check for software updates again \u21e7 + \u2318 + c Open the Computer window \u21e7 + \u2318 + d Open the desktop folder \u21e7 + \u2318 + f Open the Recents window, showing all of the files you viewed or changed recently \u21e7 + \u2318 + g Open a Go to Folder window \u21e7 + \u2318 + h Open the Home folder of the current macOS user account \u21e7 + \u2318 + i Open iCloud Drive \u21e7 + \u2318 + k Open the Network window \u2325 + \u2318 + l Open the Downloads folder \u21e7 + \u2318 + n Create a new folder \u21e7 + \u2318 + o Open the Documents folder \u21e7 + \u2318 + p Show or hide the Preview pane in Finder windows \u21e7 + \u2318 + r Open the AirDrop window \u21e7 + \u2318 + t Show or hide the tab bar in Finder windows \u2303 + \u21e7 + \u2318 + t Add selected Finder item to the Dock (OS X Mavericks or later) \u21e7 + \u2318 + u Open the Utilities folder \u2325 + \u2318 + d Show or hide the Dock \u2303 + \u2318 + t Add the selected item to the sidebar (OS X Mavericks or later) \u2325 + \u2318 + p Hide or show the path bar in Finder windows \u2325 + \u2318 + s Hide or show the Sidebar in Finder windows \u2318 + / Hide or show the status bar in Finder windows \u2318 + j Show View Options \u2318 + k Open the Connect to Server window \u2303 + \u2318 + a Make an alias of the selected item \u2318 + n Open a new Finder window \u2325 + \u2318 + n Create a new Smart Folder \u2318 + t Show or hide the tab bar when a single tab is open in the current Finder window \u2325 + \u2318 + t Show or hide the toolbar when a single tab is open in the current Finder window \u2325 + \u2318 + v Move the files in the Clipboard from their original location to the current location \u2318 + y Use Quick Look to preview the selected files \u2325 + \u2318 + v View a Quick Look slideshow of the selected files \u2318 + 1 View the items in the Finder window as icons \u2318 + 2 View the items in a Finder window as a list \u2318 + 3 View the items in a Finder window in columns \u2318 + 4 View the items in a Finder window in a gallery \u2318 + [ Go to the previous folder \u2318 + ] Go to the next folder \u2318 + \u2191 Open the folder that contains the current folder \u2303 + \u2318 + \u2191 Open the folder that contains the current folder in a new window \u2318 + \u2193 Open the selected item \u2192 Open the selected folder. This works only when in list view \u2190 Close the selected folder. This works only when in list view \u2318 + Delete Move the selected item to the Trash \u21e7 + \u2318 + Delete Empty the Trash \u2325 + \u21e7 + \u2318 + Delete Empty the Trash without confirmation dialog \u2318 + Brightness Down Turn video mirroring on or off when your Mac is connected to more than one display \u2325 + Brightness Up Open Displays preferences. This works with either Brightness key \u2303 + Brightness Up/Down Adjust brightness of your external display, if supported by your display \u2325 + \u21e7 + Brightness Up/Down Adjust display brightness in smaller steps \u2303 + \u2325 + \u21e7 + Brightness Up/Down Adjust external display brightness in smaller steps, if supported by display \u2325 + Mission Control Open Mission Control preferences \u2303 + Mission Control Show the desktop \u2303 + \u2193 Show all windows of the front app \u2325 + Volume Up Open Sound preferences. This works with any of the volume keys \u2325 + \u21e7 + Volume up/Down Adjust the sound volume in smaller steps \u2325 + Brightness Up Open Keyboard preferences. This works with either Keyboard Brightness key \u2325 + \u21e7 + Brightness Up/Down Adjust the keyboard brightness in smaller steps \u2325 + double-clicking Open the item in a separate window, then close the original window \u2318 + double-clicking Open a folder in a separate tab or window \u2318 + dragging to another volume Move the dragged item to the other volume, instead of copying it \u2325 + dragging Copy the dragged item. The pointer changes while you drag the item \u2325 + \u2318 + while dragging Make an alias of the dragged item. The pointer changes while you drag the item \u2325 + click a disclosure triangle Open all folders within the selected folder. This works only when in list view \u2318 + click a window title See the folders that contain the current folder","title":"Finder and system shortcuts"},{"location":"mac/shurtcuts/#document-shortcuts","text":"*The behavior of these shortcuts may vary with the app you're using keys description \u2318 + b Boldface the selected text, or turn boldfacing on or off \u2318 + i Italicize the selected text, or turn italics on or off \u2318 + k Add a web link \u2318 + u Underline the selected text, or turn underlining on or off \u2318 + t Show or hide the Fonts window \u2318 + d Select the Desktop folder from within an Open dialog or Save dialog \u2303 + \u2318 + d Show or hide the definition of the selected word \u21e7 + \u2318 + : Display the Spelling and Grammar window \u2318 + ; Find misspelled words in the document \u2325 + Delete Delete the word to the left of the insertion point \u2303 + h Delete the character to the left of the insertion point. Or use Delete \u2303 + d Delete the character to the right of the insertion point Fn + Delete Forward delete on keyboards that don't have a Forward Delete key \u2303 + k Delete the text between the insertion point and the end of the line or paragraph Fn + \u2191 Page Up: Scroll up one page Fn + \u2193 Page Down: Scroll down one page. Fn + \u2190 Home: Scroll to the beginning of a document. Fn + \u2192 End: Scroll to the end of a document. \u2318 + \u2191 Move the insertion point to the beginning of the document \u2318 + \u2193 Move the insertion point to the end of the document. \u2318 + \u2190 Move the insertion point to the beginning of the current line. \u2318 + \u2192 Move the insertion point to the end of the current line. \u2325 + \u2190 Move the insertion point to the beginning of the previous word \u2325 + \u2192 Move the insertion point to the end of the next word \u21e7 + \u2318 + \u2191 Select the text between the insertion point and the beginning of the document \u21e7 + \u2318 + \u2193 Select the text between the insertion point and the end of the document \u21e7 + \u2318 + \u2190 Select the text between the insertion point and the beginning of the current line \u21e7 + \u2318 + \u2192 Select the text between the insertion point and the end of the current line \u21e7 + \u2191 Extend text selection to the nearest character at the same horizontal location on the line above \u21e7 + \u2193 Extend text selection to the nearest character at the same horizontal location on the line below \u21e7 + \u2190 Extend text selection one character to the left \u21e7 + \u2192 Extend text selection one character to the right \u2325 + \u21e7 + \u2191 Extend text selection to the beginning of the current paragraph, then to the beginning of the following paragraph if pressed again \u2325 + \u21e7 + \u2193 Extend text selection to the end of the current paragraph, then to the end of the following paragraph if pressed again \u2325 + \u21e7 + \u2190 Extend text selection to the beginning of the current word, then to the beginning of the following word if pressed again \u2325 + \u21e7 + \u2192 Extend text selection to the end of the current word, then to the end of the following word if pressed again \u2303 + a Move to the beginning of the line or paragraph \u2303 + e Move to the end of a line or paragraph \u2303 + f Move one character forward \u2303 + b Move one character backward \u2303 + l Center the cursor or selection in the visible area \u2303 + p Move up one line \u2303 + n Move down one line \u2303 + o Insert a new line after the insertion point \u2303 + t Swap the character behind the insertion point with the character in front of the insertion point \u2318 + { Left align \u2318 + } Right align \u21e7 + \u2318 + | Center align \u2325 + \u2318 + f Go to the search field \u2325 + \u2318 + t Show or hide a toolbar in the app \u2325 + \u2318 + c Copy Style: Copy the formatting settings of the selected item to the Clipboard \u2325 + \u2318 + v Paste Style: Apply the copied style to the selected item \u2325 + \u21e7 + \u2318 + v Paste and Match Style: Apply the style of the surrounding content to the item pasted within that content \u2325 + \u2318 + i Show or hide the inspector window \u21e7 + \u2318 + p Page setup: Display a window for selecting document settings \u21e7 + \u2318 + s Display the Save As dialog, or duplicate the current document \u21e7 + \u2318 + (-) Decrease the size of the selected item \u21e7 + \u2318 + (+) Increase the size of the selected item \u2318 + = performs the same function \u21e7 + \u2318 + ? Open the Help menu","title":"Document shortcuts"},{"location":"mac/vmachines/","text":"Virtual Machines (M1) UTM Download the Securely run operating systems on your Mac https://github.com/utmapp/UTM/releases/latest/download/UTM.dmg VMWare Fusion VMWare Fusion is working on it Public Technical preview : https://customerconnect.vmware.com/downloads/get-download?downloadGroup=FUS-PUBTP-22H2","title":"Virtual Machines (M1)"},{"location":"mac/vmachines/#virtual-machines-m1","text":"","title":"Virtual Machines (M1)"},{"location":"mac/vmachines/#utm","text":"Download the Securely run operating systems on your Mac https://github.com/utmapp/UTM/releases/latest/download/UTM.dmg","title":"UTM"},{"location":"mac/vmachines/#vmware-fusion","text":"VMWare Fusion is working on it Public Technical preview : https://customerconnect.vmware.com/downloads/get-download?downloadGroup=FUS-PUBTP-22H2","title":"VMWare Fusion"},{"location":"mac/windows-tilling/","text":"Windows tilling Rectangle Move and resize windows in macOS using keyboard shortcuts or snap areas Download page","title":"Windows tilling"},{"location":"mac/windows-tilling/#windows-tilling","text":"","title":"Windows tilling"},{"location":"mac/windows-tilling/#rectangle","text":"Move and resize windows in macOS using keyboard shortcuts or snap areas Download page","title":"Rectangle"},{"location":"misc/color-codes/","text":"256 Color Codes Cheat-Sheet Colors 0-15 are Xterm system colors. Xterm Number COL Xterm Name HEX RGB HSL 0 Black #000000 rgb(0,0,0) hsl(0,0%,0%) 1 Maroon #800000 rgb(128,0,0) hsl(0,100%,25%) 2 Green #008000 rgb(0,128,0) hsl(120,100%,25%) 3 Olive #808000 rgb(128,128,0) hsl(60,100%,25%) 4 Navy #000080 rgb(0,0,128) hsl(240,100%,25%) 5 Purple #800080 rgb(128,0,128) hsl(300,100%,25%) 6 Teal #008080 rgb(0,128,128) hsl(180,100%,25%) 7 Silver #c0c0c0 rgb(192,192,192) hsl(0,0%,75%) 8 Grey #808080 rgb(128,128,128) hsl(0,0%,50%) 9 Red #ff0000 rgb(255,0,0) hsl(0,100%,50%) 10 Lime #00ff00 rgb(0,255,0) hsl(120,100%,50%) 11 Yellow #ffff00 rgb(255,255,0) hsl(60,100%,50%) 12 Blue #0000ff rgb(0,0,255) hsl(240,100%,50%) 13 Fuchsia #ff00ff rgb(255,0,255) hsl(300,100%,50%) 14 Aqua #00ffff rgb(0,255,255) hsl(180,100%,50%) 15 White #ffffff rgb(255,255,255) hsl(0,0%,100%) 16 Grey0 #000000 rgb(0,0,0) hsl(0,0%,0%) 17 NavyBlue #00005f rgb(0,0,95) hsl(240,100%,18%) 18 DarkBlue #000087 rgb(0,0,135) hsl(240,100%,26%) 19 Blue3 #0000af rgb(0,0,175) hsl(240,100%,34%) 20 Blue3 #0000d7 rgb(0,0,215) hsl(240,100%,42%) 21 Blue1 #0000ff rgb(0,0,255) hsl(240,100%,50%) 22 DarkGreen #005f00 rgb(0,95,0) hsl(120,100%,18%) 23 DeepSkyBlue4 #005f5f rgb(0,95,95) hsl(180,100%,18%) 24 DeepSkyBlue4 #005f87 rgb(0,95,135) hsl(97,100%,26%) 25 DeepSkyBlue4 #005faf rgb(0,95,175) hsl(07,100%,34%) 26 DodgerBlue3 #005fd7 rgb(0,95,215) hsl(13,100%,42%) 27 DodgerBlue2 #005fff rgb(0,95,255) hsl(17,100%,50%) 28 Green4 #008700 rgb(0,135,0) hsl(120,100%,26%) 29 SpringGreen4 #00875f rgb(0,135,95) hsl(62,100%,26%) 30 Turquoise4 #008787 rgb(0,135,135) hsl(180,100%,26%) 31 DeepSkyBlue3 #0087af rgb(0,135,175) hsl(93,100%,34%) 32 DeepSkyBlue3 #0087d7 rgb(0,135,215) hsl(02,100%,42%) 33 DodgerBlue1 #0087ff rgb(0,135,255) hsl(08,100%,50%) 34 Green3 #00af00 rgb(0,175,0) hsl(120,100%,34%) 35 SpringGreen3 #00af5f rgb(0,175,95) hsl(52,100%,34%) 36 DarkCyan #00af87 rgb(0,175,135) hsl(66,100%,34%) 37 LightSeaGreen #00afaf rgb(0,175,175) hsl(180,100%,34%) 38 DeepSkyBlue2 #00afd7 rgb(0,175,215) hsl(91,100%,42%) 39 DeepSkyBlue1 #00afff rgb(0,175,255) hsl(98,100%,50%) 40 Green3 #00d700 rgb(0,215,0) hsl(120,100%,42%) 41 SpringGreen3 #00d75f rgb(0,215,95) hsl(46,100%,42%) 42 SpringGreen2 #00d787 rgb(0,215,135) hsl(57,100%,42%) 43 Cyan3 #00d7af rgb(0,215,175) hsl(68,100%,42%) 44 DarkTurquoise #00d7d7 rgb(0,215,215) hsl(180,100%,42%) 45 Turquoise2 #00d7ff rgb(0,215,255) hsl(89,100%,50%) 46 Green1 #00ff00 rgb(0,255,0) hsl(120,100%,50%) 47 SpringGreen2 #00ff5f rgb(0,255,95) hsl(42,100%,50%) 48 SpringGreen1 #00ff87 rgb(0,255,135) hsl(51,100%,50%) 49 MediumSpringGreen #00ffaf rgb(0,255,175) hsl(61,100%,50%) 50 Cyan2 #00ffd7 rgb(0,255,215) hsl(70,100%,50%) 51 Cyan1 #00ffff rgb(0,255,255) hsl(180,100%,50%) 52 DarkRed #5f0000 rgb(95,0,0) hsl(0,100%,18%) 53 DeepPink4 #5f005f rgb(95,0,95) hsl(300,100%,18%) 54 Purple4 #5f0087 rgb(95,0,135) hsl(82,100%,26%) 55 Purple4 #5f00af rgb(95,0,175) hsl(72,100%,34%) 56 Purple3 #5f00d7 rgb(95,0,215) hsl(66,100%,42%) 57 BlueViolet #5f00ff rgb(95,0,255) hsl(62,100%,50%) 58 Orange4 #5f5f00 rgb(95,95,0) hsl(60,100%,18%) 59 Grey37 #5f5f5f rgb(95,95,95) hsl(0,0%,37%) 60 MediumPurple4 #5f5f87 rgb(95,95,135) hsl(240,17%,45%) 61 SlateBlue3 #5f5faf rgb(95,95,175) hsl(240,33%,52%) 62 SlateBlue3 #5f5fd7 rgb(95,95,215) hsl(240,60%,60%) 63 RoyalBlue1 #5f5fff rgb(95,95,255) hsl(240,100%,68%) 64 Chartreuse4 #5f8700 rgb(95,135,0) hsl(7,100%,26%) 65 DarkSeaGreen4 #5f875f rgb(95,135,95) hsl(120,17%,45%) 66 PaleTurquoise4 #5f8787 rgb(95,135,135) hsl(180,17%,45%) 67 SteelBlue #5f87af rgb(95,135,175) hsl(210,33%,52%) 68 SteelBlue3 #5f87d7 rgb(95,135,215) hsl(220,60%,60%) 69 CornflowerBlue #5f87ff rgb(95,135,255) hsl(225,100%,68%) 70 Chartreuse3 #5faf00 rgb(95,175,0) hsl(7,100%,34%) 71 DarkSeaGreen4 #5faf5f rgb(95,175,95) hsl(120,33%,52%) 72 CadetBlue #5faf87 rgb(95,175,135) hsl(150,33%,52%) 73 CadetBlue #5fafaf rgb(95,175,175) hsl(180,33%,52%) 74 SkyBlue3 #5fafd7 rgb(95,175,215) hsl(200,60%,60%) 75 SteelBlue1 #5fafff rgb(95,175,255) hsl(210,100%,68%) 76 Chartreuse3 #5fd700 rgb(95,215,0) hsl(3,100%,42%) 77 PaleGreen3 #5fd75f rgb(95,215,95) hsl(120,60%,60%) 78 SeaGreen3 #5fd787 rgb(95,215,135) hsl(140,60%,60%) 79 Aquamarine3 #5fd7af rgb(95,215,175) hsl(160,60%,60%) 80 MediumTurquoise #5fd7d7 rgb(95,215,215) hsl(180,60%,60%) 81 SteelBlue1 #5fd7ff rgb(95,215,255) hsl(195,100%,68%) 82 Chartreuse2 #5fff00 rgb(95,255,0) hsl(7,100%,50%) 83 SeaGreen2 #5fff5f rgb(95,255,95) hsl(120,100%,68%) 84 SeaGreen1 #5fff87 rgb(95,255,135) hsl(135,100%,68%) 85 SeaGreen1 #5fffaf rgb(95,255,175) hsl(150,100%,68%) 86 Aquamarine1 #5fffd7 rgb(95,255,215) hsl(165,100%,68%) 87 DarkSlateGray2 #5fffff rgb(95,255,255) hsl(180,100%,68%) 88 DarkRed #870000 rgb(135,0,0) hsl(0,100%,26%) 89 DeepPink4 #87005f rgb(135,0,95) hsl(17,100%,26%) 90 DarkMagenta #870087 rgb(135,0,135) hsl(300,100%,26%) 91 DarkMagenta #8700af rgb(135,0,175) hsl(86,100%,34%) 92 DarkViolet #8700d7 rgb(135,0,215) hsl(77,100%,42%) 93 Purple #8700ff rgb(135,0,255) hsl(71,100%,50%) 94 Orange4 #875f00 rgb(135,95,0) hsl(2,100%,26%) 95 LightPink4 #875f5f rgb(135,95,95) hsl(0,17%,45%) 96 Plum4 #875f87 rgb(135,95,135) hsl(300,17%,45%) 97 MediumPurple3 #875faf rgb(135,95,175) hsl(270,33%,52%) 98 MediumPurple3 #875fd7 rgb(135,95,215) hsl(260,60%,60%) 99 SlateBlue1 #875fff rgb(135,95,255) hsl(255,100%,68%) 100 Yellow4 #878700 rgb(135,135,0) hsl(60,100%,26%) 101 Wheat4 #87875f rgb(135,135,95) hsl(60,17%,45%) 102 Grey53 #878787 rgb(135,135,135) hsl(0,0%,52%) 103 LightSlateGrey #8787af rgb(135,135,175) hsl(240,20%,60%) 104 MediumPurple #8787d7 rgb(135,135,215) hsl(240,50%,68%) 105 LightSlateBlue #8787ff rgb(135,135,255) hsl(240,100%,76%) 106 Yellow4 #87af00 rgb(135,175,0) hsl(3,100%,34%) 107 DarkOliveGreen3 #87af5f rgb(135,175,95) hsl(90,33%,52%) 108 DarkSeaGreen #87af87 rgb(135,175,135) hsl(120,20%,60%) 109 LightSkyBlue3 #87afaf rgb(135,175,175) hsl(180,20%,60%) 110 LightSkyBlue3 #87afd7 rgb(135,175,215) hsl(210,50%,68%) 111 SkyBlue2 #87afff rgb(135,175,255) hsl(220,100%,76%) 112 Chartreuse2 #87d700 rgb(135,215,0) hsl(2,100%,42%) 113 DarkOliveGreen3 #87d75f rgb(135,215,95) hsl(100,60%,60%) 114 PaleGreen3 #87d787 rgb(135,215,135) hsl(120,50%,68%) 115 DarkSeaGreen3 #87d7af rgb(135,215,175) hsl(150,50%,68%) 116 DarkSlateGray3 #87d7d7 rgb(135,215,215) hsl(180,50%,68%) 117 SkyBlue1 #87d7ff rgb(135,215,255) hsl(200,100%,76%) 118 Chartreuse1 #87ff00 rgb(135,255,0) hsl(8,100%,50%) 119 LightGreen #87ff5f rgb(135,255,95) hsl(105,100%,68%) 120 LightGreen #87ff87 rgb(135,255,135) hsl(120,100%,76%) 121 PaleGreen1 #87ffaf rgb(135,255,175) hsl(140,100%,76%) 122 Aquamarine1 #87ffd7 rgb(135,255,215) hsl(160,100%,76%) 123 DarkSlateGray1 #87ffff rgb(135,255,255) hsl(180,100%,76%) 124 Red3 #af0000 rgb(175,0,0) hsl(0,100%,34%) 125 DeepPink4 #af005f rgb(175,0,95) hsl(27,100%,34%) 126 MediumVioletRed #af0087 rgb(175,0,135) hsl(13,100%,34%) 127 Magenta3 #af00af rgb(175,0,175) hsl(300,100%,34%) 128 DarkViolet #af00d7 rgb(175,0,215) hsl(88,100%,42%) 129 Purple #af00ff rgb(175,0,255) hsl(81,100%,50%) 130 DarkOrange3 #af5f00 rgb(175,95,0) hsl(2,100%,34%) 131 IndianRed #af5f5f rgb(175,95,95) hsl(0,33%,52%) 132 HotPink3 #af5f87 rgb(175,95,135) hsl(330,33%,52%) 133 MediumOrchid3 #af5faf rgb(175,95,175) hsl(300,33%,52%) 134 MediumOrchid #af5fd7 rgb(175,95,215) hsl(280,60%,60%) 135 MediumPurple2 #af5fff rgb(175,95,255) hsl(270,100%,68%) 136 DarkGoldenrod #af8700 rgb(175,135,0) hsl(6,100%,34%) 137 LightSalmon3 #af875f rgb(175,135,95) hsl(30,33%,52%) 138 RosyBrown #af8787 rgb(175,135,135) hsl(0,20%,60%) 139 Grey63 #af87af rgb(175,135,175) hsl(300,20%,60%) 140 MediumPurple2 #af87d7 rgb(175,135,215) hsl(270,50%,68%) 141 MediumPurple1 #af87ff rgb(175,135,255) hsl(260,100%,76%) 142 Gold3 #afaf00 rgb(175,175,0) hsl(60,100%,34%) 143 DarkKhaki #afaf5f rgb(175,175,95) hsl(60,33%,52%) 144 NavajoWhite3 #afaf87 rgb(175,175,135) hsl(60,20%,60%) 145 Grey69 #afafaf rgb(175,175,175) hsl(0,0%,68%) 146 LightSteelBlue3 #afafd7 rgb(175,175,215) hsl(240,33%,76%) 147 LightSteelBlue #afafff rgb(175,175,255) hsl(240,100%,84%) 148 Yellow3 #afd700 rgb(175,215,0) hsl(1,100%,42%) 149 DarkOliveGreen3 #afd75f rgb(175,215,95) hsl(80,60%,60%) 150 DarkSeaGreen3 #afd787 rgb(175,215,135) hsl(90,50%,68%) 151 DarkSeaGreen2 #afd7af rgb(175,215,175) hsl(120,33%,76%) 152 LightCyan3 #afd7d7 rgb(175,215,215) hsl(180,33%,76%) 153 LightSkyBlue1 #afd7ff rgb(175,215,255) hsl(210,100%,84%) 154 GreenYellow #afff00 rgb(175,255,0) hsl(8,100%,50%) 155 DarkOliveGreen2 #afff5f rgb(175,255,95) hsl(90,100%,68%) 156 PaleGreen1 #afff87 rgb(175,255,135) hsl(100,100%,76%) 157 DarkSeaGreen2 #afffaf rgb(175,255,175) hsl(120,100%,84%) 158 DarkSeaGreen1 #afffd7 rgb(175,255,215) hsl(150,100%,84%) 159 PaleTurquoise1 #afffff rgb(175,255,255) hsl(180,100%,84%) 160 Red3 #d70000 rgb(215,0,0) hsl(0,100%,42%) 161 DeepPink3 #d7005f rgb(215,0,95) hsl(33,100%,42%) 162 DeepPink3 #d70087 rgb(215,0,135) hsl(22,100%,42%) 163 Magenta3 #d700af rgb(215,0,175) hsl(11,100%,42%) 164 Magenta3 #d700d7 rgb(215,0,215) hsl(300,100%,42%) 165 Magenta2 #d700ff rgb(215,0,255) hsl(90,100%,50%) 166 DarkOrange3 #d75f00 rgb(215,95,0) hsl(6,100%,42%) 167 IndianRed #d75f5f rgb(215,95,95) hsl(0,60%,60%) 168 HotPink3 #d75f87 rgb(215,95,135) hsl(340,60%,60%) 169 HotPink2 #d75faf rgb(215,95,175) hsl(320,60%,60%) 170 Orchid #d75fd7 rgb(215,95,215) hsl(300,60%,60%) 171 MediumOrchid1 #d75fff rgb(215,95,255) hsl(285,100%,68%) 172 Orange3 #d78700 rgb(215,135,0) hsl(7,100%,42%) 173 LightSalmon3 #d7875f rgb(215,135,95) hsl(20,60%,60%) 174 LightPink3 #d78787 rgb(215,135,135) hsl(0,50%,68%) 175 Pink3 #d787af rgb(215,135,175) hsl(330,50%,68%) 176 Plum3 #d787d7 rgb(215,135,215) hsl(300,50%,68%) 177 Violet #d787ff rgb(215,135,255) hsl(280,100%,76%) 178 Gold3 #d7af00 rgb(215,175,0) hsl(8,100%,42%) 179 LightGoldenrod3 #d7af5f rgb(215,175,95) hsl(40,60%,60%) 180 Tan #d7af87 rgb(215,175,135) hsl(30,50%,68%) 181 MistyRose3 #d7afaf rgb(215,175,175) hsl(0,33%,76%) 182 Thistle3 #d7afd7 rgb(215,175,215) hsl(300,33%,76%) 183 Plum2 #d7afff rgb(215,175,255) hsl(270,100%,84%) 184 Yellow3 #d7d700 rgb(215,215,0) hsl(60,100%,42%) 185 Khaki3 #d7d75f rgb(215,215,95) hsl(60,60%,60%) 186 LightGoldenrod2 #d7d787 rgb(215,215,135) hsl(60,50%,68%) 187 LightYellow3 #d7d7af rgb(215,215,175) hsl(60,33%,76%) 188 Grey84 #d7d7d7 rgb(215,215,215) hsl(0,0%,84%) 189 LightSteelBlue1 #d7d7ff rgb(215,215,255) hsl(240,100%,92%) 190 Yellow2 #d7ff00 rgb(215,255,0) hsl(9,100%,50%) 191 DarkOliveGreen1 #d7ff5f rgb(215,255,95) hsl(75,100%,68%) 192 DarkOliveGreen1 #d7ff87 rgb(215,255,135) hsl(80,100%,76%) 193 DarkSeaGreen1 #d7ffaf rgb(215,255,175) hsl(90,100%,84%) 194 Honeydew2 #d7ffd7 rgb(215,255,215) hsl(120,100%,92%) 195 LightCyan1 #d7ffff rgb(215,255,255) hsl(180,100%,92%) 196 Red1 #ff0000 rgb(255,0,0) hsl(0,100%,50%) 197 DeepPink2 #ff005f rgb(255,0,95) hsl(37,100%,50%) 198 DeepPink1 #ff0087 rgb(255,0,135) hsl(28,100%,50%) 199 DeepPink1 #ff00af rgb(255,0,175) hsl(18,100%,50%) 200 Magenta2 #ff00d7 rgb(255,0,215) hsl(09,100%,50%) 201 Magenta1 #ff00ff rgb(255,0,255) hsl(300,100%,50%) 202 OrangeRed1 #ff5f00 rgb(255,95,0) hsl(2,100%,50%) 203 IndianRed1 #ff5f5f rgb(255,95,95) hsl(0,100%,68%) 204 IndianRed1 #ff5f87 rgb(255,95,135) hsl(345,100%,68%) 205 HotPink #ff5faf rgb(255,95,175) hsl(330,100%,68%) 206 HotPink #ff5fd7 rgb(255,95,215) hsl(315,100%,68%) 207 MediumOrchid1 #ff5fff rgb(255,95,255) hsl(300,100%,68%) 208 DarkOrange #ff8700 rgb(255,135,0) hsl(1,100%,50%) 209 Salmon1 #ff875f rgb(255,135,95) hsl(15,100%,68%) 210 LightCoral #ff8787 rgb(255,135,135) hsl(0,100%,76%) 211 PaleVioletRed1 #ff87af rgb(255,135,175) hsl(340,100%,76%) 212 Orchid2 #ff87d7 rgb(255,135,215) hsl(320,100%,76%) 213 Orchid1 #ff87ff rgb(255,135,255) hsl(300,100%,76%) 214 Orange1 #ffaf00 rgb(255,175,0) hsl(1,100%,50%) 215 SandyBrown #ffaf5f rgb(255,175,95) hsl(30,100%,68%) 216 LightSalmon1 #ffaf87 rgb(255,175,135) hsl(20,100%,76%) 217 LightPink1 #ffafaf rgb(255,175,175) hsl(0,100%,84%) 218 Pink1 #ffafd7 rgb(255,175,215) hsl(330,100%,84%) 219 Plum1 #ffafff rgb(255,175,255) hsl(300,100%,84%) 220 Gold1 #ffd700 rgb(255,215,0) hsl(0,100%,50%) 221 LightGoldenrod2 #ffd75f rgb(255,215,95) hsl(45,100%,68%) 222 LightGoldenrod2 #ffd787 rgb(255,215,135) hsl(40,100%,76%) 223 NavajoWhite1 #ffd7af rgb(255,215,175) hsl(30,100%,84%) 224 MistyRose1 #ffd7d7 rgb(255,215,215) hsl(0,100%,92%) 225 Thistle1 #ffd7ff rgb(255,215,255) hsl(300,100%,92%) 226 Yellow1 #ffff00 rgb(255,255,0) hsl(60,100%,50%) 227 LightGoldenrod1 #ffff5f rgb(255,255,95) hsl(60,100%,68%) 228 Khaki1 #ffff87 rgb(255,255,135) hsl(60,100%,76%) 229 Wheat1 #ffffaf rgb(255,255,175) hsl(60,100%,84%) 230 Cornsilk1 #ffffd7 rgb(255,255,215) hsl(60,100%,92%) 231 Grey100 #ffffff rgb(255,255,255) hsl(0,0%,100%) 232 Grey3 #080808 rgb(8,8,8) hsl(0,0%,3%) 233 Grey7 #121212 rgb(18,18,18) hsl(0,0%,7%) 234 Grey11 #1c1c1c rgb(28,28,28) hsl(0,0%,10%) 235 Grey15 #262626 rgb(38,38,38) hsl(0,0%,14%) 236 Grey19 #303030 rgb(48,48,48) hsl(0,0%,18%) 237 Grey23 #3a3a3a rgb(58,58,58) hsl(0,0%,22%) 238 Grey27 #444444 rgb(68,68,68) hsl(0,0%,26%) 239 Grey30 #4e4e4e rgb(78,78,78) hsl(0,0%,30%) 240 Grey35 #585858 rgb(88,88,88) hsl(0,0%,34%) 241 Grey39 #626262 rgb(98,98,98) hsl(0,0%,37%) 242 Grey42 #6c6c6c rgb(108,108,108) hsl(0,0%,40%) 243 Grey46 #767676 rgb(118,118,118) hsl(0,0%,46%) 244 Grey50 #808080 rgb(128,128,128) hsl(0,0%,50%) 245 Grey54 #8a8a8a rgb(138,138,138) hsl(0,0%,54%) 246 Grey58 #949494 rgb(148,148,148) hsl(0,0%,58%) 247 Grey62 #9e9e9e rgb(158,158,158) hsl(0,0%,61%) 248 Grey66 #a8a8a8 rgb(168,168,168) hsl(0,0%,65%) 249 Grey70 #b2b2b2 rgb(178,178,178) hsl(0,0%,69%) 250 Grey74 #bcbcbc rgb(188,188,188) hsl(0,0%,73%) 251 Grey78 #c6c6c6 rgb(198,198,198) hsl(0,0%,77%) 252 Grey82 #d0d0d0 rgb(208,208,208) hsl(0,0%,81%) 253 Grey85 #dadada rgb(218,218,218) hsl(0,0%,85%) 254 Grey89 #e4e4e4 rgb(228,228,228) hsl(0,0%,89%) 255 Grey93 #eeeeee rgb(238,238,238) hsl(0,0%,93%)","title":"256 Color Codes Cheat-Sheet"},{"location":"misc/color-codes/#256-color-codes-cheat-sheet","text":"Colors 0-15 are Xterm system colors. Xterm Number COL Xterm Name HEX RGB HSL 0 Black #000000 rgb(0,0,0) hsl(0,0%,0%) 1 Maroon #800000 rgb(128,0,0) hsl(0,100%,25%) 2 Green #008000 rgb(0,128,0) hsl(120,100%,25%) 3 Olive #808000 rgb(128,128,0) hsl(60,100%,25%) 4 Navy #000080 rgb(0,0,128) hsl(240,100%,25%) 5 Purple #800080 rgb(128,0,128) hsl(300,100%,25%) 6 Teal #008080 rgb(0,128,128) hsl(180,100%,25%) 7 Silver #c0c0c0 rgb(192,192,192) hsl(0,0%,75%) 8 Grey #808080 rgb(128,128,128) hsl(0,0%,50%) 9 Red #ff0000 rgb(255,0,0) hsl(0,100%,50%) 10 Lime #00ff00 rgb(0,255,0) hsl(120,100%,50%) 11 Yellow #ffff00 rgb(255,255,0) hsl(60,100%,50%) 12 Blue #0000ff rgb(0,0,255) hsl(240,100%,50%) 13 Fuchsia #ff00ff rgb(255,0,255) hsl(300,100%,50%) 14 Aqua #00ffff rgb(0,255,255) hsl(180,100%,50%) 15 White #ffffff rgb(255,255,255) hsl(0,0%,100%) 16 Grey0 #000000 rgb(0,0,0) hsl(0,0%,0%) 17 NavyBlue #00005f rgb(0,0,95) hsl(240,100%,18%) 18 DarkBlue #000087 rgb(0,0,135) hsl(240,100%,26%) 19 Blue3 #0000af rgb(0,0,175) hsl(240,100%,34%) 20 Blue3 #0000d7 rgb(0,0,215) hsl(240,100%,42%) 21 Blue1 #0000ff rgb(0,0,255) hsl(240,100%,50%) 22 DarkGreen #005f00 rgb(0,95,0) hsl(120,100%,18%) 23 DeepSkyBlue4 #005f5f rgb(0,95,95) hsl(180,100%,18%) 24 DeepSkyBlue4 #005f87 rgb(0,95,135) hsl(97,100%,26%) 25 DeepSkyBlue4 #005faf rgb(0,95,175) hsl(07,100%,34%) 26 DodgerBlue3 #005fd7 rgb(0,95,215) hsl(13,100%,42%) 27 DodgerBlue2 #005fff rgb(0,95,255) hsl(17,100%,50%) 28 Green4 #008700 rgb(0,135,0) hsl(120,100%,26%) 29 SpringGreen4 #00875f rgb(0,135,95) hsl(62,100%,26%) 30 Turquoise4 #008787 rgb(0,135,135) hsl(180,100%,26%) 31 DeepSkyBlue3 #0087af rgb(0,135,175) hsl(93,100%,34%) 32 DeepSkyBlue3 #0087d7 rgb(0,135,215) hsl(02,100%,42%) 33 DodgerBlue1 #0087ff rgb(0,135,255) hsl(08,100%,50%) 34 Green3 #00af00 rgb(0,175,0) hsl(120,100%,34%) 35 SpringGreen3 #00af5f rgb(0,175,95) hsl(52,100%,34%) 36 DarkCyan #00af87 rgb(0,175,135) hsl(66,100%,34%) 37 LightSeaGreen #00afaf rgb(0,175,175) hsl(180,100%,34%) 38 DeepSkyBlue2 #00afd7 rgb(0,175,215) hsl(91,100%,42%) 39 DeepSkyBlue1 #00afff rgb(0,175,255) hsl(98,100%,50%) 40 Green3 #00d700 rgb(0,215,0) hsl(120,100%,42%) 41 SpringGreen3 #00d75f rgb(0,215,95) hsl(46,100%,42%) 42 SpringGreen2 #00d787 rgb(0,215,135) hsl(57,100%,42%) 43 Cyan3 #00d7af rgb(0,215,175) hsl(68,100%,42%) 44 DarkTurquoise #00d7d7 rgb(0,215,215) hsl(180,100%,42%) 45 Turquoise2 #00d7ff rgb(0,215,255) hsl(89,100%,50%) 46 Green1 #00ff00 rgb(0,255,0) hsl(120,100%,50%) 47 SpringGreen2 #00ff5f rgb(0,255,95) hsl(42,100%,50%) 48 SpringGreen1 #00ff87 rgb(0,255,135) hsl(51,100%,50%) 49 MediumSpringGreen #00ffaf rgb(0,255,175) hsl(61,100%,50%) 50 Cyan2 #00ffd7 rgb(0,255,215) hsl(70,100%,50%) 51 Cyan1 #00ffff rgb(0,255,255) hsl(180,100%,50%) 52 DarkRed #5f0000 rgb(95,0,0) hsl(0,100%,18%) 53 DeepPink4 #5f005f rgb(95,0,95) hsl(300,100%,18%) 54 Purple4 #5f0087 rgb(95,0,135) hsl(82,100%,26%) 55 Purple4 #5f00af rgb(95,0,175) hsl(72,100%,34%) 56 Purple3 #5f00d7 rgb(95,0,215) hsl(66,100%,42%) 57 BlueViolet #5f00ff rgb(95,0,255) hsl(62,100%,50%) 58 Orange4 #5f5f00 rgb(95,95,0) hsl(60,100%,18%) 59 Grey37 #5f5f5f rgb(95,95,95) hsl(0,0%,37%) 60 MediumPurple4 #5f5f87 rgb(95,95,135) hsl(240,17%,45%) 61 SlateBlue3 #5f5faf rgb(95,95,175) hsl(240,33%,52%) 62 SlateBlue3 #5f5fd7 rgb(95,95,215) hsl(240,60%,60%) 63 RoyalBlue1 #5f5fff rgb(95,95,255) hsl(240,100%,68%) 64 Chartreuse4 #5f8700 rgb(95,135,0) hsl(7,100%,26%) 65 DarkSeaGreen4 #5f875f rgb(95,135,95) hsl(120,17%,45%) 66 PaleTurquoise4 #5f8787 rgb(95,135,135) hsl(180,17%,45%) 67 SteelBlue #5f87af rgb(95,135,175) hsl(210,33%,52%) 68 SteelBlue3 #5f87d7 rgb(95,135,215) hsl(220,60%,60%) 69 CornflowerBlue #5f87ff rgb(95,135,255) hsl(225,100%,68%) 70 Chartreuse3 #5faf00 rgb(95,175,0) hsl(7,100%,34%) 71 DarkSeaGreen4 #5faf5f rgb(95,175,95) hsl(120,33%,52%) 72 CadetBlue #5faf87 rgb(95,175,135) hsl(150,33%,52%) 73 CadetBlue #5fafaf rgb(95,175,175) hsl(180,33%,52%) 74 SkyBlue3 #5fafd7 rgb(95,175,215) hsl(200,60%,60%) 75 SteelBlue1 #5fafff rgb(95,175,255) hsl(210,100%,68%) 76 Chartreuse3 #5fd700 rgb(95,215,0) hsl(3,100%,42%) 77 PaleGreen3 #5fd75f rgb(95,215,95) hsl(120,60%,60%) 78 SeaGreen3 #5fd787 rgb(95,215,135) hsl(140,60%,60%) 79 Aquamarine3 #5fd7af rgb(95,215,175) hsl(160,60%,60%) 80 MediumTurquoise #5fd7d7 rgb(95,215,215) hsl(180,60%,60%) 81 SteelBlue1 #5fd7ff rgb(95,215,255) hsl(195,100%,68%) 82 Chartreuse2 #5fff00 rgb(95,255,0) hsl(7,100%,50%) 83 SeaGreen2 #5fff5f rgb(95,255,95) hsl(120,100%,68%) 84 SeaGreen1 #5fff87 rgb(95,255,135) hsl(135,100%,68%) 85 SeaGreen1 #5fffaf rgb(95,255,175) hsl(150,100%,68%) 86 Aquamarine1 #5fffd7 rgb(95,255,215) hsl(165,100%,68%) 87 DarkSlateGray2 #5fffff rgb(95,255,255) hsl(180,100%,68%) 88 DarkRed #870000 rgb(135,0,0) hsl(0,100%,26%) 89 DeepPink4 #87005f rgb(135,0,95) hsl(17,100%,26%) 90 DarkMagenta #870087 rgb(135,0,135) hsl(300,100%,26%) 91 DarkMagenta #8700af rgb(135,0,175) hsl(86,100%,34%) 92 DarkViolet #8700d7 rgb(135,0,215) hsl(77,100%,42%) 93 Purple #8700ff rgb(135,0,255) hsl(71,100%,50%) 94 Orange4 #875f00 rgb(135,95,0) hsl(2,100%,26%) 95 LightPink4 #875f5f rgb(135,95,95) hsl(0,17%,45%) 96 Plum4 #875f87 rgb(135,95,135) hsl(300,17%,45%) 97 MediumPurple3 #875faf rgb(135,95,175) hsl(270,33%,52%) 98 MediumPurple3 #875fd7 rgb(135,95,215) hsl(260,60%,60%) 99 SlateBlue1 #875fff rgb(135,95,255) hsl(255,100%,68%) 100 Yellow4 #878700 rgb(135,135,0) hsl(60,100%,26%) 101 Wheat4 #87875f rgb(135,135,95) hsl(60,17%,45%) 102 Grey53 #878787 rgb(135,135,135) hsl(0,0%,52%) 103 LightSlateGrey #8787af rgb(135,135,175) hsl(240,20%,60%) 104 MediumPurple #8787d7 rgb(135,135,215) hsl(240,50%,68%) 105 LightSlateBlue #8787ff rgb(135,135,255) hsl(240,100%,76%) 106 Yellow4 #87af00 rgb(135,175,0) hsl(3,100%,34%) 107 DarkOliveGreen3 #87af5f rgb(135,175,95) hsl(90,33%,52%) 108 DarkSeaGreen #87af87 rgb(135,175,135) hsl(120,20%,60%) 109 LightSkyBlue3 #87afaf rgb(135,175,175) hsl(180,20%,60%) 110 LightSkyBlue3 #87afd7 rgb(135,175,215) hsl(210,50%,68%) 111 SkyBlue2 #87afff rgb(135,175,255) hsl(220,100%,76%) 112 Chartreuse2 #87d700 rgb(135,215,0) hsl(2,100%,42%) 113 DarkOliveGreen3 #87d75f rgb(135,215,95) hsl(100,60%,60%) 114 PaleGreen3 #87d787 rgb(135,215,135) hsl(120,50%,68%) 115 DarkSeaGreen3 #87d7af rgb(135,215,175) hsl(150,50%,68%) 116 DarkSlateGray3 #87d7d7 rgb(135,215,215) hsl(180,50%,68%) 117 SkyBlue1 #87d7ff rgb(135,215,255) hsl(200,100%,76%) 118 Chartreuse1 #87ff00 rgb(135,255,0) hsl(8,100%,50%) 119 LightGreen #87ff5f rgb(135,255,95) hsl(105,100%,68%) 120 LightGreen #87ff87 rgb(135,255,135) hsl(120,100%,76%) 121 PaleGreen1 #87ffaf rgb(135,255,175) hsl(140,100%,76%) 122 Aquamarine1 #87ffd7 rgb(135,255,215) hsl(160,100%,76%) 123 DarkSlateGray1 #87ffff rgb(135,255,255) hsl(180,100%,76%) 124 Red3 #af0000 rgb(175,0,0) hsl(0,100%,34%) 125 DeepPink4 #af005f rgb(175,0,95) hsl(27,100%,34%) 126 MediumVioletRed #af0087 rgb(175,0,135) hsl(13,100%,34%) 127 Magenta3 #af00af rgb(175,0,175) hsl(300,100%,34%) 128 DarkViolet #af00d7 rgb(175,0,215) hsl(88,100%,42%) 129 Purple #af00ff rgb(175,0,255) hsl(81,100%,50%) 130 DarkOrange3 #af5f00 rgb(175,95,0) hsl(2,100%,34%) 131 IndianRed #af5f5f rgb(175,95,95) hsl(0,33%,52%) 132 HotPink3 #af5f87 rgb(175,95,135) hsl(330,33%,52%) 133 MediumOrchid3 #af5faf rgb(175,95,175) hsl(300,33%,52%) 134 MediumOrchid #af5fd7 rgb(175,95,215) hsl(280,60%,60%) 135 MediumPurple2 #af5fff rgb(175,95,255) hsl(270,100%,68%) 136 DarkGoldenrod #af8700 rgb(175,135,0) hsl(6,100%,34%) 137 LightSalmon3 #af875f rgb(175,135,95) hsl(30,33%,52%) 138 RosyBrown #af8787 rgb(175,135,135) hsl(0,20%,60%) 139 Grey63 #af87af rgb(175,135,175) hsl(300,20%,60%) 140 MediumPurple2 #af87d7 rgb(175,135,215) hsl(270,50%,68%) 141 MediumPurple1 #af87ff rgb(175,135,255) hsl(260,100%,76%) 142 Gold3 #afaf00 rgb(175,175,0) hsl(60,100%,34%) 143 DarkKhaki #afaf5f rgb(175,175,95) hsl(60,33%,52%) 144 NavajoWhite3 #afaf87 rgb(175,175,135) hsl(60,20%,60%) 145 Grey69 #afafaf rgb(175,175,175) hsl(0,0%,68%) 146 LightSteelBlue3 #afafd7 rgb(175,175,215) hsl(240,33%,76%) 147 LightSteelBlue #afafff rgb(175,175,255) hsl(240,100%,84%) 148 Yellow3 #afd700 rgb(175,215,0) hsl(1,100%,42%) 149 DarkOliveGreen3 #afd75f rgb(175,215,95) hsl(80,60%,60%) 150 DarkSeaGreen3 #afd787 rgb(175,215,135) hsl(90,50%,68%) 151 DarkSeaGreen2 #afd7af rgb(175,215,175) hsl(120,33%,76%) 152 LightCyan3 #afd7d7 rgb(175,215,215) hsl(180,33%,76%) 153 LightSkyBlue1 #afd7ff rgb(175,215,255) hsl(210,100%,84%) 154 GreenYellow #afff00 rgb(175,255,0) hsl(8,100%,50%) 155 DarkOliveGreen2 #afff5f rgb(175,255,95) hsl(90,100%,68%) 156 PaleGreen1 #afff87 rgb(175,255,135) hsl(100,100%,76%) 157 DarkSeaGreen2 #afffaf rgb(175,255,175) hsl(120,100%,84%) 158 DarkSeaGreen1 #afffd7 rgb(175,255,215) hsl(150,100%,84%) 159 PaleTurquoise1 #afffff rgb(175,255,255) hsl(180,100%,84%) 160 Red3 #d70000 rgb(215,0,0) hsl(0,100%,42%) 161 DeepPink3 #d7005f rgb(215,0,95) hsl(33,100%,42%) 162 DeepPink3 #d70087 rgb(215,0,135) hsl(22,100%,42%) 163 Magenta3 #d700af rgb(215,0,175) hsl(11,100%,42%) 164 Magenta3 #d700d7 rgb(215,0,215) hsl(300,100%,42%) 165 Magenta2 #d700ff rgb(215,0,255) hsl(90,100%,50%) 166 DarkOrange3 #d75f00 rgb(215,95,0) hsl(6,100%,42%) 167 IndianRed #d75f5f rgb(215,95,95) hsl(0,60%,60%) 168 HotPink3 #d75f87 rgb(215,95,135) hsl(340,60%,60%) 169 HotPink2 #d75faf rgb(215,95,175) hsl(320,60%,60%) 170 Orchid #d75fd7 rgb(215,95,215) hsl(300,60%,60%) 171 MediumOrchid1 #d75fff rgb(215,95,255) hsl(285,100%,68%) 172 Orange3 #d78700 rgb(215,135,0) hsl(7,100%,42%) 173 LightSalmon3 #d7875f rgb(215,135,95) hsl(20,60%,60%) 174 LightPink3 #d78787 rgb(215,135,135) hsl(0,50%,68%) 175 Pink3 #d787af rgb(215,135,175) hsl(330,50%,68%) 176 Plum3 #d787d7 rgb(215,135,215) hsl(300,50%,68%) 177 Violet #d787ff rgb(215,135,255) hsl(280,100%,76%) 178 Gold3 #d7af00 rgb(215,175,0) hsl(8,100%,42%) 179 LightGoldenrod3 #d7af5f rgb(215,175,95) hsl(40,60%,60%) 180 Tan #d7af87 rgb(215,175,135) hsl(30,50%,68%) 181 MistyRose3 #d7afaf rgb(215,175,175) hsl(0,33%,76%) 182 Thistle3 #d7afd7 rgb(215,175,215) hsl(300,33%,76%) 183 Plum2 #d7afff rgb(215,175,255) hsl(270,100%,84%) 184 Yellow3 #d7d700 rgb(215,215,0) hsl(60,100%,42%) 185 Khaki3 #d7d75f rgb(215,215,95) hsl(60,60%,60%) 186 LightGoldenrod2 #d7d787 rgb(215,215,135) hsl(60,50%,68%) 187 LightYellow3 #d7d7af rgb(215,215,175) hsl(60,33%,76%) 188 Grey84 #d7d7d7 rgb(215,215,215) hsl(0,0%,84%) 189 LightSteelBlue1 #d7d7ff rgb(215,215,255) hsl(240,100%,92%) 190 Yellow2 #d7ff00 rgb(215,255,0) hsl(9,100%,50%) 191 DarkOliveGreen1 #d7ff5f rgb(215,255,95) hsl(75,100%,68%) 192 DarkOliveGreen1 #d7ff87 rgb(215,255,135) hsl(80,100%,76%) 193 DarkSeaGreen1 #d7ffaf rgb(215,255,175) hsl(90,100%,84%) 194 Honeydew2 #d7ffd7 rgb(215,255,215) hsl(120,100%,92%) 195 LightCyan1 #d7ffff rgb(215,255,255) hsl(180,100%,92%) 196 Red1 #ff0000 rgb(255,0,0) hsl(0,100%,50%) 197 DeepPink2 #ff005f rgb(255,0,95) hsl(37,100%,50%) 198 DeepPink1 #ff0087 rgb(255,0,135) hsl(28,100%,50%) 199 DeepPink1 #ff00af rgb(255,0,175) hsl(18,100%,50%) 200 Magenta2 #ff00d7 rgb(255,0,215) hsl(09,100%,50%) 201 Magenta1 #ff00ff rgb(255,0,255) hsl(300,100%,50%) 202 OrangeRed1 #ff5f00 rgb(255,95,0) hsl(2,100%,50%) 203 IndianRed1 #ff5f5f rgb(255,95,95) hsl(0,100%,68%) 204 IndianRed1 #ff5f87 rgb(255,95,135) hsl(345,100%,68%) 205 HotPink #ff5faf rgb(255,95,175) hsl(330,100%,68%) 206 HotPink #ff5fd7 rgb(255,95,215) hsl(315,100%,68%) 207 MediumOrchid1 #ff5fff rgb(255,95,255) hsl(300,100%,68%) 208 DarkOrange #ff8700 rgb(255,135,0) hsl(1,100%,50%) 209 Salmon1 #ff875f rgb(255,135,95) hsl(15,100%,68%) 210 LightCoral #ff8787 rgb(255,135,135) hsl(0,100%,76%) 211 PaleVioletRed1 #ff87af rgb(255,135,175) hsl(340,100%,76%) 212 Orchid2 #ff87d7 rgb(255,135,215) hsl(320,100%,76%) 213 Orchid1 #ff87ff rgb(255,135,255) hsl(300,100%,76%) 214 Orange1 #ffaf00 rgb(255,175,0) hsl(1,100%,50%) 215 SandyBrown #ffaf5f rgb(255,175,95) hsl(30,100%,68%) 216 LightSalmon1 #ffaf87 rgb(255,175,135) hsl(20,100%,76%) 217 LightPink1 #ffafaf rgb(255,175,175) hsl(0,100%,84%) 218 Pink1 #ffafd7 rgb(255,175,215) hsl(330,100%,84%) 219 Plum1 #ffafff rgb(255,175,255) hsl(300,100%,84%) 220 Gold1 #ffd700 rgb(255,215,0) hsl(0,100%,50%) 221 LightGoldenrod2 #ffd75f rgb(255,215,95) hsl(45,100%,68%) 222 LightGoldenrod2 #ffd787 rgb(255,215,135) hsl(40,100%,76%) 223 NavajoWhite1 #ffd7af rgb(255,215,175) hsl(30,100%,84%) 224 MistyRose1 #ffd7d7 rgb(255,215,215) hsl(0,100%,92%) 225 Thistle1 #ffd7ff rgb(255,215,255) hsl(300,100%,92%) 226 Yellow1 #ffff00 rgb(255,255,0) hsl(60,100%,50%) 227 LightGoldenrod1 #ffff5f rgb(255,255,95) hsl(60,100%,68%) 228 Khaki1 #ffff87 rgb(255,255,135) hsl(60,100%,76%) 229 Wheat1 #ffffaf rgb(255,255,175) hsl(60,100%,84%) 230 Cornsilk1 #ffffd7 rgb(255,255,215) hsl(60,100%,92%) 231 Grey100 #ffffff rgb(255,255,255) hsl(0,0%,100%) 232 Grey3 #080808 rgb(8,8,8) hsl(0,0%,3%) 233 Grey7 #121212 rgb(18,18,18) hsl(0,0%,7%) 234 Grey11 #1c1c1c rgb(28,28,28) hsl(0,0%,10%) 235 Grey15 #262626 rgb(38,38,38) hsl(0,0%,14%) 236 Grey19 #303030 rgb(48,48,48) hsl(0,0%,18%) 237 Grey23 #3a3a3a rgb(58,58,58) hsl(0,0%,22%) 238 Grey27 #444444 rgb(68,68,68) hsl(0,0%,26%) 239 Grey30 #4e4e4e rgb(78,78,78) hsl(0,0%,30%) 240 Grey35 #585858 rgb(88,88,88) hsl(0,0%,34%) 241 Grey39 #626262 rgb(98,98,98) hsl(0,0%,37%) 242 Grey42 #6c6c6c rgb(108,108,108) hsl(0,0%,40%) 243 Grey46 #767676 rgb(118,118,118) hsl(0,0%,46%) 244 Grey50 #808080 rgb(128,128,128) hsl(0,0%,50%) 245 Grey54 #8a8a8a rgb(138,138,138) hsl(0,0%,54%) 246 Grey58 #949494 rgb(148,148,148) hsl(0,0%,58%) 247 Grey62 #9e9e9e rgb(158,158,158) hsl(0,0%,61%) 248 Grey66 #a8a8a8 rgb(168,168,168) hsl(0,0%,65%) 249 Grey70 #b2b2b2 rgb(178,178,178) hsl(0,0%,69%) 250 Grey74 #bcbcbc rgb(188,188,188) hsl(0,0%,73%) 251 Grey78 #c6c6c6 rgb(198,198,198) hsl(0,0%,77%) 252 Grey82 #d0d0d0 rgb(208,208,208) hsl(0,0%,81%) 253 Grey85 #dadada rgb(218,218,218) hsl(0,0%,85%) 254 Grey89 #e4e4e4 rgb(228,228,228) hsl(0,0%,89%) 255 Grey93 #eeeeee rgb(238,238,238) hsl(0,0%,93%)","title":"256 Color Codes Cheat-Sheet"},{"location":"misc/markdown/","text":"Markdown Markdown is a text-to-HTML conversion tool for web writers. Markdown allows you to write using an easy-to-read, easy-to-write plain text format, then convert it to structurally valid XHTML (or HTML). Documentation: Markdown Docs RFC: RFC 7763 GitHub Documentation: Writing Markdown on GitHub Headings # Heading 1 ## Heading 2 ### Heading 3 #### Heading 4 ##### Heading 5 ###### Heading 6 Here is a heading: # Heading , don't do this: #Heading Emphasis Emphasis, aka italics, with *asterisks* or _underscores_ . Strong emphasis, aka bold, with **asterisks** or __underscores__ . Combined emphasis with **asterisks and _underscores_** . Strikethrough uses two tildes. ~~Scratch this.~~ Line Breaks First line with two spaces after. And the next line. Lists Ordered Lists 1. First item 2. Second item 3. Third item Unordered Lists - First item - Second item - Third item Links Link with text: [ link-text ]( https://www.google.com ) Images Image with alt text: ![ alt-text ]( https://camo.githubusercontent.com/4d89cd791580bfb19080f8b0844ba7e1235aa4becc3f43dfd708a769e257d8de/68747470733a2f2f636e642d70726f642d312e73332e75732d776573742d3030342e6261636b626c617a6562322e636f6d2f6e65772d62616e6e6572342d7363616c65642d666f722d6769746875622e6a7067 ) Image without alt text: ![](https://camo.githubusercontent.com/4d89cd791580bfb19080f8b0844ba7e1235aa4becc3f43dfd708a769e257d8de/68747470733a2f2f636e642d70726f642d312e73332e75732d776573742d3030342e6261636b626c617a6562322e636f6d2f6e65772d62616e6e6572342d7363616c65642d666f722d6769746875622e6a7067) Position List of avail positions : Name Description left Left align data, left justify text. center Center align data, center justify text. right Right align data, right justify text. justify Double justify text. < p align = \"center\" > < img src = \"images/img\" > </ p > } Size Use as % width=\"1..100%\" < p align = \"center\" > < img src = \"images/img\" width = \"35%\" > </ p > Code Blocks Inline Code Block Inline `code` has `back-ticks around` it. Blocks of Code var s = \"JavaScript syntax highlighting\" ; alert ( s ); s = \"Python syntax highlighting\" print s No language indicated, so no syntax highlighting. But let's throw in a <b>tag</b>. Tables There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don't need to make the raw Markdown line up prettily. Basic table Code : | Syntax | Description | Test Text | | :--- | :----: | ---: | | Header | Title | Here's this | | Paragraph | Text | And more | Result : | Syntax | Description | Test Text | | :--- | :----: | ---: | | Header | Title | Here's this | | Paragraph | Text | And more | Task list To create a task list start line with square brackets with an empty space. Ex: [ ] and add text for task. To check the task replace the space between the bracket with \"x\". [x] Write the post [ ] Update the website [ ] Contact the user Rules This document contains a description of all rules, what they are checking for, as well as an examples of documents that break the rule and corrected versions of the examples. MD001 Header levels should only increment by one level at a time Tags: headers Aliases: header-increment This rule is triggered when you skip header levels in a markdown document, for example: ## Header 1 #### Header 3 We skipped out a 2nd level header in this document When using multiple header levels, nested headers should increase by only one level at a time: ## Header 1 ### Header 2 #### Header 3 ##### Header 4 ### Another Header 2 #### Another Header 3 MD002 First header should be a top level header Tags: headers Aliases: first-header-h1 Parameters: level (number; default 1) This rule is triggered when the first header in the document isn't a h1 header: ### This isn't a H1 header #### Another header The first header in the document should be a h1 header: ## Start with a H1 header ### Then use a H2 for subsections MD003 Header style Tags: headers Aliases: header-style Parameters: style ( :consistent , :atx , :atx_closed , :setext , :setext_with_atx ; default :consistent ) This rule is triggered when different header styles (atx, setext, and 'closed' atx) are used in the same document: ## ATX style H1 ### Closed ATX style H2 ## Setext style H1 =============== Be consistent with the style of header used in a document: ## ATX style H1 ### ATX style H2 The setext_with_atx doc style allows atx-style headers of level 3 or more in documents with setext style headers: Setext style H1 =============== Setext style H2 --------------- #### ATX style H3 Note: the configured header style can be a specific style to use (atx, atx_closed, setext, setext_with_atx), or simply require that the usage be consistent within the document. MD004 Unordered list style Tags: bullet, ul Aliases: ul-style Parameters: style ( :consistent , :asterisk , :plus , :dash , :sublist ; default :consistent ) This rule is triggered when the symbols used in the document for unordered list items do not match the configured unordered list style: * Item 1 + Item 2 - Item 3 To fix this issue, use the configured style for list items throughout the document: * Item 1 * Item 2 * Item 3 Note: the configured list style can be a specific symbol to use (asterisk, plus, dash), or simply require that the usage be consistent within the document (consistent) or within a level (sublist). For sublist, each level must be consistent within a document, even if they are separate lists. So this is allowed: * Item 1 * Item 2 - Item 2a + Item 2a1 - Item 2b * Item 3 Other stuff * Item 1 * Item 2 But this is not allowed: * Item 1 * Item 2 - Item 2a + Item 2a1 - Item 2b * Item 3 Other stuff - Item 1 - Item 2 MD005 Inconsistent indentation for list items at the same level Tags: bullet, ul, indentation Aliases: list-indent This rule is triggered when list items are parsed as being at the same level, but don't have the same indentation: * Item 1 * Nested Item 1 * Nested Item 2 * A misaligned item Usually this rule will be triggered because of a typo. Correct the indentation for the list to fix it: * Item 1 * Nested Item 1 * Nested Item 2 * Nested Item 3 MD006 Consider starting bulleted lists at the beginning of the line Tags: bullet, ul, indentation Aliases: ul-start-left This rule is triggered when top level lists don't start at the beginning of a line: Some text * List item * List item To fix, ensure that top level list items are not indented: Some test * List item * List item Rationale: Starting lists at the beginning of the line means that nested list items can all be indented by the same amount when an editor's indent function or the tab key is used to indent. Starting a list 1 space in means that the indent of the first nested list is less than the indent of the second level (3 characters if you use 4 space tabs, or 1 character if you use 2 space tabs). MD007 Unordered list indentation Tags: bullet, ul, indentation Aliases: ul-indent Parameters: indent (number; default 3) This rule is triggered when list items are not indented by the configured number of spaces (default: 2). Example: * List item * Nested list item indented by 3 spaces Corrected Example: * List item * Nested list item indented by 2 spaces Rationale (3 space indent): This matches the minimum possible indentation for ordered lists (i.e Kramdown won't parse anything less than 3 spaces as a sublist on OLs), and since MD005 requires consistent indentation across lists, anything less than three on this rule will cause a violation of MD005 if you have both kinds of lists in the same document. This means if you want to set this to 2, you'll need to disable MD005. Rationale (4 space indent): Same indent as code blocks, simpler for editors to implement. See https://cirosantilli.com/markdown-style-guide#spaces-before-list-marker for more information. In addition, this is a compatibility issue with multi-markdown parsers, which require a 4 space indents. See http://support.markedapp.com/discussions/problems/21-sub-lists-not-indenting for a description of the problem. MD009 Trailing spaces Tags: whitespace Aliases: no-trailing-spaces Parameters: br_spaces (number; default: 0) This rule is triggered on any lines that end with whitespace. To fix this, find the line that is triggered and remove any trailing spaces from the end. The br_spaces parameter allows an exception to this rule for a specific amount of trailing spaces used to insert an explicit line break/br element. For example, set br_spaces to 2 to allow exactly 2 spaces at the end of a line. Note: you have to set br_spaces to 2 or higher for this exception to take effect - you can't insert a br element with just a single trailing space, so if you set br_spaces to 1, the exception will be disabled, just as if it was set to the default of 0. MD010 Hard tabs Tags: whitespace, hard_tab Aliases: no-hard-tabs Parameters: ignore_code_blocks (boolean; default false) This rule is triggered by any lines that contain hard tab characters instead of using spaces for indentation. To fix this, replace any hard tab characters with spaces instead. Example: Some text * hard tab character used to indent the list item Corrected example: Some text * Spaces used to indent the list item instead You have the option to exclude this rule for code blocks. To do this, set the ignore_code_blocks parameter to true. MD011 Reversed link syntax Tags: links Aliases: no-reversed-links This rule is triggered when text that appears to be a link is encountered, but where the syntax appears to have been reversed (the [] and () are reversed): (Incorrect link syntax)[http://www.example.com/] To fix this, swap the [] and () around: [ Correct link syntax ]( http://www.example.com/ ) MD012 Multiple consecutive blank lines Tags: whitespace, blank_lines Aliases: no-multiple-blanks This rule is triggered when there are multiple consecutive blank lines in the document: Some text here Some more text here To fix this, delete the offending lines: Some text here Some more text here Note: this rule will not be triggered if there are multiple consecutive blank lines inside code blocks. MD013 Line length Tags: line_length Aliases: line-length Parameters: line_length, ignore_code_blocks, code_blocks, tables (number; default 80, boolean; default false, boolean; default true, boolean; default true) This rule is triggered when there are lines that are longer than the configured line length (default: 80 characters). To fix this, split the line up into multiple lines. This rule has an exception where there is no whitespace beyond the configured line length. This allows you to still include items such as long URLs without being forced to break them in the middle. You also have the option to exclude this rule for code blocks. To do this, set the ignore_code_blocks parameter to true. To exclude this rule for tables set the tables parameters to false. Setting the parameter code_blocks to false to exclude the rule for code blocks is deprecated and will be removed in a future release. Code blocks are included in this rule by default since it is often a requirement for document readability, and tentatively compatible with code rules. Still, some languages do not lend themselves to short lines. MD014 Dollar signs used before commands without showing output Tags: code Aliases: commands-show-output This rule is triggered when there are code blocks showing shell commands to be typed, and the shell commands are preceded by dollar signs ($): $ ls $ cat foo $ less bar The dollar signs are unnecessary in the above situation, and should not be included: ls cat foo less bar However, an exception is made when there is a need to distinguish between typed commands and command output, as in the following example: $ ls foo bar $ cat foo Hello world $ cat bar baz Rationale: it is easier to copy and paste and less noisy if the dollar signs are omitted when they are not needed. See https://cirosantilli.com/markdown-style-guide#dollar-signs-in-shell-code for more information. MD018 No space after hash on atx style header Tags: headers, atx, spaces Aliases: no-missing-space-atx This rule is triggered when spaces are missing after the hash characters in an atx style header: #Header 1 ##Header 2 To fix this, separate the header text from the hash character by a single space: ## Header 1 ### Header 2 MD019 Multiple spaces after hash on atx style header Tags: headers, atx, spaces Aliases: no-multiple-space-atx This rule is triggered when more than one space is used to separate the header text from the hash characters in an atx style header: ## Header 1 ### Header 2 To fix this, separate the header text from the hash character by a single space: ## Header 1 ### Header 2 MD020 No space inside hashes on closed atx style header Tags: headers, atx_closed, spaces Aliases: no-missing-space-closed-atx This rule is triggered when spaces are missing inside the hash characters in a closed atx style header: #Header 1# ##Header 2## To fix this, separate the header text from the hash character by a single space: ## Header 1 # ### Header 2 ## Note: this rule will fire if either side of the header is missing spaces. MD021 Multiple spaces inside hashes on closed atx style header Tags: headers, atx_closed, spaces Aliases: no-multiple-space-closed-atx This rule is triggered when more than one space is used to separate the header text from the hash characters in a closed atx style header: ## Header 1 # ### Header 2 ## To fix this, separate the header text from the hash character by a single space: ## Header 1 # ### Header 2 ## Note: this rule will fire if either side of the header contains multiple spaces. MD022 Headers should be surrounded by blank lines Tags: headers, blank_lines Aliases: blanks-around-headers This rule is triggered when headers (any style) are either not preceded or not followed by a blank line: ## Header 1 Some text Some more text ### Header 2 To fix this, ensure that all headers have a blank line both before and after (except where the header is at the beginning or end of the document): ## Header 1 Some text Some more text ### Header 2 Rationale: Aside from aesthetic reasons, some parsers, including kramdown, will not parse headers that don't have a blank line before, and will parse them as regular text. MD023 Headers must start at the beginning of the line Tags: headers, spaces Aliases: header-start-left This rule is triggered when a header is indented by one or more spaces: Some text # Indented header To fix this, ensure that all headers start at the beginning of the line: Some text ## Header Rationale: Headers that don't start at the beginning of the line will not be parsed as headers, and will instead appear as regular text. MD024 Multiple headers with the same content Tags: headers Aliases: no-duplicate-header Parameters: allow_different_nesting (boolean; default false) This rule is triggered if there are multiple headers in the document that have the same text: ## Some text ### Some text To fix this, ensure that the content of each header is different: ## Some text ### Some more text Rationale: Some markdown parses generate anchors for headers based on the header name, and having headers with the same content can cause problems with this. If the parameter allow_different_nesting is set to true , header duplication under different nesting is allowed, like it usually happens in change logs: ## Change log ### 2.0.0 #### Bug fixes #### Features ### 1.0.0 #### Bug fixes MD025 Multiple top level headers in the same document Tags: headers Aliases: single-h1 Parameters: level (number; default 1) This rule is triggered when a top level header is in use (the first line of the file is a h1 header), and more than one h1 header is in use in the document: ## Top level header ## Another top level header To fix, structure your document so that there is a single h1 header that is the title for the document, and all later headers are h2 or lower level headers: ## Title ### Header ### Another header Rationale: A top level header is a h1 on the first line of the file, and serves as the title for the document. If this convention is in use, then there can not be more than one title for the document, and the entire document should be contained within this header. Note: The level parameter can be used to change the top level (ex: to h2) in cases where an h1 is added externally. MD026 Trailing punctuation in header Tags: headers Aliases: no-trailing-punctuation Parameters: punctuation (string; default \".,;:!?\") This rule is triggered on any header that has a punctuation character as the last character in the line: ## This is a header. To fix this, remove any trailing punctuation: ## This is a header Note: The punctuation parameter can be used to specify what characters class as punctuation at the end of the header. For example, you can set it to '.,;:!' to allow headers with question marks in them, such as might be used in an FAQ. MD027 Multiple spaces after blockquote symbol Tags: blockquote, whitespace, indentation Aliases: no-multiple-space-blockquote This rule is triggered when blockquotes have more than one space after the blockquote ( > ) symbol: > This is a block quote with bad indentation > there should only be one. To fix, remove any extraneous space: > This is a blockquote with correct > indentation. MD028 Blank line inside blockquote Tags: blockquote, whitespace Aliases: no-blanks-blockquote This rule is triggered when two blockquote blocks are separated by nothing except for a blank line: > This is a blockquote > which is immediately followed by > this blockquote. Unfortunately > In some parsers, these are treated as the same blockquote. To fix this, ensure that any blockquotes that are right next to each other have some text in between: > This is a blockquote. And Jimmy also said: > This too is a blockquote. Alternatively, if they are supposed to be the same quote, then add the blockquote symbol at the beginning of the blank line: > This is a blockquote. > > This is the same blockquote. Rationale: Some markdown parsers will treat two blockquotes separated by one or more blank lines as the same blockquote, while others will treat them as separate blockquotes. MD029 Ordered list item prefix Tags: ol Aliases: ol-prefix Parameters: style ( :one , :ordered ; default :one ) This rule is triggered on ordered lists that do not either start with '1.' or do not have a prefix that increases in numerical order (depending on the configured style, which defaults to 'one'). Example valid list if the style is configured as 'one': 1. Do this. 1. Do that. 1. Done. Example valid list if the style is configured as 'ordered': 1. Do this. 2. Do that. 3. Done. MD030 Spaces after list markers Tags: ol, ul, whitespace Aliases: list-marker-space Parameters: ul_single, ol_single, ul_multi, ol_multi (number, default 1) This rule checks for the number of spaces between a list marker (e.g. ' - ', ' * ', ' + ' or ' 1. ') and the text of the list item. The number of spaces checked for depends on the document style in use, but the default is 1 space after any list marker: * Foo * Bar * Baz 1. Foo 1. Bar 1. Baz 1. Foo * Bar 1. Baz A document style may change the number of spaces after unordered list items and ordered list items independently, as well as based on whether the content of every item in the list consists of a single paragraph, or multiple paragraphs (including sub-lists and code blocks). For example, the style guide at https://cirosantilli.com/markdown-style-guide#spaces-after-list-marker specifies that 1 space after the list marker should be used if every item in the list fits within a single paragraph, but to use 2 or 3 spaces (for ordered and unordered lists respectively) if there are multiple paragraphs of content inside the list: * Foo * Bar * Baz vs. * Foo Second paragraph * Bar or 1. Foo Second paragraph 1. Bar To fix this, ensure the correct number of spaces are used after list marker for your selected document style. MD031 Fenced code blocks should be surrounded by blank lines Tags: code, blank_lines Aliases: blanks-around-fences This rule is triggered when fenced code blocks are either not preceded or not followed by a blank line: Some text ``` Code block ``` ``` Another code block ``` Some more text To fix this, ensure that all fenced code blocks have a blank line both before and after (except where the block is at the beginning or end of the document): Some text ``` Code block ``` ``` Another code block ``` Some more text Rationale: Aside from aesthetic reasons, some parsers, including kramdown, will not parse fenced code blocks that don't have blank lines before and after them. MD032 Lists should be surrounded by blank lines Tags: bullet, ul, ol, blank_lines Aliases: blanks-around-lists This rule is triggered when lists (of any kind) are either not preceded or not followed by a blank line: Some text * Some * List 1. Some 2. List Some text To fix this, ensure that all lists have a blank line both before and after (except where the block is at the beginning or end of the document): Some text * Some * List 1. Some 2. List Some text Rationale: Aside from aesthetic reasons, some parsers, including kramdown, will not parse lists that don't have blank lines before and after them. Note: List items without hanging indents are a violation of this rule; list items with hanging indents are okay: * This is not okay * This is okay MD033 Inline HTML Tags: html Aliases: no-inline-html This rule is triggered whenever raw HTML is used in a markdown document: <h1>Inline HTML header</h1> To fix this, use 'pure' markdown instead of including raw HTML: ## Markdown header Rationale: Raw HTML is allowed in markdown, but this rule is included for those who want their documents to only include \"pure\" markdown, or for those who are rendering markdown documents in something other than HTML. MD034 Bare URL used Tags: links, url Aliases: no-bare-urls This rule is triggered whenever a URL is given that isn't surrounded by angle brackets: For more information, see http://www.example.com/. To fix this, add angle brackets around the URL: For more information, see <http://www.example.com/>. Rationale: Without angle brackets, the URL isn't converted into a link in many markdown parsers. Note: if you do want a bare URL without it being converted into a link, enclose it in a code block, otherwise in some markdown parsers it will be converted: `http://www.example.com` MD035 Horizontal rule style Tags: hr Aliases: hr-style Parameters: style ( :consistent , \"---\", \"***\", or other string specifying the horizontal rule; default :consistent ) This rule is triggered when inconsistent styles of horizontal rules are used in the document: --- - - - *** * * * **** To fix this, ensure any horizontal rules used in the document are consistent, or match the given style if the rule is so configured: --- --- Note: by default, this rule is configured to just require that all horizontal rules in the document are the same, and will trigger if any of the horizontal rules are different than the first one encountered in the document. If you want to configure the rule to match a specific style, the parameter given to the 'style' option is a string containing the exact horizontal rule text that is allowed. MD036 Emphasis used instead of a header Tags: headers, emphasis Parameters: punctuation (string; default \".,;:!?\") Aliases: no-emphasis-as-header This check looks for instances where emphasized (i.e. bold or italic) text is used to separate sections, where a header should be used instead: **My document** Lorem ipsum dolor sit amet... _Another section_ Consectetur adipiscing elit, sed do eiusmod. To fix this, use markdown headers instead of emphasized text to denote sections: ## My document Lorem ipsum dolor sit amet... ### Another section Consectetur adipiscing elit, sed do eiusmod. Note: this rule looks for single line paragraphs that consist entirely of emphasized text. It won't fire on emphasis used within regular text, multi-line emphasized paragraphs, and paragraphs ending in punctuation. Similarly to rule MD026, you can configure what characters are recognized as punctuation. MD037 Spaces inside emphasis markers Tags: whitespace, emphasis Aliases: no-space-in-emphasis This rule is triggered when emphasis markers (bold, italic) are used, but they have spaces between the markers and the text: Here is some ** bold ** text. Here is some * italic * text. Here is some more __ bold __ text. Here is some more _ italic _ text. To fix this, remove the spaces around the emphasis markers: Here is some **bold** text. Here is some *italic* text. Here is some more __bold__ text. Here is some more _italic_ text. Rationale: Emphasis is only parsed as such when the asterisks/underscores aren't completely surrounded by spaces. This rule attempts to detect where they were surrounded by spaces, but it appears that emphasized text was intended by the author. MD038 Spaces inside code span elements Tags: whitespace, code Aliases: no-space-in-code This rule is triggered on code span elements that have spaces right inside the backticks: ` some text ` `some text ` ` some text` To fix this, remove the spaces inside the codespan markers: `some text` MD039 Spaces inside link text Tags: whitespace, links Aliases: no-space-in-links This rule is triggered on links that have spaces surrounding the link text: [ a link ]( http://www.example.com/ ) To fix this, remove the spaces surrounding the link text: [ a link ]( http://www.example.com/ ) MD040 Fenced code blocks should have a language specified Tags: code, language Aliases: fenced-code-language This rule is triggered when fenced code blocks are used, but a language isn't specified: ``` #!/bin/bash echo Hello world ``` To fix this, add a language specifier to the code block: ```bash #!/bin/bash echo Hello world ``` If no specific language is used, you can specify text as language. MD041 First line in file should be a top level header Tags: headers Aliases: first-line-h1 Parameters: level (number; default 1) This rule is triggered when the first line in the file isn't a top level (h1) header: This is a file without a header To fix this, add a header to the top of your file: ## File with header This is a file with a top level header Note: The level parameter can be used to change the top level (ex: to h2) in cases where an h1 is added externally. MD046 Code block style Tags: code Aliases: code-block-style Parameters: style ( :fenced , :indented , :consistent , default :fenced ) This rule is triggered when a different code block style is used than the configured one. For example, in the default configuration this rule is triggered for the following document: Some text. Code block Some more text. To fix this, used fenced code blocks: Some text. ```ruby Code block ``` Some more text. The reverse is true if the rule is configured to use the indented style. MD047 File should end with a single newline character Tags: blank_lines Aliases: single-trailing-newline This rule is triggered when there is not a single newline character at the end of a file. Example that triggers the rule: ## Heading This file ends without a newline.[EOF] To fix the violation, add a newline character to the end of the file: ## Heading This file ends with a newline. [EOF] Rationale: Some programs have trouble with files that do not end with a newline. More information: https://unix.stackexchange.com/questions/18743/whats-the-point-in-adding-a-new-line-to-the-end-of-a-file . Reference Link: markdown guide Rules: markownlint github","title":"Markdown"},{"location":"misc/markdown/#markdown","text":"Markdown is a text-to-HTML conversion tool for web writers. Markdown allows you to write using an easy-to-read, easy-to-write plain text format, then convert it to structurally valid XHTML (or HTML). Documentation: Markdown Docs RFC: RFC 7763 GitHub Documentation: Writing Markdown on GitHub","title":"Markdown"},{"location":"misc/markdown/#headings","text":"# Heading 1 ## Heading 2 ### Heading 3 #### Heading 4 ##### Heading 5 ###### Heading 6 Here is a heading: # Heading , don't do this: #Heading","title":"Headings"},{"location":"misc/markdown/#emphasis","text":"Emphasis, aka italics, with *asterisks* or _underscores_ . Strong emphasis, aka bold, with **asterisks** or __underscores__ . Combined emphasis with **asterisks and _underscores_** . Strikethrough uses two tildes. ~~Scratch this.~~","title":"Emphasis"},{"location":"misc/markdown/#line-breaks","text":"First line with two spaces after. And the next line.","title":"Line Breaks"},{"location":"misc/markdown/#lists","text":"","title":"Lists"},{"location":"misc/markdown/#ordered-lists","text":"1. First item 2. Second item 3. Third item","title":"Ordered Lists"},{"location":"misc/markdown/#unordered-lists","text":"- First item - Second item - Third item","title":"Unordered Lists"},{"location":"misc/markdown/#links","text":"Link with text: [ link-text ]( https://www.google.com )","title":"Links"},{"location":"misc/markdown/#images","text":"Image with alt text: ![ alt-text ]( https://camo.githubusercontent.com/4d89cd791580bfb19080f8b0844ba7e1235aa4becc3f43dfd708a769e257d8de/68747470733a2f2f636e642d70726f642d312e73332e75732d776573742d3030342e6261636b626c617a6562322e636f6d2f6e65772d62616e6e6572342d7363616c65642d666f722d6769746875622e6a7067 ) Image without alt text: ![](https://camo.githubusercontent.com/4d89cd791580bfb19080f8b0844ba7e1235aa4becc3f43dfd708a769e257d8de/68747470733a2f2f636e642d70726f642d312e73332e75732d776573742d3030342e6261636b626c617a6562322e636f6d2f6e65772d62616e6e6572342d7363616c65642d666f722d6769746875622e6a7067)","title":"Images"},{"location":"misc/markdown/#position","text":"List of avail positions : Name Description left Left align data, left justify text. center Center align data, center justify text. right Right align data, right justify text. justify Double justify text. < p align = \"center\" > < img src = \"images/img\" > </ p > }","title":"Position"},{"location":"misc/markdown/#size","text":"Use as % width=\"1..100%\" < p align = \"center\" > < img src = \"images/img\" width = \"35%\" > </ p >","title":"Size"},{"location":"misc/markdown/#code-blocks","text":"","title":"Code Blocks"},{"location":"misc/markdown/#inline-code-block","text":"Inline `code` has `back-ticks around` it.","title":"Inline Code Block"},{"location":"misc/markdown/#blocks-of-code","text":"var s = \"JavaScript syntax highlighting\" ; alert ( s ); s = \"Python syntax highlighting\" print s No language indicated, so no syntax highlighting. But let's throw in a <b>tag</b>.","title":"Blocks of Code"},{"location":"misc/markdown/#tables","text":"There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don't need to make the raw Markdown line up prettily. Basic table Code : | Syntax | Description | Test Text | | :--- | :----: | ---: | | Header | Title | Here's this | | Paragraph | Text | And more | Result : | Syntax | Description | Test Text | | :--- | :----: | ---: | | Header | Title | Here's this | | Paragraph | Text | And more |","title":"Tables"},{"location":"misc/markdown/#task-list","text":"To create a task list start line with square brackets with an empty space. Ex: [ ] and add text for task. To check the task replace the space between the bracket with \"x\". [x] Write the post [ ] Update the website [ ] Contact the user","title":"Task list"},{"location":"misc/markdown/#rules","text":"This document contains a description of all rules, what they are checking for, as well as an examples of documents that break the rule and corrected versions of the examples.","title":"Rules"},{"location":"misc/markdown/#md001","text":"Header levels should only increment by one level at a time Tags: headers Aliases: header-increment This rule is triggered when you skip header levels in a markdown document, for example: ## Header 1 #### Header 3 We skipped out a 2nd level header in this document When using multiple header levels, nested headers should increase by only one level at a time: ## Header 1 ### Header 2 #### Header 3 ##### Header 4 ### Another Header 2 #### Another Header 3","title":"MD001"},{"location":"misc/markdown/#md002","text":"First header should be a top level header Tags: headers Aliases: first-header-h1 Parameters: level (number; default 1) This rule is triggered when the first header in the document isn't a h1 header: ### This isn't a H1 header #### Another header The first header in the document should be a h1 header: ## Start with a H1 header ### Then use a H2 for subsections","title":"MD002"},{"location":"misc/markdown/#md003","text":"Header style Tags: headers Aliases: header-style Parameters: style ( :consistent , :atx , :atx_closed , :setext , :setext_with_atx ; default :consistent ) This rule is triggered when different header styles (atx, setext, and 'closed' atx) are used in the same document: ## ATX style H1 ### Closed ATX style H2 ## Setext style H1 =============== Be consistent with the style of header used in a document: ## ATX style H1 ### ATX style H2 The setext_with_atx doc style allows atx-style headers of level 3 or more in documents with setext style headers: Setext style H1 =============== Setext style H2 --------------- #### ATX style H3 Note: the configured header style can be a specific style to use (atx, atx_closed, setext, setext_with_atx), or simply require that the usage be consistent within the document.","title":"MD003"},{"location":"misc/markdown/#md004","text":"Unordered list style Tags: bullet, ul Aliases: ul-style Parameters: style ( :consistent , :asterisk , :plus , :dash , :sublist ; default :consistent ) This rule is triggered when the symbols used in the document for unordered list items do not match the configured unordered list style: * Item 1 + Item 2 - Item 3 To fix this issue, use the configured style for list items throughout the document: * Item 1 * Item 2 * Item 3 Note: the configured list style can be a specific symbol to use (asterisk, plus, dash), or simply require that the usage be consistent within the document (consistent) or within a level (sublist). For sublist, each level must be consistent within a document, even if they are separate lists. So this is allowed: * Item 1 * Item 2 - Item 2a + Item 2a1 - Item 2b * Item 3 Other stuff * Item 1 * Item 2 But this is not allowed: * Item 1 * Item 2 - Item 2a + Item 2a1 - Item 2b * Item 3 Other stuff - Item 1 - Item 2","title":"MD004"},{"location":"misc/markdown/#md005","text":"Inconsistent indentation for list items at the same level Tags: bullet, ul, indentation Aliases: list-indent This rule is triggered when list items are parsed as being at the same level, but don't have the same indentation: * Item 1 * Nested Item 1 * Nested Item 2 * A misaligned item Usually this rule will be triggered because of a typo. Correct the indentation for the list to fix it: * Item 1 * Nested Item 1 * Nested Item 2 * Nested Item 3","title":"MD005"},{"location":"misc/markdown/#md006","text":"Consider starting bulleted lists at the beginning of the line Tags: bullet, ul, indentation Aliases: ul-start-left This rule is triggered when top level lists don't start at the beginning of a line: Some text * List item * List item To fix, ensure that top level list items are not indented: Some test * List item * List item Rationale: Starting lists at the beginning of the line means that nested list items can all be indented by the same amount when an editor's indent function or the tab key is used to indent. Starting a list 1 space in means that the indent of the first nested list is less than the indent of the second level (3 characters if you use 4 space tabs, or 1 character if you use 2 space tabs).","title":"MD006"},{"location":"misc/markdown/#md007","text":"Unordered list indentation Tags: bullet, ul, indentation Aliases: ul-indent Parameters: indent (number; default 3) This rule is triggered when list items are not indented by the configured number of spaces (default: 2). Example: * List item * Nested list item indented by 3 spaces Corrected Example: * List item * Nested list item indented by 2 spaces Rationale (3 space indent): This matches the minimum possible indentation for ordered lists (i.e Kramdown won't parse anything less than 3 spaces as a sublist on OLs), and since MD005 requires consistent indentation across lists, anything less than three on this rule will cause a violation of MD005 if you have both kinds of lists in the same document. This means if you want to set this to 2, you'll need to disable MD005. Rationale (4 space indent): Same indent as code blocks, simpler for editors to implement. See https://cirosantilli.com/markdown-style-guide#spaces-before-list-marker for more information. In addition, this is a compatibility issue with multi-markdown parsers, which require a 4 space indents. See http://support.markedapp.com/discussions/problems/21-sub-lists-not-indenting for a description of the problem.","title":"MD007"},{"location":"misc/markdown/#md009","text":"Trailing spaces Tags: whitespace Aliases: no-trailing-spaces Parameters: br_spaces (number; default: 0) This rule is triggered on any lines that end with whitespace. To fix this, find the line that is triggered and remove any trailing spaces from the end. The br_spaces parameter allows an exception to this rule for a specific amount of trailing spaces used to insert an explicit line break/br element. For example, set br_spaces to 2 to allow exactly 2 spaces at the end of a line. Note: you have to set br_spaces to 2 or higher for this exception to take effect - you can't insert a br element with just a single trailing space, so if you set br_spaces to 1, the exception will be disabled, just as if it was set to the default of 0.","title":"MD009"},{"location":"misc/markdown/#md010","text":"Hard tabs Tags: whitespace, hard_tab Aliases: no-hard-tabs Parameters: ignore_code_blocks (boolean; default false) This rule is triggered by any lines that contain hard tab characters instead of using spaces for indentation. To fix this, replace any hard tab characters with spaces instead. Example: Some text * hard tab character used to indent the list item Corrected example: Some text * Spaces used to indent the list item instead You have the option to exclude this rule for code blocks. To do this, set the ignore_code_blocks parameter to true.","title":"MD010"},{"location":"misc/markdown/#md011","text":"Reversed link syntax Tags: links Aliases: no-reversed-links This rule is triggered when text that appears to be a link is encountered, but where the syntax appears to have been reversed (the [] and () are reversed): (Incorrect link syntax)[http://www.example.com/] To fix this, swap the [] and () around: [ Correct link syntax ]( http://www.example.com/ )","title":"MD011"},{"location":"misc/markdown/#md012","text":"Multiple consecutive blank lines Tags: whitespace, blank_lines Aliases: no-multiple-blanks This rule is triggered when there are multiple consecutive blank lines in the document: Some text here Some more text here To fix this, delete the offending lines: Some text here Some more text here Note: this rule will not be triggered if there are multiple consecutive blank lines inside code blocks.","title":"MD012"},{"location":"misc/markdown/#md013","text":"Line length Tags: line_length Aliases: line-length Parameters: line_length, ignore_code_blocks, code_blocks, tables (number; default 80, boolean; default false, boolean; default true, boolean; default true) This rule is triggered when there are lines that are longer than the configured line length (default: 80 characters). To fix this, split the line up into multiple lines. This rule has an exception where there is no whitespace beyond the configured line length. This allows you to still include items such as long URLs without being forced to break them in the middle. You also have the option to exclude this rule for code blocks. To do this, set the ignore_code_blocks parameter to true. To exclude this rule for tables set the tables parameters to false. Setting the parameter code_blocks to false to exclude the rule for code blocks is deprecated and will be removed in a future release. Code blocks are included in this rule by default since it is often a requirement for document readability, and tentatively compatible with code rules. Still, some languages do not lend themselves to short lines.","title":"MD013"},{"location":"misc/markdown/#md014","text":"Dollar signs used before commands without showing output Tags: code Aliases: commands-show-output This rule is triggered when there are code blocks showing shell commands to be typed, and the shell commands are preceded by dollar signs ($): $ ls $ cat foo $ less bar The dollar signs are unnecessary in the above situation, and should not be included: ls cat foo less bar However, an exception is made when there is a need to distinguish between typed commands and command output, as in the following example: $ ls foo bar $ cat foo Hello world $ cat bar baz Rationale: it is easier to copy and paste and less noisy if the dollar signs are omitted when they are not needed. See https://cirosantilli.com/markdown-style-guide#dollar-signs-in-shell-code for more information.","title":"MD014"},{"location":"misc/markdown/#md018","text":"No space after hash on atx style header Tags: headers, atx, spaces Aliases: no-missing-space-atx This rule is triggered when spaces are missing after the hash characters in an atx style header: #Header 1 ##Header 2 To fix this, separate the header text from the hash character by a single space: ## Header 1 ### Header 2","title":"MD018"},{"location":"misc/markdown/#md019","text":"Multiple spaces after hash on atx style header Tags: headers, atx, spaces Aliases: no-multiple-space-atx This rule is triggered when more than one space is used to separate the header text from the hash characters in an atx style header: ## Header 1 ### Header 2 To fix this, separate the header text from the hash character by a single space: ## Header 1 ### Header 2","title":"MD019"},{"location":"misc/markdown/#md020","text":"No space inside hashes on closed atx style header Tags: headers, atx_closed, spaces Aliases: no-missing-space-closed-atx This rule is triggered when spaces are missing inside the hash characters in a closed atx style header: #Header 1# ##Header 2## To fix this, separate the header text from the hash character by a single space: ## Header 1 # ### Header 2 ## Note: this rule will fire if either side of the header is missing spaces.","title":"MD020"},{"location":"misc/markdown/#md021","text":"Multiple spaces inside hashes on closed atx style header Tags: headers, atx_closed, spaces Aliases: no-multiple-space-closed-atx This rule is triggered when more than one space is used to separate the header text from the hash characters in a closed atx style header: ## Header 1 # ### Header 2 ## To fix this, separate the header text from the hash character by a single space: ## Header 1 # ### Header 2 ## Note: this rule will fire if either side of the header contains multiple spaces.","title":"MD021"},{"location":"misc/markdown/#md022","text":"Headers should be surrounded by blank lines Tags: headers, blank_lines Aliases: blanks-around-headers This rule is triggered when headers (any style) are either not preceded or not followed by a blank line: ## Header 1 Some text Some more text ### Header 2 To fix this, ensure that all headers have a blank line both before and after (except where the header is at the beginning or end of the document): ## Header 1 Some text Some more text ### Header 2 Rationale: Aside from aesthetic reasons, some parsers, including kramdown, will not parse headers that don't have a blank line before, and will parse them as regular text.","title":"MD022"},{"location":"misc/markdown/#md023","text":"Headers must start at the beginning of the line Tags: headers, spaces Aliases: header-start-left This rule is triggered when a header is indented by one or more spaces: Some text # Indented header To fix this, ensure that all headers start at the beginning of the line: Some text ## Header Rationale: Headers that don't start at the beginning of the line will not be parsed as headers, and will instead appear as regular text.","title":"MD023"},{"location":"misc/markdown/#md024","text":"Multiple headers with the same content Tags: headers Aliases: no-duplicate-header Parameters: allow_different_nesting (boolean; default false) This rule is triggered if there are multiple headers in the document that have the same text: ## Some text ### Some text To fix this, ensure that the content of each header is different: ## Some text ### Some more text Rationale: Some markdown parses generate anchors for headers based on the header name, and having headers with the same content can cause problems with this. If the parameter allow_different_nesting is set to true , header duplication under different nesting is allowed, like it usually happens in change logs: ## Change log ### 2.0.0 #### Bug fixes #### Features ### 1.0.0 #### Bug fixes","title":"MD024"},{"location":"misc/markdown/#md025","text":"Multiple top level headers in the same document Tags: headers Aliases: single-h1 Parameters: level (number; default 1) This rule is triggered when a top level header is in use (the first line of the file is a h1 header), and more than one h1 header is in use in the document: ## Top level header ## Another top level header To fix, structure your document so that there is a single h1 header that is the title for the document, and all later headers are h2 or lower level headers: ## Title ### Header ### Another header Rationale: A top level header is a h1 on the first line of the file, and serves as the title for the document. If this convention is in use, then there can not be more than one title for the document, and the entire document should be contained within this header. Note: The level parameter can be used to change the top level (ex: to h2) in cases where an h1 is added externally.","title":"MD025"},{"location":"misc/markdown/#md026","text":"Trailing punctuation in header Tags: headers Aliases: no-trailing-punctuation Parameters: punctuation (string; default \".,;:!?\") This rule is triggered on any header that has a punctuation character as the last character in the line: ## This is a header. To fix this, remove any trailing punctuation: ## This is a header Note: The punctuation parameter can be used to specify what characters class as punctuation at the end of the header. For example, you can set it to '.,;:!' to allow headers with question marks in them, such as might be used in an FAQ.","title":"MD026"},{"location":"misc/markdown/#md027","text":"Multiple spaces after blockquote symbol Tags: blockquote, whitespace, indentation Aliases: no-multiple-space-blockquote This rule is triggered when blockquotes have more than one space after the blockquote ( > ) symbol: > This is a block quote with bad indentation > there should only be one. To fix, remove any extraneous space: > This is a blockquote with correct > indentation.","title":"MD027"},{"location":"misc/markdown/#md028","text":"Blank line inside blockquote Tags: blockquote, whitespace Aliases: no-blanks-blockquote This rule is triggered when two blockquote blocks are separated by nothing except for a blank line: > This is a blockquote > which is immediately followed by > this blockquote. Unfortunately > In some parsers, these are treated as the same blockquote. To fix this, ensure that any blockquotes that are right next to each other have some text in between: > This is a blockquote. And Jimmy also said: > This too is a blockquote. Alternatively, if they are supposed to be the same quote, then add the blockquote symbol at the beginning of the blank line: > This is a blockquote. > > This is the same blockquote. Rationale: Some markdown parsers will treat two blockquotes separated by one or more blank lines as the same blockquote, while others will treat them as separate blockquotes.","title":"MD028"},{"location":"misc/markdown/#md029","text":"Ordered list item prefix Tags: ol Aliases: ol-prefix Parameters: style ( :one , :ordered ; default :one ) This rule is triggered on ordered lists that do not either start with '1.' or do not have a prefix that increases in numerical order (depending on the configured style, which defaults to 'one'). Example valid list if the style is configured as 'one': 1. Do this. 1. Do that. 1. Done. Example valid list if the style is configured as 'ordered': 1. Do this. 2. Do that. 3. Done.","title":"MD029"},{"location":"misc/markdown/#md030","text":"Spaces after list markers Tags: ol, ul, whitespace Aliases: list-marker-space Parameters: ul_single, ol_single, ul_multi, ol_multi (number, default 1) This rule checks for the number of spaces between a list marker (e.g. ' - ', ' * ', ' + ' or ' 1. ') and the text of the list item. The number of spaces checked for depends on the document style in use, but the default is 1 space after any list marker: * Foo * Bar * Baz 1. Foo 1. Bar 1. Baz 1. Foo * Bar 1. Baz A document style may change the number of spaces after unordered list items and ordered list items independently, as well as based on whether the content of every item in the list consists of a single paragraph, or multiple paragraphs (including sub-lists and code blocks). For example, the style guide at https://cirosantilli.com/markdown-style-guide#spaces-after-list-marker specifies that 1 space after the list marker should be used if every item in the list fits within a single paragraph, but to use 2 or 3 spaces (for ordered and unordered lists respectively) if there are multiple paragraphs of content inside the list: * Foo * Bar * Baz vs. * Foo Second paragraph * Bar or 1. Foo Second paragraph 1. Bar To fix this, ensure the correct number of spaces are used after list marker for your selected document style.","title":"MD030"},{"location":"misc/markdown/#md031","text":"Fenced code blocks should be surrounded by blank lines Tags: code, blank_lines Aliases: blanks-around-fences This rule is triggered when fenced code blocks are either not preceded or not followed by a blank line: Some text ``` Code block ``` ``` Another code block ``` Some more text To fix this, ensure that all fenced code blocks have a blank line both before and after (except where the block is at the beginning or end of the document): Some text ``` Code block ``` ``` Another code block ``` Some more text Rationale: Aside from aesthetic reasons, some parsers, including kramdown, will not parse fenced code blocks that don't have blank lines before and after them.","title":"MD031"},{"location":"misc/markdown/#md032","text":"Lists should be surrounded by blank lines Tags: bullet, ul, ol, blank_lines Aliases: blanks-around-lists This rule is triggered when lists (of any kind) are either not preceded or not followed by a blank line: Some text * Some * List 1. Some 2. List Some text To fix this, ensure that all lists have a blank line both before and after (except where the block is at the beginning or end of the document): Some text * Some * List 1. Some 2. List Some text Rationale: Aside from aesthetic reasons, some parsers, including kramdown, will not parse lists that don't have blank lines before and after them. Note: List items without hanging indents are a violation of this rule; list items with hanging indents are okay: * This is not okay * This is okay","title":"MD032"},{"location":"misc/markdown/#md033","text":"Inline HTML Tags: html Aliases: no-inline-html This rule is triggered whenever raw HTML is used in a markdown document: <h1>Inline HTML header</h1> To fix this, use 'pure' markdown instead of including raw HTML: ## Markdown header Rationale: Raw HTML is allowed in markdown, but this rule is included for those who want their documents to only include \"pure\" markdown, or for those who are rendering markdown documents in something other than HTML.","title":"MD033"},{"location":"misc/markdown/#md034","text":"Bare URL used Tags: links, url Aliases: no-bare-urls This rule is triggered whenever a URL is given that isn't surrounded by angle brackets: For more information, see http://www.example.com/. To fix this, add angle brackets around the URL: For more information, see <http://www.example.com/>. Rationale: Without angle brackets, the URL isn't converted into a link in many markdown parsers. Note: if you do want a bare URL without it being converted into a link, enclose it in a code block, otherwise in some markdown parsers it will be converted: `http://www.example.com`","title":"MD034"},{"location":"misc/markdown/#md035","text":"Horizontal rule style Tags: hr Aliases: hr-style Parameters: style ( :consistent , \"---\", \"***\", or other string specifying the horizontal rule; default :consistent ) This rule is triggered when inconsistent styles of horizontal rules are used in the document: --- - - - *** * * * **** To fix this, ensure any horizontal rules used in the document are consistent, or match the given style if the rule is so configured: --- --- Note: by default, this rule is configured to just require that all horizontal rules in the document are the same, and will trigger if any of the horizontal rules are different than the first one encountered in the document. If you want to configure the rule to match a specific style, the parameter given to the 'style' option is a string containing the exact horizontal rule text that is allowed.","title":"MD035"},{"location":"misc/markdown/#md036","text":"Emphasis used instead of a header Tags: headers, emphasis Parameters: punctuation (string; default \".,;:!?\") Aliases: no-emphasis-as-header This check looks for instances where emphasized (i.e. bold or italic) text is used to separate sections, where a header should be used instead: **My document** Lorem ipsum dolor sit amet... _Another section_ Consectetur adipiscing elit, sed do eiusmod. To fix this, use markdown headers instead of emphasized text to denote sections: ## My document Lorem ipsum dolor sit amet... ### Another section Consectetur adipiscing elit, sed do eiusmod. Note: this rule looks for single line paragraphs that consist entirely of emphasized text. It won't fire on emphasis used within regular text, multi-line emphasized paragraphs, and paragraphs ending in punctuation. Similarly to rule MD026, you can configure what characters are recognized as punctuation.","title":"MD036"},{"location":"misc/markdown/#md037","text":"Spaces inside emphasis markers Tags: whitespace, emphasis Aliases: no-space-in-emphasis This rule is triggered when emphasis markers (bold, italic) are used, but they have spaces between the markers and the text: Here is some ** bold ** text. Here is some * italic * text. Here is some more __ bold __ text. Here is some more _ italic _ text. To fix this, remove the spaces around the emphasis markers: Here is some **bold** text. Here is some *italic* text. Here is some more __bold__ text. Here is some more _italic_ text. Rationale: Emphasis is only parsed as such when the asterisks/underscores aren't completely surrounded by spaces. This rule attempts to detect where they were surrounded by spaces, but it appears that emphasized text was intended by the author.","title":"MD037"},{"location":"misc/markdown/#md038","text":"Spaces inside code span elements Tags: whitespace, code Aliases: no-space-in-code This rule is triggered on code span elements that have spaces right inside the backticks: ` some text ` `some text ` ` some text` To fix this, remove the spaces inside the codespan markers: `some text`","title":"MD038"},{"location":"misc/markdown/#md039","text":"Spaces inside link text Tags: whitespace, links Aliases: no-space-in-links This rule is triggered on links that have spaces surrounding the link text: [ a link ]( http://www.example.com/ ) To fix this, remove the spaces surrounding the link text: [ a link ]( http://www.example.com/ )","title":"MD039"},{"location":"misc/markdown/#md040","text":"Fenced code blocks should have a language specified Tags: code, language Aliases: fenced-code-language This rule is triggered when fenced code blocks are used, but a language isn't specified: ``` #!/bin/bash echo Hello world ``` To fix this, add a language specifier to the code block: ```bash #!/bin/bash echo Hello world ``` If no specific language is used, you can specify text as language.","title":"MD040"},{"location":"misc/markdown/#md041","text":"First line in file should be a top level header Tags: headers Aliases: first-line-h1 Parameters: level (number; default 1) This rule is triggered when the first line in the file isn't a top level (h1) header: This is a file without a header To fix this, add a header to the top of your file: ## File with header This is a file with a top level header Note: The level parameter can be used to change the top level (ex: to h2) in cases where an h1 is added externally.","title":"MD041"},{"location":"misc/markdown/#md046","text":"Code block style Tags: code Aliases: code-block-style Parameters: style ( :fenced , :indented , :consistent , default :fenced ) This rule is triggered when a different code block style is used than the configured one. For example, in the default configuration this rule is triggered for the following document: Some text. Code block Some more text. To fix this, used fenced code blocks: Some text. ```ruby Code block ``` Some more text. The reverse is true if the rule is configured to use the indented style.","title":"MD046"},{"location":"misc/markdown/#md047","text":"File should end with a single newline character Tags: blank_lines Aliases: single-trailing-newline This rule is triggered when there is not a single newline character at the end of a file. Example that triggers the rule: ## Heading This file ends without a newline.[EOF] To fix the violation, add a newline character to the end of the file: ## Heading This file ends with a newline. [EOF] Rationale: Some programs have trouble with files that do not end with a newline. More information: https://unix.stackexchange.com/questions/18743/whats-the-point-in-adding-a-new-line-to-the-end-of-a-file .","title":"MD047"},{"location":"misc/markdown/#reference","text":"Link: markdown guide Rules: markownlint github","title":"Reference"},{"location":"misc/mermaid/","text":"Mermaid graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!];","title":"Mermaid"},{"location":"misc/mermaid/#mermaid","text":"graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!];","title":"Mermaid"},{"location":"misc/mkdocs/","text":"MKDocs Material Admonition markdown_extensions: - admonition - pymdownx.details - pymdownx.superfences Supported types Following is a list of type qualifiers provided by Material for MkDocs, whereas the default type, and thus fallback for unknown type qualifiers, is note 1 : How to Use the type belong !!! as : !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. note Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. abstract Abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. info Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. tip Tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. success Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. question Question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. warning Warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. failure Failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. danger Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. bug Bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. example Example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. quote Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Previously, some of the supported types defined more than one qualifier. For example, authors could use summary or tldr as alternative qualifiers to render an ##### abstract admonition. As this increased the size of the CSS that is shipped with Material for MkDocs, the additional type qualifiers are now all deprecated and will be removed in the next major version. This will also be mentioned in the upgrade guide. \u21a9","title":"MKDocs"},{"location":"misc/mkdocs/#mkdocs","text":"","title":"MKDocs"},{"location":"misc/mkdocs/#material","text":"","title":"Material"},{"location":"misc/mkdocs/#admonition","text":"markdown_extensions: - admonition - pymdownx.details - pymdownx.superfences","title":"Admonition"},{"location":"misc/mkdocs/#supported-types","text":"Following is a list of type qualifiers provided by Material for MkDocs, whereas the default type, and thus fallback for unknown type qualifiers, is note 1 :","title":"Supported types"},{"location":"misc/mkdocs/#how-to","text":"Use the type belong !!! as : !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"How to"},{"location":"misc/mkdocs/#note","text":"Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"note"},{"location":"misc/mkdocs/#abstract","text":"Abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"abstract"},{"location":"misc/mkdocs/#info","text":"Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"info"},{"location":"misc/mkdocs/#tip","text":"Tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"tip"},{"location":"misc/mkdocs/#success","text":"Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"success"},{"location":"misc/mkdocs/#question","text":"Question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"question"},{"location":"misc/mkdocs/#warning","text":"Warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"warning"},{"location":"misc/mkdocs/#failure","text":"Failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"failure"},{"location":"misc/mkdocs/#danger","text":"Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"danger"},{"location":"misc/mkdocs/#bug","text":"Bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"bug"},{"location":"misc/mkdocs/#example","text":"Example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"example"},{"location":"misc/mkdocs/#quote","text":"Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Previously, some of the supported types defined more than one qualifier. For example, authors could use summary or tldr as alternative qualifiers to render an ##### abstract admonition. As this increased the size of the CSS that is shipped with Material for MkDocs, the additional type qualifiers are now all deprecated and will be removed in the next major version. This will also be mentioned in the upgrade guide. \u21a9","title":"quote"},{"location":"misc/obsidian/","text":"Obsidian Admonitions Types The following admonition types are currently supported: Type Aliases note note, seealso abstract abstract, summary, tldr info info, todo tip tip, hint, important success success, check, done question question, help, faq warning warning, caution, attention failure failure, fail, missing danger danger, error bug bug example example quote quote, cite Parameters ```ad- # Admonition type. See below for a list of available types. title: # Admonition title. collapse: # Create a collapsible admonition. icon: # Override the icon. color: # Override the color. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Example Note : ( ad-note ) title: This is a note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Obsidian"},{"location":"misc/obsidian/#obsidian","text":"","title":"Obsidian"},{"location":"misc/obsidian/#admonitions","text":"","title":"Admonitions"},{"location":"misc/obsidian/#types","text":"The following admonition types are currently supported: Type Aliases note note, seealso abstract abstract, summary, tldr info info, todo tip tip, hint, important success success, check, done question question, help, faq warning warning, caution, attention failure failure, fail, missing danger danger, error bug bug example example quote quote, cite","title":"Types"},{"location":"misc/obsidian/#parameters","text":"```ad- # Admonition type. See below for a list of available types. title: # Admonition title. collapse: # Create a collapsible admonition. icon: # Override the icon. color: # Override the color. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla.","title":"Parameters"},{"location":"misc/obsidian/#example","text":"Note : ( ad-note ) title: This is a note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Example"},{"location":"monitoring/centreon/","text":"Centreon Central Here are somes Centreon tips & tricks Analyse V\u00e9rifier les connexions tent\u00e9es : /var/log/centreon/login.log Poller List storage from poller : /usr/lib/centreon/plugins/centreon-plugins/centreon_plugins.pl --plugin = os::linux::snmp::plugin --mode = list-storages --hostname = $HOST | grep / Stats Voir les stats du poller : /usr/sbin/centenginestats R\u00e9pertoire du log tail -f /var/log/centreon-broker/poller-module.log Yellow state Last update yellow ? Lors d'une migration de poller, s'assurer que l'adresse du central soit bien mensionn\u00e9e dans le broker du poller. Commandes Liste de commandes centreons \u00e0 garder en t\u00eate Plugin Commande du plugin centreon : /usr/lib/centreon/plugins/centreon-plugins/centreon_plugins.pl Lister les FS : On va utiliser le mode list-storages : /usr/lib/centreon/plugins/centreon-plugins/centreon_plugins.pl --plugin = os::linux::snmp::plugin --mode = list-storages --hostname = ${ iP }","title":"Centreon Central"},{"location":"monitoring/centreon/#centreon-central","text":"Here are somes Centreon tips & tricks","title":"Centreon Central"},{"location":"monitoring/centreon/#analyse","text":"V\u00e9rifier les connexions tent\u00e9es : /var/log/centreon/login.log","title":"Analyse"},{"location":"monitoring/centreon/#poller","text":"List storage from poller : /usr/lib/centreon/plugins/centreon-plugins/centreon_plugins.pl --plugin = os::linux::snmp::plugin --mode = list-storages --hostname = $HOST | grep /","title":"Poller"},{"location":"monitoring/centreon/#stats","text":"Voir les stats du poller : /usr/sbin/centenginestats R\u00e9pertoire du log tail -f /var/log/centreon-broker/poller-module.log","title":"Stats"},{"location":"monitoring/centreon/#yellow-state","text":"Last update yellow ? Lors d'une migration de poller, s'assurer que l'adresse du central soit bien mensionn\u00e9e dans le broker du poller.","title":"Yellow state"},{"location":"monitoring/centreon/#commandes","text":"Liste de commandes centreons \u00e0 garder en t\u00eate","title":"Commandes"},{"location":"monitoring/centreon/#plugin","text":"Commande du plugin centreon : /usr/lib/centreon/plugins/centreon-plugins/centreon_plugins.pl Lister les FS : On va utiliser le mode list-storages : /usr/lib/centreon/plugins/centreon-plugins/centreon_plugins.pl --plugin = os::linux::snmp::plugin --mode = list-storages --hostname = ${ iP }","title":"Plugin"},{"location":"monitoring/nagios/","text":"Nagios Installation Installation based on rpm packages rhel7 yum install -y yum-utils yum-config-manager --enable rhel-7-server-optional-rpms oel yum install -y yum-utils yum-config-manager --enable ol7_optional_latest Script curl https://assets.nagios.com/downloads/nagiosxi/install.sh | sh Configuration File : /etc/nagios/objects/commands.cfg","title":"Nagios"},{"location":"monitoring/nagios/#nagios","text":"","title":"Nagios"},{"location":"monitoring/nagios/#installation","text":"Installation based on rpm packages","title":"Installation"},{"location":"monitoring/nagios/#rhel7","text":"yum install -y yum-utils yum-config-manager --enable rhel-7-server-optional-rpms","title":"rhel7"},{"location":"monitoring/nagios/#oel","text":"yum install -y yum-utils yum-config-manager --enable ol7_optional_latest","title":"oel"},{"location":"monitoring/nagios/#script","text":"curl https://assets.nagios.com/downloads/nagiosxi/install.sh | sh","title":"Script"},{"location":"monitoring/nagios/#configuration","text":"File : /etc/nagios/objects/commands.cfg","title":"Configuration"},{"location":"monitoring/readme/","text":"README The Monitoring Console is a web application available through any browser that can connect to the host where you installed it. You will access the Monitoring Console through the Web Console that is automatically installed on the same host.","title":"README"},{"location":"monitoring/readme/#readme","text":"The Monitoring Console is a web application available through any browser that can connect to the host where you installed it. You will access the Monitoring Console through the Web Console that is automatically installed on the same host.","title":"README"},{"location":"network/certmanager/","text":"Cert-Manager Cert-manager adds certificates and certificate issuers as resource types in Kubernetes clusters, and simplifies the process of obtaining, renewing and using those certificates. Documentation & Project Homepage: Cert-Manager Docs Self-Signed Certificates Upload existing CA.key and CA.crt files (Option 1) 1. Create a self-signed CA (ssl-certs) creating a ca.key (private-key) and ca.crt (certificate) (ca.key) openssl genrsa -out ca.key 4096 (ca.crt) openssl req -new -x509 -sha256 -days 365 -key ca.key -out ca.crt 2. Convert the files to a one line base64 decoded string (only works on Linux base64 tool) cat ca.key | base64 -w 0 3. Create a new ssl secret object using the strings apiVersion : v1 kind : Secret metadata : name : ssl-issuer-secret # (Optional) Metadata # --- # namespace: your-namespace type : Opaque data : tls.crt : <base64-decoded-string> tls.key : <base64-decoded-string> 4. Create a new ClusterIssuer or Issuer object by using the ssl secret apiVersion : cert-manager.io/v1 kind : ClusterIssuer metadata : name : selfsigned-issuer # (Optional) Metadata # --- # namespace: your-namespace spec : ca : secretName : ssl-issuer-secret Create CA through Cert-manager (Option 2) Create a new ClusterIssuer or Issuer object by using the selfSigned Attribute. apiVersion : cert-manager.io/v1 kind : ClusterIssuer metadata : name : root-issuer spec : selfSigned : {} Troubleshooting Common Errors DNS Record not yet propagated The error, Waiting for DNS-01 challenge propagation: DNS record for \"your-dns-record\" not yet propagated. , might occur in the challenge object. Cert-Manager creates a TXT Record on the DNS provider and checks, whether the record is existing, before issuing the certificate. In a split-dns environment, this could be a problem when internal DNS Servers can't resolve the TXT Record on the Cloud DNS. You can use the extraArgs --dns01-recursive-nameservers-only , and --dns01-recursive-nameservers=8.8.8.8:53,1.1.1.1:53 , to specific the DNS Resolvers used for the challenge. No solver found The error, Failed to determine a valid solver configuration for the set of domains on the Order: no configured challenge solvers can be used for this challenge might occur in the order object, when no solver can't be found for the DNS Hostname. Make sure your solvers have a corrent dnsZones configured that matches the DNS Hostnames Zone.","title":"Cert-Manager"},{"location":"network/certmanager/#cert-manager","text":"Cert-manager adds certificates and certificate issuers as resource types in Kubernetes clusters, and simplifies the process of obtaining, renewing and using those certificates. Documentation & Project Homepage: Cert-Manager Docs","title":"Cert-Manager"},{"location":"network/certmanager/#self-signed-certificates","text":"","title":"Self-Signed Certificates"},{"location":"network/certmanager/#upload-existing-cakey-and-cacrt-files-option-1","text":"","title":"Upload existing CA.key and CA.crt files (Option 1)"},{"location":"network/certmanager/#1-create-a-self-signed-ca-ssl-certs-creating-a-cakey-private-key-and-cacrt-certificate","text":"(ca.key) openssl genrsa -out ca.key 4096 (ca.crt) openssl req -new -x509 -sha256 -days 365 -key ca.key -out ca.crt","title":"1. Create a self-signed CA (ssl-certs) creating a ca.key (private-key) and ca.crt (certificate)"},{"location":"network/certmanager/#2-convert-the-files-to-a-one-line-base64-decoded-string-only-works-on-linux-base64-tool","text":"cat ca.key | base64 -w 0","title":"2. Convert the files to a one line base64 decoded string (only works on Linux base64 tool)"},{"location":"network/certmanager/#3-create-a-new-ssl-secret-object-using-the-strings","text":"apiVersion : v1 kind : Secret metadata : name : ssl-issuer-secret # (Optional) Metadata # --- # namespace: your-namespace type : Opaque data : tls.crt : <base64-decoded-string> tls.key : <base64-decoded-string>","title":"3. Create a new ssl secret object using the strings"},{"location":"network/certmanager/#4-create-a-new-clusterissuer-or-issuer-object-by-using-the-ssl-secret","text":"apiVersion : cert-manager.io/v1 kind : ClusterIssuer metadata : name : selfsigned-issuer # (Optional) Metadata # --- # namespace: your-namespace spec : ca : secretName : ssl-issuer-secret","title":"4. Create a new ClusterIssuer or Issuer object by using the ssl secret"},{"location":"network/certmanager/#create-ca-through-cert-manager-option-2","text":"Create a new ClusterIssuer or Issuer object by using the selfSigned Attribute. apiVersion : cert-manager.io/v1 kind : ClusterIssuer metadata : name : root-issuer spec : selfSigned : {}","title":"Create CA through Cert-manager (Option 2)"},{"location":"network/certmanager/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"network/certmanager/#common-errors","text":"DNS Record not yet propagated The error, Waiting for DNS-01 challenge propagation: DNS record for \"your-dns-record\" not yet propagated. , might occur in the challenge object. Cert-Manager creates a TXT Record on the DNS provider and checks, whether the record is existing, before issuing the certificate. In a split-dns environment, this could be a problem when internal DNS Servers can't resolve the TXT Record on the Cloud DNS. You can use the extraArgs --dns01-recursive-nameservers-only , and --dns01-recursive-nameservers=8.8.8.8:53,1.1.1.1:53 , to specific the DNS Resolvers used for the challenge. No solver found The error, Failed to determine a valid solver configuration for the set of domains on the Order: no configured challenge solvers can be used for this challenge might occur in the order object, when no solver can't be found for the DNS Hostname. Make sure your solvers have a corrent dnsZones configured that matches the DNS Hostnames Zone.","title":"Common Errors"},{"location":"network/homeassistant/","text":"HomeAssistant Installation Pre-Requirement Update the system; then reboot sudo apt update -y sudo apt upgrade -y Next step, installing depedences : sudo apt-get install -y python3 python3-dev python3-venv python3-pip bluez libffi-dev libssl-dev libjpeg-dev zlib1g-dev autoconf build-essential libopenjp2-7 libtiff5 libturbojpeg0-dev tzdata ffmpeg liblapack3 liblapack-dev libatlas-base-dev Configuration Python Venv Create the main python venv : python3 -m venv homeassistant Source it and install wheel source homeassistant/bin/activate python3 - m pip install wheel Once you have installed the required Python package, it is now time to install Home Assistant Core pip3 install homeassistant Run Source the python venv and run hass command : source homeassistant/bin/activate hass Then go to http://X.X.X.X:8123 Layrier commander : ip a | awk '/global/ {print \"http://\"$2}' | sed 's/\\/24/:8123/g' References https://www.home-assistant.io/installation/","title":"HomeAssistant"},{"location":"network/homeassistant/#homeassistant","text":"","title":"HomeAssistant"},{"location":"network/homeassistant/#installation","text":"","title":"Installation"},{"location":"network/homeassistant/#pre-requirement","text":"Update the system; then reboot sudo apt update -y sudo apt upgrade -y Next step, installing depedences : sudo apt-get install -y python3 python3-dev python3-venv python3-pip bluez libffi-dev libssl-dev libjpeg-dev zlib1g-dev autoconf build-essential libopenjp2-7 libtiff5 libturbojpeg0-dev tzdata ffmpeg liblapack3 liblapack-dev libatlas-base-dev","title":"Pre-Requirement"},{"location":"network/homeassistant/#configuration","text":"","title":"Configuration"},{"location":"network/homeassistant/#python-venv","text":"Create the main python venv : python3 -m venv homeassistant Source it and install wheel source homeassistant/bin/activate python3 - m pip install wheel Once you have installed the required Python package, it is now time to install Home Assistant Core pip3 install homeassistant","title":"Python Venv"},{"location":"network/homeassistant/#run","text":"Source the python venv and run hass command : source homeassistant/bin/activate hass Then go to http://X.X.X.X:8123 Layrier commander : ip a | awk '/global/ {print \"http://\"$2}' | sed 's/\\/24/:8123/g'","title":"Run"},{"location":"network/homeassistant/#references","text":"https://www.home-assistant.io/installation/","title":"References"},{"location":"network/http-status/","text":"HTTP Status Codes Categories 1XX status codes: Informational Requests 2XX status codes: Successful Requests 3XX status codes: Redirects 4XX status codes: Client Errors 5XX status codes: Server Errors Complete List Code Name Description 100 Continue Everything so far is OK and that the client should continue with the request or ignore it if it is already finished. 101 Switching Protocols The client has asked the server to change protocols and the server has agreed to do so. 102 Processing The server has received and is processing the request, but that it does not have a final response yet. 103 Early Hints Used to return some response headers before final HTTP message. 200 OK Successful request. 201 Created The server acknowledged the created resource. 202 Accepted The client's request has been received but the server is still processing it. 203 Non-Authoritative Information The response that the server sent to the client is not the same as it was when the server sent it. 204 No Content There is no content to send for this request 205 Reset Content Tells the user agent to reset the document which sent this request. 206 Partial Content This response code is used when the range-header is sent from the client to request only part of a resource. 207 Multi-Status Conveys information about multiple resources, for situations where multiple status codes might be appropriate. 208 Already Reported The members of a DAV binding have already been enumerated in a preceding part of the multi-status response. 226 IM Used IM is a specific extension of the HTTP protocol. The extension allows a HTTP server to send diffs (changes) of resources to clients. 300 Multiple Choices The request has more than one possible response. The user agent should choose one. 301 Moved Permanently The URL of the requested resource has been changed permanently. The new URL is given in the response. 302 Found This response code means that the URI of requested resource has been changed temporarily 303 See Other The server sent this response to direct the client to get the requested resource at another URI with a GET request. 304 Not Modified It tells the client that the response has not been modified, so the client can continue to use the same cached version of the response. 305 Use Proxy Defined in a previous version of the HTTP specification to indicate that a requested response must be accessed by a proxy. (discontinued) 307 Temporary Redirect The server sends this response to direct the client to get the requested resource at another URI with same method that was used in the prior request. 308 Permanent Redirect This means that the resource is now permanently located at another URI, specified by the Location: HTTP Response header. 400 Bad Request The server could not understand the request 401 Unauthorized The client didn't authenticate himself. 402 Payment Required This response code is reserved for future use. The initial aim for creating this code was using it for digital payment systems, however this status code is used very rarely and no standard convention exists. 403 Forbidden The client does not have access rights to the content 404 Not Found The server can not find the requested resource 405 Method Not Allowed The request method is known by the server but is not supported by the target resource 406 Not Acceptable The reponse doens't conforms to the creteria given by the client 407 Proxy Authentication Required This is similar to 401 Unauthorized but authentication is needed to be done by a proxy. 408 Request Timeout This response is sent on an idle connection by some servers, even without any previous request by the client. 409 Conflict This response is sent when a request conflicts with the current state of the server. 410 Gone This response is sent when the requested content has been permanently deleted from server, with no forwarding address. 411 Length Required Server rejected the request because the Content-Length header field is not defined and the server requires it. 412 Precondition Failed Access to the target resource has been denied. 413 Payload Too Large Request entity is larger than limits defined by server. 414 Request-URI Too Long The URI requested by the client is longer than the server is willing to interpret. 415 Unsupported Media Type The media format is not supported by the server. 416 Requested Range Not Satisfiable The range specified by the Range header field in the request cannot be fulfilled. 417 Expectation Failed the expectation indicated by the Expect request header field cannot be met by the server. 418 I'm a teapot The server refuses the attempt to brew coffee with a teapot. 421 Misdirected Request The request was directed at a server that is not able to produce a response. 422 Unprocessable Entity The request was well-formed but was unable to be followed due to semantic errors. 423 Locked The resource that is being accessed is locked. 424 Failed Dependency The request failed due to failure of a previous request. 426 Upgrade Required The server refuses to perform the request using the current protocol but might be willing to do so after the client upgrades to a different protocol. 428 Precondition Required his response is intended to prevent the 'lost update' problem, where a client GETs a resource's state, modifies it and PUTs it back to the server, when meanwhile a third party has modified the state on the server, leading to a conflict. 429 Too Many Requests The user has sent too many requests in a given amount of time 431 Request Header Fields Too Large The server is can't process the request because its header fields are too large. 444 Connection Closed Without Response The connection opened, but no data was written. 451 Unavailable For Legal Reasons The user agent requested a resource that cannot legally be provided (such as a web page censored by a government) 499 Client Closed Request The client closed the connection, despite the server was processing the request already. 500 Internal Server Error The server has encountered a situation it does not know how to handle. 501 Not Implemented The request method is not supported by the server and cannot be handled. 502 Bad Gateway This error response means that the server, while working as a gateway to get a response needed to handle the request, got an invalid response. 503 Service Unavailable The server is not ready to handle the request. 504 Gateway Timeout This error response is given when the server is acting as a gateway and cannot get a response in time. 505 HTTP Version Not Supported The HTTP version used in the request is not supported by the server. 506 Variant Also Negotiates the chosen variant resource is configured to engage in transparent content negotiation itself, and is therefore not a proper end point in the negotiation process. 507 Insufficient Storage The method could not be performed on the resource because the server is unable to store the representation needed to successfully complete the request. 508 Loop Detected The server detected an infinite loop while processing the request. 510 Not Extended Further extensions to the request are required for the server to fulfill it. 511 Network Authentication Required Indicates that the client needs to authenticate to gain network access. 599 Network Connect Timeout Error The connection timed out due to a overloaded server, a hardware error or a infrastructure error.","title":"HTTP Status Codes"},{"location":"network/http-status/#http-status-codes","text":"","title":"HTTP Status Codes"},{"location":"network/http-status/#categories","text":"1XX status codes: Informational Requests 2XX status codes: Successful Requests 3XX status codes: Redirects 4XX status codes: Client Errors 5XX status codes: Server Errors","title":"Categories"},{"location":"network/http-status/#complete-list","text":"Code Name Description 100 Continue Everything so far is OK and that the client should continue with the request or ignore it if it is already finished. 101 Switching Protocols The client has asked the server to change protocols and the server has agreed to do so. 102 Processing The server has received and is processing the request, but that it does not have a final response yet. 103 Early Hints Used to return some response headers before final HTTP message. 200 OK Successful request. 201 Created The server acknowledged the created resource. 202 Accepted The client's request has been received but the server is still processing it. 203 Non-Authoritative Information The response that the server sent to the client is not the same as it was when the server sent it. 204 No Content There is no content to send for this request 205 Reset Content Tells the user agent to reset the document which sent this request. 206 Partial Content This response code is used when the range-header is sent from the client to request only part of a resource. 207 Multi-Status Conveys information about multiple resources, for situations where multiple status codes might be appropriate. 208 Already Reported The members of a DAV binding have already been enumerated in a preceding part of the multi-status response. 226 IM Used IM is a specific extension of the HTTP protocol. The extension allows a HTTP server to send diffs (changes) of resources to clients. 300 Multiple Choices The request has more than one possible response. The user agent should choose one. 301 Moved Permanently The URL of the requested resource has been changed permanently. The new URL is given in the response. 302 Found This response code means that the URI of requested resource has been changed temporarily 303 See Other The server sent this response to direct the client to get the requested resource at another URI with a GET request. 304 Not Modified It tells the client that the response has not been modified, so the client can continue to use the same cached version of the response. 305 Use Proxy Defined in a previous version of the HTTP specification to indicate that a requested response must be accessed by a proxy. (discontinued) 307 Temporary Redirect The server sends this response to direct the client to get the requested resource at another URI with same method that was used in the prior request. 308 Permanent Redirect This means that the resource is now permanently located at another URI, specified by the Location: HTTP Response header. 400 Bad Request The server could not understand the request 401 Unauthorized The client didn't authenticate himself. 402 Payment Required This response code is reserved for future use. The initial aim for creating this code was using it for digital payment systems, however this status code is used very rarely and no standard convention exists. 403 Forbidden The client does not have access rights to the content 404 Not Found The server can not find the requested resource 405 Method Not Allowed The request method is known by the server but is not supported by the target resource 406 Not Acceptable The reponse doens't conforms to the creteria given by the client 407 Proxy Authentication Required This is similar to 401 Unauthorized but authentication is needed to be done by a proxy. 408 Request Timeout This response is sent on an idle connection by some servers, even without any previous request by the client. 409 Conflict This response is sent when a request conflicts with the current state of the server. 410 Gone This response is sent when the requested content has been permanently deleted from server, with no forwarding address. 411 Length Required Server rejected the request because the Content-Length header field is not defined and the server requires it. 412 Precondition Failed Access to the target resource has been denied. 413 Payload Too Large Request entity is larger than limits defined by server. 414 Request-URI Too Long The URI requested by the client is longer than the server is willing to interpret. 415 Unsupported Media Type The media format is not supported by the server. 416 Requested Range Not Satisfiable The range specified by the Range header field in the request cannot be fulfilled. 417 Expectation Failed the expectation indicated by the Expect request header field cannot be met by the server. 418 I'm a teapot The server refuses the attempt to brew coffee with a teapot. 421 Misdirected Request The request was directed at a server that is not able to produce a response. 422 Unprocessable Entity The request was well-formed but was unable to be followed due to semantic errors. 423 Locked The resource that is being accessed is locked. 424 Failed Dependency The request failed due to failure of a previous request. 426 Upgrade Required The server refuses to perform the request using the current protocol but might be willing to do so after the client upgrades to a different protocol. 428 Precondition Required his response is intended to prevent the 'lost update' problem, where a client GETs a resource's state, modifies it and PUTs it back to the server, when meanwhile a third party has modified the state on the server, leading to a conflict. 429 Too Many Requests The user has sent too many requests in a given amount of time 431 Request Header Fields Too Large The server is can't process the request because its header fields are too large. 444 Connection Closed Without Response The connection opened, but no data was written. 451 Unavailable For Legal Reasons The user agent requested a resource that cannot legally be provided (such as a web page censored by a government) 499 Client Closed Request The client closed the connection, despite the server was processing the request already. 500 Internal Server Error The server has encountered a situation it does not know how to handle. 501 Not Implemented The request method is not supported by the server and cannot be handled. 502 Bad Gateway This error response means that the server, while working as a gateway to get a response needed to handle the request, got an invalid response. 503 Service Unavailable The server is not ready to handle the request. 504 Gateway Timeout This error response is given when the server is acting as a gateway and cannot get a response in time. 505 HTTP Version Not Supported The HTTP version used in the request is not supported by the server. 506 Variant Also Negotiates the chosen variant resource is configured to engage in transparent content negotiation itself, and is therefore not a proper end point in the negotiation process. 507 Insufficient Storage The method could not be performed on the resource because the server is unable to store the representation needed to successfully complete the request. 508 Loop Detected The server detected an infinite loop while processing the request. 510 Not Extended Further extensions to the request are required for the server to fulfill it. 511 Network Authentication Required Indicates that the client needs to authenticate to gain network access. 599 Network Connect Timeout Error The connection timed out due to a overloaded server, a hardware error or a infrastructure error.","title":"Complete List"},{"location":"network/mkcert/","text":"Certificate Generator How to How to use this script ? Open a terminal and run a ssh connection to pki-adm : ssh pki-adm You should be logged as su : sudo su - You are able to run this script from everywhere. Run Simply run this script like : mkcert This script will return you theses informations : Welcome to the cert gen Please follow these steps : Enter the name ONLY : Barack Enter the surname ONLY : OBAMA Fill wich type would you want : 'client' or 'operator' : client Raw script #!/bin/bash # # Written by sboistel on June 2021 # # Create user certificate # Var bin = /usr/local/bin key_pass = $( cat /dev/urandom | tr -dc 'a-z0-9' | head -c 16 ) # Generate random password Pki = /etc/pki/ # root folder of reverse-${type} # Welcome echo \"\" echo \"Welcome to the cert gen\" echo \"Please follow these steps :\" echo \"Enter the name ONLY : Barack\" echo \"Enter the surname ONLY : OBAMA\" echo \"Fill wich type would you want : 'client' or 'operator' : client\" echo \"\" # Get Informaitons ## User information ### Name read -rp \"Enter the name ONLY : \" name na = $( echo ${ name ,, } | cut -c 1 ) # 1st letter of name lowercasedededed ### Surname read -rp \"Enter the surname ONLY : \" surname surna = ${ surname ,, } # surname lowercased ### Username username = ${ na }${ surna } #1st letter of name + surname ## Type of user echo \"Fill wich type would you want : 'client' or 'operator' : \" types =( \"client\" \"operator\" ) select typ in \" ${ types [@] } \" ; do case \" $typ \" in \"client\" ) ctype = \"client\" && break ;; \"operator\" ) ctype = \"operator\" && break ;; * ) echo \"Wrong choice, please select the number of the type you want.\" ;; esac done ### Working Directory : Determine the user type trough the $ctype if [ \" $ctype \" = \"client\" ] ; then WD = $Pki /reverse-client/users elif [ \" $ctype \" = \"operator\" ] ; then WD = $Pki /reverse-operator/users fi ### CA Directory : Determine the CA type trough the $ctype if [ \" $ctype \" = \"client\" ] ; then ca_type = $Pki /reverse-client/intermediate-CA elif [ \" $ctype \" = \"operator\" ] ; then ca_type = $Pki /reverse-operator/intermediate-CA fi # Traitement ## Creating Directory echo \"Go to the $username directory\" mkdir -pv $WD / $username cd $WD / $username ## Create the credentials for the SSM echo \"# $username credentials\" >> ${ username } _key_pass.md echo \"> $key_pass \" >> ${ username } _key_pass.md ## Let's Certificate ### KEY echo \"Generate the $username key\" openssl genrsa -des3 -passout pass: ${ key_pass } -out ${ username } .key 4096 ### CSR echo \"Generate the $username csr\" openssl req -new -key $username .key -passin pass: ${ key_pass } -out $username .csr -subj \"/C=FR/ST=France/L=Paris/O=Docki/OU=sboistel/CN=Intermediate CA\" ### Make Cert / P12 #### Generate the Cert with the CA echo \"Generate the $username crt\" $bin /make-crt-with-intermediate-ca $username $ca_type #### Generate the P12 with the CA echo \"Generate the $username p12\" $bin /make-p12-with-intermediate-ca $username $ca_type # End Print echo \"The $username 's certificat has been created.\" echo \"The credentials are stored into the ${ username } _key_pass.md file :\" echo \"Let's communicate the key password to the SSM/user\" cat ${ username } _key_pass.md # EOF","title":"Certificate Generator"},{"location":"network/mkcert/#certificate-generator","text":"","title":"Certificate Generator"},{"location":"network/mkcert/#how-to","text":"How to use this script ? Open a terminal and run a ssh connection to pki-adm : ssh pki-adm You should be logged as su : sudo su - You are able to run this script from everywhere.","title":"How to"},{"location":"network/mkcert/#run","text":"Simply run this script like : mkcert This script will return you theses informations : Welcome to the cert gen Please follow these steps : Enter the name ONLY : Barack Enter the surname ONLY : OBAMA Fill wich type would you want : 'client' or 'operator' : client","title":"Run"},{"location":"network/mkcert/#raw-script","text":"#!/bin/bash # # Written by sboistel on June 2021 # # Create user certificate # Var bin = /usr/local/bin key_pass = $( cat /dev/urandom | tr -dc 'a-z0-9' | head -c 16 ) # Generate random password Pki = /etc/pki/ # root folder of reverse-${type} # Welcome echo \"\" echo \"Welcome to the cert gen\" echo \"Please follow these steps :\" echo \"Enter the name ONLY : Barack\" echo \"Enter the surname ONLY : OBAMA\" echo \"Fill wich type would you want : 'client' or 'operator' : client\" echo \"\" # Get Informaitons ## User information ### Name read -rp \"Enter the name ONLY : \" name na = $( echo ${ name ,, } | cut -c 1 ) # 1st letter of name lowercasedededed ### Surname read -rp \"Enter the surname ONLY : \" surname surna = ${ surname ,, } # surname lowercased ### Username username = ${ na }${ surna } #1st letter of name + surname ## Type of user echo \"Fill wich type would you want : 'client' or 'operator' : \" types =( \"client\" \"operator\" ) select typ in \" ${ types [@] } \" ; do case \" $typ \" in \"client\" ) ctype = \"client\" && break ;; \"operator\" ) ctype = \"operator\" && break ;; * ) echo \"Wrong choice, please select the number of the type you want.\" ;; esac done ### Working Directory : Determine the user type trough the $ctype if [ \" $ctype \" = \"client\" ] ; then WD = $Pki /reverse-client/users elif [ \" $ctype \" = \"operator\" ] ; then WD = $Pki /reverse-operator/users fi ### CA Directory : Determine the CA type trough the $ctype if [ \" $ctype \" = \"client\" ] ; then ca_type = $Pki /reverse-client/intermediate-CA elif [ \" $ctype \" = \"operator\" ] ; then ca_type = $Pki /reverse-operator/intermediate-CA fi # Traitement ## Creating Directory echo \"Go to the $username directory\" mkdir -pv $WD / $username cd $WD / $username ## Create the credentials for the SSM echo \"# $username credentials\" >> ${ username } _key_pass.md echo \"> $key_pass \" >> ${ username } _key_pass.md ## Let's Certificate ### KEY echo \"Generate the $username key\" openssl genrsa -des3 -passout pass: ${ key_pass } -out ${ username } .key 4096 ### CSR echo \"Generate the $username csr\" openssl req -new -key $username .key -passin pass: ${ key_pass } -out $username .csr -subj \"/C=FR/ST=France/L=Paris/O=Docki/OU=sboistel/CN=Intermediate CA\" ### Make Cert / P12 #### Generate the Cert with the CA echo \"Generate the $username crt\" $bin /make-crt-with-intermediate-ca $username $ca_type #### Generate the P12 with the CA echo \"Generate the $username p12\" $bin /make-p12-with-intermediate-ca $username $ca_type # End Print echo \"The $username 's certificat has been created.\" echo \"The credentials are stored into the ${ username } _key_pass.md file :\" echo \"Let's communicate the key password to the SSM/user\" cat ${ username } _key_pass.md # EOF","title":"Raw script"},{"location":"network/ngrok/","text":"ngrok Donwload get https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz Unarchive tar xvzf ngrok-stable-linux-amd64.tgz -C /usr/local/bin Download Keys and repos curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | tee /etc/apt/trusted.gpg.d/ngrok.asc /dev/null echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" | tee /etc/apt/sources.list.d/ngrok.list Installation apt update && apt install ngrok snap install ngrok Run ngrok authtoken 218oHoLLOZgqVR7tex3w2SzDtnq_4rgFjQzqqXYYezF6AxuV9 ngrok http 80","title":"ngrok"},{"location":"network/ngrok/#ngrok","text":"","title":"ngrok"},{"location":"network/ngrok/#donwload","text":"get https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz","title":"Donwload"},{"location":"network/ngrok/#unarchive","text":"tar xvzf ngrok-stable-linux-amd64.tgz -C /usr/local/bin","title":"Unarchive"},{"location":"network/ngrok/#download-keys-and-repos","text":"curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | tee /etc/apt/trusted.gpg.d/ngrok.asc /dev/null echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" | tee /etc/apt/sources.list.d/ngrok.list","title":"Download Keys and repos"},{"location":"network/ngrok/#installation","text":"apt update && apt install ngrok snap install ngrok","title":"Installation"},{"location":"network/ngrok/#run","text":"ngrok authtoken 218oHoLLOZgqVR7tex3w2SzDtnq_4rgFjQzqqXYYezF6AxuV9 ngrok http 80","title":"Run"},{"location":"network/openvpn/","text":"OpenVPN Install via repository (recommended) * LINK The recommended method to install the OpenVPN Access Server is to use the official OpenVPN Access Server software repository. You will need to be logged on to your Linux system either on the console or via SSH, and have root privileges. Then copy and paste the commands below to add the repository to your system, and install the OpenVPN Access Server client bundle and the OpenVPN Access Server package itself. Installing the package 'openvpn-as' will automatically pull in the required client bundle as well. apt update && apt -y install ca-certificates wget net-tools gnupg wget -qO - <https://as-repository.openvpn.net/as-repo-public.gpg> | apt-key add - echo \"deb <http://as-repository.openvpn.net/as/debian> buster main\" >/etc/apt/sources.list.d/openvpn-as-repo.list apt update && apt -y install openvpn-as Configuration Follow theses steps : OpenVPN Website","title":"OpenVPN"},{"location":"network/openvpn/#openvpn","text":"","title":"OpenVPN"},{"location":"network/openvpn/#install-via-repository","text":"(recommended) * LINK The recommended method to install the OpenVPN Access Server is to use the official OpenVPN Access Server software repository. You will need to be logged on to your Linux system either on the console or via SSH, and have root privileges. Then copy and paste the commands below to add the repository to your system, and install the OpenVPN Access Server client bundle and the OpenVPN Access Server package itself. Installing the package 'openvpn-as' will automatically pull in the required client bundle as well. apt update && apt -y install ca-certificates wget net-tools gnupg wget -qO - <https://as-repository.openvpn.net/as-repo-public.gpg> | apt-key add - echo \"deb <http://as-repository.openvpn.net/as/debian> buster main\" >/etc/apt/sources.list.d/openvpn-as-repo.list apt update && apt -y install openvpn-as","title":"Install via repository"},{"location":"network/openvpn/#configuration","text":"Follow theses steps : OpenVPN Website","title":"Configuration"},{"location":"network/performance/","text":"Newtork performances On Server side : 10 = secondes iperf -s -i 10 On client host : $SERVER = target @iP iperf -i 10 -c $SERVER","title":"Newtork performances"},{"location":"network/performance/#newtork-performances","text":"On Server side : 10 = secondes iperf -s -i 10 On client host : $SERVER = target @iP iperf -i 10 -c $SERVER","title":"Newtork performances"},{"location":"network/pi-hole/","text":"Pi-Hole Requirement Set static iP @ Installation Installing packages apt install curl Download & run the installation file curl -sSL https://install.pi-hole.net | bash Configuration Change the main password pihole -a -p","title":"Pi-Hole"},{"location":"network/pi-hole/#pi-hole","text":"","title":"Pi-Hole"},{"location":"network/pi-hole/#requirement","text":"Set static iP @","title":"Requirement"},{"location":"network/pi-hole/#installation","text":"Installing packages apt install curl Download & run the installation file curl -sSL https://install.pi-hole.net | bash","title":"Installation"},{"location":"network/pi-hole/#configuration","text":"Change the main password pihole -a -p","title":"Configuration"},{"location":"network/readme/","text":"Networking","title":"Networking"},{"location":"network/readme/#networking","text":"","title":"Networking"},{"location":"network/ssl/","text":"SSL Certificates X.509 is an ITU standard defining the format of public key certificates. X.509 are used in TLS/SSL, which is the basis for HTTPS. An X.509 certificate binds an identity to a public key using a digital signature. A certificate contains an identity (hostname, organization, etc.) and a public key (RSA, DSA, ECDSA, ed25519, etc.), and is either signed by a Certificate Authority or is Self-Signed. Self-Signed Certificates Generate CA Generate RSA openssl genrsa -aes256 -out ca-key.pem 4096 Generate a public CA Cert openssl req -new -x509 -sha256 -days 365 -key ca-key.pem -out ca.pem Generate Certificate Create a RSA key openssl genrsa -out cert-key.pem 4096 Create a Certificate Signing Request (CSR) openssl req -new -sha256 -subj \"/CN=yourcn\" -key cert-key.pem -out cert.csr Create a extfile with all the alternative names echo \"subjectAltName=DNS:your-dns.record,IP:257.10.10.1\" >> extfile.cnf # optional echo extendedKeyUsage = serverAuth >> extfile.cnf Create the certificate openssl x509 -req -sha256 -days 365 -in cert.csr -CA ca.pem -CAkey ca-key.pem -out cert.pem -extfile extfile.cnf -CAcreateserial Certificate Formats X.509 Certificates exist in Base64 Formats PEM (.pem, .crt, .ca-bundle) , PKCS#7 (.p7b, p7s) and Binary Formats DER (.der, .cer) , PKCS#12 (.pfx, p12) . Convert Certs COMMAND CONVERSION openssl x509 -outform der -in cert.pem -out cert.der PEM to DER openssl x509 -inform der -in cert.der -out cert.pem DER to PEM openssl pkcs12 -in cert.pfx -out cert.pem -nodes PFX to PEM Verify Certificates openssl verify -CAfile ca.pem -verbose cert.pem Install the CA Cert as a trusted root CA On Debian & Derivatives Move the CA certificate ( ca.pem ) into /usr/local/share/ca-certificates/ca.crt . Update the Cert Store with: sudo update-ca-certificates Refer the documentation here and here. On Fedora Move the CA certificate ( ca.pem ) to /etc/pki/ca-trust/source/anchors/ca.pem or /usr/share/pki/ca-trust-source/anchors/ca.pem Now run (with sudo if necessary): update-ca-trust Refer the documentation here. On Arch System-wide \u2013 Arch(p11-kit) (From arch wiki) - Run (As root) trust anchor --store myCA.crt - The certificate will be written to /etc/ca-certificates/trust-source/myCA.p11-kit and the \"legacy\" directories automatically updated. - If you get \"no configured writable location\" or a similar error, import the CA manually: - Copy the certificate to the /etc/ca-certificates/trust-source/anchors directory. - and then update-ca-trust wiki page here On Windows Assuming the path to your generated CA certificate as C:\\ca.pem , run: Import-Certificate -FilePath \"C:\\ca.pem\" -CertStoreLocation Cert :\\ LocalMachine \\ Root - Set -CertStoreLocation to Cert:\\CurrentUser\\Root in case you want to trust certificates only for the logged in user. OR In Command Prompt, run: certutil.exe -addstore root C: \\c a.pem certutil.exe is a built-in tool (classic System32 one) and adds a system-wide trust anchor. On Android The exact steps vary device-to-device, but here is a generalised guide: 1. Open Phone Settings 2. Locate Encryption and Credentials section. It is generally found under Settings > Security > Encryption and Credentials 3. Choose Install a certificate 4. Choose CA Certificate 5. Locate the certificate file ca.pem on your SD Card/Internal Storage using the file manager. 6. Select to load it. 7. Done! SSL Security Cheat-Sheet ... TBD TLS Version and Ciphers Scanning for TLS Version and supported Ciphers: nmap --script ssl-enum-ciphers <target> Tool Link Description Qualys SSL Labs https://www.ssllabs.com/projects/index.html SSL Security Tools by Qualys","title":"SSL Certificates"},{"location":"network/ssl/#ssl-certificates","text":"X.509 is an ITU standard defining the format of public key certificates. X.509 are used in TLS/SSL, which is the basis for HTTPS. An X.509 certificate binds an identity to a public key using a digital signature. A certificate contains an identity (hostname, organization, etc.) and a public key (RSA, DSA, ECDSA, ed25519, etc.), and is either signed by a Certificate Authority or is Self-Signed.","title":"SSL Certificates"},{"location":"network/ssl/#self-signed-certificates","text":"","title":"Self-Signed Certificates"},{"location":"network/ssl/#generate-ca","text":"Generate RSA openssl genrsa -aes256 -out ca-key.pem 4096 Generate a public CA Cert openssl req -new -x509 -sha256 -days 365 -key ca-key.pem -out ca.pem","title":"Generate CA"},{"location":"network/ssl/#generate-certificate","text":"Create a RSA key openssl genrsa -out cert-key.pem 4096 Create a Certificate Signing Request (CSR) openssl req -new -sha256 -subj \"/CN=yourcn\" -key cert-key.pem -out cert.csr Create a extfile with all the alternative names echo \"subjectAltName=DNS:your-dns.record,IP:257.10.10.1\" >> extfile.cnf # optional echo extendedKeyUsage = serverAuth >> extfile.cnf Create the certificate openssl x509 -req -sha256 -days 365 -in cert.csr -CA ca.pem -CAkey ca-key.pem -out cert.pem -extfile extfile.cnf -CAcreateserial","title":"Generate Certificate"},{"location":"network/ssl/#certificate-formats","text":"X.509 Certificates exist in Base64 Formats PEM (.pem, .crt, .ca-bundle) , PKCS#7 (.p7b, p7s) and Binary Formats DER (.der, .cer) , PKCS#12 (.pfx, p12) .","title":"Certificate Formats"},{"location":"network/ssl/#convert-certs","text":"COMMAND CONVERSION openssl x509 -outform der -in cert.pem -out cert.der PEM to DER openssl x509 -inform der -in cert.der -out cert.pem DER to PEM openssl pkcs12 -in cert.pfx -out cert.pem -nodes PFX to PEM","title":"Convert Certs"},{"location":"network/ssl/#verify-certificates","text":"openssl verify -CAfile ca.pem -verbose cert.pem","title":"Verify Certificates"},{"location":"network/ssl/#install-the-ca-cert-as-a-trusted-root-ca","text":"","title":"Install the CA Cert as a trusted root CA"},{"location":"network/ssl/#on-debian-derivatives","text":"Move the CA certificate ( ca.pem ) into /usr/local/share/ca-certificates/ca.crt . Update the Cert Store with: sudo update-ca-certificates Refer the documentation here and here.","title":"On Debian &amp; Derivatives"},{"location":"network/ssl/#on-fedora","text":"Move the CA certificate ( ca.pem ) to /etc/pki/ca-trust/source/anchors/ca.pem or /usr/share/pki/ca-trust-source/anchors/ca.pem Now run (with sudo if necessary): update-ca-trust Refer the documentation here.","title":"On Fedora"},{"location":"network/ssl/#on-arch","text":"System-wide \u2013 Arch(p11-kit) (From arch wiki) - Run (As root) trust anchor --store myCA.crt - The certificate will be written to /etc/ca-certificates/trust-source/myCA.p11-kit and the \"legacy\" directories automatically updated. - If you get \"no configured writable location\" or a similar error, import the CA manually: - Copy the certificate to the /etc/ca-certificates/trust-source/anchors directory. - and then update-ca-trust wiki page here","title":"On Arch"},{"location":"network/ssl/#on-windows","text":"Assuming the path to your generated CA certificate as C:\\ca.pem , run: Import-Certificate -FilePath \"C:\\ca.pem\" -CertStoreLocation Cert :\\ LocalMachine \\ Root - Set -CertStoreLocation to Cert:\\CurrentUser\\Root in case you want to trust certificates only for the logged in user. OR In Command Prompt, run: certutil.exe -addstore root C: \\c a.pem certutil.exe is a built-in tool (classic System32 one) and adds a system-wide trust anchor.","title":"On Windows"},{"location":"network/ssl/#on-android","text":"The exact steps vary device-to-device, but here is a generalised guide: 1. Open Phone Settings 2. Locate Encryption and Credentials section. It is generally found under Settings > Security > Encryption and Credentials 3. Choose Install a certificate 4. Choose CA Certificate 5. Locate the certificate file ca.pem on your SD Card/Internal Storage using the file manager. 6. Select to load it. 7. Done!","title":"On Android"},{"location":"network/ssl/#ssl-security-cheat-sheet","text":"... TBD","title":"SSL Security Cheat-Sheet"},{"location":"network/ssl/#tls-version-and-ciphers","text":"Scanning for TLS Version and supported Ciphers: nmap --script ssl-enum-ciphers <target> Tool Link Description Qualys SSL Labs https://www.ssllabs.com/projects/index.html SSL Security Tools by Qualys","title":"TLS Version and Ciphers"},{"location":"storage/bareos/","text":"Bareos Job How do job command works ? Mean Command Which files shall be backed up? show filesets (I=Included, E=Excluded) What\u2019s the server doing? status dir What\u2019s the status of a certain job? status jobid=xx What\u2019s the client doing? status client What\u2019s the streamer doing? status storage Anything new? messages Means Command Last jobs list jobs Specifique Job list jobid=xx Statistics about last jobs list jobtotal Which files were backed up? list files jobid=xx Level list Base Catalog Data Differential DiskToCatalog Full Incremental InitCatalog Since VirtualFull VolumeToCatalog Status table view Status means T Terminated normally C Created but not yet running R Running B Blocked E Terminated in Error e Non-fatal error f Fatal error D Verify Differences A Canceled by the user F Waiting on the File daemon S Waiting on the Storage daemon m Waiting for a new Volume to be mounted M Waiting for a Mount s Waiting for Storage resource j Waiting for Job resource c Waiting for Client resource d Wating for Maximum jobs t Waiting for Start Time p Waiting for higher priority job to finish W Terminated with warnings","title":"Bareos"},{"location":"storage/bareos/#bareos","text":"","title":"Bareos"},{"location":"storage/bareos/#job","text":"How do job command works ? Mean Command Which files shall be backed up? show filesets (I=Included, E=Excluded) What\u2019s the server doing? status dir What\u2019s the status of a certain job? status jobid=xx What\u2019s the client doing? status client What\u2019s the streamer doing? status storage Anything new? messages Means Command Last jobs list jobs Specifique Job list jobid=xx Statistics about last jobs list jobtotal Which files were backed up? list files jobid=xx","title":"Job"},{"location":"storage/bareos/#level-list","text":"Base Catalog Data Differential DiskToCatalog Full Incremental InitCatalog Since VirtualFull VolumeToCatalog","title":"Level list"},{"location":"storage/bareos/#status-table-view","text":"Status means T Terminated normally C Created but not yet running R Running B Blocked E Terminated in Error e Non-fatal error f Fatal error D Verify Differences A Canceled by the user F Waiting on the File daemon S Waiting on the Storage daemon m Waiting for a new Volume to be mounted M Waiting for a Mount s Waiting for Storage resource j Waiting for Job resource c Waiting for Client resource d Wating for Maximum jobs t Waiting for Start Time p Waiting for higher priority job to finish W Terminated with warnings","title":"Status table view"},{"location":"storage/cloudera/","text":"Cloudera How to identify if NUMA is enabled NUMA has to enabled in the BIOS. If dmesg does not have records of numa initialization during bootup, then it is possible that NUMA related messages in the kernel ring buffer might have been overwritten. NUMA Enabled Systems If NUMA is enabled on BIOS, then execute the command \u2018numactl \u2013hardware\u2018 to list inventory of available nodes on the system. Below is example output of numactl \u2013hardware on a system which has NUMA. numactl --hardware available: 2 nodes ( 0 -1 ) node 0 cpus: 0 1 2 3 4 5 6 7 16 17 18 19 20 21 22 23 node 0 size: 8157 MB node 0 free: 88 MB node 1 cpus: 8 9 10 11 12 13 14 15 24 25 26 27 28 29 30 31 node 1 size: 8191 MB node 1 free: 5176 MB node distances: node 0 1 0 : 10 20 1 : 20 10 NUMA Disabled Systems 1. If NUMA is disabled on BIOS, then the command \u2018numactl \u2013show\u2018 does not show multiple nodes. numactl --show policy: default preferred node: current physcpubind: 0 1 2 3 4 5 6 7 8 9 10 11 cpubind: 0 nodebind: 0 membind: 0 2. The command \u2018numactl \u2013hardware\u2018 also does not list multiple nodes available: 1 nodes ( 0 ) node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 node 0 size: 65525 MB node 0 free: 17419 MB node distances: node 0 0 : 10 3. If the server does not have NUMA support or if the BIOS option is not enabled, then the following messages will be seen in dmesg No NUMA configuration found Faking a node at 0000000000000000 -0000001027fff000 4. If ACPI is disabled, that will also disable NUMA; verify that ACPI is not disabled by a grub.conf kernel parameter and remove it if found: $ grep acpi = off /proc/cmdline Charts Building Health select health_good_rate * 100 as \"good health\" , health_concerning_rate * 100 as \"concerning health\" , health_bad_rate * 100 as \"bad health\" , health_disabled_rate * 100 as \"disabled health\" , health_unknown_rate * 100 as \"unknown health\" where entityName = \"hdfs:$node-ha\" select health_good_rate * 100 as \"good health\" where entityName = \"hdfs:$node-ha\" History select dfs_capacity as \"HDFS\" ,( dfs_capacity_used + dfs_capacity_used_non_hdfs ) as \"Used\" where entityName = \"hdfs:$node-ha\" System CPU select cpu_user_rate / getHostFact ( numCores , 1 ) * 100 , cpu_system_rate / getHostFact ( numCores , 1 ) * 100 , cpu_nice_rate / getHostFact ( numCores , 1 ) * 100 , cpu_iowait_rate / getHostFact ( numCores , 1 ) * 100 , cpu_irq_rate / getHostFact ( numCores , 1 ) * 100 , cpu_soft_irq_rate / getHostFact ( numCores , 1 ) * 100 , cpu_steal_rate / getHostFact ( numCores , 1 ) * 100 RAM select swap_used , physical_memory_used , physical_memory_total WHERE hostname RLIKE \".*data.*\" User Repository List user home directories : hdfs dfs -ls /user/ Get user home directory acl as example : hdfs dfs -getfacl /user/JohnDoe cf Hadoop cheat-sheet","title":"Cloudera"},{"location":"storage/cloudera/#cloudera","text":"","title":"Cloudera"},{"location":"storage/cloudera/#how-to-identify-if-numa-is-enabled","text":"NUMA has to enabled in the BIOS. If dmesg does not have records of numa initialization during bootup, then it is possible that NUMA related messages in the kernel ring buffer might have been overwritten.","title":"How to identify if NUMA is enabled"},{"location":"storage/cloudera/#numa-enabled-systems","text":"If NUMA is enabled on BIOS, then execute the command \u2018numactl \u2013hardware\u2018 to list inventory of available nodes on the system. Below is example output of numactl \u2013hardware on a system which has NUMA. numactl --hardware available: 2 nodes ( 0 -1 ) node 0 cpus: 0 1 2 3 4 5 6 7 16 17 18 19 20 21 22 23 node 0 size: 8157 MB node 0 free: 88 MB node 1 cpus: 8 9 10 11 12 13 14 15 24 25 26 27 28 29 30 31 node 1 size: 8191 MB node 1 free: 5176 MB node distances: node 0 1 0 : 10 20 1 : 20 10","title":"NUMA Enabled Systems"},{"location":"storage/cloudera/#numa-disabled-systems","text":"","title":"NUMA Disabled Systems"},{"location":"storage/cloudera/#1-if-numa-is-disabled-on-bios-then-the-command-numactl-show-does-not-show-multiple-nodes","text":"numactl --show policy: default preferred node: current physcpubind: 0 1 2 3 4 5 6 7 8 9 10 11 cpubind: 0 nodebind: 0 membind: 0","title":"1. If NUMA is disabled on BIOS, then the command \u2018numactl \u2013show\u2018 does not show multiple nodes."},{"location":"storage/cloudera/#2-the-command-numactl-hardware-also-does-not-list-multiple-nodes","text":"available: 1 nodes ( 0 ) node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 node 0 size: 65525 MB node 0 free: 17419 MB node distances: node 0 0 : 10","title":"2. The command \u2018numactl \u2013hardware\u2018 also does not list multiple nodes"},{"location":"storage/cloudera/#3-if-the-server-does-not-have-numa-support-or-if-the-bios-option-is-not-enabled-then-the-following-messages-will-be-seen-in-dmesg","text":"No NUMA configuration found Faking a node at 0000000000000000 -0000001027fff000","title":"3. If the server does not have NUMA support or if the BIOS option is not enabled, then the following messages will be seen in dmesg"},{"location":"storage/cloudera/#4-if-acpi-is-disabled-that-will-also-disable-numa-verify-that-acpi-is-not-disabled-by-a-grubconf-kernel-parameter-and-remove-it-if-found","text":"$ grep acpi = off /proc/cmdline","title":"4. If ACPI is disabled, that will also disable NUMA; verify that ACPI is not disabled by a grub.conf kernel parameter and remove it if found:"},{"location":"storage/cloudera/#charts-building","text":"","title":"Charts Building"},{"location":"storage/cloudera/#health","text":"select health_good_rate * 100 as \"good health\" , health_concerning_rate * 100 as \"concerning health\" , health_bad_rate * 100 as \"bad health\" , health_disabled_rate * 100 as \"disabled health\" , health_unknown_rate * 100 as \"unknown health\" where entityName = \"hdfs:$node-ha\" select health_good_rate * 100 as \"good health\" where entityName = \"hdfs:$node-ha\"","title":"Health"},{"location":"storage/cloudera/#history","text":"select dfs_capacity as \"HDFS\" ,( dfs_capacity_used + dfs_capacity_used_non_hdfs ) as \"Used\" where entityName = \"hdfs:$node-ha\"","title":"History"},{"location":"storage/cloudera/#system","text":"","title":"System"},{"location":"storage/cloudera/#cpu","text":"select cpu_user_rate / getHostFact ( numCores , 1 ) * 100 , cpu_system_rate / getHostFact ( numCores , 1 ) * 100 , cpu_nice_rate / getHostFact ( numCores , 1 ) * 100 , cpu_iowait_rate / getHostFact ( numCores , 1 ) * 100 , cpu_irq_rate / getHostFact ( numCores , 1 ) * 100 , cpu_soft_irq_rate / getHostFact ( numCores , 1 ) * 100 , cpu_steal_rate / getHostFact ( numCores , 1 ) * 100","title":"CPU"},{"location":"storage/cloudera/#ram","text":"select swap_used , physical_memory_used , physical_memory_total WHERE hostname RLIKE \".*data.*\"","title":"RAM"},{"location":"storage/cloudera/#user-repository","text":"List user home directories : hdfs dfs -ls /user/ Get user home directory acl as example : hdfs dfs -getfacl /user/JohnDoe cf Hadoop cheat-sheet","title":"User Repository"},{"location":"storage/db2/","text":"IBM DB2 Installation As root Untar the archive file tar -xvf linuxx64_client.tar.gz Install db2 ./client/db2_install -b /opt/db/v11.5 Create user client /opt/ibm/db2/v11.5/instance/db2icrt -s client lully Migration As root db2cfexp db2cfexp.log template As instance user db2cfimp export.log Check directories Run db2 cmd as user sourced profile list db directory list node directory","title":"IBM DB2"},{"location":"storage/db2/#ibm-db2","text":"","title":"IBM DB2"},{"location":"storage/db2/#installation","text":"As root Untar the archive file tar -xvf linuxx64_client.tar.gz Install db2 ./client/db2_install -b /opt/db/v11.5","title":"Installation"},{"location":"storage/db2/#create-user-client","text":"/opt/ibm/db2/v11.5/instance/db2icrt -s client lully","title":"Create user client"},{"location":"storage/db2/#migration","text":"As root db2cfexp db2cfexp.log template As instance user db2cfimp export.log","title":"Migration"},{"location":"storage/db2/#check-directories","text":"Run db2 cmd as user sourced profile list db directory list node directory","title":"Check directories"},{"location":"storage/hadoop/","text":"Hadoop Interact with system Example hdfs dfs -mkdir /user/John Deprecated way : hadoop fs -mkdir /user/John","title":"Hadoop"},{"location":"storage/hadoop/#hadoop","text":"Interact with system Example hdfs dfs -mkdir /user/John Deprecated way : hadoop fs -mkdir /user/John","title":"Hadoop"},{"location":"storage/mariadb/","text":"MariaDB Install MariaDB sudo apt update sudo apt install mariadb-server sudo mysql_secure_installation Access Database from outside Open /etc/mysql/mariadb.conf.d/50-server.cnf and change the bind-address to: ... bind-address = 0.0.0.0 ... Create Administrative User Create a new user newuser for the host localhost with a new password : CREATE USER 'newuser' @'localhost' IDENTIFIED BY 'password' ; Grant all permissions to the new user GRANT ALL PRIVILEGES ON * . * TO 'newuser' @'localhost' ; Update permissions FLUSH PRIVILEGES ;","title":"MariaDB"},{"location":"storage/mariadb/#mariadb","text":"","title":"MariaDB"},{"location":"storage/mariadb/#install-mariadb","text":"sudo apt update sudo apt install mariadb-server sudo mysql_secure_installation","title":"Install MariaDB"},{"location":"storage/mariadb/#access-database-from-outside","text":"Open /etc/mysql/mariadb.conf.d/50-server.cnf and change the bind-address to: ... bind-address = 0.0.0.0 ...","title":"Access Database from outside"},{"location":"storage/mariadb/#create-administrative-user","text":"Create a new user newuser for the host localhost with a new password : CREATE USER 'newuser' @'localhost' IDENTIFIED BY 'password' ; Grant all permissions to the new user GRANT ALL PRIVILEGES ON * . * TO 'newuser' @'localhost' ; Update permissions FLUSH PRIVILEGES ;","title":"Create Administrative User"},{"location":"storage/mysql/","text":"MySQL Here are somes SQL tips & tricks Format Pager Set page print as infinit : pager less - SFIX ;","title":"MySQL"},{"location":"storage/mysql/#mysql","text":"Here are somes SQL tips & tricks","title":"MySQL"},{"location":"storage/mysql/#format","text":"","title":"Format"},{"location":"storage/mysql/#pager","text":"Set page print as infinit : pager less - SFIX ;","title":"Pager"},{"location":"storage/oracle/","text":"Oracle Here are somes Oracle tips & tricks Spfile SPFILE (Fichier de param\u00e8tres persistant) est un fichier binaire recherch\u00e9 automatiquement au d\u00e9marrage de l\u2019instance. Son nom par d\u00e9faut est spfile< SID >.ora. Il est situ\u00e9 dans $ORACLE_HOME/dbs/. Le fichier SPFILE est recommand\u00e9 par Oracle en raison de la possibilit\u00e9 de g\u00e9r\u00e9 dynamiquement de nombreux param\u00e8tres d\u2019initialisation. Il est modifi\u00e9 par le moteur Oracle. PFILE (Fichier de param\u00e8tres statique) est un fichier texte recherch\u00e9 automatiquement au d\u00e9marrage de l\u2019instance en l\u2019absence du fichier SPFILE. Il est modifi\u00e9 manuellement par le DBA. Son nom par d\u00e9faut est : init< SID >.ora et il est situ\u00e9 dans $ORACLE_HOME/dbs. Les modifications prennent effet qu\u2019apr\u00e8s le red\u00e9marrage de l\u2019instance. CR\u00c9ER UN SPFILE A PARTIR D\u2019UN PFILE Vous pouvez cr\u00e9er un fichier SPFILE \u00e0 partir d\u2019un fichier PFILE via la commande suivante (instance d\u00e9marr\u00e9e ou non) et ou le nom d\u2019instance est DBA01 : CREATE SPFILE = \u2018$ ORACLE_HOME / dbs / spfileDBA01 . ora \u2019 FROM PFILE = \u2018$ ORACLE_HOME / dbs / initDBA01 . ora \u2018 Control file Le fichier de contr\u00f4le est un fichier binaire, il contient des informations sur la structure physique de la base. Il est cr\u00e9\u00e9 pendant la cr\u00e9ation de la base et il est modifi\u00e9 en permanence. Ce fichier doit \u00eatre toujours disponible car il est consult\u00e9; et modifi\u00e9 fr\u00e9quemment par le serveur oracle. Et il est indispensable pour la restauration de la base. Pour afficher les noms des fichiers de contr\u00f4le on utilise : SHOW PARAMETER CONTROL_FILES SELECT VALUE FROM V$PARAMETER WHERE NAME = 'control_files' ; Redolog Les fichiers Redo Logs servent \u00e0 enregistrer toutes les modifications commit\u00e9es effectu\u00e9es sur le base de donn\u00e9es. Ils servent \u00e0 prot\u00e9ger la base de donn\u00e9es dans le cas d\u2019un \u00e9chec d\u2019instance. En cas de restauration de la base de donn\u00e9es, on utilise les redo logs pour \u2018rejouer\u2019 les modifications qui ont eu lieu, les transactions valid\u00e9es (commit \u00e0 la fin de la transaction) sont enregistr\u00e9es dans les fichiers de donn\u00e9es Oracle et les transactions non valid\u00e9es, s\u2019il y en a, sont effac\u00e9es des fichiers de donn\u00e9es. Data base file Les fichiers physiques d\u2019une base Oracle permettent de stocker de mani\u00e8re persistante les donn\u00e9es manipul\u00e9es par Oracle. Archive log Quand la base est en mode NOARCHIVELOG, l\u2019archivage des fichiers redo est d\u00e9sactiv\u00e9. Le fichier de contr\u00f4le indique que les groupes des fichiers redo pleins ne sont plus n\u00e9cessaires. D\u00e8s qu\u2019ils sont inactifs apr\u00e8s un log switch, le groupe sera disponible pour une r\u00e9utilisation par la LGWR . \u2192 (lgwr \u00e9crit toutes les entr\u00e9es refaites qui ont \u00e9t\u00e9 copi\u00e9es dans le tampon depuis la derni\u00e8re fois.) Le mode NOARCHIVELOG prot\u00e8ge la base contre une d\u00e9faillance d\u2019instance et non pas contre une d\u00e9faillance media. Seulement les modifications r\u00e9centes dans la base, stock\u00e9s dans les groupes de fichiers redo en ligne seront disponibles pour la restauration de la base. En mode NOARCHIVELOG, on ne peut pas sauvegarder en ligne une tablespace. Pour restaurer une base en mode NOARCHIVELOG, on est oblig\u00e9 de faire une sauvegarde compl\u00e8te quand la base est ferm\u00e9e. Quand la base est en mode ARCHIVELOG, l\u2019archivage des fichiers redo est activ\u00e9. Le fichier de contr\u00f4le de la base signale que les groupes contenant des fichiers redo pleins ne peuvent pas \u00eatre utilis\u00e9s par le process LGWR tant que les groupes n\u2019ont pas \u00e9t\u00e9 archiv\u00e9s. V\u00e9rifier s\u2019il y a pr\u00e9sence d\u2019Archive log : archive log list Conna\u00eetre la destination de chacune d\u2019entre-elles : show parameter log_archive_dest Passer en mode d'archivage ( attention \u00e0 ne pas omettre de monter seulement l'instance afin d'effectuer la manipulation. Celle-ci subira donc une relance **) : ALTER DATABASE ARCHIVELOG ; Informations Conna\u00eetre les informations et version de composant oracle : odacli describe - component Conna\u00eetre le nom de la base sur laquelle on est connect\u00e9e : show parameter name Ou encore pour soucis de suret\u00e9 : show parameter unique Conna\u00eetre le owner d\u2019une table : select disctinct owner from all_tables ; Savoir si la base tourne ou non en SQL : SELECT INSTANCE_NAME , STATUS , DATABASE_STATUS FROM V$INSTANCE ; Diag Tunning Name Interpr\u00e9ter Syntaxe : CONTROL_MANAGEMENT_PACK_ACCESS = { NONE | DIAGNOSTIC | DIAGNOSTIC+TUNING} D\u00e9sactiver Passon la m\u00e9moire tampon mais aussi le spfile \u00e0 none En tant que sysdba : ALTER SYSTEM SET CONTROL_MANAGEMENT_PACK_ACCESS = NONE SCOPE = BOTH ; Check V\u00e9rifier s\u2019il est activ\u00e9 : show parameter control_management_pack_access Ou encore : select display_value from v$parameter where name = 'control_management_pack_access' ; Bring impdp R\u00e9ccup\u00e9rer la vue sur un import en bacground : impdp \\ \"/ as sysdba\\\" ATTACH = \"SYS_IMPORT_FULL_01\" Global Prefs Get Global prefs : SELECT DBMS_STATS . get_prefs ( 'CONCURRENT' ) FROM dual ; Global Perfs State SQL Command True DBMS_STATS.SET_GLOBAL_PREFS('CONCURRENT','TRUE'); False DBMS_STATS.SET_GLOBAL_PREFS('CONCURRENT','FALSE'); LSNRCTL L\u2019utilitaire de contr\u00f4le d\u2019\u00e9coute vous permet d\u2019administrer des listeners. Vous pouvez utiliser ses commandes pour ex\u00e9cuter des fonctions de gestion de base sur un ou plusieurs listeners. En outre, vous pouvez afficher et modifier les param\u00e8tres. Commandes possible : - start - Stop - Status - Services - Servacls - Version - Reload - save_config - Trace - Spawn - Quit - Exit - set - show Effectuer un status du service listener : Il se peut que celuic-ci ne se nomme pas LISTENER, il s\u2019agit des param\u00e8tres pas d\u00e9faut : lsnrctl status LISTENER ODACLI R\u00e9pertorier toutes les bases de donn\u00e9es de l\u2019appliance : odacli list-databases Afficher les d\u00e9tails de la base de donn\u00e9es : odacli describe-database Cr\u00e9er une nouvelle base de donn\u00e9es : odacli create-database Supprimer une base de donn\u00e9es : odacli delete-database R\u00e9seau : - On trouvera les identifiants r\u00e9seau : odacli list-network On y trouve tout les d\u00e9tails de ce r\u00e9seau : :: odacli describe-ntwork -i $identifiants_r\u00e9seau OSWBBA java - jar / opt / oracle / oak / oswbb / oswbba . jar - i / opt / oracle / oak / oswbb / archive - b Mar 18 00 : 00 : 00 2019 - e Mar 19 00 : 00 : 00 Ressources Afin de v\u00e9rifier l\u2019\u00e9tat du param\u00e8tre SESSIONS : SHOW parameter sessions Processes PROCESSES sp\u00e9cifie le nombre maximal de processus utilisateur du syst\u00e8me d\u2019exploitation pouvant se connecter simultan\u00e9ment \u00e0 Oracle. Sa valeur doit autoriser tous les processus d\u2019arri\u00e8re-plan tels que les verrous, les processus de file d\u2019attente de travaux et les processus d\u2019ex\u00e9cution parall\u00e8les. Les valeurs par d\u00e9faut des param\u00e8tres SESSIONS et TRANSACTIONS sont d\u00e9riv\u00e9es de ce param\u00e8tre. Par cons\u00e9quent, si vous modifiez la valeur de PROCESSES, vous devez d\u00e9terminer si vous souhaitez ajuster les valeurs de ces param\u00e8tres d\u00e9riv\u00e9s. Afin de v\u00e9rifier l\u2019\u00e9tat du param\u00e8tre PROCESSES : SHOW parameter processes Application du param\u00e8tre : ALTER SYSTEM SET processes=[VALUE AS INTEGER] SCOPE=SPFILE ; Transactions TRANSACTIONS sp\u00e9cifie le nombre maximal de transactions simultan\u00e9es. Des valeurs plus \u00e9lev\u00e9es augmentent la taille du SGA et peuvent augmenter le nombre de segments de restauration allou\u00e9s. La valeur par d\u00e9faut est sup\u00e9rieure \u00e0 SESSIONS (et \u00e0 son tour, PROCESSES) pour permettre les transactions r\u00e9cursives. V\u00e9rifier les param\u00e8tres Afin de v\u00e9rifier l\u2019\u00e9tat du param\u00e8tre TRANSACTIONS : SHOW parameter transactions Application du param\u00e8tre : ALTER SYSTEM SET transactions=[VALUE AS INTEGER] SCOPE=SPFILE ; \u26a0 Application des param\u00e8tres : Afin d\u2019appliquer des param\u00e8tres modifi\u00e9s dans le spfile , un relance de l\u2019instance sera requis : shutdown immediate startup Account D\u00e9bloquer des compte v\u00e9rouill\u00e9 : SQL > conn / AS sysdba Connected . SQL > ALTER USER $ USER BY ******** account UNLOCK ; USER altered . SQL > ALTER USER $ USER IDENTIFIED BY ******** account UNLOCK ; USER altered . SQLPLUS Param\u00e9trage de l\u2019interface sqlplus : linesize La longueur des lignes par d\u00e9faut 80 caract\u00e8res : set linesize 200 col Il d\u00e9fini un format de sortie pour une colonne particuli\u00e8re : col table_name for a20 set pause on Permet une attente de RETURN pour faire d\u00e9filer les lignes suivantes ( comme la commande more). spool La sortie standard et d\u2019erreur est redirig\u00e9e dans le fichier indiqu\u00e9 dans la commande. La commande \u201cspool off\u201d ferme le fichier. Utiliser la commande SQL **start** or **@** pour effectuer les script tel que .sql STATSPACK Analyser Mise en forme du resultat : col OWNER format a10 col SEGMENT_NAME format a60 col SEGMENT_TYPE format a15 set pagesize 1000 select owner , segment_name , segment_type , bytes / 1024 / 1024 from dba_segments where tablespace_name = 'STATSPACK_TBS' and segment_type = 'TABLE' order by bytes desc ; Corriger 1. Purge STATSPACK Renseigner la plage d'id \u00e0 purger : DEFINE losnapid = 1 -- low snap id DEFINE hisnapid = 2 -- high snap id @?/ rdbms / admin / sppurge . sql 2. Move table How to move dba_segments : select 'alter table ' || owner || '.' || segment_name || ' move;' from dba_segments where tablespace_name = 'STATSPACK_TBS' and segment_type = 'TABLE' order by bytes desc ; 3. Rebuild Index How to rebuild dba_indexes : select 'alter index ' || owner || '.' || index_name || ' rebuild;' from dba_indexes where status = 'UNUSABLE' ; TNSNAME Comment la v\u00e9rifier : [ oracle @ oda ~ ] # env | grep TNS TNS_ADMIN =/ backup / TNS Le fichier est donc dans /backup/TNS/tnsname.ora . Configuration: Voici un exemple de configuration : ( DESCRIPTION = ( ADDRESS = ( PROTOCOL = TCP )( HOST = `` iP de la machine `` )( PORT = 1521 )) ( CONNECT_DATA = ( SERVER = DEDICATED ) ( SERVICE_NAME = `` Nom de la base `` ) ) ) Tablespace Know the tablesapces size : set line 1000 set pagesize 100 col \"Tablespace\" FOR a22 col \"Used MB\" FOR 99 , 999 , 999 col \"Free MB\" FOR 99 , 999 , 999 col \"Total MB\" FOR 99 , 999 , 999 SELECT df . tablespace_name \"Tablespace\" , totalusedspace \"Used MB\" , ( df . totalspace - tu . totalusedspace ) \"Free MB\" , df . totalspace \"Total MB\" , round ( 100 * ( ( df . totalspace - tu . totalusedspace ) / df . totalspace )) \"Pct. Free\" , df . MAX_SIZE / 1024 / 1024 / 1024 \"Max Size Go\" FROM ( SELECT tablespace_name , round ( SUM ( bytes ) / 1048576 ) TotalSpace , sum ( decode ( AUTOEXTENSIBLE , 'YES' , MAXBYTES , BYTES )) MAX_SIZE FROM dba_data_files GROUP BY tablespace_name ) df , ( SELECT round ( SUM ( bytes ) / ( 1024 * 1024 )) totalusedspace , tablespace_name FROM dba_segments GROUP BY tablespace_name ) tu WHERE df . tablespace_name = tu . tablespace_name ;","title":"Oracle"},{"location":"storage/oracle/#oracle","text":"Here are somes Oracle tips & tricks","title":"Oracle"},{"location":"storage/oracle/#spfile","text":"SPFILE (Fichier de param\u00e8tres persistant) est un fichier binaire recherch\u00e9 automatiquement au d\u00e9marrage de l\u2019instance. Son nom par d\u00e9faut est spfile< SID >.ora. Il est situ\u00e9 dans $ORACLE_HOME/dbs/. Le fichier SPFILE est recommand\u00e9 par Oracle en raison de la possibilit\u00e9 de g\u00e9r\u00e9 dynamiquement de nombreux param\u00e8tres d\u2019initialisation. Il est modifi\u00e9 par le moteur Oracle. PFILE (Fichier de param\u00e8tres statique) est un fichier texte recherch\u00e9 automatiquement au d\u00e9marrage de l\u2019instance en l\u2019absence du fichier SPFILE. Il est modifi\u00e9 manuellement par le DBA. Son nom par d\u00e9faut est : init< SID >.ora et il est situ\u00e9 dans $ORACLE_HOME/dbs. Les modifications prennent effet qu\u2019apr\u00e8s le red\u00e9marrage de l\u2019instance. CR\u00c9ER UN SPFILE A PARTIR D\u2019UN PFILE Vous pouvez cr\u00e9er un fichier SPFILE \u00e0 partir d\u2019un fichier PFILE via la commande suivante (instance d\u00e9marr\u00e9e ou non) et ou le nom d\u2019instance est DBA01 : CREATE SPFILE = \u2018$ ORACLE_HOME / dbs / spfileDBA01 . ora \u2019 FROM PFILE = \u2018$ ORACLE_HOME / dbs / initDBA01 . ora \u2018","title":"Spfile"},{"location":"storage/oracle/#control-file","text":"Le fichier de contr\u00f4le est un fichier binaire, il contient des informations sur la structure physique de la base. Il est cr\u00e9\u00e9 pendant la cr\u00e9ation de la base et il est modifi\u00e9 en permanence. Ce fichier doit \u00eatre toujours disponible car il est consult\u00e9; et modifi\u00e9 fr\u00e9quemment par le serveur oracle. Et il est indispensable pour la restauration de la base. Pour afficher les noms des fichiers de contr\u00f4le on utilise : SHOW PARAMETER CONTROL_FILES SELECT VALUE FROM V$PARAMETER WHERE NAME = 'control_files' ;","title":"Control file"},{"location":"storage/oracle/#redolog","text":"Les fichiers Redo Logs servent \u00e0 enregistrer toutes les modifications commit\u00e9es effectu\u00e9es sur le base de donn\u00e9es. Ils servent \u00e0 prot\u00e9ger la base de donn\u00e9es dans le cas d\u2019un \u00e9chec d\u2019instance. En cas de restauration de la base de donn\u00e9es, on utilise les redo logs pour \u2018rejouer\u2019 les modifications qui ont eu lieu, les transactions valid\u00e9es (commit \u00e0 la fin de la transaction) sont enregistr\u00e9es dans les fichiers de donn\u00e9es Oracle et les transactions non valid\u00e9es, s\u2019il y en a, sont effac\u00e9es des fichiers de donn\u00e9es.","title":"Redolog"},{"location":"storage/oracle/#data-base-file","text":"Les fichiers physiques d\u2019une base Oracle permettent de stocker de mani\u00e8re persistante les donn\u00e9es manipul\u00e9es par Oracle.","title":"Data base file"},{"location":"storage/oracle/#archive-log","text":"Quand la base est en mode NOARCHIVELOG, l\u2019archivage des fichiers redo est d\u00e9sactiv\u00e9. Le fichier de contr\u00f4le indique que les groupes des fichiers redo pleins ne sont plus n\u00e9cessaires. D\u00e8s qu\u2019ils sont inactifs apr\u00e8s un log switch, le groupe sera disponible pour une r\u00e9utilisation par la LGWR . \u2192 (lgwr \u00e9crit toutes les entr\u00e9es refaites qui ont \u00e9t\u00e9 copi\u00e9es dans le tampon depuis la derni\u00e8re fois.) Le mode NOARCHIVELOG prot\u00e8ge la base contre une d\u00e9faillance d\u2019instance et non pas contre une d\u00e9faillance media. Seulement les modifications r\u00e9centes dans la base, stock\u00e9s dans les groupes de fichiers redo en ligne seront disponibles pour la restauration de la base. En mode NOARCHIVELOG, on ne peut pas sauvegarder en ligne une tablespace. Pour restaurer une base en mode NOARCHIVELOG, on est oblig\u00e9 de faire une sauvegarde compl\u00e8te quand la base est ferm\u00e9e. Quand la base est en mode ARCHIVELOG, l\u2019archivage des fichiers redo est activ\u00e9. Le fichier de contr\u00f4le de la base signale que les groupes contenant des fichiers redo pleins ne peuvent pas \u00eatre utilis\u00e9s par le process LGWR tant que les groupes n\u2019ont pas \u00e9t\u00e9 archiv\u00e9s. V\u00e9rifier s\u2019il y a pr\u00e9sence d\u2019Archive log : archive log list Conna\u00eetre la destination de chacune d\u2019entre-elles : show parameter log_archive_dest Passer en mode d'archivage ( attention \u00e0 ne pas omettre de monter seulement l'instance afin d'effectuer la manipulation. Celle-ci subira donc une relance **) : ALTER DATABASE ARCHIVELOG ;","title":"Archive log"},{"location":"storage/oracle/#informations","text":"Conna\u00eetre les informations et version de composant oracle : odacli describe - component Conna\u00eetre le nom de la base sur laquelle on est connect\u00e9e : show parameter name Ou encore pour soucis de suret\u00e9 : show parameter unique Conna\u00eetre le owner d\u2019une table : select disctinct owner from all_tables ; Savoir si la base tourne ou non en SQL : SELECT INSTANCE_NAME , STATUS , DATABASE_STATUS FROM V$INSTANCE ;","title":"Informations"},{"location":"storage/oracle/#diag-tunning","text":"Name Interpr\u00e9ter Syntaxe : CONTROL_MANAGEMENT_PACK_ACCESS = { NONE | DIAGNOSTIC | DIAGNOSTIC+TUNING} D\u00e9sactiver Passon la m\u00e9moire tampon mais aussi le spfile \u00e0 none En tant que sysdba : ALTER SYSTEM SET CONTROL_MANAGEMENT_PACK_ACCESS = NONE SCOPE = BOTH ;","title":"Diag Tunning"},{"location":"storage/oracle/#check","text":"V\u00e9rifier s\u2019il est activ\u00e9 : show parameter control_management_pack_access Ou encore : select display_value from v$parameter where name = 'control_management_pack_access' ;","title":"Check"},{"location":"storage/oracle/#bring-impdp","text":"R\u00e9ccup\u00e9rer la vue sur un import en bacground : impdp \\ \"/ as sysdba\\\" ATTACH = \"SYS_IMPORT_FULL_01\"","title":"Bring impdp"},{"location":"storage/oracle/#global-prefs","text":"Get Global prefs : SELECT DBMS_STATS . get_prefs ( 'CONCURRENT' ) FROM dual ; Global Perfs State SQL Command True DBMS_STATS.SET_GLOBAL_PREFS('CONCURRENT','TRUE'); False DBMS_STATS.SET_GLOBAL_PREFS('CONCURRENT','FALSE');","title":"Global Prefs"},{"location":"storage/oracle/#lsnrctl","text":"L\u2019utilitaire de contr\u00f4le d\u2019\u00e9coute vous permet d\u2019administrer des listeners. Vous pouvez utiliser ses commandes pour ex\u00e9cuter des fonctions de gestion de base sur un ou plusieurs listeners. En outre, vous pouvez afficher et modifier les param\u00e8tres. Commandes possible : - start - Stop - Status - Services - Servacls - Version - Reload - save_config - Trace - Spawn - Quit - Exit - set - show Effectuer un status du service listener : Il se peut que celuic-ci ne se nomme pas LISTENER, il s\u2019agit des param\u00e8tres pas d\u00e9faut : lsnrctl status LISTENER","title":"LSNRCTL"},{"location":"storage/oracle/#odacli","text":"R\u00e9pertorier toutes les bases de donn\u00e9es de l\u2019appliance : odacli list-databases Afficher les d\u00e9tails de la base de donn\u00e9es : odacli describe-database Cr\u00e9er une nouvelle base de donn\u00e9es : odacli create-database Supprimer une base de donn\u00e9es : odacli delete-database R\u00e9seau : - On trouvera les identifiants r\u00e9seau : odacli list-network On y trouve tout les d\u00e9tails de ce r\u00e9seau : :: odacli describe-ntwork -i $identifiants_r\u00e9seau","title":"ODACLI"},{"location":"storage/oracle/#oswbba","text":"java - jar / opt / oracle / oak / oswbb / oswbba . jar - i / opt / oracle / oak / oswbb / archive - b Mar 18 00 : 00 : 00 2019 - e Mar 19 00 : 00 : 00","title":"OSWBBA"},{"location":"storage/oracle/#ressources","text":"Afin de v\u00e9rifier l\u2019\u00e9tat du param\u00e8tre SESSIONS : SHOW parameter sessions","title":"Ressources"},{"location":"storage/oracle/#processes","text":"PROCESSES sp\u00e9cifie le nombre maximal de processus utilisateur du syst\u00e8me d\u2019exploitation pouvant se connecter simultan\u00e9ment \u00e0 Oracle. Sa valeur doit autoriser tous les processus d\u2019arri\u00e8re-plan tels que les verrous, les processus de file d\u2019attente de travaux et les processus d\u2019ex\u00e9cution parall\u00e8les. Les valeurs par d\u00e9faut des param\u00e8tres SESSIONS et TRANSACTIONS sont d\u00e9riv\u00e9es de ce param\u00e8tre. Par cons\u00e9quent, si vous modifiez la valeur de PROCESSES, vous devez d\u00e9terminer si vous souhaitez ajuster les valeurs de ces param\u00e8tres d\u00e9riv\u00e9s. Afin de v\u00e9rifier l\u2019\u00e9tat du param\u00e8tre PROCESSES : SHOW parameter processes Application du param\u00e8tre : ALTER SYSTEM SET processes=[VALUE AS INTEGER] SCOPE=SPFILE ;","title":"Processes"},{"location":"storage/oracle/#transactions","text":"TRANSACTIONS sp\u00e9cifie le nombre maximal de transactions simultan\u00e9es. Des valeurs plus \u00e9lev\u00e9es augmentent la taille du SGA et peuvent augmenter le nombre de segments de restauration allou\u00e9s. La valeur par d\u00e9faut est sup\u00e9rieure \u00e0 SESSIONS (et \u00e0 son tour, PROCESSES) pour permettre les transactions r\u00e9cursives.","title":"Transactions"},{"location":"storage/oracle/#verifier-les-parametres","text":"Afin de v\u00e9rifier l\u2019\u00e9tat du param\u00e8tre TRANSACTIONS : SHOW parameter transactions Application du param\u00e8tre : ALTER SYSTEM SET transactions=[VALUE AS INTEGER] SCOPE=SPFILE ; \u26a0 Application des param\u00e8tres : Afin d\u2019appliquer des param\u00e8tres modifi\u00e9s dans le spfile , un relance de l\u2019instance sera requis : shutdown immediate startup","title":"V\u00e9rifier les param\u00e8tres"},{"location":"storage/oracle/#account","text":"D\u00e9bloquer des compte v\u00e9rouill\u00e9 : SQL > conn / AS sysdba Connected . SQL > ALTER USER $ USER BY ******** account UNLOCK ; USER altered . SQL > ALTER USER $ USER IDENTIFIED BY ******** account UNLOCK ; USER altered .","title":"Account"},{"location":"storage/oracle/#sqlplus","text":"Param\u00e9trage de l\u2019interface sqlplus :","title":"SQLPLUS"},{"location":"storage/oracle/#linesize","text":"La longueur des lignes par d\u00e9faut 80 caract\u00e8res : set linesize 200","title":"linesize"},{"location":"storage/oracle/#col","text":"Il d\u00e9fini un format de sortie pour une colonne particuli\u00e8re : col table_name for a20","title":"col"},{"location":"storage/oracle/#set-pause-on","text":"Permet une attente de RETURN pour faire d\u00e9filer les lignes suivantes ( comme la commande more).","title":"set pause on"},{"location":"storage/oracle/#spool","text":"La sortie standard et d\u2019erreur est redirig\u00e9e dans le fichier indiqu\u00e9 dans la commande. La commande \u201cspool off\u201d ferme le fichier. Utiliser la commande SQL **start** or **@** pour effectuer les script tel que .sql","title":"spool"},{"location":"storage/oracle/#statspack","text":"","title":"STATSPACK"},{"location":"storage/oracle/#analyser","text":"Mise en forme du resultat : col OWNER format a10 col SEGMENT_NAME format a60 col SEGMENT_TYPE format a15 set pagesize 1000 select owner , segment_name , segment_type , bytes / 1024 / 1024 from dba_segments where tablespace_name = 'STATSPACK_TBS' and segment_type = 'TABLE' order by bytes desc ;","title":"Analyser"},{"location":"storage/oracle/#corriger","text":"","title":"Corriger"},{"location":"storage/oracle/#1-purge-statspack","text":"Renseigner la plage d'id \u00e0 purger : DEFINE losnapid = 1 -- low snap id DEFINE hisnapid = 2 -- high snap id @?/ rdbms / admin / sppurge . sql","title":"1. Purge STATSPACK"},{"location":"storage/oracle/#2-move-table","text":"How to move dba_segments : select 'alter table ' || owner || '.' || segment_name || ' move;' from dba_segments where tablespace_name = 'STATSPACK_TBS' and segment_type = 'TABLE' order by bytes desc ;","title":"2. Move table"},{"location":"storage/oracle/#3-rebuild-index","text":"How to rebuild dba_indexes : select 'alter index ' || owner || '.' || index_name || ' rebuild;' from dba_indexes where status = 'UNUSABLE' ;","title":"3. Rebuild Index"},{"location":"storage/oracle/#tnsname","text":"Comment la v\u00e9rifier : [ oracle @ oda ~ ] # env | grep TNS TNS_ADMIN =/ backup / TNS Le fichier est donc dans /backup/TNS/tnsname.ora .","title":"TNSNAME"},{"location":"storage/oracle/#configuration","text":"Voici un exemple de configuration : ( DESCRIPTION = ( ADDRESS = ( PROTOCOL = TCP )( HOST = `` iP de la machine `` )( PORT = 1521 )) ( CONNECT_DATA = ( SERVER = DEDICATED ) ( SERVICE_NAME = `` Nom de la base `` ) ) )","title":"Configuration:"},{"location":"storage/oracle/#tablespace","text":"Know the tablesapces size : set line 1000 set pagesize 100 col \"Tablespace\" FOR a22 col \"Used MB\" FOR 99 , 999 , 999 col \"Free MB\" FOR 99 , 999 , 999 col \"Total MB\" FOR 99 , 999 , 999 SELECT df . tablespace_name \"Tablespace\" , totalusedspace \"Used MB\" , ( df . totalspace - tu . totalusedspace ) \"Free MB\" , df . totalspace \"Total MB\" , round ( 100 * ( ( df . totalspace - tu . totalusedspace ) / df . totalspace )) \"Pct. Free\" , df . MAX_SIZE / 1024 / 1024 / 1024 \"Max Size Go\" FROM ( SELECT tablespace_name , round ( SUM ( bytes ) / 1048576 ) TotalSpace , sum ( decode ( AUTOEXTENSIBLE , 'YES' , MAXBYTES , BYTES )) MAX_SIZE FROM dba_data_files GROUP BY tablespace_name ) df , ( SELECT round ( SUM ( bytes ) / ( 1024 * 1024 )) totalusedspace , tablespace_name FROM dba_segments GROUP BY tablespace_name ) tu WHERE df . tablespace_name = tu . tablespace_name ;","title":"Tablespace"},{"location":"tool/freeipa/","text":"Free IPA Hostname echo \"ldap{01,02}.home.test ldap{1,2}\" > /etc/hostname Firewall firewall-cmd --add-service=freeipa-ldap{,s} --permanent firewall-cmd --reload FreeIPA serv{dns} packages yum install ipa-server ipa-server-dns FreeIPA setup ipa-server-install ou ipa-server-install -U -p user -a password --ip-address = ip -n fqdn -r FQDN --hostname = ${ hostname -f } --setup-dns --auto-reverse Autau create home directory authconfig --enablemkhomedir --update Check access ipactl status Kerebros token : admin kinit admin klist Steps 1 nmtui -> hostname ldap0{1,2}.ipa.test 2 echo \"$(hostname -I) $(hostname -f) ldap0{1,2}\" >> /etc/hosts 3 firewall-cmd --add-service=freeipa-ldap{,s} --permanent firewall-cmd --reload 4 yum install freeipa-server ipa-server-dns 5 ipa-server-install 6 kinit admin ipa user-add ipa passwrd yum install ipa-server hostnamctl set-hostname freeipa.sboistel.lan ipa-server-install --setup-dns","title":"Free IPA"},{"location":"tool/freeipa/#free-ipa","text":"","title":"Free IPA"},{"location":"tool/freeipa/#hostname","text":"echo \"ldap{01,02}.home.test ldap{1,2}\" > /etc/hostname","title":"Hostname"},{"location":"tool/freeipa/#firewall","text":"firewall-cmd --add-service=freeipa-ldap{,s} --permanent firewall-cmd --reload","title":"Firewall"},{"location":"tool/freeipa/#freeipa-servdns-packages","text":"yum install ipa-server ipa-server-dns","title":"FreeIPA serv{dns} packages"},{"location":"tool/freeipa/#freeipa-setup","text":"ipa-server-install ou ipa-server-install -U -p user -a password --ip-address = ip -n fqdn -r FQDN --hostname = ${ hostname -f } --setup-dns --auto-reverse","title":"FreeIPA setup"},{"location":"tool/freeipa/#autau-create-home-directory","text":"authconfig --enablemkhomedir --update","title":"Autau create home directory"},{"location":"tool/freeipa/#check-access","text":"ipactl status","title":"Check access"},{"location":"tool/freeipa/#kerebros-token-admin","text":"kinit admin klist","title":"Kerebros token : admin"},{"location":"tool/freeipa/#steps","text":"","title":"Steps"},{"location":"tool/freeipa/#1","text":"nmtui -> hostname ldap0{1,2}.ipa.test","title":"1"},{"location":"tool/freeipa/#2","text":"echo \"$(hostname -I) $(hostname -f) ldap0{1,2}\" >> /etc/hosts","title":"2"},{"location":"tool/freeipa/#3","text":"firewall-cmd --add-service=freeipa-ldap{,s} --permanent firewall-cmd --reload","title":"3"},{"location":"tool/freeipa/#4","text":"yum install freeipa-server ipa-server-dns","title":"4"},{"location":"tool/freeipa/#5","text":"ipa-server-install","title":"5"},{"location":"tool/freeipa/#6","text":"kinit admin ipa user-add ipa passwrd yum install ipa-server hostnamctl set-hostname freeipa.sboistel.lan ipa-server-install --setup-dns","title":"6"},{"location":"tool/guacamole/","text":"Guacamole Apache Guacamole is a clientless remote desktop gateway. It supports standard protocols like VNC, RDP, and SSH. We call it clientless because no plugins or client software are required. Thanks to HTML5, once Guacamole is installed on a server, all you need to access your desktops is a web browser . Server Requiere depedences APT:DEB/Ubuntu apt install libcairo2-dev libtool-bin libossp-uuid-dev Optional depedences APT:DEB/Ubuntu apt install libavcodec-dev libavformat-dev libavutil-dev libswscale-dev freerdp2-dev libpango1.0-dev libssh2-1-dev libtelnet-dev libvncserver-dev libwebsockets-dev libpulse-dev libssl-dev libvorbis-dev libwebp-dev Obtain code APT:DEB/Ubuntu apt install git Donwload the guacamole server repository: git clone <git://github.com/apache/guacamole-server.git> Build process cd guacamole-server autoreconf -fi ./configure --with-init-dir = /etc/init.d --enable-allow-freerdp-snapshots make Installation make install ldconfig Guest agent Requierement APT:DEB/Ubuntu apt install git maven RPM:Fedora/Centos/Rhel: yum install git maven Donwload the guacamole client repository git clone <git://github.com/apache/guacamole-client.git> mvn package Source : https://kifarunix.com/install-apache-guacamole-on-ubuntu-21-04/ Server Installation Update : apt update Software needed : apt install build-essential libcairo2-dev libpng-dev libtool-bin libossp-uuid-dev libavcodec-dev libavformat-dev libavutil-dev libswscale-dev freerdp2-dev libpango1.0-dev libssh2-1-dev libvncserver-dev libtelnet-dev libssl-dev libvorbis-dev libwebp-dev Guacamole Server Downlaod cd /usr/src/ wget <https://downloads.apache.org/guacamole/1.3.0/source/guacamole-server-1.3.0.tar.gz> tar xzvf guacamole-server-1.3.0.tar.gz Configuration For more configure options, run, ./configure --help Verifying if anything is missing cd guacamole-server-1.3.0 ./configure --with-init-dir = /etc/init.d","title":"Guacamole"},{"location":"tool/guacamole/#guacamole","text":"Apache Guacamole is a clientless remote desktop gateway. It supports standard protocols like VNC, RDP, and SSH. We call it clientless because no plugins or client software are required. Thanks to HTML5, once Guacamole is installed on a server, all you need to access your desktops is a web browser .","title":"Guacamole"},{"location":"tool/guacamole/#server","text":"","title":"Server"},{"location":"tool/guacamole/#requiere-depedences","text":"","title":"Requiere depedences"},{"location":"tool/guacamole/#aptdebubuntu","text":"apt install libcairo2-dev libtool-bin libossp-uuid-dev","title":"APT:DEB/Ubuntu"},{"location":"tool/guacamole/#optional-depedences","text":"APT:DEB/Ubuntu apt install libavcodec-dev libavformat-dev libavutil-dev libswscale-dev freerdp2-dev libpango1.0-dev libssh2-1-dev libtelnet-dev libvncserver-dev libwebsockets-dev libpulse-dev libssl-dev libvorbis-dev libwebp-dev","title":"Optional depedences"},{"location":"tool/guacamole/#obtain-code","text":"APT:DEB/Ubuntu apt install git Donwload the guacamole server repository: git clone <git://github.com/apache/guacamole-server.git>","title":"Obtain code"},{"location":"tool/guacamole/#build-process","text":"cd guacamole-server autoreconf -fi ./configure --with-init-dir = /etc/init.d --enable-allow-freerdp-snapshots make","title":"Build process"},{"location":"tool/guacamole/#installation","text":"make install ldconfig","title":"Installation"},{"location":"tool/guacamole/#guest-agent","text":"","title":"Guest agent"},{"location":"tool/guacamole/#requierement","text":"APT:DEB/Ubuntu apt install git maven RPM:Fedora/Centos/Rhel: yum install git maven Donwload the guacamole client repository git clone <git://github.com/apache/guacamole-client.git> mvn package Source : https://kifarunix.com/install-apache-guacamole-on-ubuntu-21-04/","title":"Requierement"},{"location":"tool/guacamole/#server-installation","text":"Update : apt update Software needed : apt install build-essential libcairo2-dev libpng-dev libtool-bin libossp-uuid-dev libavcodec-dev libavformat-dev libavutil-dev libswscale-dev freerdp2-dev libpango1.0-dev libssh2-1-dev libvncserver-dev libtelnet-dev libssl-dev libvorbis-dev libwebp-dev","title":"Server Installation"},{"location":"tool/guacamole/#guacamole-server","text":"","title":"Guacamole Server"},{"location":"tool/guacamole/#downlaod","text":"cd /usr/src/ wget <https://downloads.apache.org/guacamole/1.3.0/source/guacamole-server-1.3.0.tar.gz> tar xzvf guacamole-server-1.3.0.tar.gz","title":"Downlaod"},{"location":"tool/guacamole/#configuration","text":"For more configure options, run, ./configure --help","title":"Configuration"},{"location":"tool/guacamole/#verifying-if-anything-is-missing","text":"cd guacamole-server-1.3.0 ./configure --with-init-dir = /etc/init.d","title":"Verifying if anything is missing"},{"location":"tool/netbox/","text":"IPAM - Netbox NetBox is an infrastructure resource modeling (IRM) application designed to empower network automation. Initially conceived by the network engineering team at DigitalOcean, NetBox was developed specifically to address the needs of network and infrastructure engineers. NetBox is made available as open source under the Apache 2 license. It encompasses the following aspects of network management: IP address management (IPAM) - IP networks and addresses, VRFs, and VLANs Equipment racks - Organized by group and site Devices - Types of devices and where they are installed Connections - Network, console, and power connections among devices Virtualization - Virtual machines and clusters Data circuits - Long-haul communications circuits and providers Secrets - Encrypted storage of sensitive credentials How to install netbox Requieste yum install git","title":"IPAM - Netbox"},{"location":"tool/netbox/#ipam-netbox","text":"NetBox is an infrastructure resource modeling (IRM) application designed to empower network automation. Initially conceived by the network engineering team at DigitalOcean, NetBox was developed specifically to address the needs of network and infrastructure engineers. NetBox is made available as open source under the Apache 2 license. It encompasses the following aspects of network management: IP address management (IPAM) - IP networks and addresses, VRFs, and VLANs Equipment racks - Organized by group and site Devices - Types of devices and where they are installed Connections - Network, console, and power connections among devices Virtualization - Virtual machines and clusters Data circuits - Long-haul communications circuits and providers Secrets - Encrypted storage of sensitive credentials","title":"IPAM - Netbox"},{"location":"tool/netbox/#how-to-install-netbox","text":"","title":"How to install netbox"},{"location":"tool/netbox/#requieste","text":"yum install git","title":"Requieste"},{"location":"tool/pi-hole/","text":"Pi-Hole Requirement Set static iP @ Installation Installing packages apt install curl Download & run the installation file curl -sSL https://install.pi-hole.net | bash Configuration Change the main password pihole -a -p","title":"Pi-Hole"},{"location":"tool/pi-hole/#pi-hole","text":"","title":"Pi-Hole"},{"location":"tool/pi-hole/#requirement","text":"Set static iP @","title":"Requirement"},{"location":"tool/pi-hole/#installation","text":"Installing packages apt install curl Download & run the installation file curl -sSL https://install.pi-hole.net | bash","title":"Installation"},{"location":"tool/pi-hole/#configuration","text":"Change the main password pihole -a -p","title":"Configuration"},{"location":"tool/readme/","text":"README","title":"README"},{"location":"tool/readme/#readme","text":"","title":"README"},{"location":"tool/rhel_idm/","text":"Red Hat Identity Management (IdM) Commandes Show $USER ipa user-show monuser --all Client Add Client : ipa-client-install --domain = dnsname --server = fqdn --realm = DNSNAME --mkhomedir --ntp-server = iP1 --ntp-server = iP2","title":"Red Hat Identity Management (IdM)"},{"location":"tool/rhel_idm/#red-hat-identity-management-idm","text":"","title":"Red Hat Identity Management (IdM)"},{"location":"tool/rhel_idm/#commandes","text":"Show $USER ipa user-show monuser --all","title":"Commandes"},{"location":"tool/rhel_idm/#client","text":"Add Client : ipa-client-install --domain = dnsname --server = fqdn --realm = DNSNAME --mkhomedir --ntp-server = iP1 --ntp-server = iP2","title":"Client"},{"location":"tool/rundeck/","text":"Rundeck Rundeck is runbook automation that gives you and your colleagues self-service access to the processes and tools they need to get their job done. Installation Ubuntu or Debian disto Community version Java Warning Rundeck depends on Java 11 or Java 8 . The Java 14 packages will satisfy this dependency however Rundeck will not function properly with them. It is recommended to install the openjdk-11-jre-headless package manually. sudo apt-get install openjdk-11-jre-headless Quick installation curl https://raw.githubusercontent.com/rundeck/packaging/main/scripts/deb-setup.sh 2 > /dev/null | sudo bash -s rundeck Manual installation Bring signed keys : curl -L https://packages.rundeck.com/pagerduty/rundeck/gpgkey | sudo apt-key add - Create new sources list /etc/apt/sources.list.d/rundeck.list : deb https://packages.rundeck.com/pagerduty/rundeck/any/ any main deb-src https://packages.rundeck.com/pagerduty/rundeck/any/ any main Now, lets install Download package if relavant from the download page sudo apt update sudo apt install rundeck Post Installation URL ? Change the URL into the /etc/rundeck directory > might be run as root Replace the 10..x by your iP sed -i 's/localhost/10..x/g' rundeck-config.properties framework.properties Service Enable the rundeckd service sudo systemctl enable rundeckd Start the rundeckd service sudo systemctl start rundeckd To verify that the service started correctly, tail the logs: tail -f /var/log/rundeck/service.log Copied! The service is ready once you see something similar to: Grails application running at http://localhost:4440 in environment: production Yes there is locahost in the log I know ... Logging in for the first time Navigate to http://10..x:4440/ (open new window) in a browser. Log in with the username admin and password admin Rundeck is now up and running !","title":"Rundeck"},{"location":"tool/rundeck/#rundeck","text":"Rundeck is runbook automation that gives you and your colleagues self-service access to the processes and tools they need to get their job done.","title":"Rundeck"},{"location":"tool/rundeck/#installation","text":"","title":"Installation"},{"location":"tool/rundeck/#ubuntu-or-debian-disto","text":"Community version","title":"Ubuntu or Debian disto"},{"location":"tool/rundeck/#java","text":"Warning Rundeck depends on Java 11 or Java 8 . The Java 14 packages will satisfy this dependency however Rundeck will not function properly with them. It is recommended to install the openjdk-11-jre-headless package manually. sudo apt-get install openjdk-11-jre-headless","title":"Java"},{"location":"tool/rundeck/#quick-installation","text":"curl https://raw.githubusercontent.com/rundeck/packaging/main/scripts/deb-setup.sh 2 > /dev/null | sudo bash -s rundeck","title":"Quick installation"},{"location":"tool/rundeck/#manual-installation","text":"Bring signed keys : curl -L https://packages.rundeck.com/pagerduty/rundeck/gpgkey | sudo apt-key add - Create new sources list /etc/apt/sources.list.d/rundeck.list : deb https://packages.rundeck.com/pagerduty/rundeck/any/ any main deb-src https://packages.rundeck.com/pagerduty/rundeck/any/ any main Now, lets install Download package if relavant from the download page sudo apt update sudo apt install rundeck","title":"Manual installation"},{"location":"tool/rundeck/#post-installation","text":"","title":"Post Installation"},{"location":"tool/rundeck/#url","text":"Change the URL into the /etc/rundeck directory > might be run as root Replace the 10..x by your iP sed -i 's/localhost/10..x/g' rundeck-config.properties framework.properties","title":"URL ?"},{"location":"tool/rundeck/#service","text":"Enable the rundeckd service sudo systemctl enable rundeckd Start the rundeckd service sudo systemctl start rundeckd To verify that the service started correctly, tail the logs: tail -f /var/log/rundeck/service.log Copied! The service is ready once you see something similar to: Grails application running at http://localhost:4440 in environment: production Yes there is locahost in the log I know ...","title":"Service"},{"location":"tool/rundeck/#logging-in-for-the-first-time","text":"Navigate to http://10..x:4440/ (open new window) in a browser. Log in with the username admin and password admin Rundeck is now up and running !","title":"Logging in for the first time"},{"location":"tool/sshs/","text":"sshs Terminal user interface for SSH. It uses ~/.ssh/config to list and connect to hosts. Requirements You need to have ssh installed and accessible from your terminal. How to install Homebrew brew install sshs Chocolatey Thanks to Jakub Lev\u00fd for maintaining this package on Chocolatey. choco install sshs From releases Releases contains prebuilt binaries for Linux, macOS and Windows. You can download them at https://github.com/quantumsheep/sshs/releases. From sources git clone https://github.com/quantumsheep/sshs.git cd sshs make make install You can check the main repository : https://github.com/quantumsheep/sshs","title":"sshs"},{"location":"tool/sshs/#sshs","text":"Terminal user interface for SSH. It uses ~/.ssh/config to list and connect to hosts.","title":"sshs"},{"location":"tool/sshs/#requirements","text":"You need to have ssh installed and accessible from your terminal.","title":"Requirements"},{"location":"tool/sshs/#how-to-install","text":"","title":"How to install"},{"location":"tool/sshs/#homebrew","text":"brew install sshs","title":"Homebrew"},{"location":"tool/sshs/#chocolatey","text":"Thanks to Jakub Lev\u00fd for maintaining this package on Chocolatey. choco install sshs","title":"Chocolatey"},{"location":"tool/sshs/#from-releases","text":"Releases contains prebuilt binaries for Linux, macOS and Windows. You can download them at https://github.com/quantumsheep/sshs/releases.","title":"From releases"},{"location":"tool/sshs/#from-sources","text":"git clone https://github.com/quantumsheep/sshs.git cd sshs make make install You can check the main repository : https://github.com/quantumsheep/sshs","title":"From sources"},{"location":"tool/ui-path/","text":"UI-path Bri\u00e8ve liste de software : UI Path Automation Anywhere Blue prism Microsoft Power automate RPA (Robotic Process Automation) : Bot (logiciel, digital worker) Soft/wrokflow/processus Pilot\u00e9 via un orchestrator (Fournit par le prestataire. Ex UIPath) Deux type d'automation : Attended Unattended IDE UiPath Studio Pro Language List of project language : VB VB.Net C++ C#w","title":"UI-path"},{"location":"tool/ui-path/#ui-path","text":"Bri\u00e8ve liste de software : UI Path Automation Anywhere Blue prism Microsoft Power automate RPA (Robotic Process Automation) : Bot (logiciel, digital worker) Soft/wrokflow/processus Pilot\u00e9 via un orchestrator (Fournit par le prestataire. Ex UIPath) Deux type d'automation : Attended Unattended","title":"UI-path"},{"location":"tool/ui-path/#ide","text":"UiPath Studio Pro","title":"IDE"},{"location":"tool/ui-path/#language","text":"List of project language : VB VB.Net C++ C#w","title":"Language"},{"location":"tool/vnc-tiger/","text":"VNC Tiger VNC Session How to create new VNC Session ? Change the VNCpassword vncpassword Directory Move to the session direcotry : cd /etc/systemd/system Session file Copy old vncserver.service file to a new one : cp [ vncserver@ { N\u00b0 } .service ]( mailto:vncserver@ { N\u00b0 } .service ) vncserver@: { New N\u00b0 } .service Replace : sed -i 's/olduser/newuser/g' vncserver@: { New N\u00b0 } .service Service Enable the service : systemctl enable vncserver@: { New N\u00b0 } .service","title":"VNC Tiger"},{"location":"tool/vnc-tiger/#vnc-tiger","text":"","title":"VNC Tiger"},{"location":"tool/vnc-tiger/#vnc-session","text":"How to create new VNC Session ?","title":"VNC Session"},{"location":"tool/vnc-tiger/#change-the-vncpassword","text":"vncpassword","title":"Change the VNCpassword"},{"location":"tool/vnc-tiger/#directory","text":"Move to the session direcotry : cd /etc/systemd/system","title":"Directory"},{"location":"tool/vnc-tiger/#session-file","text":"Copy old vncserver.service file to a new one : cp [ vncserver@ { N\u00b0 } .service ]( mailto:vncserver@ { N\u00b0 } .service ) vncserver@: { New N\u00b0 } .service Replace : sed -i 's/olduser/newuser/g' vncserver@: { New N\u00b0 } .service","title":"Session file"},{"location":"tool/vnc-tiger/#service","text":"Enable the service : systemctl enable vncserver@: { New N\u00b0 } .service","title":"Service"},{"location":"tool/vscode/","text":"VSCode MacOS vscode keyboard shortcuts Howto vscode custom shortcuts Learn vscode keyboard shortcuts Side Menu shortcut description \u2318 + B Hide show side menu \u2318 + \u21e7 + E Explorer window \u2318 + \u21e7 + F Find window \u2318 + \u21e7 + J Find in files window \u2303 + \u21e7 + G Git window \u2318 + \u21e7 + D Debug window \u2318 + \u21e7 + X Extension window Multi-Cursor Editing shortcut description \u2318 + \u2325 + \u2193 add a new cursor below \u2325 + Click add a new cursor at the mouse click \u2318 + \u21e7 + L add new cursor behind all instances of a word Split editor shortcut description \u2318 + \\ split Split Window focusing shortcut description \u2318 + 0 explorer panel \u2318 + 1 1st window split window \u2318 + 2 2nd window split window \u2303 + ~ terminal window ^ + tab switch between tabs \u2318 + ~ switch between VS code editor windows IntelliSense shortcut description \u2303 + Space to invoke IntelliSense Line Action shortcut description \u21e7 + \u2325 + \u2193 copy the line and insert below \u21e7 + \u2325 + \u2191 copy the line and insert above \u2325 + \u2193 move entire line below \u2325 + \u2191 move entire line above \u2318 + \u21e7 + K delete entire line Rename Refactoring shortcut description F2 (Fn + F2) Rename Symbol in the current project Right Mouse Click -> Rename Symbol Rename Symbol in the current project Formatting shortcut description \u21e7 + \u2325 + F format entire document \u2318 + K and \u2318 F format selected text Transform selected shortcut description ^ + \u21e7 + \u2325 + L transform selected to lower ^ + \u21e7 + \u2325 + U transform selected to upper ^ + \u21e7 + \u2325 + S transform selected to snake ^ + \u21e7 + \u2325 + T transform selected to titelcase Code Folding shortcut description \u2318 + \u2325 + [ fold \u2318 + \u2325 + ] unfold \u2318 K and \u2318 0 fold all \u2318 K and \u2318 J unfold all \u2318 K and \u2318 1 fold 1 level \u2318 K and \u2318 2 fold 2 levels \u2318 K and \u2318 5 fold 5 levels Errors and Warnings shortcut description F8 navigate across errors Code Server /lib/systemd/system/code-server.service [ Unit ] Description = code-server After = nginx.service [ Service ] Type = simple User = lully ExecStart = /usr/local/bin/code-server serve Restart = always [ Install ] WantedBy = multi-user.target Sources https://code.visualstudio.com/docs/remote/vscode-server https://github.com/coder/code-server","title":"VSCode"},{"location":"tool/vscode/#vscode","text":"MacOS vscode keyboard shortcuts Howto vscode custom shortcuts Learn vscode keyboard shortcuts","title":"VSCode"},{"location":"tool/vscode/#side-menu","text":"shortcut description \u2318 + B Hide show side menu \u2318 + \u21e7 + E Explorer window \u2318 + \u21e7 + F Find window \u2318 + \u21e7 + J Find in files window \u2303 + \u21e7 + G Git window \u2318 + \u21e7 + D Debug window \u2318 + \u21e7 + X Extension window","title":"Side Menu"},{"location":"tool/vscode/#multi-cursor-editing","text":"shortcut description \u2318 + \u2325 + \u2193 add a new cursor below \u2325 + Click add a new cursor at the mouse click \u2318 + \u21e7 + L add new cursor behind all instances of a word","title":"Multi-Cursor Editing"},{"location":"tool/vscode/#split-editor","text":"shortcut description \u2318 + \\ split","title":"Split editor"},{"location":"tool/vscode/#split-window-focusing","text":"shortcut description \u2318 + 0 explorer panel \u2318 + 1 1st window split window \u2318 + 2 2nd window split window \u2303 + ~ terminal window ^ + tab switch between tabs \u2318 + ~ switch between VS code editor windows","title":"Split Window focusing"},{"location":"tool/vscode/#intellisense","text":"shortcut description \u2303 + Space to invoke IntelliSense","title":"IntelliSense"},{"location":"tool/vscode/#line-action","text":"shortcut description \u21e7 + \u2325 + \u2193 copy the line and insert below \u21e7 + \u2325 + \u2191 copy the line and insert above \u2325 + \u2193 move entire line below \u2325 + \u2191 move entire line above \u2318 + \u21e7 + K delete entire line","title":"Line Action"},{"location":"tool/vscode/#rename-refactoring","text":"shortcut description F2 (Fn + F2) Rename Symbol in the current project Right Mouse Click -> Rename Symbol Rename Symbol in the current project","title":"Rename Refactoring"},{"location":"tool/vscode/#formatting","text":"shortcut description \u21e7 + \u2325 + F format entire document \u2318 + K and \u2318 F format selected text","title":"Formatting"},{"location":"tool/vscode/#transform-selected","text":"shortcut description ^ + \u21e7 + \u2325 + L transform selected to lower ^ + \u21e7 + \u2325 + U transform selected to upper ^ + \u21e7 + \u2325 + S transform selected to snake ^ + \u21e7 + \u2325 + T transform selected to titelcase","title":"Transform selected"},{"location":"tool/vscode/#code-folding","text":"shortcut description \u2318 + \u2325 + [ fold \u2318 + \u2325 + ] unfold \u2318 K and \u2318 0 fold all \u2318 K and \u2318 J unfold all \u2318 K and \u2318 1 fold 1 level \u2318 K and \u2318 2 fold 2 levels \u2318 K and \u2318 5 fold 5 levels","title":"Code Folding"},{"location":"tool/vscode/#errors-and-warnings","text":"shortcut description F8 navigate across errors","title":"Errors and Warnings"},{"location":"tool/vscode/#code-server","text":"/lib/systemd/system/code-server.service [ Unit ] Description = code-server After = nginx.service [ Service ] Type = simple User = lully ExecStart = /usr/local/bin/code-server serve Restart = always [ Install ] WantedBy = multi-user.target","title":"Code Server"},{"location":"tool/vscode/#sources","text":"https://code.visualstudio.com/docs/remote/vscode-server https://github.com/coder/code-server","title":"Sources"},{"location":"tool/wikijs/","text":"Wiki JS Getting started with a Wiki.js installation on Linux Before going any further, make sure your system meets all the requirements . Looking for a complete, easy step-by-step installation guide, including all dependencies and an auto-updater? Check out the Ubuntu-based installation guide. {.is-info} Install Download the latest version of Wiki.js wget https://github.com/Requarks/wiki/releases/latest/download/wiki-js.tar.gz Extract the package to the final destination of your choice mkdir wiki tar xzf wiki-js.tar.gz -C ./wiki cd ./wiki Rename the sample config file to config.yml mv config.sample.yml config.yml Edit the config file and fill in your database and port settings ( Configuration Reference ) nano config.yml For SQLite installations only: (skip this step otherwise) Fetch native bindings for SQLite3 npm rebuild sqlite3 Run Wiki.js node server Wait until you are invited to open to the setup page in your browser. Complete the setup wizard to finish the installation. Run as service There are several solutions to run Wiki.js as a background service. We'll focus on systemd in this guide as it's available in nearly all linux distributions. Create a new file named wiki.service inside directory /etc/systemd/system . nano /etc/systemd/system/wiki.service Paste the following contents (assuming your wiki is installed at /var/wiki ): [Unit] Description = Wiki.js After = network.target [Service] Type = simple ExecStart = /usr/bin/node server Restart = always # Consider creating a dedicated user for Wiki.js here: User = nobody Environment = NODE_ENV=production WorkingDirectory = /var/wiki [Install] WantedBy = multi-user.target Save the service file ( CTRL + X , followed by Y ). Reload systemd: systemctl daemon-reload Run the service: systemctl start wiki Enable the service on system boot. systemctl enable wiki Note: You can see the logs of the service using journalctl -u wiki {.align-abstopright}","title":"Wiki JS"},{"location":"tool/wikijs/#wiki-js","text":"Getting started with a Wiki.js installation on Linux Before going any further, make sure your system meets all the requirements . Looking for a complete, easy step-by-step installation guide, including all dependencies and an auto-updater? Check out the Ubuntu-based installation guide. {.is-info}","title":"Wiki JS"},{"location":"tool/wikijs/#install","text":"Download the latest version of Wiki.js wget https://github.com/Requarks/wiki/releases/latest/download/wiki-js.tar.gz Extract the package to the final destination of your choice mkdir wiki tar xzf wiki-js.tar.gz -C ./wiki cd ./wiki Rename the sample config file to config.yml mv config.sample.yml config.yml Edit the config file and fill in your database and port settings ( Configuration Reference ) nano config.yml For SQLite installations only: (skip this step otherwise) Fetch native bindings for SQLite3 npm rebuild sqlite3 Run Wiki.js node server Wait until you are invited to open to the setup page in your browser. Complete the setup wizard to finish the installation.","title":"Install"},{"location":"tool/wikijs/#run-as-service","text":"There are several solutions to run Wiki.js as a background service. We'll focus on systemd in this guide as it's available in nearly all linux distributions. Create a new file named wiki.service inside directory /etc/systemd/system . nano /etc/systemd/system/wiki.service Paste the following contents (assuming your wiki is installed at /var/wiki ): [Unit] Description = Wiki.js After = network.target [Service] Type = simple ExecStart = /usr/bin/node server Restart = always # Consider creating a dedicated user for Wiki.js here: User = nobody Environment = NODE_ENV=production WorkingDirectory = /var/wiki [Install] WantedBy = multi-user.target Save the service file ( CTRL + X , followed by Y ). Reload systemd: systemctl daemon-reload Run the service: systemctl start wiki Enable the service on system boot. systemctl enable wiki Note: You can see the logs of the service using journalctl -u wiki {.align-abstopright}","title":"Run as service"},{"location":"windows/account/","text":"Account How to change user account Let's take a look to how to change user password without any access through Windows ISO. Boot on Windows 10 ISO On the language screen, chose your language and hit SHIFT+F10 Get Logical Volume inforations When the cmd terminal is oppened, list Diske Caption and Volume Name : wmic logicaldisk get caption , VolumeName Move to the Disk you want (letter found with the previous command) d : Go to the system32 folder cd windows \\ system32 Utilman Use utilman despite off cmd.exe ren utilman . exe utilman . exe . bak ren cmd . exe utilman . exe Reboot wpeutil reboot Change user password After rebooting, clic on accessibility icon Change password Change the user password Example : net user admin root net user $USER pass Active user Active user net user $USER / active : yes Reboot wpeutil reboot Replace utilman despite off cmd.exe ren utilman . exe cmd . exe ren utilman . exe . bak utilman . exe","title":"Account"},{"location":"windows/account/#account","text":"","title":"Account"},{"location":"windows/account/#how-to-change-user-account","text":"Let's take a look to how to change user password without any access through Windows ISO. Boot on Windows 10 ISO On the language screen, chose your language and hit SHIFT+F10","title":"How to change user account"},{"location":"windows/account/#get-logical-volume-inforations","text":"When the cmd terminal is oppened, list Diske Caption and Volume Name : wmic logicaldisk get caption , VolumeName Move to the Disk you want (letter found with the previous command) d : Go to the system32 folder cd windows \\ system32","title":"Get Logical Volume inforations"},{"location":"windows/account/#utilman","text":"Use utilman despite off cmd.exe ren utilman . exe utilman . exe . bak ren cmd . exe utilman . exe Reboot wpeutil reboot","title":"Utilman"},{"location":"windows/account/#change-user-password","text":"After rebooting, clic on accessibility icon","title":"Change user password"},{"location":"windows/account/#change-password","text":"Change the user password Example : net user admin root net user $USER pass","title":"Change password"},{"location":"windows/account/#active-user","text":"Active user net user $USER / active : yes Reboot wpeutil reboot Replace utilman despite off cmd.exe ren utilman . exe cmd . exe ren utilman . exe . bak utilman . exe","title":"Active user"},{"location":"windows/apps/","text":"Apps Kill task How to force killing task ? taskkill / F / IM OpenWith . exe / T Google Chrome kiosk mode Ouvrir une page web avec Google Chrome dans une page d\u00e9tach\u00e9e: Chrome . exe - -app = http ://","title":"Apps"},{"location":"windows/apps/#apps","text":"","title":"Apps"},{"location":"windows/apps/#kill-task","text":"How to force killing task ? taskkill / F / IM OpenWith . exe / T","title":"Kill task"},{"location":"windows/apps/#google-chrome","text":"","title":"Google Chrome"},{"location":"windows/apps/#kiosk-mode","text":"Ouvrir une page web avec Google Chrome dans une page d\u00e9tach\u00e9e: Chrome . exe - -app = http ://","title":"kiosk mode"},{"location":"windows/kms/","text":"Key Management Services (KMS) KMS uses a client-server model to active Windows clients and is used for volume activation on your local network. KMS clients connect to a KMS server, called the KMS host, for activation. The KMS clients that a KMS host can activate are dependent on the host key used to activate the KMS host. This article walks you through the steps you need to create a KMS host. To learn more about KMS and the initial planning considerations, see Key Management Services (KMS) activation planning . Prerequisites A computer running Windows Server or Windows. A KMS host running on a Windows Server operating system can activate computers running both server and client operating systems, however a KMS host running on a Windows client operating system can only activate computers also running client operating systems. The user account you use must be a member of the Administrators group on the KMS host. A KMS host key for your organization. You can get this key from the Product Keys section of the Volume Licensing Service Center .","title":"Key Management Services (KMS)"},{"location":"windows/kms/#key-management-services-kms","text":"KMS uses a client-server model to active Windows clients and is used for volume activation on your local network. KMS clients connect to a KMS server, called the KMS host, for activation. The KMS clients that a KMS host can activate are dependent on the host key used to activate the KMS host. This article walks you through the steps you need to create a KMS host. To learn more about KMS and the initial planning considerations, see Key Management Services (KMS) activation planning .","title":"Key Management Services (KMS)"},{"location":"windows/kms/#prerequisites","text":"A computer running Windows Server or Windows. A KMS host running on a Windows Server operating system can activate computers running both server and client operating systems, however a KMS host running on a Windows client operating system can only activate computers also running client operating systems. The user account you use must be a member of the Administrators group on the KMS host. A KMS host key for your organization. You can get this key from the Product Keys section of the Volume Licensing Service Center .","title":"Prerequisites"},{"location":"windows/powershell/","text":"Powershell Complex or repetitive tasks often take a great deal of administrative time. Organizations prefer to automate these tasks to reduce costs and avoid errors. Automation is important in the Customer Relationship Management (CRM) company example. There, you're testing your software on multiple Linux Virtual Machines (VMs) that you need to continuously delete and recreate. You want to use a PowerShell script to automate the creation of the VMs versus creating them manually each time. Beyond the core operation of creating a VM, you have a few more requirements for your script: You'll create multiple VMs, so you want to put the creation inside a loop You need to create VMs in three different resource groups, so the name of the resource group should be passed to the script as a parameter In this section, you'll see how to write and execute an Azure PowerShell script that meets these requirements. What is a PowerShell script? A PowerShell script is a text file containing commands and control constructs. The commands are invocations of cmdlets. The control constructs are programming features like loops, variables, parameters, comments, etc., supplied by PowerShell. PowerShell script files have a .ps1 file extension. You can create and save these files with any text editor. Tip If you\u2019re writing PowerShell scripts under Windows, you can use the Windows PowerShell Integrated Scripting Environment (ISE). This editor provides features such as syntax coloring and a list of available cmdlets. The following screenshot shows the Windows PowerShell Integrated Scripting Environment (ISE) with a sample script to connect to Azure and create a virtual machine in Azure. Once you've written the script, execute it from the PowerShell command line by passing the name of the file preceded by a dot and a backslash: PowerShell .\\ myScript . ps1 Install Windows Update Install-Module -Name PSWindowsUpdate List all Commands Get-Command -module PSWindowsUpdate Get-WUInstall PowerShell techniques PowerShell has many features found in typical programming languages. You can define variables, use branches and loops, capture command-line parameters, write functions, add comments, and so on. We'll need three features for our script : variables loops parameters Variables In the last unit, you saw that PowerShell supports variables. Use $ to declare a variable and = to assign a value. For example : $loc = \"East US\" $iterations = 3 Variables can hold objects. For example, the following definition sets the adminCredential variable to the object returned by the Get-Credential cmdlet. $adminCredential = Get-Credential To obtain the value stored in a variable, use the $ prefix and its name, as in the following : $loc = \"East US\" $iterations = 3 Variables can hold objects. For example, the following definition sets the adminCredential variable to the object returned by the Get-Credential cmdlet. PowerShell $adminCredential = Get-Credential To obtain the value stored in a variable, use the $ prefix and its name, as in the following: PowerShell $loc = \"East US\" New-AzResourceGroup -Name \"MyResourceGroup\" -Location $loc Loops PowerShell has several loop structures, including For , Do...While , and For...Each . The For loop is the best match for our needs because we'll execute a cmdlet a fixed number of times. The following example shows the core syntax. The example runs for two iterations and prints the value of i each time. The comparison operators are written -lt for \"less than\", -le for \"less than or equal\", -eq for \"equal\", -ne for \"not equal\", etc. PowerShell For ( $i = 1 ; $i -lt 3 ; $i ++) { $i } Parameters When you execute a script, you can pass arguments on the command line. You can provide names for each parameter to help the script extract the values. For example: PowerShell .\\ setupEnvironment . ps1 -size 5 -location \"East US\" Inside the script, you'll capture the values into variables. In this example, the parameters are matched by name: PowerShell param ( [string] $location , [int] $size ) You can omit the names from the command line. For example: PowerShell .\\setupEnvironment.ps1 5 \"East US\" Inside the script, you'll rely on position for matching when the parameters are unnamed: PowerShell param([int]$size, [string]$location) We could take these parameters as input and use a loop to create a set of VMs from the given parameters. We'll try that next. The combination of PowerShell and Azure PowerShell gives you all the tools you need to automate Azure. In our CRM example, we'll be able to create multiple Linux VMs using a parameter to keep the script generic and a loop to avoid repeated code. This script allows us to execute a formerly complex operation in a single step.","title":"Powershell"},{"location":"windows/powershell/#powershell","text":"Complex or repetitive tasks often take a great deal of administrative time. Organizations prefer to automate these tasks to reduce costs and avoid errors. Automation is important in the Customer Relationship Management (CRM) company example. There, you're testing your software on multiple Linux Virtual Machines (VMs) that you need to continuously delete and recreate. You want to use a PowerShell script to automate the creation of the VMs versus creating them manually each time. Beyond the core operation of creating a VM, you have a few more requirements for your script: You'll create multiple VMs, so you want to put the creation inside a loop You need to create VMs in three different resource groups, so the name of the resource group should be passed to the script as a parameter In this section, you'll see how to write and execute an Azure PowerShell script that meets these requirements.","title":"Powershell"},{"location":"windows/powershell/#what-is-a-powershell-script","text":"A PowerShell script is a text file containing commands and control constructs. The commands are invocations of cmdlets. The control constructs are programming features like loops, variables, parameters, comments, etc., supplied by PowerShell. PowerShell script files have a .ps1 file extension. You can create and save these files with any text editor. Tip If you\u2019re writing PowerShell scripts under Windows, you can use the Windows PowerShell Integrated Scripting Environment (ISE). This editor provides features such as syntax coloring and a list of available cmdlets. The following screenshot shows the Windows PowerShell Integrated Scripting Environment (ISE) with a sample script to connect to Azure and create a virtual machine in Azure. Once you've written the script, execute it from the PowerShell command line by passing the name of the file preceded by a dot and a backslash: PowerShell .\\ myScript . ps1","title":"What is a PowerShell script?"},{"location":"windows/powershell/#install-windows-update","text":"Install-Module -Name PSWindowsUpdate","title":"Install Windows Update"},{"location":"windows/powershell/#list-all-commands","text":"Get-Command -module PSWindowsUpdate Get-WUInstall","title":"List all Commands"},{"location":"windows/powershell/#powershell-techniques","text":"PowerShell has many features found in typical programming languages. You can define variables, use branches and loops, capture command-line parameters, write functions, add comments, and so on. We'll need three features for our script : variables loops parameters","title":"PowerShell techniques"},{"location":"windows/powershell/#variables","text":"In the last unit, you saw that PowerShell supports variables. Use $ to declare a variable and = to assign a value. For example : $loc = \"East US\" $iterations = 3 Variables can hold objects. For example, the following definition sets the adminCredential variable to the object returned by the Get-Credential cmdlet. $adminCredential = Get-Credential To obtain the value stored in a variable, use the $ prefix and its name, as in the following : $loc = \"East US\" $iterations = 3 Variables can hold objects. For example, the following definition sets the adminCredential variable to the object returned by the Get-Credential cmdlet. PowerShell $adminCredential = Get-Credential To obtain the value stored in a variable, use the $ prefix and its name, as in the following: PowerShell $loc = \"East US\" New-AzResourceGroup -Name \"MyResourceGroup\" -Location $loc","title":"Variables"},{"location":"windows/powershell/#loops","text":"PowerShell has several loop structures, including For , Do...While , and For...Each . The For loop is the best match for our needs because we'll execute a cmdlet a fixed number of times. The following example shows the core syntax. The example runs for two iterations and prints the value of i each time. The comparison operators are written -lt for \"less than\", -le for \"less than or equal\", -eq for \"equal\", -ne for \"not equal\", etc. PowerShell For ( $i = 1 ; $i -lt 3 ; $i ++) { $i }","title":"Loops"},{"location":"windows/powershell/#parameters","text":"When you execute a script, you can pass arguments on the command line. You can provide names for each parameter to help the script extract the values. For example: PowerShell .\\ setupEnvironment . ps1 -size 5 -location \"East US\" Inside the script, you'll capture the values into variables. In this example, the parameters are matched by name: PowerShell param ( [string] $location , [int] $size ) You can omit the names from the command line. For example: PowerShell .\\setupEnvironment.ps1 5 \"East US\" Inside the script, you'll rely on position for matching when the parameters are unnamed: PowerShell param([int]$size, [string]$location) We could take these parameters as input and use a loop to create a set of VMs from the given parameters. We'll try that next. The combination of PowerShell and Azure PowerShell gives you all the tools you need to automate Azure. In our CRM example, we'll be able to create multiple Linux VMs using a parameter to keep the script generic and a loop to avoid repeated code. This script allows us to execute a formerly complex operation in a single step.","title":"Parameters"},{"location":"windows/readme/","text":"README Windows is a group of several proprietary graphical operating system families developed and marketed by Microsoft . Each family caters to a certain sector of the computing industry. For example, Windows NT for consumers, Windows Server for servers, and Windows IoT for embedded systems. Defunct Windows families include Windows 9x, Windows Mobile, and Windows Phone.","title":"README"},{"location":"windows/readme/#readme","text":"Windows is a group of several proprietary graphical operating system families developed and marketed by Microsoft . Each family caters to a certain sector of the computing industry. For example, Windows NT for consumers, Windows Server for servers, and Windows IoT for embedded systems. Defunct Windows families include Windows 9x, Windows Mobile, and Windows Phone.","title":"README"},{"location":"windows/storage/","text":"Storage How to change device drive icon ? Open regedit as administrator : Go to Ordinateur\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\DriveIcons Create a new key as the correspond lettre of your drive. Create a new sub key as Defaulticon : Ordinateur \\ HKEY_LOCAL_MACHINE \\ SOFTWARE \\ Microsoft \\ Windows \\ CurrentVersion \\ Explorer \\ DriveIcons \\ D \\ Defaulticon Mod the chaine containned in Defaulticon key with the full path of your ico file.","title":"Storage"},{"location":"windows/storage/#storage","text":"","title":"Storage"},{"location":"windows/storage/#how-to-change-device-drive-icon","text":"Open regedit as administrator : Go to Ordinateur\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\DriveIcons Create a new key as the correspond lettre of your drive. Create a new sub key as Defaulticon : Ordinateur \\ HKEY_LOCAL_MACHINE \\ SOFTWARE \\ Microsoft \\ Windows \\ CurrentVersion \\ Explorer \\ DriveIcons \\ D \\ Defaulticon Mod the chaine containned in Defaulticon key with the full path of your ico file.","title":"How to change device drive icon ?"},{"location":"windows/terminal/","text":"Windows Terminal Install Windows Terminal Windows Store: Windows Terminal Keyboard Shortcuts Applic\u00adation commands ALT - F4: Close window CTRL - S\u00adHIFT - F: Find CTRL - S\u00adHIF\u00adT - SPACE: Open dropdown CTRL - ,: Open settings file ALT - ENTER - F11: Toggle full screen Tab commands CTRL - S\u00adHIFT - D: Duplicate tab CTRL - S\u00adHIFT - T: New tab CTRL - S\u00adHIFT - P: New tab from profile p=1..9 CTRL - TAB: Switch to next tab CTRL - S\u00adHIF\u00adT - TAB: Switch to prev tab CTRL - ALT - N: Switch to tab n=0..9 Pane commands ALT - SH\u00adIFT - D: Split pane optimally. Active profile ALT - SH\u00adIFT - -: Split pane horizontally. Default profile ALT - SH\u00adIFT - +: Split pane vertically. Default profile ALT - SHIFT - ARROWS: Resize pane ALT - ARROWS: Move pane focus CTRL - S\u00adHIFT - W: Close innermost pane, tab, or window Clipboard commands CTRL - C: Copy CTRL - V: Paste Scrollback commands CTRL - S\u00adHIFT - UP: Scroll up CTRL - S\u00adHIF\u00adT - DOWN: Scroll down CTRL - S\u00adHIF\u00adT - PGUP: Scroll page up CTRL - S\u00adHIF\u00adT - PGDN: Scroll page down Visual adjustment commands CTRL - =: Increase font size CTRL - -: Decrease font size CTRL - 0: Reset font size","title":"Windows Terminal"},{"location":"windows/terminal/#windows-terminal","text":"","title":"Windows Terminal"},{"location":"windows/terminal/#install-windows-terminal","text":"Windows Store: Windows Terminal","title":"Install Windows Terminal"},{"location":"windows/terminal/#keyboard-shortcuts","text":"Applic\u00adation commands ALT - F4: Close window CTRL - S\u00adHIFT - F: Find CTRL - S\u00adHIF\u00adT - SPACE: Open dropdown CTRL - ,: Open settings file ALT - ENTER - F11: Toggle full screen Tab commands CTRL - S\u00adHIFT - D: Duplicate tab CTRL - S\u00adHIFT - T: New tab CTRL - S\u00adHIFT - P: New tab from profile p=1..9 CTRL - TAB: Switch to next tab CTRL - S\u00adHIF\u00adT - TAB: Switch to prev tab CTRL - ALT - N: Switch to tab n=0..9 Pane commands ALT - SH\u00adIFT - D: Split pane optimally. Active profile ALT - SH\u00adIFT - -: Split pane horizontally. Default profile ALT - SH\u00adIFT - +: Split pane vertically. Default profile ALT - SHIFT - ARROWS: Resize pane ALT - ARROWS: Move pane focus CTRL - S\u00adHIFT - W: Close innermost pane, tab, or window Clipboard commands CTRL - C: Copy CTRL - V: Paste Scrollback commands CTRL - S\u00adHIFT - UP: Scroll up CTRL - S\u00adHIF\u00adT - DOWN: Scroll down CTRL - S\u00adHIF\u00adT - PGUP: Scroll page up CTRL - S\u00adHIF\u00adT - PGDN: Scroll page down Visual adjustment commands CTRL - =: Increase font size CTRL - -: Decrease font size CTRL - 0: Reset font size","title":"Keyboard Shortcuts"},{"location":"windows/vars-env/","text":"Environment Variables in Windows How to use them in PowerShell Environment Varaibles can be used in PowerShell ([[powershell]]) with the prefix $env: . Example Variable: %APPDATA% In Powershell: $env:APPDATA List of environment variables Variable Description %ALLUSERSPROFILE% C:\\ProgramData %APPDATA% C:\\Users{username}\\AppData\\Roaming %COMMONPROGRAMFILES% C:\\Program Files\\Common Files %COMMONPROGRAMFILES(x86)% C:\\Program Files (x86)\\Common Files %CommonProgramW6432% C:\\Program Files\\Common Files %COMSPEC% C:\\Windows\\System32\\cmd.exe %HOMEDRIVE% C:\\ %HOMEPATH% C:\\Users{username} %LOCALAPPDATA% C:\\Users{username}\\AppData\\Local %LOGONSERVER% \\{domain_logon_server} %PATH% C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem %PathExt% .com;.exe;.bat;.cmd;.vbs;.vbe;.js;.jse;.wsf;.wsh;.msc %PROGRAMDATA% C:\\ProgramData %PROGRAMFILES% C:\\Program Files %ProgramW6432% C:\\Program Files %PROGRAMFILES(X86)% C:\\Program Files (x86) %PROMPT% $P$G %SystemDrive% C: %SystemRoot% C:\\Windows %TEMP% C:\\Users{username}\\AppData\\Local\\Temp %TMP% C:\\Users{username}\\AppData\\Local\\Temp %USERDOMAIN% Userdomain associated with current user. %USERDOMAIN_ROAMINGPROFILE% Userdomain associated with roaming profile. %USERNAME% {username} %USERPROFILE% C:\\Users{username} %WINDIR% C:\\Windows %PUBLIC% C:\\Users\\Public %PSModulePath% %SystemRoot%\\system32\\WindowsPowerShell\\v1.0\\Modules\\ %OneDrive% C:\\Users{username}\\OneDrive %DriverData% C:\\Windows\\System32\\Drivers\\DriverData %CD% Outputs current directory path. (Command Prompt.) %CMDCMDLINE% Outputs command line used to launch current Command Prompt session. (Command Prompt.) %CMDEXTVERSION% Outputs the number of current command processor extensions. (Command Prompt.) %COMPUTERNAME% Outputs the system name. %DATE% Outputs current date. (Command Prompt.) %TIME% Outputs time. (Command Prompt.) %ERRORLEVEL% Outputs the number of defining exit status of previous command. (Command Prompt.) %PROCESSOR_IDENTIFIER% Outputs processor identifier. %PROCESSOR_LEVEL% Outputs processor level. %PROCESSOR_REVISION% Outputs processor revision. %NUMBER_OF_PROCESSORS% Outputs the number of physical and virtual cores. %RANDOM% Outputs random number from 0 through 32767. %OS% Windows_NT","title":"Environment Variables in Windows"},{"location":"windows/vars-env/#environment-variables-in-windows","text":"","title":"Environment Variables in Windows"},{"location":"windows/vars-env/#how-to-use-them-in-powershell","text":"Environment Varaibles can be used in PowerShell ([[powershell]]) with the prefix $env: .","title":"How to use them in PowerShell"},{"location":"windows/vars-env/#example","text":"Variable: %APPDATA% In Powershell: $env:APPDATA","title":"Example"},{"location":"windows/vars-env/#list-of-environment-variables","text":"Variable Description %ALLUSERSPROFILE% C:\\ProgramData %APPDATA% C:\\Users{username}\\AppData\\Roaming %COMMONPROGRAMFILES% C:\\Program Files\\Common Files %COMMONPROGRAMFILES(x86)% C:\\Program Files (x86)\\Common Files %CommonProgramW6432% C:\\Program Files\\Common Files %COMSPEC% C:\\Windows\\System32\\cmd.exe %HOMEDRIVE% C:\\ %HOMEPATH% C:\\Users{username} %LOCALAPPDATA% C:\\Users{username}\\AppData\\Local %LOGONSERVER% \\{domain_logon_server} %PATH% C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem %PathExt% .com;.exe;.bat;.cmd;.vbs;.vbe;.js;.jse;.wsf;.wsh;.msc %PROGRAMDATA% C:\\ProgramData %PROGRAMFILES% C:\\Program Files %ProgramW6432% C:\\Program Files %PROGRAMFILES(X86)% C:\\Program Files (x86) %PROMPT% $P$G %SystemDrive% C: %SystemRoot% C:\\Windows %TEMP% C:\\Users{username}\\AppData\\Local\\Temp %TMP% C:\\Users{username}\\AppData\\Local\\Temp %USERDOMAIN% Userdomain associated with current user. %USERDOMAIN_ROAMINGPROFILE% Userdomain associated with roaming profile. %USERNAME% {username} %USERPROFILE% C:\\Users{username} %WINDIR% C:\\Windows %PUBLIC% C:\\Users\\Public %PSModulePath% %SystemRoot%\\system32\\WindowsPowerShell\\v1.0\\Modules\\ %OneDrive% C:\\Users{username}\\OneDrive %DriverData% C:\\Windows\\System32\\Drivers\\DriverData %CD% Outputs current directory path. (Command Prompt.) %CMDCMDLINE% Outputs command line used to launch current Command Prompt session. (Command Prompt.) %CMDEXTVERSION% Outputs the number of current command processor extensions. (Command Prompt.) %COMPUTERNAME% Outputs the system name. %DATE% Outputs current date. (Command Prompt.) %TIME% Outputs time. (Command Prompt.) %ERRORLEVEL% Outputs the number of defining exit status of previous command. (Command Prompt.) %PROCESSOR_IDENTIFIER% Outputs processor identifier. %PROCESSOR_LEVEL% Outputs processor level. %PROCESSOR_REVISION% Outputs processor revision. %NUMBER_OF_PROCESSORS% Outputs the number of physical and virtual cores. %RANDOM% Outputs random number from 0 through 32767. %OS% Windows_NT","title":"List of environment variables"},{"location":"windows/windows-boot/","text":"Windows Boot How to restore Windows 10 MBR La d\u00e9marche consiste \u00e0 remplacer le MBR qui permet d'amorcer GRUB en lui substituant un MBR pointant sur le lanceur de Windows. Le remplacement du MBR est r\u00e9alis\u00e9 \u00e0 partir du disque de restauration Windows ou du CD d'installation. Booter depuis le CD d'installation et choisir \"R\u00e9parer ou r\u00e9cup\u00e9rer une installation de Windows\". On s\u00e9lectionnera ensuite l'installation de Windows dans la liste des choix propos\u00e9s et on saisira le mot de passe administrateur. Au prompt, taper : C :\\ WINDOWS > fixboot C :\\ WINDOWS > fixmbr La surface disque utilis\u00e9e par Fedora n'est pas automatiquement r\u00e9-allou\u00e9e . C'est l'affaire de fdsik. La r\u00e9allocation consiste en un nouveau formatage, sous le format vfat ou ntfs ou autre, selon le choix - si l'on souhaite r\u00e9-allouer les partitions au profit de Windows. On pourra ainsi modifier le format de tout ou partie des partitions et notamment les fusionner. fdisk existe dans l'environnement Windows (ou un programme \u00e9quivalent). On red\u00e9marrera par la commande : C :\\ WINDOWS > exit Restauration Grub Si les partitions Linux n'ont pas \u00e9t\u00e9 r\u00e9-allou\u00e9es, il est toujours possible de restaurer GRUB (et ainsi le boot sur Fedora ou Windows)","title":"Windows Boot"},{"location":"windows/windows-boot/#windows-boot","text":"","title":"Windows Boot"},{"location":"windows/windows-boot/#how-to-restore-windows-10-mbr","text":"La d\u00e9marche consiste \u00e0 remplacer le MBR qui permet d'amorcer GRUB en lui substituant un MBR pointant sur le lanceur de Windows. Le remplacement du MBR est r\u00e9alis\u00e9 \u00e0 partir du disque de restauration Windows ou du CD d'installation. Booter depuis le CD d'installation et choisir \"R\u00e9parer ou r\u00e9cup\u00e9rer une installation de Windows\". On s\u00e9lectionnera ensuite l'installation de Windows dans la liste des choix propos\u00e9s et on saisira le mot de passe administrateur. Au prompt, taper : C :\\ WINDOWS > fixboot C :\\ WINDOWS > fixmbr La surface disque utilis\u00e9e par Fedora n'est pas automatiquement r\u00e9-allou\u00e9e . C'est l'affaire de fdsik. La r\u00e9allocation consiste en un nouveau formatage, sous le format vfat ou ntfs ou autre, selon le choix - si l'on souhaite r\u00e9-allouer les partitions au profit de Windows. On pourra ainsi modifier le format de tout ou partie des partitions et notamment les fusionner. fdisk existe dans l'environnement Windows (ou un programme \u00e9quivalent). On red\u00e9marrera par la commande : C :\\ WINDOWS > exit Restauration Grub Si les partitions Linux n'ont pas \u00e9t\u00e9 r\u00e9-allou\u00e9es, il est toujours possible de restaurer GRUB (et ainsi le boot sur Fedora ou Windows)","title":"How to restore Windows 10 MBR"},{"location":"windows/windows-system/","text":"System Trouver la date d\u2019installation Windows. systeminfo | find \"installation\" Se rendre rapidement sur la page de gestion des software: \u00c9x\u00e9cuter la commande suivante (dans invite de commande ou executer ou menu d\u00e9marr\u00e9) Appwiz . cpl Hosts file Hosts file configuration location : C :\\ windows \\ system32 \\ drivers \\ etc \\ License Temps restant disponible \u00e0 la license en cours DISM / online / Get-CurrentEdition DISM / online / Get-TargetEditions slmgr . vbs / ipk LICENCE #\"Force\" || Dism /Online /Set-Edition:ServerDatacenter /AcceptEula /ProductKey:LICENCE slmgr . vbs / dlv #Check","title":"System"},{"location":"windows/windows-system/#system","text":"Trouver la date d\u2019installation Windows. systeminfo | find \"installation\" Se rendre rapidement sur la page de gestion des software: \u00c9x\u00e9cuter la commande suivante (dans invite de commande ou executer ou menu d\u00e9marr\u00e9) Appwiz . cpl","title":"System"},{"location":"windows/windows-system/#hosts-file","text":"Hosts file configuration location : C :\\ windows \\ system32 \\ drivers \\ etc \\","title":"Hosts file"},{"location":"windows/windows-system/#license","text":"Temps restant disponible \u00e0 la license en cours DISM / online / Get-CurrentEdition DISM / online / Get-TargetEditions slmgr . vbs / ipk LICENCE #\"Force\" || Dism /Online /Set-Edition:ServerDatacenter /AcceptEula /ProductKey:LICENCE slmgr . vbs / dlv #Check","title":"License"},{"location":"windows/wsl/","text":"WSL Backup and Restore WSL Listing Running Distros wsl - -list - -verbose Starting/Restarting a Distro wsl - -distribution DISTRO-NAME Terminate a Running Distro wsl - -t DISTRO-NAME Terminate All Running Distros and WSL process wsl - -shutdown Backup a WSL Distro wsl - -export ( distribution ) ( filename . tar ) Restore a WSL Distro from Backup wsl - -import ( distribution ) ( install location ) ( file location and filename ) Symbolic Links Link .ssh folder sudo ln -s /mnt/c/Users/lempa/.ssh ~/.ssh Link .kube folder sudo ln -s /mnt/c/Users/lempa/.ssh ~/.ssh File Permissions Advanced settings configuration in WSL: WSL Config Parameters Example wsl.conf [automount] enabled = true options = \"metadata,uid=1000,gid=1000,umask=077,fmask=11,case=off\" mountFsTab = true [interop] enabled = false appendWindowsPath = false Networking Port Forwarding Find IP Address bash . exe -c \"ifconfig eth0 | grep 'inet '\" Add PortForwarding $port = 8080 $remoteaddr = 0 . 0 . 0 . 0 netsh interface portproxy add v4tov4 listenport = $port connectport = $port connectaddress = $remoteaddr netsh advfirewall firewall add rule name = $port dir = in action = allow protocol = TCP localport = $port Delete PortForwarding $port = 8080 netsh interface portproxy delete v4tov4 listenport = $port netsh advfirewall firewall delete rule name = $port Show PortForwardings netsh interface portproxy show v4tov4 Linux desktop in WSL2 With WSL2 it's possible to install and run a Linux desktop environment (XFCE). A tutorial on how to implement that, can be found here .","title":"WSL"},{"location":"windows/wsl/#wsl","text":"","title":"WSL"},{"location":"windows/wsl/#backup-and-restore-wsl","text":"","title":"Backup and Restore WSL"},{"location":"windows/wsl/#listing-running-distros","text":"wsl - -list - -verbose","title":"Listing Running Distros"},{"location":"windows/wsl/#startingrestarting-a-distro","text":"wsl - -distribution DISTRO-NAME","title":"Starting/Restarting a Distro"},{"location":"windows/wsl/#terminate-a-running-distro","text":"wsl - -t DISTRO-NAME","title":"Terminate a Running Distro"},{"location":"windows/wsl/#terminate-all-running-distros-and-wsl-process","text":"wsl - -shutdown","title":"Terminate All Running Distros and WSL process"},{"location":"windows/wsl/#backup-a-wsl-distro","text":"wsl - -export ( distribution ) ( filename . tar )","title":"Backup a WSL Distro"},{"location":"windows/wsl/#restore-a-wsl-distro-from-backup","text":"wsl - -import ( distribution ) ( install location ) ( file location and filename )","title":"Restore a WSL Distro from Backup"},{"location":"windows/wsl/#symbolic-links","text":"","title":"Symbolic Links"},{"location":"windows/wsl/#link-ssh-folder","text":"sudo ln -s /mnt/c/Users/lempa/.ssh ~/.ssh","title":"Link .ssh folder"},{"location":"windows/wsl/#link-kube-folder","text":"sudo ln -s /mnt/c/Users/lempa/.ssh ~/.ssh","title":"Link .kube folder"},{"location":"windows/wsl/#file-permissions","text":"Advanced settings configuration in WSL: WSL Config Parameters Example wsl.conf [automount] enabled = true options = \"metadata,uid=1000,gid=1000,umask=077,fmask=11,case=off\" mountFsTab = true [interop] enabled = false appendWindowsPath = false","title":"File Permissions"},{"location":"windows/wsl/#networking","text":"","title":"Networking"},{"location":"windows/wsl/#port-forwarding","text":"Find IP Address bash . exe -c \"ifconfig eth0 | grep 'inet '\" Add PortForwarding $port = 8080 $remoteaddr = 0 . 0 . 0 . 0 netsh interface portproxy add v4tov4 listenport = $port connectport = $port connectaddress = $remoteaddr netsh advfirewall firewall add rule name = $port dir = in action = allow protocol = TCP localport = $port Delete PortForwarding $port = 8080 netsh interface portproxy delete v4tov4 listenport = $port netsh advfirewall firewall delete rule name = $port Show PortForwardings netsh interface portproxy show v4tov4","title":"Port Forwarding"},{"location":"windows/wsl/#linux-desktop-in-wsl2","text":"With WSL2 it's possible to install and run a Linux desktop environment (XFCE). A tutorial on how to implement that, can be found here .","title":"Linux desktop in WSL2"}]}